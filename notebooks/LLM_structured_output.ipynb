{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using structured JSON output feature from OpenAI\n",
    "Sources: \n",
    "- OpenAI web page for JSON formatting rules to use 'strict' mode: https://platform.openai.com/docs/guides/structured-outputs\n",
    "- A Python Package for high-level usage of LLM structured output: https://github.com/dottxt-ai/outlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip uninstall -y sympy pysb torch outlines\n",
    "# !pip install pysb sympy==1.11.1\n",
    "# !pip install torch sympy==1.13.1 --no-deps\n",
    "# !pip install outlines --no-deps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import os\n",
    "# get current path\n",
    "sys.path.append(str(Path.cwd().parent))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Providing the JSON schema directly as the response format\n",
    "- I.e. Provide the indra JSON schema to the `response_format` parameter of `OpenAI.beta.chat.completions.parse` function of OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OpenAI enforces a subset of the 'JSON Schema' language. The below is a list of non-exhaustive rules that is enforced:\n",
    "1. root JSON object is 'object' type\n",
    "2. 'required' includes all and only the fields in 'property' \n",
    "    - This ensures LLM doesn't generate any key-val pair in 'property' that is not defined in the schema.\n",
    "    - To make a defined field in 'property' optional, we can add \"null\" as an optional type of that field. \n",
    "3. 'additionalProperties' field is set to false and is included for every 'object' type.\n",
    "4. Each sub-schema in 'anyOf', namely \"#/definitions/RegulateActivity\", \"#/definitions/Modification\", \"#/definitions/SelfModification\", etc. has a different first key\n",
    "   in their 'property' field. <br>\n",
    "   This is achievable by adding a new field with a unique constant value. E.g. \"#/definitions/RegulateActivity\" has \n",
    "   ```\n",
    "   \"kind\": {\n",
    "                \"type\": \"string\",\n",
    "                \"const\": \"RegulateActivity\"\n",
    "            }\n",
    "    ```\n",
    "    And \"#/definitions/Modification\" has\n",
    "    ```\n",
    "    \"kind\": {\n",
    "                \"type\": \"string\",\n",
    "                \"const\": \"Modification\"\n",
    "            }\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The below schema follows all the rules for OpenAI 'strict' mode, except for one. It contains the 'allOf' syntax, which OpenAI doesn't currently support.\n",
    "- We can resolve 'allOf' syntax by merging the items and removing the 'allOf' syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from indra.statements.io import stmts_from_json\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from indra_gpt.util.util import merge_allOf\n",
    "\n",
    "# Load the JSON schema\n",
    "schema_path = \"/Users/thomaslim/gyorilab/indra_gpt/indra_gpt/resources/indra_schema_openai_structured_output.json\"\n",
    "with open(schema_path, \"r\") as f:\n",
    "    schema = json.load(f)\n",
    "\n",
    "post_processed_schema = merge_allOf(schema, schema)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample Prompt\n",
    "prompt = \"We found that 24 hours of BMP pretreatment caused a doubling in PTEN half-life (15.1 hours to 28.4 hours, p = 0.03, n = 4).\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use `outlines` package to use OpenAI's 'structured outputs' feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import outlines\n",
    "\n",
    "# Use OpenAI API instead of local model\n",
    "model = outlines.models.openai(\"gpt-4o\")  # Or \"gpt-4-turbo\" for cheaper API cost\n",
    "# Define generators\n",
    "generator = outlines.generate.json(model, json.dumps(post_processed_schema))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: [2025-02-25 15:25:22] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "result = generator(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"statements\": [\n",
      "    {\n",
      "      \"kind\": \"RegulateAmount\",\n",
      "      \"type\": \"IncreaseAmount\",\n",
      "      \"subj\": {\n",
      "        \"name\": \"BMP\",\n",
      "        \"mods\": null,\n",
      "        \"mutations\": null,\n",
      "        \"bound_conditions\": null,\n",
      "        \"activity\": null,\n",
      "        \"location\": null,\n",
      "        \"db_refs\": {\n",
      "          \"HGNC\": null,\n",
      "          \"UP\": null,\n",
      "          \"FPLX\": null,\n",
      "          \"CHEBI\": null,\n",
      "          \"GO\": null,\n",
      "          \"TEXT\": \"Bone Morphogenetic Protein\",\n",
      "          \"NCIT\": null\n",
      "        },\n",
      "        \"sbo\": null\n",
      "      },\n",
      "      \"obj\": {\n",
      "        \"name\": \"PTEN\",\n",
      "        \"mods\": null,\n",
      "        \"mutations\": null,\n",
      "        \"bound_conditions\": null,\n",
      "        \"activity\": null,\n",
      "        \"location\": null,\n",
      "        \"db_refs\": {\n",
      "          \"HGNC\": \"9588\",\n",
      "          \"UP\": \"P60484\",\n",
      "          \"FPLX\": null,\n",
      "          \"CHEBI\": null,\n",
      "          \"GO\": null,\n",
      "          \"TEXT\": \"Phosphatase and Tensin Homolog\",\n",
      "          \"NCIT\": \"C17312\"\n",
      "        },\n",
      "        \"sbo\": null\n",
      "      },\n",
      "      \"evidence\": [\n",
      "        {\n",
      "          \"text\": \"We found that 24 hours of BMP pretreatment caused a doubling in PTEN half-life (15.1 hours to 28.4 hours, p = 0.03, n = 4).\",\n",
      "          \"source_api\": null,\n",
      "          \"pmid\": null,\n",
      "          \"source_id\": null,\n",
      "          \"annotations\": null,\n",
      "          \"epistemics\": null\n",
      "        }\n",
      "      ],\n",
      "      \"id\": null,\n",
      "      \"supports\": null,\n",
      "      \"supported_by\": null\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(result, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: [2025-02-24 09:24:55] indra.preassembler.grounding_mapper.disambiguate - INDRA DB is not available for text content retrieval for grounding disambiguation.\n"
     ]
    }
   ],
   "source": [
    "from indra_gpt.post_process.post_processor import PostProcessor\n",
    "\n",
    "pp = PostProcessor()\n",
    "post_processed_statement_json = pp.post_process_extracted_statement_json(result)\n",
    "post_processed_statement_json = post_processed_statement_json['statements']\n",
    "from indra.statements import stmts_from_json\n",
    "\n",
    "statements = stmts_from_json(post_processed_statement_json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[IncreaseAmount(BMP(), PTEN())]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'output': {'statements': [{'kind': 'RegulateAmount', 'type': 'IncreaseAmount', 'subj': {'name': 'BMP', 'mods': None, 'mutations': None, 'bound_conditions': None, 'activity': None, 'location': None, 'db_refs': {'HGNC': None, 'UP': None, 'FPLX': None, 'CHEBI': None, 'GO': None, 'TEXT': 'BMP', 'NCIT': None}, 'sbo': None}, 'obj': {'name': 'PTEN', 'mods': None, 'mutations': None, 'bound_conditions': None, 'activity': None, 'location': None, 'db_refs': {'HGNC': 'HGNC:9588', 'UP': 'P60484', 'FPLX': 'PTEN', 'CHEBI': None, 'GO': None, 'TEXT': 'PTEN', 'NCIT': None}, 'sbo': None}, 'evidence': [{'text': '24 hours of BMP pretreatment caused a doubling in PTEN half-life (15.1 hours to 28.4 hours, p = 0.03, n = 4).', 'source_api': 'experimental', 'pmid': None, 'source_id': None, 'annotations': None, 'epistemics': None}], 'id': None, 'supports': None, 'supported_by': None}]}}\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import json\n",
    "\n",
    "# Define the SageMaker runtime client\n",
    "sm_runtime = boto3.client(\"sagemaker-runtime\", region_name=\"us-east-2\")\n",
    "\n",
    "endpoint_name = \"outlines-serverless-ep-2025-02-25-19-44-15\"\n",
    "\n",
    "# Example JSON payload\n",
    "payload = {\n",
    "    \"json_schema\": post_processed_schema,\n",
    "    \"prompt\": prompt\n",
    "}\n",
    "\n",
    "# Invoke the endpoint\n",
    "response = sm_runtime.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    ContentType=\"application/json\",\n",
    "    Body=json.dumps(payload)\n",
    ")\n",
    "\n",
    "# Parse the response\n",
    "result = json.loads(response[\"Body\"].read().decode(\"utf-8\"))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Directly using OpenAI API call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_format={\n",
    "        \"type\": \"json_schema\", \n",
    "        \"json_schema\": {\n",
    "            \"name\": \"indra_statement_json\",\n",
    "            \"strict\": True, \n",
    "            \"schema\": post_processed_schema\n",
    "        }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: [2025-02-11 18:29:28] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "completion = client.beta.chat.completions.parse(\n",
    "    model=\"gpt-4o-2024-08-06\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Extract the event information.\"},\n",
    "        {\"role\": \"user\", \"content\": \"We found that 24 hours of BMP pretreatment caused a doubling in PTEN half-life (15.1 hours to 28.4 hours, p = 0.03, n = 4).\"},\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"statements\":[{\"kind\":\"RegulateAmount\",\"type\":\"IncreaseAmount\",\"subj\":{\"name\":\"BMP\",\"mods\":null,\"mutations\":null,\"bound_conditions\":null,\"activity\":null,\"location\":null,\"db_refs\":null,\"sbo\":null},\"obj\":{\"name\":\"PTEN\",\"mods\":null,\"mutations\":null,\"bound_conditions\":null,\"activity\":null,\"location\":null,\"db_refs\":null,\"sbo\":null},\"evidence\":[{\"text\":\"We found that 24 hours of BMP pretreatment caused a doubling in PTEN half-life (15.1 hours to 28.4 hours, p = 0.03, n = 4).\",\"source_api\":null,\"pmid\":null,\"source_id\":null,\"annotations\":null,\"epistemics\":null}],\"id\":null,\"supports\":null,\"supported_by\":null}]}'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"statements\": [\n",
      "        {\n",
      "            \"kind\": \"RegulateAmount\",\n",
      "            \"type\": \"IncreaseAmount\",\n",
      "            \"subj\": {\n",
      "                \"name\": \"BMP\",\n",
      "                \"mods\": null,\n",
      "                \"mutations\": null,\n",
      "                \"bound_conditions\": null,\n",
      "                \"activity\": null,\n",
      "                \"location\": null,\n",
      "                \"db_refs\": null,\n",
      "                \"sbo\": null\n",
      "            },\n",
      "            \"obj\": {\n",
      "                \"name\": \"PTEN\",\n",
      "                \"mods\": null,\n",
      "                \"mutations\": null,\n",
      "                \"bound_conditions\": null,\n",
      "                \"activity\": null,\n",
      "                \"location\": null,\n",
      "                \"db_refs\": null,\n",
      "                \"sbo\": null\n",
      "            },\n",
      "            \"evidence\": [\n",
      "                {\n",
      "                    \"text\": \"We found that 24 hours of BMP pretreatment caused a doubling in PTEN half-life (15.1 hours to 28.4 hours, p = 0.03, n = 4).\",\n",
      "                    \"source_api\": null,\n",
      "                    \"pmid\": null,\n",
      "                    \"source_id\": null,\n",
      "                    \"annotations\": null,\n",
      "                    \"epistemics\": null\n",
      "                }\n",
      "            ],\n",
      "            \"id\": null,\n",
      "            \"supports\": null,\n",
      "            \"supported_by\": null\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(result, indent=4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply to benchmark corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "indra_benchmark_corpus_sample_50 = json.load(open(\"/Users/thomaslim/gyorilab/indra_gpt/indra_gpt/resources/indra_benchmark_corpus_sample_50.json\", \"r\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming indra_benchmark_corpus_all_correct is a list of JSON objects\n",
    "data = [\n",
    "    {\n",
    "        'text': obj['evidence'][0]['text'] if 'evidence' in obj and obj['evidence'] else None,\n",
    "        'original_json_statement': obj\n",
    "    }\n",
    "    for obj in indra_benchmark_corpus_sample_50\n",
    "]\n",
    "\n",
    "# Convert list to DataFrame\n",
    "df = pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now use the indra.statements.io.stmt_from_json to convert the extracted_statement_json to a list of INDRA statements\n",
    "for i, row in df.iterrows():\n",
    "    try:\n",
    "        indra_statement_from_original = stmts_from_json([row.original_json_statement], on_missing_support='handle')\n",
    "        df.at[i, 'indra_statements_from_original'] = indra_statement_from_original\n",
    "    except Exception as e:\n",
    "        df.at[i, 'indra_statements_from_original'] = str(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: [2025-02-11 11:25:07] openai._base_client - Retrying request to /chat/completions in 0.414386 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: [2025-02-11 11:25:31] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: [2025-02-11 11:25:31] openai._base_client - Retrying request to /chat/completions in 0.464199 seconds\n",
      "INFO: [2025-02-11 11:25:38] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: [2025-02-11 11:25:38] openai._base_client - Retrying request to /chat/completions in 0.395519 seconds\n",
      "INFO: [2025-02-11 11:25:53] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: [2025-02-11 11:25:53] openai._base_client - Retrying request to /chat/completions in 0.396036 seconds\n",
      "INFO: [2025-02-11 11:26:17] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: [2025-02-11 11:26:17] openai._base_client - Retrying request to /chat/completions in 0.412226 seconds\n",
      "INFO: [2025-02-11 11:26:46] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: [2025-02-11 11:26:46] openai._base_client - Retrying request to /chat/completions in 0.475213 seconds\n",
      "INFO: [2025-02-11 11:27:16] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: [2025-02-11 11:27:16] openai._base_client - Retrying request to /chat/completions in 0.414239 seconds\n",
      "INFO: [2025-02-11 11:27:28] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: [2025-02-11 11:27:28] openai._base_client - Retrying request to /chat/completions in 0.420389 seconds\n",
      "INFO: [2025-02-11 11:27:37] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: [2025-02-11 11:27:37] openai._base_client - Retrying request to /chat/completions in 0.432746 seconds\n",
      "INFO: [2025-02-11 11:27:50] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: [2025-02-11 11:27:50] openai._base_client - Retrying request to /chat/completions in 0.477403 seconds\n",
      "INFO: [2025-02-11 11:27:55] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: [2025-02-11 11:27:55] openai._base_client - Retrying request to /chat/completions in 0.378140 seconds\n",
      "INFO: [2025-02-11 11:28:02] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: [2025-02-11 11:28:02] openai._base_client - Retrying request to /chat/completions in 0.491952 seconds\n",
      "INFO: [2025-02-11 11:28:12] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: [2025-02-11 11:28:12] openai._base_client - Retrying request to /chat/completions in 0.473731 seconds\n",
      "INFO: [2025-02-11 11:28:20] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: [2025-02-11 11:28:20] openai._base_client - Retrying request to /chat/completions in 0.420897 seconds\n",
      "INFO: [2025-02-11 11:28:28] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: [2025-02-11 11:28:28] openai._base_client - Retrying request to /chat/completions in 0.489453 seconds\n",
      "INFO: [2025-02-11 11:28:52] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: [2025-02-11 11:28:52] openai._base_client - Retrying request to /chat/completions in 0.469331 seconds\n",
      "INFO: [2025-02-11 11:29:04] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: [2025-02-11 11:29:04] openai._base_client - Retrying request to /chat/completions in 0.438618 seconds\n",
      "INFO: [2025-02-11 11:29:18] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: [2025-02-11 11:29:18] openai._base_client - Retrying request to /chat/completions in 0.451753 seconds\n",
      "INFO: [2025-02-11 11:29:34] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: [2025-02-11 11:29:34] openai._base_client - Retrying request to /chat/completions in 0.476815 seconds\n",
      "INFO: [2025-02-11 11:29:45] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: [2025-02-11 11:29:45] openai._base_client - Retrying request to /chat/completions in 0.411696 seconds\n",
      "INFO: [2025-02-11 11:29:54] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: [2025-02-11 11:29:54] openai._base_client - Retrying request to /chat/completions in 0.448970 seconds\n",
      "INFO: [2025-02-11 11:30:08] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: [2025-02-11 11:30:08] openai._base_client - Retrying request to /chat/completions in 0.403195 seconds\n",
      "INFO: [2025-02-11 11:30:41] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: [2025-02-11 11:30:41] openai._base_client - Retrying request to /chat/completions in 0.456889 seconds\n",
      "INFO: [2025-02-11 11:30:51] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: [2025-02-11 11:30:51] openai._base_client - Retrying request to /chat/completions in 0.461112 seconds\n",
      "INFO: [2025-02-11 11:30:57] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: [2025-02-11 11:30:57] openai._base_client - Retrying request to /chat/completions in 0.438096 seconds\n",
      "INFO: [2025-02-11 11:31:11] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: [2025-02-11 11:31:11] openai._base_client - Retrying request to /chat/completions in 0.428821 seconds\n",
      "INFO: [2025-02-11 11:31:37] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: [2025-02-11 11:31:37] openai._base_client - Retrying request to /chat/completions in 0.408087 seconds\n",
      "INFO: [2025-02-11 11:32:04] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: [2025-02-11 11:32:04] openai._base_client - Retrying request to /chat/completions in 0.385943 seconds\n",
      "INFO: [2025-02-11 11:32:10] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: [2025-02-11 11:32:10] openai._base_client - Retrying request to /chat/completions in 0.457730 seconds\n",
      "INFO: [2025-02-11 11:32:18] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: [2025-02-11 11:32:18] openai._base_client - Retrying request to /chat/completions in 0.463447 seconds\n",
      "INFO: [2025-02-11 11:32:34] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: [2025-02-11 11:32:34] openai._base_client - Retrying request to /chat/completions in 0.440441 seconds\n",
      "INFO: [2025-02-11 11:32:40] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: [2025-02-11 11:32:40] openai._base_client - Retrying request to /chat/completions in 0.410419 seconds\n",
      "INFO: [2025-02-11 11:32:52] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: [2025-02-11 11:32:52] openai._base_client - Retrying request to /chat/completions in 0.387422 seconds\n",
      "INFO: [2025-02-11 11:33:00] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: [2025-02-11 11:33:00] openai._base_client - Retrying request to /chat/completions in 0.445662 seconds\n",
      "INFO: [2025-02-11 11:33:16] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: [2025-02-11 11:33:16] openai._base_client - Retrying request to /chat/completions in 0.428367 seconds\n",
      "INFO: [2025-02-11 11:33:29] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: [2025-02-11 11:33:29] openai._base_client - Retrying request to /chat/completions in 0.388550 seconds\n",
      "INFO: [2025-02-11 11:33:51] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: [2025-02-11 11:33:51] openai._base_client - Retrying request to /chat/completions in 0.380461 seconds\n",
      "INFO: [2025-02-11 11:33:59] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: [2025-02-11 11:33:59] openai._base_client - Retrying request to /chat/completions in 0.441990 seconds\n",
      "INFO: [2025-02-11 11:34:09] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: [2025-02-11 11:34:09] openai._base_client - Retrying request to /chat/completions in 0.451370 seconds\n",
      "INFO: [2025-02-11 11:34:17] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: [2025-02-11 11:34:17] openai._base_client - Retrying request to /chat/completions in 0.471131 seconds\n",
      "INFO: [2025-02-11 11:34:33] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: [2025-02-11 11:34:33] openai._base_client - Retrying request to /chat/completions in 0.412531 seconds\n",
      "INFO: [2025-02-11 11:34:47] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: [2025-02-11 11:34:47] openai._base_client - Retrying request to /chat/completions in 0.409203 seconds\n",
      "INFO: [2025-02-11 11:34:57] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: [2025-02-11 11:34:57] openai._base_client - Retrying request to /chat/completions in 0.454420 seconds\n",
      "INFO: [2025-02-11 11:35:19] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: [2025-02-11 11:35:19] openai._base_client - Retrying request to /chat/completions in 0.468710 seconds\n",
      "INFO: [2025-02-11 11:35:32] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: [2025-02-11 11:35:32] openai._base_client - Retrying request to /chat/completions in 0.375736 seconds\n",
      "INFO: [2025-02-11 11:35:41] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: [2025-02-11 11:35:41] openai._base_client - Retrying request to /chat/completions in 0.420785 seconds\n",
      "INFO: [2025-02-11 11:35:47] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: [2025-02-11 11:35:47] openai._base_client - Retrying request to /chat/completions in 0.481375 seconds\n",
      "INFO: [2025-02-11 11:35:53] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: [2025-02-11 11:35:53] openai._base_client - Retrying request to /chat/completions in 0.476957 seconds\n",
      "INFO: [2025-02-11 11:36:10] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: [2025-02-11 11:36:10] openai._base_client - Retrying request to /chat/completions in 0.406294 seconds\n",
      "INFO: [2025-02-11 11:36:20] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "# Extract statements\n",
    "for i, row in df.iterrows():\n",
    "    try:\n",
    "        extracted_statement_json = generator(row.text)\n",
    "        df.at[i, 'extracted_statement_json'] = extracted_statement_json['statements']\n",
    "    except Exception as e:\n",
    "        df.at[i, 'extracted_statement_json'] = str(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recursively go through each key-value, and if it is an empty string or list or dict, remove the key-value pair\n",
    "def remove_empty_strings_and_lists(d):\n",
    "    for key, value in list(d.items()):\n",
    "        if isinstance(value, dict):\n",
    "            remove_empty_strings_and_lists(value)\n",
    "        elif isinstance(value, list):\n",
    "            for i in value:\n",
    "                if isinstance(i, dict):\n",
    "                    remove_empty_strings_and_lists(i)\n",
    "        if value in [None, \"\", [], {}]:\n",
    "            del d[key]\n",
    "    return d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [2025-02-11 11:44:29] indra.statements.agent - Invalid activity type: cytokine production\n",
      "WARNING: [2025-02-11 11:44:29] indra.statements.statements - Agent in ActiveForm should not have ActivityConditions.\n",
      "WARNING: [2025-02-11 11:44:29] indra.statements.statements - Invalid activity type: cytokine production\n",
      "WARNING: [2025-02-11 11:44:29] indra.statements.agent - Invalid activity type: stimulation\n",
      "WARNING: [2025-02-11 11:44:29] indra.statements.statements - Invalid activity type: SM22 promoter activity\n",
      "WARNING: [2025-02-11 11:44:29] indra.statements.agent - Invalid activity type: stimulation\n",
      "WARNING: [2025-02-11 11:44:29] indra.statements.statements - Invalid activity type: SM22 promoter activity\n",
      "WARNING: [2025-02-11 11:44:29] indra.statements.statements - Invalid activity type: induction\n",
      "WARNING: [2025-02-11 11:44:29] indra.statements.statements - Invalid activity type: None\n",
      "WARNING: [2025-02-11 11:44:29] indra.statements.statements - Invalid activity type: None\n",
      "WARNING: [2025-02-11 11:44:29] indra.statements.statements - Invalid activity type: None\n",
      "WARNING: [2025-02-11 11:44:29] indra.statements.statements - Invalid activity type: None\n",
      "WARNING: [2025-02-11 11:44:29] indra.statements.statements - Invalid activity type: None\n",
      "WARNING: [2025-02-11 11:44:29] indra.statements.statements - Invalid activity type: None\n",
      "WARNING: [2025-02-11 11:44:29] indra.statements.statements - Invalid activity type: Autophosphorylation\n",
      "WARNING: [2025-02-11 11:44:29] indra.statements.statements - Invalid activity type: binding\n",
      "WARNING: [2025-02-11 11:44:29] indra.statements.agent - Unknown modification type: ubiquitin\n",
      "WARNING: [2025-02-11 11:44:29] indra.statements.agent - Unknown modification type: ubiquitin\n",
      "WARNING: [2025-02-11 11:44:29] indra.statements.io - Error creating statement: attribute name must be string, not 'NoneType'\n",
      "WARNING: [2025-02-11 11:44:29] indra.statements.statements - Invalid activity type: None\n",
      "WARNING: [2025-02-11 11:44:29] indra.statements.statements - Invalid activity type: expression\n",
      "WARNING: [2025-02-11 11:44:29] indra.statements.statements - Invalid activity type: downstream signaling\n",
      "WARNING: [2025-02-11 11:44:29] indra.statements.statements - Invalid activity type: TMZ Sensitizing\n",
      "WARNING: [2025-02-11 11:44:29] indra.statements.statements - Invalid activity type: phosphorylation\n",
      "WARNING: [2025-02-11 11:44:29] indra.statements.io - Error creating statement: Invalid residue name: 'S28'\n",
      "WARNING: [2025-02-11 11:44:29] indra.statements.statements - Invalid activity type: desilencing\n",
      "WARNING: [2025-02-11 11:44:29] indra.statements.statements - Invalid activity type: binding\n",
      "WARNING: [2025-02-11 11:44:29] indra.statements.statements - Invalid activity type: None\n",
      "WARNING: [2025-02-11 11:44:29] indra.statements.statements - Invalid activity type: None\n",
      "WARNING: [2025-02-11 11:44:29] indra.statements.statements - Invalid activity type: protein stability\n",
      "WARNING: [2025-02-11 11:44:29] indra.statements.statements - Invalid activity type: phosphorylation\n",
      "WARNING: [2025-02-11 11:44:29] indra.statements.statements - Invalid activity type: phosphorylation\n",
      "WARNING: [2025-02-11 11:44:29] indra.statements.statements - Invalid activity type: phosphorylation\n",
      "WARNING: [2025-02-11 11:44:29] indra.statements.statements - Invalid activity type: binding\n",
      "WARNING: [2025-02-11 11:44:29] indra.statements.statements - Invalid activity type: phosphorylation\n",
      "WARNING: [2025-02-11 11:44:29] indra.statements.statements - Invalid activity type: None\n",
      "WARNING: [2025-02-11 11:44:29] indra.statements.statements - Invalid activity type: None\n",
      "WARNING: [2025-02-11 11:44:29] indra.statements.io - Error creating statement: Invalid residue name: 'N/A'\n",
      "WARNING: [2025-02-11 11:44:29] indra.statements.io - Error creating statement: Invalid residue name: 'N/A'\n",
      "WARNING: [2025-02-11 11:44:29] indra.statements.agent - Unknown modification type: Phosphorylation\n",
      "WARNING: [2025-02-11 11:44:29] indra.statements.agent - Unknown modification type: Phosphorylation\n",
      "WARNING: [2025-02-11 11:44:29] indra.statements.io - Error creating statement: attribute name must be string, not 'NoneType'\n"
     ]
    }
   ],
   "source": [
    "# Now ally the indra.statements.io.stmt_from_json to convert the extracted_statement_json to a list of INDRA statements\n",
    "for i, row in df.iterrows():\n",
    "    try:\n",
    "        cleaned = [remove_empty_strings_and_lists(x) for x in row.extracted_statement_json]\n",
    "        indra_statement_from_generated = stmts_from_json(cleaned, on_missing_support='handle')\n",
    "        df.at[i, 'indra_statement_from_generated'] = indra_statement_from_generated\n",
    "    except Exception as e:\n",
    "        df.at[i, 'indra_statement_from_generated'] = str(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These HY specific CD8+ T cells produced interferon gamma (IFNG) following peptide stimulation, demonstrating their functional capacity.\n",
      "[Activation(KDM5D(), IFNG())]\n",
      "[ActiveForm(CD8+ T cell(location: extracellular region), cytokine production, True)]\n"
     ]
    }
   ],
   "source": [
    "i = 2\n",
    "print(df.text[i])\n",
    "print(df.indra_statements_from_original[i])\n",
    "print(df.indra_statement_from_generated[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(* There is issue with parsing 'Association' statements because in 'indra.statements.statements' module, line 2263 \n",
    "`members = [Statement._from_json(m) for m in members]` where the dict objects of 'members' is expected to be Statement instead\n",
    "of Agent, and Statement requires 'type' property, but Agent does not have 'type' property, leading to missing key error. Either this line should be changed to `members = [Agent._from_json(m) for m in members]` or the schema should add 'type' field in Agent definition)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "indra_gpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
