{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78a77c60-6ad0-45d3-95be-86ff946eff68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This module contains functions for extracting statements from text by\\nfeeding the full json schema to ChatGPT.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"This module contains functions for extracting statements from text by\n",
    "feeding the full json schema to ChatGPT.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2fc074b8-bd5d-472c-bb4e-6ffd48465345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import json\n",
    "import random\n",
    "import pandas as pd\n",
    "from indra.statements.io import stmt_from_json\n",
    "from tqdm import tqdm\n",
    "from tqdm.contrib.logging import logging_redirect_tqdm\n",
    "from indra_gpt.api import run_openai_chat\n",
    "from indra_gpt.constants import JSON_SCHEMA\n",
    "import openai.error\n",
    "from indra.statements import Agent\n",
    "from indra.ontology.standardize import standardize_agent_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf0e95f7-8130-4512-952e-9f43124a141e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpt_stmt_json(stmt_json_examples, evidence_text):\n",
    "    \"\"\"\n",
    "    function to feed chatGPT a prompt including the full json schema and\n",
    "    ask it to generate a json object for a sentence using information in\n",
    "    the schema\n",
    "\n",
    "    :param stmt_json_examples:\n",
    "    :param evidence_text:\n",
    "    :return response:\n",
    "    \"\"\"\n",
    "\n",
    "    ############################# PROMPT ENGINEERING ###########################\n",
    "\n",
    "    json_schema_string = json.dumps(JSON_SCHEMA)  # converting json schema to a string\n",
    "\n",
    "    # full prompt including schema\n",
    "    PROMPT = (\n",
    "        \"Read the following JSON schema for a statement \"\n",
    "        \"object:\\n\\n```json\\n\"\n",
    "        + json_schema_string\n",
    "        + \"\\n```\\n\\nExtract the relation from the following sentence and put it in a JSON object matching the schema above. The JSON object needs to be able to pass a validation against the provided schema. If the statement type is 'RegulateActivity', list it instead as either 'Activation' or 'Inhibition'. If the statement type is 'RegulateAmount', list it instead as either 'IncreaseAmount' or 'DecreaseAmount'. Only respond with \"\n",
    "        \"the JSON object.\\n\\nSentence: \"\n",
    "    )\n",
    "\n",
    "    # reduced prompt not including schema\n",
    "    PROMPT_reduced = (\n",
    "        \"Extract the relation from the following sentence and put it in a \"\n",
    "        \"JSON object matching the schema above. The JSON object needs to be \"\n",
    "        \"able to pass a validation against the provided schema. If the \"\n",
    "        \"statement type is 'RegulateActivity', list it instead as either \"\n",
    "        \"'Activation' or 'Inhibition'. If the statement type is \"\n",
    "        \"'RegulateAmount', list it instead as either 'IncreaseAmount' or 'DecreaseAmount'. Only \"\n",
    "        \"respond with \"\n",
    "        \"the JSON object.\\n\\nSentence: \"\n",
    "    )\n",
    "\n",
    "    ############################## HISTORY ############################\n",
    "\n",
    "    # variables to feed the chat history:\n",
    "    stmt_json_1 = stmt_json_examples[0]  #\n",
    "    # first example json in the training\n",
    "    # dataframe\n",
    "    ev_text_1 = stmt_json_1[\"evidence\"][0][\"text\"]  # first example sentence\n",
    "    # extracted from the example json\n",
    "    stmt_json_2 = stmt_json_examples[1]  #\n",
    "    # second example json in the\n",
    "    # training dataframe\n",
    "    ev_text_2 = stmt_json_2[\"evidence\"][0][\"text\"]  # second example sentence\n",
    "    # extracted from the example json\n",
    "\n",
    "    # create the chat history, including the prompt with the schema,\n",
    "    # the first example json to feed chatGPT as a sample, the reduced prompt\n",
    "    # without schema, the second example json to feed chatGPT as a sample\n",
    "    history = [\n",
    "        {\"role\": \"user\", \"content\": PROMPT + ev_text_1},  # prompt with schema\n",
    "        {\"role\": \"assistant\", \"content\": json.dumps(stmt_json_1)},\n",
    "        # first stmt json example\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": PROMPT_reduced + ev_text_2,\n",
    "        },  # prompt without schema\n",
    "        {\"role\": \"assistant\", \"content\": json.dumps(stmt_json_2)},\n",
    "        # second stmt json example\n",
    "    ]\n",
    "\n",
    "    ################### RUN PROMPT TO ASK CHATGPT #####################\n",
    "\n",
    "    prompt = PROMPT_reduced + evidence_text[\"evidence\"][0][\"text\"]\n",
    "    # format the main prompt to ask chatGPT without being fed sample\n",
    "    # data to only include the reduced prompt without the json schema +\n",
    "    # the main sentence inputted into the gpt_stmt_json function\n",
    "\n",
    "    chat_gpt_json = run_openai_chat(\n",
    "        prompt,\n",
    "        model=\"gpt-3.5-turbo-16k\",\n",
    "        chat_history=history,\n",
    "        max_tokens=9000,\n",
    "        strip=False,\n",
    "        debug=False,\n",
    "    )  # use run_openai_chat\n",
    "    # function on prompt, specifying model and max_tokens parameters as\n",
    "    # needed\n",
    "    return chat_gpt_json  # return chatGPT's response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8dc8f0b3-1563-45b7-b177-b627d9fb5907",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_indra_object(stmt):\n",
    "    \"\"\"\n",
    "    function to get rid of irrelevant parts of the indra statement\n",
    "    dictionary\n",
    "\n",
    "    :param stmt:\n",
    "    :return stmt:\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    stmt[\"evidence\"] = [{\"text\": stmt[\"evidence\"][0].get(\"text\")}]\n",
    "\n",
    "    del stmt[\"id\"]\n",
    "    del stmt[\"matches_hash\"]\n",
    "\n",
    "    if 'supports' in stmt:\n",
    "        del stmt['supports']\n",
    "    if 'supported_by' in stmt:\n",
    "        del stmt['supported_by']\n",
    "\n",
    "    return stmt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7f47b565-ba34-413b-a411-e80502a77c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_object_list = [] # list of every inputted json object\n",
    "outputs = []  # list of every output by chatGPT\n",
    "sentences = []  # list of the sentences fed to the prompt\n",
    "statements = []  # list of json statements returned from outputted json\n",
    "    # object by chatGPT (when applicable to a sentence and its outputted json\n",
    "    # object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "52a64225-2dfc-40c0-afc3-8179d28d85d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(json_file):\n",
    "\n",
    "    \"\"\"\n",
    "    function to run above operations on inputted training dataframe of\n",
    "    json objects\n",
    "\n",
    "    :param json_file:\n",
    "    :output tsv file:\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    with open(json_file, \"r\") as f:\n",
    "        json_content = json.load(f) # load json file\n",
    "\n",
    "    json_object_list.append(json_content[:50])  # append first 50 json objects to\n",
    "    # json_object_list\n",
    "    json_object_list = [process_indra_object(stmt) for stmt in\n",
    "    json_object_list] # run processing function on each json object to trim\n",
    "    # it down\n",
    "\n",
    "    for json_object in tqdm(\n",
    "        json_object_list, desc=\"Extracting\", unit=\"statement\", unit_scale=True\n",
    "    ): # loop through each json object in json_object_list\n",
    "\n",
    "        #sample_list = [json_object_list[0],json_object_list[1]] # unhash\n",
    "        # when debugging\n",
    "\n",
    "        sample_list = random.sample(json_object_list, 2) # take in a random\n",
    "        # sample of any 2 json objects to feed to the chat history per\n",
    "        # iteration\n",
    "\n",
    "        sentence = json_object[\"evidence\"][0][\"text\"]\n",
    "        sentences.append(sentence) # get the sentence from the current json\n",
    "        # object and append to the sentences list\n",
    "\n",
    "        try:\n",
    "            with logging_redirect_tqdm():\n",
    "                response = gpt_stmt_json(sample_list, json_object) # run\n",
    "                # gpt_stmt_json function on the randomly sampled list and\n",
    "                # current json object\n",
    "        except openai.error.InvalidRequestError as e:\n",
    "            error_text = f\"OpenAI error: {e}\" # if chatGPT fails to create a\n",
    "            # response\n",
    "            outputs.append(error_text) # append error message\n",
    "            statements.append(error_text) # append error message\n",
    "            continue\n",
    "\n",
    "        outputs.append(response) # append chatGPT's response to outputs list\n",
    "\n",
    "        \"\"\"\n",
    "        Some generated json objects are able to take in the\n",
    "        json.loads and stmt_from_json functions to return a statement\n",
    "        json. Some are not. Use the try/except method to extract statement\n",
    "        jsons from the generated json objects for the ones that work.\n",
    "        Append them to the list of all statements extracted. If it doesn't\n",
    "        work on a generated json object, just append that there was an\n",
    "        error loading the statement.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            json_str = json.loads(response) # load the response\n",
    "            stmt_n = stmt_from_json(json_str)  # extract the INDRA statement\n",
    "            # object from the string\n",
    "            statements.append(stmt_n) # append extracted statement to\n",
    "            # statements list\n",
    "        except IndexError as e:\n",
    "            statements.append(f\"Error: {e}\") # otherwise append error message\n",
    "\n",
    "    print(\"Done.\")  # print done to know when main function has finished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5695cf4c-a93d-48c1-97e3-b493283360a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting:   0%|                                                                                              | 0.00/50.0 [00:00<?, ?statement/s]WARNING: [2023-09-18 14:52:29] indra.statements.statements - Invalid activity type: acetylation\n",
      "Extracting:   2%|█▋                                                                                     | 1.00/50.0 [00:03<03:05, 3.78s/statement]WARNING: [2023-09-18 14:52:33] indra.statements.agent - ModCondition missing is_modified, defaulting to True\n",
      "WARNING: [2023-09-18 14:52:33] indra.statements.io - Error creating statement: Invalid residue name: 'K120'\n",
      "Extracting:   4%|███▍                                                                                   | 2.00/50.0 [00:07<03:09, 3.96s/statement]WARNING: [2023-09-18 14:52:37] indra.statements.statements - Invalid activity type: acetylation\n",
      "Extracting:  10%|████████▋                                                                              | 5.00/50.0 [00:19<02:52, 3.84s/statement]WARNING: [2023-09-18 14:52:49] indra.statements.statements - Invalid activity type: None\n",
      "Extracting:  16%|█████████████▉                                                                         | 8.00/50.0 [00:29<02:16, 3.26s/statement]WARNING: [2023-09-18 14:52:58] indra.statements.io - Error creating statement: __init__() takes 1 positional argument but 4 were given\n",
      "Extracting:  20%|█████████████████▍                                                                     | 10.0/50.0 [00:36<02:21, 3.53s/statement]WARNING: [2023-09-18 14:53:06] indra.statements.statements - Invalid activity type: production\n",
      "Extracting:  26%|██████████████████████▌                                                                | 13.0/50.0 [00:47<02:10, 3.52s/statement]WARNING: [2023-09-18 14:53:16] indra.statements.statements - Invalid activity type: None\n",
      "Extracting:  30%|██████████████████████████                                                             | 15.0/50.0 [00:54<02:02, 3.50s/statement]WARNING: [2023-09-18 14:53:22] indra.statements.statements - Invalid activity type: nucleosome relaxation\n",
      "Extracting:  50%|███████████████████████████████████████████▌                                           | 25.0/50.0 [01:27<01:18, 3.13s/statement]WARNING: [2023-09-18 14:53:55] indra.statements.statements - Invalid activity type: activation\n",
      "Extracting:  62%|█████████████████████████████████████████████████████▉                                 | 31.0/50.0 [01:46<01:04, 3.40s/statement]WARNING: [2023-09-18 14:54:14] indra.statements.statements - Invalid activity type: expression\n",
      "Extracting:  64%|███████████████████████████████████████████████████████▋                               | 32.0/50.0 [01:49<00:57, 3.21s/statement]WARNING: [2023-09-18 14:54:17] indra.statements.statements - Invalid activity type: expression\n",
      "Extracting: 100%|███████████████████████████████████████████████████████████████████████████████████████| 50.0/50.0 [02:49<00:00, 3.39s/statement]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            sentence  \\\n",
      "0  C5a promotes the proliferation of human nasoph...   \n",
      "1  Furthermore, acetylation of p53 K120 by the MO...   \n",
      "2  Indeed, we show that upon treatment with chemo...   \n",
      "3  We found that 24 hours of BMP pretreatment cau...   \n",
      "4  Activation of atypical protein kinase C zeta b...   \n",
      "\n",
      "                                               input  \\\n",
      "0  {\"type\": \"Acetylation\", \"enz\": {\"name\": \"C5\", ...   \n",
      "1  {\"type\": \"Acetylation\", \"enz\": {\"name\": \"KANSL...   \n",
      "2  {\"type\": \"Acetylation\", \"enz\": {\"name\": \"EP300...   \n",
      "3  {\"type\": \"Activation\", \"subj\": {\"name\": \"BMP\",...   \n",
      "4  {\"type\": \"Activation\", \"subj\": {\"name\": \"Caspa...   \n",
      "\n",
      "                               generated_json_object  \\\n",
      "0  {\"type\": \"Activation\", \"subj\": {\"name\": \"C5a\",...   \n",
      "1  {\"type\": \"Activation\", \"subj\": {\"name\": \"MOF a...   \n",
      "2  {\"type\": \"Activation\", \"subj\": {\"name\": \"ABL1\"...   \n",
      "3  {\"type\": \"IncreaseAmount\", \"subj\": {\"name\": \"B...   \n",
      "4  {\"type\": \"Activation\", \"subj\": {\"name\": \"Caspa...   \n",
      "\n",
      "                       extracted_statement  \n",
      "0  Activation(C5a(), STAT3(), acetylation)  \n",
      "1           Error: list index out of range  \n",
      "2   Activation(ABL1(), P73(), acetylation)  \n",
      "3            IncreaseAmount(BMP(), PTEN())  \n",
      "4   Activation(Caspase(), PRKCZ(), kinase)  \n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main(\"indra_benchmark_corpus_all_correct.json\") # run main function here\n",
    "    \n",
    "    df = pd.DataFrame(\n",
    "        {\n",
    "            \"sentence\": sentences,\n",
    "            \"input\": [json.dumps(js) for js in json_object_list],\n",
    "            \"generated_json_object\": outputs,\n",
    "            \"extracted_statement\": statements,\n",
    "        }\n",
    "    )     # save sentences, json_object_list, outputs, and statements as a pandas\n",
    "    # dataframe\n",
    "    df.to_csv(\"statement_json_extraction_results.tsv\", sep=\"\\t\",\n",
    "              index=False) # save dataframe as tsv file\n",
    "\n",
    "    print(df[:5]) # print first 5 rows of dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8d69c8-bb6c-4f18-80e0-d9dc8bd0b24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen8 = json.loads(df['generated_json_object'][8])\n",
    "subj = Agent._from_json(gen8['subj'])  # load the agent\n",
    "standardize_agent_name(subj) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
