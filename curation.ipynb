{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bca64466",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thomaslim/miniconda3/envs/indra_gpt/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "INFO: [2025-07-01 09:30:00] httpx - HTTP Request: GET https://raw.githubusercontent.com/BerriAI/litellm/main/model_prices_and_context_window.json \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "\n",
    "import indra_gpt.chat_curate.chat_curate\n",
    "importlib.reload(indra_gpt.chat_curate.chat_curate)\n",
    "from indra_gpt.chat_curate.chat_curate import *\n",
    "\n",
    "import indra_gpt.chat_curate.eval\n",
    "importlib.reload(indra_gpt.chat_curate.eval)\n",
    "from indra_gpt.chat_curate.eval import (curation_statement_evidence_pair_comparison_json, \n",
    "                                        curation_statement_comparison_json)\n",
    "\n",
    "import pickle\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59caf037",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_DIR = Path.cwd().joinpath(\"output/curated_statements_sample_100\")\n",
    "if not RESULTS_DIR.exists():\n",
    "    RESULTS_DIR.mkdir(parents=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a574e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: [2025-07-01 09:30:00] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list\n",
      "INFO: [2025-07-01 09:30:00] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-07-01 09:30:00] indra.sources.indra_db_rest.util - data: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• Fetching all curations from INDRA DB...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: [2025-07-01 09:30:02] indra_db_rest.query_processor - Retrieving statements that have hash -10558769985488922, -12064636854697961, -13295983281851382, -14213213083155331, -16253859176692871, -16488861539572024, -16507077386690032, -16547197524937149, -16614904339675969, -18863224253297223, -19358276560732315, -19540873943256728, -19594858394048257, -20095856845760100, -20155356540515066, -20905000153811208, -22129299903885771, -24407073837268975, -25167674544775862, -25685577301218461, -25687800924410749, -26040559113565892, -26186913902459663, -29144964812931735, -29611002097870603, -29615932207517012, -3035906237295811, -31640842146491461, -31649991562866730, -31734835008003753, -33584033074123684, -33633204848848179, -35980800557648489, -36016319529798526, -4259562148975527, -4289213873112161, -4820006348997044, -627992662320746, -6287275938202915, -7189243357890503, -8918741695867224, -895298493819940, -980605458670407, 10900723066461018, 12039417786486187, 12852949112266658, 13991637048397514, 14461478333067931, 15020981259412066, 15625440211547875, 15883888354785577, 16086433650681890, 16295593167987208, 16957903542949535, 17291997831815074, 17433662571000991, 18047521695546414, 19046737298505955, 19433305736572282, 1979435449291167, 20463906136114117, 2078133867265037, 21720618841642068, 22077079225651769, 22898183937865329, 2295877906536253, 23127004838335713, 23208543970032346, 23484238322005967, 23534859870816183, 23874434764041501, 23986439730214991, 24105295490673034, 24477639752946169, 24674212246738944, 24742171390513876, 2560863705819459, 25954429068606351, 2642167277518507, 26442745201639531, 28063295869356555, 28150214412432901, 29165227727197835, 31160008118740626, 31201759134025410, 33210056013716605, 3330420443506836, 33628940232530458, 33644193719692107, 35977264716224321, 4253105343576156, 4686400007541378, 5409300677524704, 547176214361027, 6500149591235807, 6567684280629832, 7111390245224, 771219815581060, 8876112165442530, or 9878756468919283.\n",
      "INFO: [2025-07-01 09:30:02] indra_db_rest.request_logs - Running 0th request for statements\n",
      "INFO: [2025-07-01 09:30:02] indra_db_rest.request_logs -   LIMIT: None\n",
      "INFO: [2025-07-01 09:30:02] indra_db_rest.request_logs -   OFFSET: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßπ Extracting unique statement hashes...\n",
      "üîç Fetching 100 curated statements from INDRA DB...\n",
      "‚úÖ Saved 89 curated statements to: /Users/thomaslim/gyorilab/indra_gpt/output/curated_statements_sample_100/statements.pkl\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from indra.sources import indra_db_rest\n",
    "\n",
    "# Step 1: Get all curations from the INDRA DB\n",
    "print(\"üì• Fetching all curations from INDRA DB...\")\n",
    "curations = indra_db_rest.get_curations()\n",
    "\n",
    "# Step 2: Extract unique statement hashes from curations\n",
    "print(\"üßπ Extracting unique statement hashes...\")\n",
    "unique_hashes = list({c['pa_hash'] for c in curations if 'pa_hash' in c})\n",
    "\n",
    "# Step 3: Randomly sample up to 100 curated statement hashes\n",
    "sample_size = min(100, len(unique_hashes))\n",
    "sampled_hashes = random.sample(unique_hashes, sample_size)\n",
    "\n",
    "# Step 4: Fetch full statements by hash (including all evidences)\n",
    "print(f\"üîç Fetching {sample_size} curated statements from INDRA DB...\")\n",
    "stmt_proc = indra_db_rest.get_statements_by_hash(sampled_hashes, ev_limit=100)\n",
    "curated_statements = stmt_proc.statements\n",
    "\n",
    "# Step 5: Save to pickle\n",
    "output_path = RESULTS_DIR / \"statements.pkl\"\n",
    "\n",
    "with open(output_path, \"wb\") as f:\n",
    "    pickle.dump(curated_statements, f)\n",
    "\n",
    "print(f\"‚úÖ Saved {len(curated_statements)} curated statements to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8b436a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Curating statements with chat curation:   0%|          | 0/89 [00:00<?, ?it/s]INFO: [2025-07-01 09:30:46] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.68 seconds\n",
      "\u001b[92m09:30:46 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:30:46] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:30:48] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:30:48 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:30:48] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:30:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:30:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:30:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:30:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:30:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:30:48] indra_gpt.chat_curate.chat_curate - LLM call took 2.30 seconds\n",
      "INFO: [2025-07-01 09:30:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:30:50] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.66 seconds\n",
      "\u001b[92m09:30:50 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:30:50] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:30:51] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:30:51 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:30:51] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:30:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:30:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:30:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:30:51] indra_gpt.chat_curate.chat_curate - LLM call took 1.15 seconds\n",
      "INFO: [2025-07-01 09:30:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:30:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:30:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:30:53] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.65 seconds\n",
      "\u001b[92m09:30:53 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:30:53] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:30:54] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:30:54 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:30:54] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:30:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:30:54] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:30:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:30:54] indra_gpt.chat_curate.chat_curate - LLM call took 1.35 seconds\n",
      "INFO: [2025-07-01 09:30:54] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:30:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:30:54] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:30:56] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.69 seconds\n",
      "\u001b[92m09:30:56 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:30:56] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:30:58] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:30:58 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:30:58] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:30:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:30:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:30:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:30:58] indra_gpt.chat_curate.chat_curate - LLM call took 1.85 seconds\n",
      "INFO: [2025-07-01 09:30:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:30:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:30:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:31:00] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.65 seconds\n",
      "\u001b[92m09:31:00 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:31:00] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:31:01] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:31:01 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:31:01] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:31:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:31:01] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:31:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:31:01] indra_gpt.chat_curate.chat_curate - LLM call took 0.95 seconds\n",
      "Curating statements with chat curation:   1%|          | 1/89 [00:27<40:46, 27.80s/it]INFO: [2025-07-01 09:31:01] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:31:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:31:01] indra_gpt.chat_curate.chat_curate - Skipping agent None with no db_refs or None value in the agent list.\n",
      "INFO: [2025-07-01 09:31:01] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:31:02] indra_gpt.chat_curate.chat_curate - Prompt generation took 0.83 seconds\n",
      "\u001b[92m09:31:02 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:31:02] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:31:03] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:31:03 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:31:03] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:31:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:31:03] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:31:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:31:03] indra_gpt.chat_curate.chat_curate - LLM call took 0.92 seconds\n",
      "INFO: [2025-07-01 09:31:03] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:31:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:31:03] indra_gpt.chat_curate.chat_curate - Skipping agent None with no db_refs or None value in the agent list.\n",
      "INFO: [2025-07-01 09:31:03] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:31:04] indra_gpt.chat_curate.chat_curate - Prompt generation took 0.83 seconds\n",
      "\u001b[92m09:31:04 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:31:04] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:31:04] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:31:04 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:31:04] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:31:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:31:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:31:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:31:04] indra_gpt.chat_curate.chat_curate - LLM call took 0.58 seconds\n",
      "INFO: [2025-07-01 09:31:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:31:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:31:04] indra_gpt.chat_curate.chat_curate - Skipping agent None with no db_refs or None value in the agent list.\n",
      "INFO: [2025-07-01 09:31:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:31:05] indra_gpt.chat_curate.chat_curate - Prompt generation took 0.83 seconds\n",
      "\u001b[92m09:31:05 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:31:05] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:31:06] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:31:06 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:31:06] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:31:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:31:06] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:31:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:31:06] indra_gpt.chat_curate.chat_curate - LLM call took 0.72 seconds\n",
      "INFO: [2025-07-01 09:31:06] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:31:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:31:06] indra_gpt.chat_curate.chat_curate - Skipping agent None with no db_refs or None value in the agent list.\n",
      "INFO: [2025-07-01 09:31:06] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:31:07] indra_gpt.chat_curate.chat_curate - Prompt generation took 0.83 seconds\n",
      "\u001b[92m09:31:07 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:31:07] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:31:08] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:31:08 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:31:08] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:31:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:31:08] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:31:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:31:08] indra_gpt.chat_curate.chat_curate - LLM call took 0.55 seconds\n",
      "INFO: [2025-07-01 09:31:08] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:31:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:31:08] indra_gpt.chat_curate.chat_curate - Skipping agent None with no db_refs or None value in the agent list.\n",
      "INFO: [2025-07-01 09:31:08] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:31:09] indra_gpt.chat_curate.chat_curate - Prompt generation took 0.82 seconds\n",
      "\u001b[92m09:31:09 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:31:09] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:31:09] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:31:09 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:31:09] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:31:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:31:09] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:31:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:31:09] indra_gpt.chat_curate.chat_curate - LLM call took 0.68 seconds\n",
      "Curating statements with chat curation:   2%|‚ñè         | 2/89 [00:36<23:39, 16.32s/it]INFO: [2025-07-01 09:31:09] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:31:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:31:09] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:31:11] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.66 seconds\n",
      "\u001b[92m09:31:11 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:31:11] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:31:14] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:31:14 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:31:14] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:31:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:31:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:31:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:31:14] indra_gpt.chat_curate.chat_curate - LLM call took 2.41 seconds\n",
      "INFO: [2025-07-01 09:31:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:31:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:31:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:31:15] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.65 seconds\n",
      "\u001b[92m09:31:15 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:31:15] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:31:16] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:31:16 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:31:16] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:31:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:31:16] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:31:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:31:16] indra_gpt.chat_curate.chat_curate - LLM call took 0.96 seconds\n",
      "INFO: [2025-07-01 09:31:16] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:31:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:31:16] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:31:18] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.66 seconds\n",
      "\u001b[92m09:31:18 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:31:18] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:31:21] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:31:21 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:31:21] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:31:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:31:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:31:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:31:21] indra_gpt.chat_curate.chat_curate - LLM call took 2.58 seconds\n",
      "INFO: [2025-07-01 09:31:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:31:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:31:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:31:23] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.71 seconds\n",
      "\u001b[92m09:31:23 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:31:23] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:31:24] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:31:24 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:31:24] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:31:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:31:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:31:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:31:24] indra_gpt.chat_curate.chat_curate - LLM call took 0.67 seconds\n",
      "INFO: [2025-07-01 09:31:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:31:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:31:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:31:26] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.74 seconds\n",
      "\u001b[92m09:31:26 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:31:26] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:31:26] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:31:26 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:31:26] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:31:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:31:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:31:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:31:26] indra_gpt.chat_curate.chat_curate - LLM call took 0.62 seconds\n",
      "Curating statements with chat curation:   3%|‚ñé         | 3/89 [00:52<23:46, 16.59s/it]INFO: [2025-07-01 09:31:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:31:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:31:26] indra_gpt.chat_curate.chat_curate - Skipping agent p2() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "INFO: [2025-07-01 09:31:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:31:27] indra_gpt.chat_curate.chat_curate - Prompt generation took 0.90 seconds\n",
      "\u001b[92m09:31:27 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:31:27] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:31:28] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:31:28 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:31:28] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:31:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:31:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:31:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:31:28] indra_gpt.chat_curate.chat_curate - LLM call took 0.58 seconds\n",
      "INFO: [2025-07-01 09:31:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:31:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:31:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:31:28] indra_gpt.chat_curate.chat_curate - Skipping agent p2() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "INFO: [2025-07-01 09:31:29] indra_gpt.chat_curate.chat_curate - Prompt generation took 0.83 seconds\n",
      "\u001b[92m09:31:29 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:31:29] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:31:30] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:31:30 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:31:30] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:31:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:31:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:31:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:31:30] indra_gpt.chat_curate.chat_curate - LLM call took 0.86 seconds\n",
      "INFO: [2025-07-01 09:31:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:31:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:31:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:31:30] indra_gpt.chat_curate.chat_curate - Skipping agent p2() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "INFO: [2025-07-01 09:31:30] indra_gpt.chat_curate.chat_curate - Prompt generation took 0.82 seconds\n",
      "\u001b[92m09:31:30 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:31:30] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:31:31] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:31:31 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:31:31] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:31:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:31:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:31:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:31:31] indra_gpt.chat_curate.chat_curate - LLM call took 0.54 seconds\n",
      "INFO: [2025-07-01 09:31:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:31:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:31:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:31:31] indra_gpt.chat_curate.chat_curate - Skipping agent p2() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "INFO: [2025-07-01 09:31:32] indra_gpt.chat_curate.chat_curate - Prompt generation took 0.83 seconds\n",
      "\u001b[92m09:31:32 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:31:32] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:31:33] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:31:33 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:31:33] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:31:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:31:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:31:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:31:33] indra_gpt.chat_curate.chat_curate - LLM call took 0.57 seconds\n",
      "INFO: [2025-07-01 09:31:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:31:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:31:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:31:33] indra_gpt.chat_curate.chat_curate - Skipping agent p2() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "INFO: [2025-07-01 09:31:34] indra_gpt.chat_curate.chat_curate - Prompt generation took 0.83 seconds\n",
      "\u001b[92m09:31:34 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:31:34] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:31:34] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:31:34 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:31:34] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:31:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:31:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:31:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:31:34] indra_gpt.chat_curate.chat_curate - LLM call took 0.66 seconds\n",
      "Curating statements with chat curation:   4%|‚ñç         | 4/89 [01:01<18:43, 13.22s/it]INFO: [2025-07-01 09:31:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:31:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:31:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:31:36] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.72 seconds\n",
      "\u001b[92m09:31:36 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:31:36] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:31:37] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:31:37 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:31:37] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:31:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:31:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:31:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:31:37] indra_gpt.chat_curate.chat_curate - LLM call took 0.57 seconds\n",
      "INFO: [2025-07-01 09:31:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:31:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:31:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:31:39] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.73 seconds\n",
      "\u001b[92m09:31:39 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:31:39] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:31:39] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:31:39 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:31:39] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:31:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:31:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:31:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:31:39] indra_gpt.chat_curate.chat_curate - LLM call took 0.60 seconds\n",
      "INFO: [2025-07-01 09:31:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:31:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:31:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:31:41] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.72 seconds\n",
      "\u001b[92m09:31:41 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:31:41] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:31:42] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:31:42 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:31:42] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:31:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:31:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:31:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:31:42] indra_gpt.chat_curate.chat_curate - LLM call took 0.66 seconds\n",
      "INFO: [2025-07-01 09:31:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:31:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:31:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:31:44] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.72 seconds\n",
      "\u001b[92m09:31:44 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:31:44] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:31:45] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:31:45 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:31:45] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:31:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:31:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:31:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:31:45] indra_gpt.chat_curate.chat_curate - LLM call took 0.65 seconds\n",
      "INFO: [2025-07-01 09:31:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:31:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:31:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:31:47] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.75 seconds\n",
      "\u001b[92m09:31:47 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:31:47] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:31:48] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:31:48 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:31:48] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:31:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:31:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:31:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:31:48] indra_gpt.chat_curate.chat_curate - LLM call took 1.21 seconds\n",
      "Curating statements with chat curation:   6%|‚ñå         | 5/89 [01:14<18:41, 13.35s/it]INFO: [2025-07-01 09:31:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:31:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:31:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:31:50] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.71 seconds\n",
      "\u001b[92m09:31:50 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:31:50] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:31:50] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:31:50 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:31:50] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:31:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:31:50] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:31:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:31:50] indra_gpt.chat_curate.chat_curate - LLM call took 0.59 seconds\n",
      "INFO: [2025-07-01 09:31:50] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:31:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:31:50] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:31:52] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.67 seconds\n",
      "\u001b[92m09:31:52 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:31:52] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:31:53] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:31:53 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:31:53] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:31:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:31:53] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:31:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:31:53] indra_gpt.chat_curate.chat_curate - LLM call took 0.55 seconds\n",
      "INFO: [2025-07-01 09:31:53] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:31:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:31:53] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:31:55] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.67 seconds\n",
      "\u001b[92m09:31:55 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:31:55] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:31:55] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:31:55 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:31:55] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:31:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:31:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:31:55] indra_gpt.chat_curate.chat_curate - LLM call took 0.56 seconds\n",
      "\u001b[92m09:31:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:31:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:31:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:31:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:31:57] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.67 seconds\n",
      "\u001b[92m09:31:57 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:31:57] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:31:58] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:31:58 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:31:58] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:31:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:31:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:31:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:31:58] indra_gpt.chat_curate.chat_curate - LLM call took 0.67 seconds\n",
      "INFO: [2025-07-01 09:31:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:31:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:31:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:32:00] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.67 seconds\n",
      "\u001b[92m09:32:00 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:32:00] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:32:00] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:32:00 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:32:00] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:32:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:32:00] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:32:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:32:00] indra_gpt.chat_curate.chat_curate - LLM call took 0.61 seconds\n",
      "Curating statements with chat curation:   7%|‚ñã         | 6/89 [01:27<18:07, 13.10s/it]INFO: [2025-07-01 09:32:00] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:32:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:32:00] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:32:02] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.76 seconds\n",
      "\u001b[92m09:32:02 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:32:02] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:32:03] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:32:03 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:32:03] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:32:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:32:03] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:32:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:32:03] indra_gpt.chat_curate.chat_curate - LLM call took 0.61 seconds\n",
      "INFO: [2025-07-01 09:32:03] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:32:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:32:03] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:32:05] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.77 seconds\n",
      "\u001b[92m09:32:05 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:32:05] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:32:06] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:32:06 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:32:06] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:32:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:32:06] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:32:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:32:06] indra_gpt.chat_curate.chat_curate - LLM call took 0.77 seconds\n",
      "INFO: [2025-07-01 09:32:06] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:32:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:32:06] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:32:08] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.76 seconds\n",
      "\u001b[92m09:32:08 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:32:08] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:32:08] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:32:08 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:32:08] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:32:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:32:08] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:32:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:32:08] indra_gpt.chat_curate.chat_curate - LLM call took 0.67 seconds\n",
      "INFO: [2025-07-01 09:32:08] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:32:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:32:09] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:32:10] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.75 seconds\n",
      "\u001b[92m09:32:10 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:32:10] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:32:11] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:32:11 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:32:11] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:32:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:32:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:32:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:32:11] indra_gpt.chat_curate.chat_curate - LLM call took 0.68 seconds\n",
      "INFO: [2025-07-01 09:32:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:32:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:32:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:32:13] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.75 seconds\n",
      "\u001b[92m09:32:13 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:32:13] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:32:14] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:32:14 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:32:14] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:32:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:32:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:32:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:32:14] indra_gpt.chat_curate.chat_curate - LLM call took 0.59 seconds\n",
      "Curating statements with chat curation:   8%|‚ñä         | 7/89 [01:40<17:59, 13.17s/it]INFO: [2025-07-01 09:32:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:32:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:32:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:32:16] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.66 seconds\n",
      "\u001b[92m09:32:16 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:32:16] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:32:21] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:32:21 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:32:21] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:32:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:32:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:32:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:32:21] indra_gpt.chat_curate.chat_curate - LLM call took 5.20 seconds\n",
      "INFO: [2025-07-01 09:32:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:32:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:32:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:32:23] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.67 seconds\n",
      "\u001b[92m09:32:23 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:32:23] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:32:26] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:32:26 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:32:26] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:32:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:32:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:32:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:32:26] indra_gpt.chat_curate.chat_curate - LLM call took 3.45 seconds\n",
      "INFO: [2025-07-01 09:32:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:32:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:32:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:32:28] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.66 seconds\n",
      "\u001b[92m09:32:28 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:32:28] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:32:30] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:32:30 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:32:30] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:32:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:32:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:32:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:32:30] indra_gpt.chat_curate.chat_curate - LLM call took 2.19 seconds\n",
      "INFO: [2025-07-01 09:32:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:32:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:32:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:32:32] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.73 seconds\n",
      "\u001b[92m09:32:32 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:32:32] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:32:34] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:32:34 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:32:34] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:32:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:32:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:32:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:32:34] indra_gpt.chat_curate.chat_curate - LLM call took 1.62 seconds\n",
      "INFO: [2025-07-01 09:32:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:32:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:32:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:32:36] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.70 seconds\n",
      "\u001b[92m09:32:36 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:32:36] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:32:37] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:32:37 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:32:37] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:32:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:32:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:32:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:32:37] indra_gpt.chat_curate.chat_curate - LLM call took 0.68 seconds\n",
      "Curating statements with chat curation:   9%|‚ñâ         | 8/89 [02:03<21:56, 16.25s/it]INFO: [2025-07-01 09:32:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:32:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:32:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:32:39] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.72 seconds\n",
      "\u001b[92m09:32:39 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:32:39] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:32:39] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:32:39 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:32:39] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:32:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:32:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:32:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:32:39] indra_gpt.chat_curate.chat_curate - LLM call took 0.64 seconds\n",
      "INFO: [2025-07-01 09:32:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:32:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:32:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:32:41] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.77 seconds\n",
      "\u001b[92m09:32:41 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:32:41] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:32:42] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:32:42 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:32:42] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:32:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:32:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:32:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:32:42] indra_gpt.chat_curate.chat_curate - LLM call took 0.60 seconds\n",
      "INFO: [2025-07-01 09:32:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:32:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:32:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:32:44] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.72 seconds\n",
      "\u001b[92m09:32:44 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:32:44] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:32:45] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:32:45 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:32:45] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:32:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:32:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:32:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:32:45] indra_gpt.chat_curate.chat_curate - LLM call took 0.82 seconds\n",
      "INFO: [2025-07-01 09:32:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:32:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:32:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:32:47] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.69 seconds\n",
      "\u001b[92m09:32:47 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:32:47] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:32:47] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:32:47 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:32:47] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:32:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:32:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:32:47] indra_gpt.chat_curate.chat_curate - LLM call took 0.72 seconds\n",
      "\u001b[92m09:32:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:32:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:32:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:32:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:32:49] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.66 seconds\n",
      "\u001b[92m09:32:49 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:32:49] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:32:50] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:32:50 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:32:50] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:32:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:32:50] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:32:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:32:50] indra_gpt.chat_curate.chat_curate - LLM call took 0.88 seconds\n",
      "Curating statements with chat curation:  10%|‚ñà         | 9/89 [02:16<20:31, 15.39s/it]INFO: [2025-07-01 09:32:50] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:32:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:32:50] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:32:52] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.71 seconds\n",
      "\u001b[92m09:32:52 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:32:52] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:32:53] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:32:53 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:32:53] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:32:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:32:53] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:32:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:32:53] indra_gpt.chat_curate.chat_curate - LLM call took 0.91 seconds\n",
      "INFO: [2025-07-01 09:32:53] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:32:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:32:53] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:32:55] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.70 seconds\n",
      "\u001b[92m09:32:55 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:32:55] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:32:56] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:32:56 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:32:56] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:32:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:32:56] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:32:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:32:56] indra_gpt.chat_curate.chat_curate - LLM call took 0.72 seconds\n",
      "INFO: [2025-07-01 09:32:56] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:32:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:32:56] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:32:58] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.69 seconds\n",
      "\u001b[92m09:32:58 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:32:58] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:32:58] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:32:58 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:32:58] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:32:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:32:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:32:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:32:58] indra_gpt.chat_curate.chat_curate - LLM call took 0.66 seconds\n",
      "INFO: [2025-07-01 09:32:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:32:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:32:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:33:00] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.66 seconds\n",
      "\u001b[92m09:33:00 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:33:00] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:33:01] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:33:01 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:33:01] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:33:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:33:01] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:33:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:33:01] indra_gpt.chat_curate.chat_curate - LLM call took 0.85 seconds\n",
      "INFO: [2025-07-01 09:33:01] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:33:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:33:01] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:33:03] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.74 seconds\n",
      "\u001b[92m09:33:03 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:33:03] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:33:04] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:33:04 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:33:04] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:33:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:33:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:33:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:33:04] indra_gpt.chat_curate.chat_curate - LLM call took 0.68 seconds\n",
      "Curating statements with chat curation:  11%|‚ñà         | 10/89 [02:30<19:32, 14.85s/it]INFO: [2025-07-01 09:33:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:33:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:33:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:33:06] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.71 seconds\n",
      "\u001b[92m09:33:06 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:33:06] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:33:06] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:33:06 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:33:06] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:33:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:33:06] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:33:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:33:06] indra_gpt.chat_curate.chat_curate - LLM call took 0.70 seconds\n",
      "INFO: [2025-07-01 09:33:06] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:33:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:33:06] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:33:08] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.66 seconds\n",
      "\u001b[92m09:33:08 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:33:08] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:33:09] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:33:09 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:33:09] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:33:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:33:09] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:33:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:33:09] indra_gpt.chat_curate.chat_curate - LLM call took 0.83 seconds\n",
      "INFO: [2025-07-01 09:33:09] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:33:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:33:09] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:33:11] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.69 seconds\n",
      "\u001b[92m09:33:11 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:33:11] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:33:12] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:33:12 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:33:12] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:33:12 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:33:12] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:33:12 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:33:12] indra_gpt.chat_curate.chat_curate - LLM call took 0.58 seconds\n",
      "INFO: [2025-07-01 09:33:12] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:33:12 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:33:12] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:33:14] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.70 seconds\n",
      "\u001b[92m09:33:14 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:33:14] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:33:14] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:33:14 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:33:14] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:33:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:33:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:33:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:33:14] indra_gpt.chat_curate.chat_curate - LLM call took 0.60 seconds\n",
      "INFO: [2025-07-01 09:33:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:33:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:33:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:33:16] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.68 seconds\n",
      "\u001b[92m09:33:16 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:33:16] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:33:18] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:33:18 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:33:18] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:33:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:33:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:33:18] indra_gpt.chat_curate.chat_curate - LLM call took 1.54 seconds\n",
      "\u001b[92m09:33:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  12%|‚ñà‚ñè        | 11/89 [02:44<18:58, 14.59s/it]INFO: [2025-07-01 09:33:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:33:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:33:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:33:20] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.68 seconds\n",
      "\u001b[92m09:33:20 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:33:20] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:33:21] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:33:21 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:33:21] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:33:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:33:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:33:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:33:21] indra_gpt.chat_curate.chat_curate - LLM call took 0.87 seconds\n",
      "INFO: [2025-07-01 09:33:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:33:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:33:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:33:22] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.67 seconds\n",
      "\u001b[92m09:33:22 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:33:22] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:33:23] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:33:23 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:33:23] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:33:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:33:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:33:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:33:23] indra_gpt.chat_curate.chat_curate - LLM call took 0.76 seconds\n",
      "INFO: [2025-07-01 09:33:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:33:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:33:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:33:25] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.67 seconds\n",
      "\u001b[92m09:33:25 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:33:25] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:33:26] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:33:26 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:33:26] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:33:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:33:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:33:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:33:26] indra_gpt.chat_curate.chat_curate - LLM call took 0.68 seconds\n",
      "INFO: [2025-07-01 09:33:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:33:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:33:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:33:28] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.73 seconds\n",
      "\u001b[92m09:33:28 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:33:28] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:33:29] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:33:29 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:33:29] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:33:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:33:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:33:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:33:29] indra_gpt.chat_curate.chat_curate - LLM call took 0.74 seconds\n",
      "INFO: [2025-07-01 09:33:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:33:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:33:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:33:30] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.65 seconds\n",
      "\u001b[92m09:33:30 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:33:30] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:33:31] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:33:31 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:33:31] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:33:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:33:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:33:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:33:31] indra_gpt.chat_curate.chat_curate - LLM call took 0.55 seconds\n",
      "Curating statements with chat curation:  13%|‚ñà‚ñé        | 12/89 [02:57<18:13, 14.20s/it]INFO: [2025-07-01 09:33:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:33:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:33:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:33:33] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.66 seconds\n",
      "\u001b[92m09:33:33 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:33:33] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:33:34] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:33:34 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:33:34] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:33:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:33:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:33:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:33:34] indra_gpt.chat_curate.chat_curate - LLM call took 0.66 seconds\n",
      "INFO: [2025-07-01 09:33:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:33:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:33:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:33:35] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.68 seconds\n",
      "\u001b[92m09:33:36 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:33:36] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:33:36] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:33:36 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:33:36] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:33:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:33:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:33:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:33:36] indra_gpt.chat_curate.chat_curate - LLM call took 0.55 seconds\n",
      "INFO: [2025-07-01 09:33:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:33:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:33:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:33:38] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.69 seconds\n",
      "\u001b[92m09:33:38 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:33:38] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:33:39] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:33:39 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:33:39] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:33:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:33:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:33:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:33:39] indra_gpt.chat_curate.chat_curate - LLM call took 0.72 seconds\n",
      "INFO: [2025-07-01 09:33:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:33:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:33:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:33:41] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.70 seconds\n",
      "\u001b[92m09:33:41 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:33:41] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:33:41] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:33:41 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:33:41] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:33:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:33:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:33:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:33:41] indra_gpt.chat_curate.chat_curate - LLM call took 0.67 seconds\n",
      "INFO: [2025-07-01 09:33:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:33:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:33:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:33:43] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.74 seconds\n",
      "\u001b[92m09:33:43 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:33:43] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:33:44] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:33:44 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:33:44] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:33:44 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:33:44] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:33:44 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:33:44] indra_gpt.chat_curate.chat_curate - LLM call took 0.71 seconds\n",
      "Curating statements with chat curation:  15%|‚ñà‚ñç        | 13/89 [03:10<17:33, 13.86s/it]INFO: [2025-07-01 09:33:44] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:33:44 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:33:44] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:33:46] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.73 seconds\n",
      "\u001b[92m09:33:46 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:33:46] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:33:47] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:33:47 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:33:47] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:33:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:33:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:33:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:33:47] indra_gpt.chat_curate.chat_curate - LLM call took 0.64 seconds\n",
      "INFO: [2025-07-01 09:33:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:33:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:33:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:33:49] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.77 seconds\n",
      "\u001b[92m09:33:49 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:33:49] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:33:49] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:33:49 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:33:49] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:33:49 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:33:49] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:33:49 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:33:49] indra_gpt.chat_curate.chat_curate - LLM call took 0.69 seconds\n",
      "INFO: [2025-07-01 09:33:49] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:33:49 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:33:49] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:33:51] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.78 seconds\n",
      "\u001b[92m09:33:51 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:33:51] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:33:52] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:33:52 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:33:52] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:33:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:33:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:33:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:33:52] indra_gpt.chat_curate.chat_curate - LLM call took 0.80 seconds\n",
      "INFO: [2025-07-01 09:33:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:33:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:33:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:33:54] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.75 seconds\n",
      "\u001b[92m09:33:54 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:33:54] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:33:55] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:33:55 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:33:55] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:33:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:33:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:33:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:33:55] indra_gpt.chat_curate.chat_curate - LLM call took 0.65 seconds\n",
      "INFO: [2025-07-01 09:33:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:33:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:33:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:33:57] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.72 seconds\n",
      "\u001b[92m09:33:57 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:33:57] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:33:58] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:33:58 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:33:58] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:33:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:33:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:33:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:33:58] indra_gpt.chat_curate.chat_curate - LLM call took 0.64 seconds\n",
      "Curating statements with chat curation:  16%|‚ñà‚ñå        | 14/89 [03:24<17:11, 13.76s/it]INFO: [2025-07-01 09:33:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:33:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:33:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:34:00] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.77 seconds\n",
      "\u001b[92m09:34:00 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:34:00] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:34:00] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:34:00 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:34:00] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:34:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:34:00] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:34:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:34:00] indra_gpt.chat_curate.chat_curate - LLM call took 0.68 seconds\n",
      "INFO: [2025-07-01 09:34:00] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:34:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:34:00] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:34:02] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.68 seconds\n",
      "\u001b[92m09:34:02 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:34:02] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:34:03] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:34:03 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:34:03] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:34:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:34:03] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:34:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:34:03] indra_gpt.chat_curate.chat_curate - LLM call took 0.59 seconds\n",
      "INFO: [2025-07-01 09:34:03] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:34:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:34:03] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:34:05] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.70 seconds\n",
      "\u001b[92m09:34:05 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:34:05] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:34:06] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:34:06 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:34:06] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:34:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:34:06] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:34:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:34:06] indra_gpt.chat_curate.chat_curate - LLM call took 0.86 seconds\n",
      "INFO: [2025-07-01 09:34:06] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:34:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:34:06] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:34:08] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.66 seconds\n",
      "\u001b[92m09:34:08 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:34:08] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:34:08] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:34:08 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:34:08] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:34:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:34:08] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:34:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:34:08] indra_gpt.chat_curate.chat_curate - LLM call took 0.75 seconds\n",
      "INFO: [2025-07-01 09:34:08] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:34:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:34:08] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:34:10] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.67 seconds\n",
      "\u001b[92m09:34:10 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:34:10] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:34:11] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:34:11 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:34:11] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:34:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:34:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:34:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:34:11] indra_gpt.chat_curate.chat_curate - LLM call took 0.72 seconds\n",
      "Curating statements with chat curation:  17%|‚ñà‚ñã        | 15/89 [03:37<16:50, 13.65s/it]INFO: [2025-07-01 09:34:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:34:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:34:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:34:13] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.68 seconds\n",
      "\u001b[92m09:34:13 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:34:13] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:34:14] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:34:14 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:34:14] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:34:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:34:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:34:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:34:14] indra_gpt.chat_curate.chat_curate - LLM call took 0.63 seconds\n",
      "INFO: [2025-07-01 09:34:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:34:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:34:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:34:16] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.68 seconds\n",
      "\u001b[92m09:34:16 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:34:16] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:34:16] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:34:16 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:34:16] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:34:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:34:16] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:34:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:34:16] indra_gpt.chat_curate.chat_curate - LLM call took 0.71 seconds\n",
      "INFO: [2025-07-01 09:34:16] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:34:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:34:16] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:34:18] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.66 seconds\n",
      "\u001b[92m09:34:18 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:34:18] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:34:19] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:34:19 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:34:19] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:34:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:34:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:34:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:34:19] indra_gpt.chat_curate.chat_curate - LLM call took 0.68 seconds\n",
      "INFO: [2025-07-01 09:34:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:34:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:34:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:34:21] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.67 seconds\n",
      "\u001b[92m09:34:21 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:34:21] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:34:21] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:34:21 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:34:21] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:34:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:34:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:34:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:34:21] indra_gpt.chat_curate.chat_curate - LLM call took 0.70 seconds\n",
      "INFO: [2025-07-01 09:34:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:34:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:34:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:34:23] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.70 seconds\n",
      "\u001b[92m09:34:23 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:34:23] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:34:24] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:34:24 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:34:24] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:34:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:34:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:34:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:34:24] indra_gpt.chat_curate.chat_curate - LLM call took 0.54 seconds\n",
      "Curating statements with chat curation:  18%|‚ñà‚ñä        | 16/89 [03:50<16:21, 13.44s/it]INFO: [2025-07-01 09:34:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:34:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:34:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:34:26] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.83 seconds\n",
      "\u001b[92m09:34:26 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:34:26] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:34:27] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:34:27 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:34:27] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:34:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:34:27] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:34:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:34:27] indra_gpt.chat_curate.chat_curate - LLM call took 0.72 seconds\n",
      "INFO: [2025-07-01 09:34:27] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:34:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:34:27] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:34:29] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.74 seconds\n",
      "\u001b[92m09:34:29 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:34:29] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:34:29] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:34:29 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:34:29] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:34:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:34:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:34:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:34:29] indra_gpt.chat_curate.chat_curate - LLM call took 0.56 seconds\n",
      "INFO: [2025-07-01 09:34:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:34:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:34:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:34:31] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.79 seconds\n",
      "\u001b[92m09:34:31 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:34:31] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:34:36] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:34:36 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:34:36] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:34:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:34:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:34:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:34:36] indra_gpt.chat_curate.chat_curate - LLM call took 4.78 seconds\n",
      "INFO: [2025-07-01 09:34:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:34:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:34:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:34:38] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.72 seconds\n",
      "\u001b[92m09:34:38 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:34:38] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:34:39] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:34:39 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:34:39] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:34:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:34:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:34:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:34:39] indra_gpt.chat_curate.chat_curate - LLM call took 0.61 seconds\n",
      "INFO: [2025-07-01 09:34:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:34:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:34:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:34:41] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.79 seconds\n",
      "\u001b[92m09:34:41 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:34:41] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:34:41] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:34:41 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:34:41] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:34:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:34:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:34:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:34:41] indra_gpt.chat_curate.chat_curate - LLM call took 0.71 seconds\n",
      "Curating statements with chat curation:  19%|‚ñà‚ñâ        | 17/89 [04:08<17:36, 14.68s/it]INFO: [2025-07-01 09:34:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:34:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:34:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:34:43] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.68 seconds\n",
      "\u001b[92m09:34:43 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:34:43] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:34:44] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:34:44 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:34:44] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:34:44 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:34:44] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:34:44 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:34:44] indra_gpt.chat_curate.chat_curate - LLM call took 0.61 seconds\n",
      "INFO: [2025-07-01 09:34:44] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:34:44 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:34:44] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:34:46] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.69 seconds\n",
      "\u001b[92m09:34:46 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:34:46] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:34:47] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:34:47 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:34:47] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:34:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:34:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:34:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:34:47] indra_gpt.chat_curate.chat_curate - LLM call took 0.58 seconds\n",
      "INFO: [2025-07-01 09:34:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:34:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:34:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:34:49] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.68 seconds\n",
      "\u001b[92m09:34:49 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:34:49] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:34:49] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:34:49 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:34:49] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:34:49 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:34:49] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:34:49 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:34:49] indra_gpt.chat_curate.chat_curate - LLM call took 0.78 seconds\n",
      "INFO: [2025-07-01 09:34:49] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:34:49 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:34:49] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:34:51] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.67 seconds\n",
      "\u001b[92m09:34:51 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:34:51] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:34:52] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:34:52 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:34:52] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:34:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:34:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:34:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:34:52] indra_gpt.chat_curate.chat_curate - LLM call took 0.61 seconds\n",
      "INFO: [2025-07-01 09:34:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:34:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:34:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:34:54] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.68 seconds\n",
      "\u001b[92m09:34:54 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:34:54] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:34:54] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:34:54 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:34:54] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:34:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:34:54] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:34:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:34:54] indra_gpt.chat_curate.chat_curate - LLM call took 0.59 seconds\n",
      "Curating statements with chat curation:  20%|‚ñà‚ñà        | 18/89 [04:21<16:43, 14.14s/it]INFO: [2025-07-01 09:34:54] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:34:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:34:54] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:34:56] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.72 seconds\n",
      "\u001b[92m09:34:56 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:34:56] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:34:58] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:34:58 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:34:58] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:34:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:34:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:34:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:34:58] indra_gpt.chat_curate.chat_curate - LLM call took 1.52 seconds\n",
      "INFO: [2025-07-01 09:34:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:34:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:34:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:35:00] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.69 seconds\n",
      "\u001b[92m09:35:00 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:35:00] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:35:01] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:35:01 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:35:01] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:35:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:35:01] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:35:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:35:01] indra_gpt.chat_curate.chat_curate - LLM call took 1.03 seconds\n",
      "INFO: [2025-07-01 09:35:01] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:35:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:35:01] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:35:03] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.66 seconds\n",
      "\u001b[92m09:35:03 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:35:03] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:35:03] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:35:03 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:35:03] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:35:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:35:03] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:35:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:35:03] indra_gpt.chat_curate.chat_curate - LLM call took 0.66 seconds\n",
      "INFO: [2025-07-01 09:35:03] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:35:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:35:03] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:35:05] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.73 seconds\n",
      "\u001b[92m09:35:05 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:35:05] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:35:06] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:35:06 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:35:06] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:35:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:35:06] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:35:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:35:06] indra_gpt.chat_curate.chat_curate - LLM call took 0.51 seconds\n",
      "INFO: [2025-07-01 09:35:06] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:35:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:35:06] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:35:08] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.71 seconds\n",
      "\u001b[92m09:35:08 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:35:08] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:35:08] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:35:08 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:35:08] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:35:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:35:08] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:35:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:35:08] indra_gpt.chat_curate.chat_curate - LLM call took 0.50 seconds\n",
      "Curating statements with chat curation:  21%|‚ñà‚ñà‚ñè       | 19/89 [04:35<16:27, 14.11s/it]INFO: [2025-07-01 09:35:08] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:35:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:35:08] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:35:10] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.70 seconds\n",
      "\u001b[92m09:35:10 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:35:10] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:35:11] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:35:11 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:35:11] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:35:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:35:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:35:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:35:11] indra_gpt.chat_curate.chat_curate - LLM call took 0.70 seconds\n",
      "INFO: [2025-07-01 09:35:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:35:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:35:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:35:13] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.69 seconds\n",
      "\u001b[92m09:35:13 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:35:13] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:35:14] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:35:14 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:35:14] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:35:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:35:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:35:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:35:14] indra_gpt.chat_curate.chat_curate - LLM call took 1.44 seconds\n",
      "INFO: [2025-07-01 09:35:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:35:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:35:15] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:35:16] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.68 seconds\n",
      "\u001b[92m09:35:16 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:35:16] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:35:17] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:35:17 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:35:17] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:35:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:35:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:35:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:35:17] indra_gpt.chat_curate.chat_curate - LLM call took 0.91 seconds\n",
      "INFO: [2025-07-01 09:35:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:35:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:35:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:35:19] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.69 seconds\n",
      "\u001b[92m09:35:19 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:35:19] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:35:20] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:35:20 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:35:20] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:35:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:35:20] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:35:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:35:20] indra_gpt.chat_curate.chat_curate - LLM call took 0.73 seconds\n",
      "INFO: [2025-07-01 09:35:20] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:35:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:35:20] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:35:22] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.74 seconds\n",
      "\u001b[92m09:35:22 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:35:22] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:35:23] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:35:23 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:35:23] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:35:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:35:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:35:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:35:23] indra_gpt.chat_curate.chat_curate - LLM call took 0.65 seconds\n",
      "Curating statements with chat curation:  22%|‚ñà‚ñà‚ñè       | 20/89 [04:49<16:16, 14.15s/it]INFO: [2025-07-01 09:35:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:35:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:35:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:35:25] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.75 seconds\n",
      "\u001b[92m09:35:25 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:35:25] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:35:25] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:35:25 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:35:25] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:35:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:35:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:35:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:35:25] indra_gpt.chat_curate.chat_curate - LLM call took 0.68 seconds\n",
      "INFO: [2025-07-01 09:35:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:35:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:35:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:35:28] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.91 seconds\n",
      "\u001b[92m09:35:28 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:35:28] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:35:28] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:35:28 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:35:28] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:35:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:35:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:35:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:35:28] indra_gpt.chat_curate.chat_curate - LLM call took 0.67 seconds\n",
      "INFO: [2025-07-01 09:35:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:35:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:35:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:35:30] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.97 seconds\n",
      "\u001b[92m09:35:30 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:35:30] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:35:31] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:35:31 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:35:31] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:35:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:35:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:35:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:35:31] indra_gpt.chat_curate.chat_curate - LLM call took 0.75 seconds\n",
      "INFO: [2025-07-01 09:35:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:35:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:35:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:35:33] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.96 seconds\n",
      "\u001b[92m09:35:33 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:35:33] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:35:34] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:35:34 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:35:34] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:35:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:35:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:35:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:35:34] indra_gpt.chat_curate.chat_curate - LLM call took 0.67 seconds\n",
      "INFO: [2025-07-01 09:35:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:35:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:35:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:35:36] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.79 seconds\n",
      "\u001b[92m09:35:36 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:35:36] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:35:37] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:35:37 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:35:37] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:35:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:35:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:35:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:35:37] indra_gpt.chat_curate.chat_curate - LLM call took 0.98 seconds\n",
      "Curating statements with chat curation:  24%|‚ñà‚ñà‚ñé       | 21/89 [05:03<16:08, 14.24s/it]INFO: [2025-07-01 09:35:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:35:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:35:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:35:39] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.79 seconds\n",
      "\u001b[92m09:35:39 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:35:39] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:35:40] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:35:40 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:35:40] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:35:40 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:35:40] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:35:40 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:35:40] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:35:40 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:35:40] indra_gpt.chat_curate.chat_curate - LLM call took 0.70 seconds\n",
      "INFO: [2025-07-01 09:35:40] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:35:42] indra_gpt.chat_curate.chat_curate - Prompt generation took 2.14 seconds\n",
      "\u001b[92m09:35:42 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:35:42] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:35:43] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:35:43 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:35:43] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:35:43 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:35:43] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:35:43 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:35:43] indra_gpt.chat_curate.chat_curate - LLM call took 0.76 seconds\n",
      "INFO: [2025-07-01 09:35:43] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:35:43 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:35:43] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:35:45] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.94 seconds\n",
      "\u001b[92m09:35:45 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:35:45] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:35:46] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:35:46 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:35:46] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:35:46 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:35:46] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:35:46 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:35:46] indra_gpt.chat_curate.chat_curate - LLM call took 0.71 seconds\n",
      "INFO: [2025-07-01 09:35:46] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:35:46 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:35:46] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:35:48] indra_gpt.chat_curate.chat_curate - Prompt generation took 2.03 seconds\n",
      "\u001b[92m09:35:48 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:35:48] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:35:49] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:35:49 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:35:49] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:35:49 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:35:49] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:35:49 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:35:49] indra_gpt.chat_curate.chat_curate - LLM call took 0.65 seconds\n",
      "INFO: [2025-07-01 09:35:49] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:35:49 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:35:49] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:35:51] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.88 seconds\n",
      "\u001b[92m09:35:51 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:35:51] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:35:52] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:35:52 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:35:52] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:35:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:35:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:35:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:35:52] indra_gpt.chat_curate.chat_curate - LLM call took 0.81 seconds\n",
      "Curating statements with chat curation:  25%|‚ñà‚ñà‚ñç       | 22/89 [05:18<16:04, 14.39s/it]INFO: [2025-07-01 09:35:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:35:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:35:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:35:54] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.86 seconds\n",
      "\u001b[92m09:35:54 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:35:54] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:35:55] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:35:55 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:35:55] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:35:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:35:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:35:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:35:55] indra_gpt.chat_curate.chat_curate - LLM call took 0.89 seconds\n",
      "INFO: [2025-07-01 09:35:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:35:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:35:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:35:57] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.74 seconds\n",
      "\u001b[92m09:35:57 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:35:57] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:35:57] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:35:57 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:35:57] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:35:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:35:57] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:35:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:35:57] indra_gpt.chat_curate.chat_curate - LLM call took 0.57 seconds\n",
      "INFO: [2025-07-01 09:35:57] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:35:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:35:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:35:59] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.66 seconds\n",
      "\u001b[92m09:35:59 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:35:59] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:36:00] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:36:00 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:36:00] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:36:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:36:00] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:36:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:36:00] indra_gpt.chat_curate.chat_curate - LLM call took 0.81 seconds\n",
      "INFO: [2025-07-01 09:36:00] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:36:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:36:00] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:36:02] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.74 seconds\n",
      "\u001b[92m09:36:02 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:36:02] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:36:03] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:36:03 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:36:03] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:36:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:36:03] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:36:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:36:03] indra_gpt.chat_curate.chat_curate - LLM call took 0.57 seconds\n",
      "INFO: [2025-07-01 09:36:03] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:36:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:36:03] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:36:05] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.73 seconds\n",
      "\u001b[92m09:36:05 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:36:05] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:36:06] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:36:06 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:36:06] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:36:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:36:06] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:36:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:36:06] indra_gpt.chat_curate.chat_curate - LLM call took 0.82 seconds\n",
      "Curating statements with chat curation:  26%|‚ñà‚ñà‚ñå       | 23/89 [05:32<15:36, 14.19s/it]INFO: [2025-07-01 09:36:06] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:36:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:36:06] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:36:07] indra_gpt.chat_curate.chat_curate - Prompt generation took 0.91 seconds\n",
      "\u001b[92m09:36:07 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:36:07] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:36:07] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:36:07 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:36:07] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:36:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:36:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:36:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:36:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:36:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:36:07] indra_gpt.chat_curate.chat_curate - LLM call took 0.55 seconds\n",
      "INFO: [2025-07-01 09:36:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:36:08] indra_gpt.chat_curate.chat_curate - Prompt generation took 0.91 seconds\n",
      "\u001b[92m09:36:08 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:36:08] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:36:09] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:36:09 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:36:09] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:36:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:36:09] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:36:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:36:09] indra_gpt.chat_curate.chat_curate - LLM call took 0.79 seconds\n",
      "INFO: [2025-07-01 09:36:09] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:36:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:36:09] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:36:10] indra_gpt.chat_curate.chat_curate - Prompt generation took 0.91 seconds\n",
      "\u001b[92m09:36:10 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:36:10] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:36:12] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:36:12 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:36:12] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:36:12 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:36:12] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:36:12 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:36:12] indra_gpt.chat_curate.chat_curate - LLM call took 1.30 seconds\n",
      "INFO: [2025-07-01 09:36:12] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:36:12 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:36:12] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:36:13] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.24 seconds\n",
      "\u001b[92m09:36:13 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:36:13] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:36:14] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:36:14 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:36:14] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:36:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:36:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:36:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:36:14] indra_gpt.chat_curate.chat_curate - LLM call took 0.54 seconds\n",
      "INFO: [2025-07-01 09:36:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:36:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:36:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:36:15] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.05 seconds\n",
      "\u001b[92m09:36:15 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:36:15] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:36:16] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:36:16 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:36:16] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:36:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:36:16] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:36:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:36:16] indra_gpt.chat_curate.chat_curate - LLM call took 1.31 seconds\n",
      "Curating statements with chat curation:  27%|‚ñà‚ñà‚ñã       | 24/89 [05:43<14:16, 13.17s/it]INFO: [2025-07-01 09:36:16] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:36:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:36:16] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:36:19] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.88 seconds\n",
      "\u001b[92m09:36:19 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:36:19] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:36:19] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:36:19 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:36:19] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:36:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:36:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:36:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:36:19] indra_gpt.chat_curate.chat_curate - LLM call took 0.92 seconds\n",
      "INFO: [2025-07-01 09:36:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:36:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:36:20] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:36:22] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.96 seconds\n",
      "\u001b[92m09:36:22 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:36:22] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:36:22] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:36:22 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:36:22] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:36:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:36:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:36:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:36:22] indra_gpt.chat_curate.chat_curate - LLM call took 0.54 seconds\n",
      "INFO: [2025-07-01 09:36:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:36:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:36:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:36:24] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.86 seconds\n",
      "\u001b[92m09:36:24 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:36:24] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:36:25] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:36:25 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:36:25] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:36:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:36:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:36:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:36:25] indra_gpt.chat_curate.chat_curate - LLM call took 0.69 seconds\n",
      "INFO: [2025-07-01 09:36:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:36:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:36:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:36:28] indra_gpt.chat_curate.chat_curate - Prompt generation took 2.41 seconds\n",
      "\u001b[92m09:36:28 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:36:28] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:36:29] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:36:29 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:36:29] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:36:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:36:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:36:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:36:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:36:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:36:29] indra_gpt.chat_curate.chat_curate - LLM call took 1.10 seconds\n",
      "INFO: [2025-07-01 09:36:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:36:31] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.78 seconds\n",
      "\u001b[92m09:36:31 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:36:31] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:36:31] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:36:31 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:36:31] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:36:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:36:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:36:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:36:31] indra_gpt.chat_curate.chat_curate - LLM call took 0.61 seconds\n",
      "Curating statements with chat curation:  28%|‚ñà‚ñà‚ñä       | 25/89 [05:58<14:40, 13.75s/it]INFO: [2025-07-01 09:36:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:36:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:36:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:36:34] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.94 seconds\n",
      "\u001b[92m09:36:34 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:36:34] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:36:35] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:36:35 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:36:35] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:36:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:36:35] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:36:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:36:35] indra_gpt.chat_curate.chat_curate - LLM call took 1.14 seconds\n",
      "INFO: [2025-07-01 09:36:35] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:36:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:36:35] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:36:37] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.96 seconds\n",
      "\u001b[92m09:36:37 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:36:37] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:36:38] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:36:38 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:36:38] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:36:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:36:38] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:36:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:36:38] indra_gpt.chat_curate.chat_curate - LLM call took 0.73 seconds\n",
      "INFO: [2025-07-01 09:36:38] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:36:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:36:38] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:36:40] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.73 seconds\n",
      "\u001b[92m09:36:40 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:36:40] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:36:41] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:36:41 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:36:41] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:36:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:36:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:36:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:36:41] indra_gpt.chat_curate.chat_curate - LLM call took 0.78 seconds\n",
      "INFO: [2025-07-01 09:36:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:36:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:36:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:36:43] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.73 seconds\n",
      "\u001b[92m09:36:43 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:36:43] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:36:43] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:36:43 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:36:43] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:36:43 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:36:43] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:36:43 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:36:43] indra_gpt.chat_curate.chat_curate - LLM call took 0.66 seconds\n",
      "INFO: [2025-07-01 09:36:43] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:36:43 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:36:43] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:36:45] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.78 seconds\n",
      "\u001b[92m09:36:45 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:36:45] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:36:46] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:36:46 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:36:46] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:36:46 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:36:46] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:36:46 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:36:46] indra_gpt.chat_curate.chat_curate - LLM call took 0.68 seconds\n",
      "Curating statements with chat curation:  29%|‚ñà‚ñà‚ñâ       | 26/89 [06:12<14:39, 13.96s/it]INFO: [2025-07-01 09:36:46] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:36:46 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:36:46] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:36:48] indra_gpt.chat_curate.chat_curate - Prompt generation took 2.03 seconds\n",
      "\u001b[92m09:36:48 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:36:48] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:36:49] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:36:49 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:36:49] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:36:49 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:36:49] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:36:49 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:36:49] indra_gpt.chat_curate.chat_curate - LLM call took 0.89 seconds\n",
      "INFO: [2025-07-01 09:36:49] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:36:49 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:36:49] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:36:51] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.87 seconds\n",
      "\u001b[92m09:36:51 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:36:51] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:36:52] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:36:52 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:36:52] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:36:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:36:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:36:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:36:52] indra_gpt.chat_curate.chat_curate - LLM call took 0.72 seconds\n",
      "INFO: [2025-07-01 09:36:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:36:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:36:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:36:54] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.70 seconds\n",
      "\u001b[92m09:36:54 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:36:54] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:36:55] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:36:55 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:36:55] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:36:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:36:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:36:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:36:55] indra_gpt.chat_curate.chat_curate - LLM call took 0.60 seconds\n",
      "INFO: [2025-07-01 09:36:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:36:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:36:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:36:56] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.66 seconds\n",
      "\u001b[92m09:36:56 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:36:56] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:36:57] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:36:57 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:36:57] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:36:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:36:57] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:36:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:36:57] indra_gpt.chat_curate.chat_curate - LLM call took 0.67 seconds\n",
      "INFO: [2025-07-01 09:36:57] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:36:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:36:57] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:36:59] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.71 seconds\n",
      "\u001b[92m09:36:59 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:36:59] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:37:00] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:37:00 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:37:00] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:37:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:37:00] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:37:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:37:00] indra_gpt.chat_curate.chat_curate - LLM call took 0.70 seconds\n",
      "Curating statements with chat curation:  30%|‚ñà‚ñà‚ñà       | 27/89 [06:26<14:24, 13.94s/it]INFO: [2025-07-01 09:37:00] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:37:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:37:00] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:37:02] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.73 seconds\n",
      "\u001b[92m09:37:02 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:37:02] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:37:02] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:37:03 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:37:03] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:37:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:37:03] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:37:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:37:03] indra_gpt.chat_curate.chat_curate - LLM call took 0.67 seconds\n",
      "INFO: [2025-07-01 09:37:03] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:37:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:37:03] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:37:04] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.69 seconds\n",
      "\u001b[92m09:37:04 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:37:04] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:37:05] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:37:05 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:37:05] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:37:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:37:05] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:37:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:37:05] indra_gpt.chat_curate.chat_curate - LLM call took 0.62 seconds\n",
      "INFO: [2025-07-01 09:37:05] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:37:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:37:05] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:37:07] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.68 seconds\n",
      "\u001b[92m09:37:07 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:37:07] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:37:08] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:37:08 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:37:08] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:37:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:37:08] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:37:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:37:08] indra_gpt.chat_curate.chat_curate - LLM call took 0.64 seconds\n",
      "INFO: [2025-07-01 09:37:08] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:37:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:37:08] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:37:10] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.67 seconds\n",
      "\u001b[92m09:37:10 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:37:10] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:37:10] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:37:10 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:37:10] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:37:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:37:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:37:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:37:10] indra_gpt.chat_curate.chat_curate - LLM call took 0.64 seconds\n",
      "INFO: [2025-07-01 09:37:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:37:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:37:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:37:12] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.73 seconds\n",
      "\u001b[92m09:37:12 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:37:12] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:37:13] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:37:13 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:37:13] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:37:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:37:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:37:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:37:13] indra_gpt.chat_curate.chat_curate - LLM call took 0.58 seconds\n",
      "Curating statements with chat curation:  31%|‚ñà‚ñà‚ñà‚ñè      | 28/89 [06:39<13:52, 13.65s/it]INFO: [2025-07-01 09:37:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:37:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:37:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:37:15] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.66 seconds\n",
      "\u001b[92m09:37:15 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:37:15] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:37:15] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:37:15 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:37:15] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:37:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:37:15] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:37:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:37:15] indra_gpt.chat_curate.chat_curate - LLM call took 0.71 seconds\n",
      "INFO: [2025-07-01 09:37:15] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:37:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:37:16] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:37:17] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.71 seconds\n",
      "\u001b[92m09:37:17 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:37:17] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:37:18] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:37:18 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:37:18] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:37:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:37:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:37:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:37:18] indra_gpt.chat_curate.chat_curate - LLM call took 0.70 seconds\n",
      "INFO: [2025-07-01 09:37:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:37:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:37:18] indra_gpt.chat_curate.chat_curate - Skipping evidence with no text for statement 14461478333067931: Evidence(source_api='ubibrowser',\n",
      "         annotations={\n",
      "                      \"agents\": {\n",
      "                       \"raw_text\": [\n",
      "                        null,\n",
      "                        null\n",
      "                       ]\n",
      "                      },\n",
      "                      \"prior_uuids\": [\n",
      "                       \"8770d509-ea4a-43af-a5cd-c5e65c0fe4e1\"\n",
      "                      ]\n",
      "                     }\n",
      "         )\n",
      "\n",
      "\n",
      "INFO: [2025-07-01 09:37:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:37:20] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.70 seconds\n",
      "\u001b[92m09:37:20 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:37:20] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:37:21] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:37:21 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:37:21] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:37:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:37:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:37:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:37:21] indra_gpt.chat_curate.chat_curate - LLM call took 0.70 seconds\n",
      "INFO: [2025-07-01 09:37:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:37:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:37:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:37:23] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.73 seconds\n",
      "\u001b[92m09:37:23 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:37:23] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:37:24] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:37:24 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:37:24] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:37:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:37:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:37:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:37:24] indra_gpt.chat_curate.chat_curate - LLM call took 0.84 seconds\n",
      "Curating statements with chat curation:  33%|‚ñà‚ñà‚ñà‚ñé      | 29/89 [06:50<12:47, 12.80s/it]INFO: [2025-07-01 09:37:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:37:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:37:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:37:26] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.74 seconds\n",
      "\u001b[92m09:37:26 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:37:26] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:37:26] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:37:26 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:37:26] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:37:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:37:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:37:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:37:26] indra_gpt.chat_curate.chat_curate - LLM call took 0.65 seconds\n",
      "INFO: [2025-07-01 09:37:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:37:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:37:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:37:28] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.68 seconds\n",
      "\u001b[92m09:37:28 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:37:28] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:37:29] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:37:29 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:37:29] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:37:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:37:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:37:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:37:29] indra_gpt.chat_curate.chat_curate - LLM call took 0.60 seconds\n",
      "INFO: [2025-07-01 09:37:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:37:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:37:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:37:31] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.70 seconds\n",
      "\u001b[92m09:37:31 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:37:31] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:37:31] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:37:31 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:37:31] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:37:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:37:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:37:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:37:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:37:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:37:31] indra_gpt.chat_curate.chat_curate - LLM call took 0.58 seconds\n",
      "INFO: [2025-07-01 09:37:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:37:33] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.70 seconds\n",
      "\u001b[92m09:37:33 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:37:33] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:37:34] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:37:34 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:37:34] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:37:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:37:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:37:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:37:34] indra_gpt.chat_curate.chat_curate - LLM call took 0.57 seconds\n",
      "INFO: [2025-07-01 09:37:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:37:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:37:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:37:36] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.67 seconds\n",
      "\u001b[92m09:37:36 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:37:36] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:37:37] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:37:37 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:37:37] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:37:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:37:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:37:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:37:37] indra_gpt.chat_curate.chat_curate - LLM call took 0.72 seconds\n",
      "Curating statements with chat curation:  34%|‚ñà‚ñà‚ñà‚ñé      | 30/89 [07:03<12:37, 12.84s/it]INFO: [2025-07-01 09:37:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:37:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:37:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:37:38] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.67 seconds\n",
      "\u001b[92m09:37:38 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:37:38] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:37:39] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:37:39 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:37:39] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:37:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:37:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:37:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:37:39] indra_gpt.chat_curate.chat_curate - LLM call took 0.68 seconds\n",
      "INFO: [2025-07-01 09:37:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:37:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:37:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:37:41] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.69 seconds\n",
      "\u001b[92m09:37:41 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:37:41] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:37:42] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:37:42 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:37:42] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:37:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:37:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:37:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:37:42] indra_gpt.chat_curate.chat_curate - LLM call took 0.62 seconds\n",
      "INFO: [2025-07-01 09:37:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:37:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:37:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:37:44] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.65 seconds\n",
      "\u001b[92m09:37:44 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:37:44] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:37:44] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:37:44 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:37:44] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:37:44 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:37:44] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:37:44 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:37:44] indra_gpt.chat_curate.chat_curate - LLM call took 0.75 seconds\n",
      "INFO: [2025-07-01 09:37:44] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:37:44 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:37:44] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:37:46] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.67 seconds\n",
      "\u001b[92m09:37:46 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:37:46] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:37:47] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:37:47 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:37:47] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:37:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:37:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:37:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:37:47] indra_gpt.chat_curate.chat_curate - LLM call took 0.64 seconds\n",
      "INFO: [2025-07-01 09:37:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:37:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:37:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:37:49] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.67 seconds\n",
      "\u001b[92m09:37:49 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:37:49] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:37:50] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:37:50 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:37:50] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:37:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:37:50] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:37:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:37:50] indra_gpt.chat_curate.chat_curate - LLM call took 0.67 seconds\n",
      "Curating statements with chat curation:  35%|‚ñà‚ñà‚ñà‚ñç      | 31/89 [07:16<12:28, 12.91s/it]INFO: [2025-07-01 09:37:50] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:37:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:37:50] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:37:52] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.71 seconds\n",
      "\u001b[92m09:37:52 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:37:52] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:37:52] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:37:52 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:37:52] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:37:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:37:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:37:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:37:52] indra_gpt.chat_curate.chat_curate - LLM call took 0.60 seconds\n",
      "INFO: [2025-07-01 09:37:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:37:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:37:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:37:54] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.75 seconds\n",
      "\u001b[92m09:37:54 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:37:54] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:37:55] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:37:55 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:37:55] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:37:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:37:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:37:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:37:55] indra_gpt.chat_curate.chat_curate - LLM call took 0.55 seconds\n",
      "INFO: [2025-07-01 09:37:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:37:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:37:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:37:57] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.73 seconds\n",
      "\u001b[92m09:37:57 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:37:57] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:37:58] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:37:58 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:37:58] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:37:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:37:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:37:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:37:58] indra_gpt.chat_curate.chat_curate - LLM call took 1.01 seconds\n",
      "INFO: [2025-07-01 09:37:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:37:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:37:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:38:00] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.75 seconds\n",
      "\u001b[92m09:38:00 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:38:00] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:38:00] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:38:00 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:38:00] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:38:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:38:00] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:38:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:38:00] indra_gpt.chat_curate.chat_curate - LLM call took 0.68 seconds\n",
      "INFO: [2025-07-01 09:38:00] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:38:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:38:00] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:38:02] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.73 seconds\n",
      "\u001b[92m09:38:02 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:38:02] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:38:03] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:38:03 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:38:03] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:38:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:38:03] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:38:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:38:03] indra_gpt.chat_curate.chat_curate - LLM call took 0.66 seconds\n",
      "Curating statements with chat curation:  36%|‚ñà‚ñà‚ñà‚ñå      | 32/89 [07:29<12:26, 13.09s/it]INFO: [2025-07-01 09:38:03] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:38:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:38:03] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:38:04] indra_gpt.chat_curate.chat_curate - Prompt generation took 0.95 seconds\n",
      "\u001b[92m09:38:04 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:38:04] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:38:05] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:38:05 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:38:05] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:38:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:38:05] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:38:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:38:05] indra_gpt.chat_curate.chat_curate - LLM call took 0.84 seconds\n",
      "INFO: [2025-07-01 09:38:05] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:38:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:38:05] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:38:06] indra_gpt.chat_curate.chat_curate - Prompt generation took 0.92 seconds\n",
      "\u001b[92m09:38:06 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:38:06] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:38:07] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:38:07 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:38:07] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:38:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:38:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:38:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:38:07] indra_gpt.chat_curate.chat_curate - LLM call took 0.74 seconds\n",
      "INFO: [2025-07-01 09:38:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:38:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:38:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:38:08] indra_gpt.chat_curate.chat_curate - Prompt generation took 0.91 seconds\n",
      "\u001b[92m09:38:08 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:38:08] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:38:09] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:38:09 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:38:09] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:38:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:38:09] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:38:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:38:09] indra_gpt.chat_curate.chat_curate - LLM call took 0.57 seconds\n",
      "INFO: [2025-07-01 09:38:09] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:38:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:38:09] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:38:10] indra_gpt.chat_curate.chat_curate - Prompt generation took 0.90 seconds\n",
      "\u001b[92m09:38:10 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:38:10] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:38:11] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:38:11 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:38:11] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:38:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:38:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:38:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:38:11] indra_gpt.chat_curate.chat_curate - LLM call took 0.59 seconds\n",
      "INFO: [2025-07-01 09:38:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:38:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:38:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:38:12] indra_gpt.chat_curate.chat_curate - Prompt generation took 0.90 seconds\n",
      "\u001b[92m09:38:12 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:38:12] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:38:12] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:38:12 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:38:12] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:38:12 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:38:12] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:38:12 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:38:12] indra_gpt.chat_curate.chat_curate - LLM call took 0.58 seconds\n",
      "Curating statements with chat curation:  37%|‚ñà‚ñà‚ñà‚ñã      | 33/89 [07:39<11:08, 11.93s/it]INFO: [2025-07-01 09:38:12] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:38:12 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:38:12] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:38:14] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.72 seconds\n",
      "\u001b[92m09:38:14 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:38:14] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:38:15] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:38:15 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:38:15] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:38:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:38:15] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:38:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:38:15] indra_gpt.chat_curate.chat_curate - LLM call took 0.68 seconds\n",
      "INFO: [2025-07-01 09:38:15] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:38:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:38:15] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:38:17] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.65 seconds\n",
      "\u001b[92m09:38:17 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:38:17] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:38:18] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:38:18 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:38:18] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:38:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:38:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:38:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:38:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:38:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:38:18] indra_gpt.chat_curate.chat_curate - LLM call took 0.61 seconds\n",
      "INFO: [2025-07-01 09:38:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:38:20] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.70 seconds\n",
      "\u001b[92m09:38:20 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:38:20] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:38:20] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:38:20 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:38:20] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:38:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:38:20] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:38:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:38:20] indra_gpt.chat_curate.chat_curate - LLM call took 0.85 seconds\n",
      "INFO: [2025-07-01 09:38:20] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:38:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:38:20] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:38:22] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.65 seconds\n",
      "\u001b[92m09:38:22 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:38:22] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:38:23] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:38:23 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:38:23] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:38:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:38:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:38:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:38:23] indra_gpt.chat_curate.chat_curate - LLM call took 0.62 seconds\n",
      "INFO: [2025-07-01 09:38:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:38:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:38:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:38:25] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.68 seconds\n",
      "\u001b[92m09:38:25 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:38:25] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:38:26] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:38:26 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:38:26] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:38:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:38:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:38:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:38:26] indra_gpt.chat_curate.chat_curate - LLM call took 0.68 seconds\n",
      "Curating statements with chat curation:  38%|‚ñà‚ñà‚ñà‚ñä      | 34/89 [07:52<11:16, 12.30s/it]INFO: [2025-07-01 09:38:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:38:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:38:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:38:28] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.79 seconds\n",
      "\u001b[92m09:38:28 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:38:28] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:38:28] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:38:28 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:38:28] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:38:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:38:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:38:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:38:28] indra_gpt.chat_curate.chat_curate - LLM call took 0.67 seconds\n",
      "INFO: [2025-07-01 09:38:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:38:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:38:28] indra_gpt.chat_curate.chat_curate - Skipping evidence with no text for statement -10558769985488922: Evidence(source_api='ctd',\n",
      "         pmid='25646720',\n",
      "         annotations={\n",
      "                      \"interaction_action\": \"increases^expression\",\n",
      "                      \"agents\": {\n",
      "                       \"raw_text\": [\n",
      "                        null,\n",
      "                        null\n",
      "                       ]\n",
      "                      },\n",
      "                      \"prior_uuids\": [\n",
      "                       \"6adcd77a-c2f3-44de-8575-994f25c622f7\"\n",
      "                      ]\n",
      "                     },\n",
      "         context={\n",
      "                  \"species\": {\n",
      "                   \"name\": \"Rattus norvegicus\",\n",
      "                   \"db_refs\": {\n",
      "                    \"TAXONOMY\": \"10116\"\n",
      "                   }\n",
      "                  },\n",
      "                  \"type\": \"bio\"\n",
      "                 },\n",
      "         text_refs={\n",
      "                    \"PMID\": \"25646720\"\n",
      "                   }\n",
      "         )\n",
      "\n",
      "\n",
      "INFO: [2025-07-01 09:38:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:38:28] indra_gpt.chat_curate.chat_curate - Skipping evidence with no text for statement -10558769985488922: Evidence(source_api='ctd',\n",
      "         pmid='17327447',\n",
      "         annotations={\n",
      "                      \"interaction_action\": \"increases^abundance\",\n",
      "                      \"agents\": {\n",
      "                       \"raw_text\": [\n",
      "                        null,\n",
      "                        null\n",
      "                       ]\n",
      "                      },\n",
      "                      \"prior_uuids\": [\n",
      "                       \"1e0419a3-fcc4-436a-a946-f4f9faa2982e\"\n",
      "                      ]\n",
      "                     },\n",
      "         context={\n",
      "                  \"species\": {\n",
      "                   \"name\": \"Homo sapiens\",\n",
      "                   \"db_refs\": {\n",
      "                    \"TAXONOMY\": \"9606\"\n",
      "                   }\n",
      "                  },\n",
      "                  \"type\": \"bio\"\n",
      "                 },\n",
      "         text_refs={\n",
      "                    \"PMID\": \"17327447\"\n",
      "                   }\n",
      "         )\n",
      "\n",
      "\n",
      "INFO: [2025-07-01 09:38:28] indra_gpt.chat_curate.chat_curate - Skipping evidence with no text for statement -10558769985488922: Evidence(source_api='ctd',\n",
      "         pmid='21212296',\n",
      "         annotations={\n",
      "                      \"interaction_action\": \"increases^expression\",\n",
      "                      \"agents\": {\n",
      "                       \"raw_text\": [\n",
      "                        null,\n",
      "                        null\n",
      "                       ]\n",
      "                      },\n",
      "                      \"prior_uuids\": [\n",
      "                       \"640af7e4-fdf9-40ed-a017-ccecd5d97a65\"\n",
      "                      ]\n",
      "                     },\n",
      "         context={\n",
      "                  \"species\": {\n",
      "                   \"name\": \"Gallus gallus\",\n",
      "                   \"db_refs\": {\n",
      "                    \"TAXONOMY\": \"9031\"\n",
      "                   }\n",
      "                  },\n",
      "                  \"type\": \"bio\"\n",
      "                 },\n",
      "         text_refs={\n",
      "                    \"PMID\": \"21212296\"\n",
      "                   }\n",
      "         )\n",
      "\n",
      "\n",
      "INFO: [2025-07-01 09:38:30] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.74 seconds\n",
      "\u001b[92m09:38:30 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:38:30] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:38:31] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:38:31 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:38:31] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:38:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:38:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:38:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:38:31] indra_gpt.chat_curate.chat_curate - LLM call took 0.65 seconds\n",
      "Curating statements with chat curation:  39%|‚ñà‚ñà‚ñà‚ñâ      | 35/89 [07:57<09:12, 10.23s/it]INFO: [2025-07-01 09:38:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:38:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:38:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:38:33] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.67 seconds\n",
      "\u001b[92m09:38:33 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:38:33] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:38:34] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:38:34 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:38:34] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:38:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:38:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:38:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:38:34] indra_gpt.chat_curate.chat_curate - LLM call took 0.69 seconds\n",
      "INFO: [2025-07-01 09:38:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:38:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:38:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:38:36] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.66 seconds\n",
      "\u001b[92m09:38:36 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:38:36] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:38:36] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:38:36 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:38:36] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:38:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:38:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:38:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:38:36] indra_gpt.chat_curate.chat_curate - LLM call took 0.62 seconds\n",
      "INFO: [2025-07-01 09:38:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:38:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:38:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:38:38] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.66 seconds\n",
      "\u001b[92m09:38:38 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:38:38] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:38:39] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:38:39 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:38:39] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:38:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:38:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:38:39] indra_gpt.chat_curate.chat_curate - LLM call took 0.59 seconds\n",
      "\u001b[92m09:38:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:38:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:38:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:38:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:38:41] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.69 seconds\n",
      "\u001b[92m09:38:41 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:38:41] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:38:41] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:38:41 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:38:41] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:38:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:38:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:38:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:38:41] indra_gpt.chat_curate.chat_curate - LLM call took 0.59 seconds\n",
      "INFO: [2025-07-01 09:38:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:38:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:38:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:38:43] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.70 seconds\n",
      "\u001b[92m09:38:43 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:38:43] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:38:44] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:38:44 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:38:44] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:38:44 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:38:44] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:38:44 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:38:44] indra_gpt.chat_curate.chat_curate - LLM call took 0.58 seconds\n",
      "Curating statements with chat curation:  40%|‚ñà‚ñà‚ñà‚ñà      | 36/89 [08:10<09:43, 11.01s/it]INFO: [2025-07-01 09:38:44] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:38:44 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:38:44] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:38:46] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.67 seconds\n",
      "\u001b[92m09:38:46 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:38:46] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:38:48] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:38:48 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:38:48] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:38:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:38:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:38:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:38:48] indra_gpt.chat_curate.chat_curate - LLM call took 2.30 seconds\n",
      "INFO: [2025-07-01 09:38:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:38:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:38:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:38:50] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.67 seconds\n",
      "\u001b[92m09:38:50 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:38:50] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:38:50] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:38:50 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:38:50] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:38:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:38:50] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:38:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:38:50] indra_gpt.chat_curate.chat_curate - LLM call took 0.51 seconds\n",
      "INFO: [2025-07-01 09:38:50] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:38:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:38:50] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:38:52] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.69 seconds\n",
      "\u001b[92m09:38:52 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:38:52] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:38:54] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:38:54 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:38:54] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:38:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:38:54] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:38:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:38:54] indra_gpt.chat_curate.chat_curate - LLM call took 1.36 seconds\n",
      "INFO: [2025-07-01 09:38:54] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:38:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:38:54] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:38:56] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.72 seconds\n",
      "\u001b[92m09:38:56 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:38:56] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:38:56] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:38:56 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:38:56] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:38:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:38:56] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:38:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:38:56] indra_gpt.chat_curate.chat_curate - LLM call took 0.66 seconds\n",
      "INFO: [2025-07-01 09:38:56] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:38:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:38:56] indra_gpt.chat_curate.chat_curate - Skipping evidence with no text for statement -24407073837268975: Evidence(source_api='biogrid',\n",
      "         pmid='19766626',\n",
      "         source_id='723971',\n",
      "         annotations={\n",
      "                      \"biogrid_int_id\": \"723971\",\n",
      "                      \"entrez_a\": \"10771\",\n",
      "                      \"entrez_b\": \"8554\",\n",
      "                      \"biogrid_a\": \"115989\",\n",
      "                      \"biogrid_b\": \"114124\",\n",
      "                      \"syst_name_a\": \"RP11-486H9.1\",\n",
      "                      \"syst_name_b\": null,\n",
      "                      \"hgnc_a\": \"ZMYND11\",\n",
      "                      \"hgnc_b\": \"PIAS1\",\n",
      "                      \"syn_a\": \"BRAM1|BS69|MRD30\",\n",
      "                      \"syn_b\": \"DDXBP1|GBP|GU/RH-II|ZMIZ3\",\n",
      "                      \"exp_system\": \"Affinity Capture-Western\",\n",
      "                      \"exp_system_type\": \"physical\",\n",
      "                      \"author\": \"Yu B (2009)\",\n",
      "                      \"pmid\": \"19766626\",\n",
      "                      \"organism_a\": \"9606\",\n",
      "                      \"organism_b\": \"9606\",\n",
      "                      \"throughput\": \"Low Throughput\",\n",
      "                      \"score\": null,\n",
      "                      \"modification\": null,\n",
      "                      \"phenotypes\": null,\n",
      "                      \"qualifications\": null,\n",
      "                      \"tags\": null,\n",
      "                      \"source_db\": \"BIOGRID\",\n",
      "                      \"agents\": {\n",
      "                       \"raw_text\": [\n",
      "                        \"RP11-486H9.1\",\n",
      "                        null\n",
      "                       ]\n",
      "                      },\n",
      "                      \"prior_uuids\": [\n",
      "                       \"1e78db56-ba7b-49d8-b3eb-7d6287d1ed53\"\n",
      "                      ]\n",
      "                     },\n",
      "         text_refs={\n",
      "                    \"PMID\": \"19766626\"\n",
      "                   }\n",
      "         )\n",
      "\n",
      "\n",
      "Curating statements with chat curation:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 37/89 [08:23<09:57, 11.50s/it]INFO: [2025-07-01 09:38:56] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:38:58] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.66 seconds\n",
      "\u001b[92m09:38:58 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:38:58] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:38:59] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:38:59 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:38:59] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:38:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:38:59] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:38:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:38:59] indra_gpt.chat_curate.chat_curate - LLM call took 0.73 seconds\n",
      "INFO: [2025-07-01 09:38:59] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:38:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:38:59] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:39:01] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.78 seconds\n",
      "\u001b[92m09:39:01 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:39:01] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:39:02] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:39:02 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:39:02] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:39:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:39:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:39:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:39:02] indra_gpt.chat_curate.chat_curate - LLM call took 1.01 seconds\n",
      "INFO: [2025-07-01 09:39:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:39:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:39:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:39:04] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.70 seconds\n",
      "\u001b[92m09:39:04 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:39:04] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:39:05] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:39:05 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:39:05] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:39:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:39:05] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:39:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:39:05] indra_gpt.chat_curate.chat_curate - LLM call took 0.98 seconds\n",
      "INFO: [2025-07-01 09:39:05] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:39:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:39:05] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:39:07] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.76 seconds\n",
      "\u001b[92m09:39:07 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:39:07] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:39:08] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:39:08 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:39:08] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:39:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:39:08] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:39:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:39:08] indra_gpt.chat_curate.chat_curate - LLM call took 0.95 seconds\n",
      "INFO: [2025-07-01 09:39:08] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:39:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:39:08] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:39:10] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.66 seconds\n",
      "\u001b[92m09:39:10 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:39:10] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:39:11] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:39:11 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:39:11] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:39:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:39:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:39:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:39:11] indra_gpt.chat_curate.chat_curate - LLM call took 0.65 seconds\n",
      "Curating statements with chat curation:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 38/89 [08:37<10:28, 12.33s/it]INFO: [2025-07-01 09:39:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:39:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:39:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:39:13] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.68 seconds\n",
      "\u001b[92m09:39:13 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:39:13] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:39:13] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:39:13 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:39:13] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:39:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:39:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:39:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:39:13] indra_gpt.chat_curate.chat_curate - LLM call took 0.66 seconds\n",
      "INFO: [2025-07-01 09:39:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:39:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:39:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:39:15] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.67 seconds\n",
      "\u001b[92m09:39:15 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:39:15] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:39:16] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:39:16 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:39:16] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:39:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:39:16] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:39:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:39:16] indra_gpt.chat_curate.chat_curate - LLM call took 0.65 seconds\n",
      "INFO: [2025-07-01 09:39:16] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:39:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:39:16] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:39:18] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.66 seconds\n",
      "\u001b[92m09:39:18 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:39:18] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:39:18] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:39:18 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:39:18] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:39:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:39:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:39:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:39:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:39:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:39:18] indra_gpt.chat_curate.chat_curate - LLM call took 0.74 seconds\n",
      "INFO: [2025-07-01 09:39:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:39:20] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.69 seconds\n",
      "\u001b[92m09:39:20 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:39:20] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:39:21] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:39:21 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:39:21] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:39:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:39:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:39:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:39:21] indra_gpt.chat_curate.chat_curate - LLM call took 0.73 seconds\n",
      "INFO: [2025-07-01 09:39:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:39:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:39:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:39:23] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.69 seconds\n",
      "\u001b[92m09:39:23 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:39:23] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:39:24] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:39:24 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:39:24] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:39:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:39:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:39:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:39:24] indra_gpt.chat_curate.chat_curate - LLM call took 0.64 seconds\n",
      "Curating statements with chat curation:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 39/89 [08:50<10:27, 12.56s/it]INFO: [2025-07-01 09:39:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:39:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:39:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:39:26] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.67 seconds\n",
      "\u001b[92m09:39:26 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:39:26] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:39:27] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:39:27 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:39:27] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:39:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:39:27] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:39:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:39:27] indra_gpt.chat_curate.chat_curate - LLM call took 1.56 seconds\n",
      "INFO: [2025-07-01 09:39:27] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:39:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:39:27] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:39:29] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.72 seconds\n",
      "\u001b[92m09:39:29 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:39:29] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:39:30] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:39:35 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:39:35] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:39:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:39:35] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:39:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:39:35] indra_gpt.chat_curate.chat_curate - LLM call took 5.70 seconds\n",
      "INFO: [2025-07-01 09:39:35] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:39:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:39:35] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:39:37] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.74 seconds\n",
      "\u001b[92m09:39:37 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:39:37] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:39:38] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:39:38 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:39:38] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:39:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:39:38] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:39:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:39:38] indra_gpt.chat_curate.chat_curate - LLM call took 0.62 seconds\n",
      "INFO: [2025-07-01 09:39:38] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:39:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:39:38] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:39:39] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.67 seconds\n",
      "\u001b[92m09:39:39 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:39:39] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:39:40] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:39:40 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:39:40] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:39:40 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:39:40] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:39:40 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:39:40] indra_gpt.chat_curate.chat_curate - LLM call took 0.72 seconds\n",
      "INFO: [2025-07-01 09:39:40] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:39:40 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:39:40] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:39:42] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.73 seconds\n",
      "\u001b[92m09:39:42 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:39:42] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:39:43] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:39:43 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:39:43] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:39:43 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:39:43] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:39:43 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:39:43] indra_gpt.chat_curate.chat_curate - LLM call took 0.75 seconds\n",
      "Curating statements with chat curation:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 40/89 [09:09<11:53, 14.57s/it]INFO: [2025-07-01 09:39:43] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:39:43 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:39:43] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:39:45] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.69 seconds\n",
      "\u001b[92m09:39:45 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:39:45] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:39:46] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:39:46 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:39:46] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:39:46 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:39:46] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:39:46 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:39:46] indra_gpt.chat_curate.chat_curate - LLM call took 0.66 seconds\n",
      "INFO: [2025-07-01 09:39:46] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:39:46 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:39:46] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:39:48] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.69 seconds\n",
      "\u001b[92m09:39:48 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:39:48] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:39:49] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:39:49 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:39:49] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:39:49 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:39:49] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:39:49 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:39:49] indra_gpt.chat_curate.chat_curate - LLM call took 1.03 seconds\n",
      "INFO: [2025-07-01 09:39:49] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:39:49 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:39:49] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:39:51] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.75 seconds\n",
      "\u001b[92m09:39:51 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:39:51] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:39:51] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:39:51 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:39:51] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:39:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:39:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:39:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:39:51] indra_gpt.chat_curate.chat_curate - LLM call took 0.69 seconds\n",
      "INFO: [2025-07-01 09:39:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:39:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:39:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:39:53] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.70 seconds\n",
      "\u001b[92m09:39:53 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:39:53] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:39:54] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:39:54 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:39:54] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:39:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:39:54] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:39:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:39:54] indra_gpt.chat_curate.chat_curate - LLM call took 0.70 seconds\n",
      "INFO: [2025-07-01 09:39:54] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:39:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:39:54] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:39:56] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.69 seconds\n",
      "\u001b[92m09:39:56 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:39:56] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:39:57] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:39:57 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:39:57] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:39:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:39:57] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:39:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:39:57] indra_gpt.chat_curate.chat_curate - LLM call took 0.69 seconds\n",
      "Curating statements with chat curation:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 41/89 [09:23<11:26, 14.30s/it]INFO: [2025-07-01 09:39:57] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:39:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:39:57] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:39:58] indra_gpt.chat_curate.chat_curate - Prompt generation took 0.91 seconds\n",
      "\u001b[92m09:39:58 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:39:58] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:39:59] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:39:59 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:39:59] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:39:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:39:59] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:39:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:39:59] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:39:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:39:59] indra_gpt.chat_curate.chat_curate - LLM call took 0.79 seconds\n",
      "INFO: [2025-07-01 09:39:59] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:40:00] indra_gpt.chat_curate.chat_curate - Prompt generation took 0.91 seconds\n",
      "\u001b[92m09:40:00 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:40:00] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:40:00] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:40:00 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:40:00] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:40:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:40:00] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:40:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:40:00] indra_gpt.chat_curate.chat_curate - LLM call took 0.58 seconds\n",
      "INFO: [2025-07-01 09:40:00] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:40:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:40:00] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:40:02] indra_gpt.chat_curate.chat_curate - Prompt generation took 0.91 seconds\n",
      "\u001b[92m09:40:02 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:40:02] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:40:02] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:40:02 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:40:02] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:40:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:40:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:40:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:40:02] indra_gpt.chat_curate.chat_curate - LLM call took 0.89 seconds\n",
      "INFO: [2025-07-01 09:40:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:40:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:40:03] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:40:04] indra_gpt.chat_curate.chat_curate - Prompt generation took 0.90 seconds\n",
      "\u001b[92m09:40:04 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:40:04] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:40:05] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:40:05 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:40:05] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:40:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:40:05] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:40:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:40:05] indra_gpt.chat_curate.chat_curate - LLM call took 0.88 seconds\n",
      "INFO: [2025-07-01 09:40:05] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:40:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:40:05] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:40:06] indra_gpt.chat_curate.chat_curate - Prompt generation took 0.91 seconds\n",
      "\u001b[92m09:40:06 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:40:06] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:40:06] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:40:06 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:40:06] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:40:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:40:06] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:40:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:40:06] indra_gpt.chat_curate.chat_curate - LLM call took 0.69 seconds\n",
      "Curating statements with chat curation:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 42/89 [09:33<10:07, 12.92s/it]INFO: [2025-07-01 09:40:06] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:40:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:40:06] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:40:08] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.66 seconds\n",
      "\u001b[92m09:40:08 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:40:08] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:40:09] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:40:09 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:40:09] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:40:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:40:09] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:40:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:40:09] indra_gpt.chat_curate.chat_curate - LLM call took 0.67 seconds\n",
      "INFO: [2025-07-01 09:40:09] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:40:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:40:09] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:40:11] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.66 seconds\n",
      "\u001b[92m09:40:11 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:40:11] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:40:12] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:40:12 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:40:12] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:40:12 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:40:12] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:40:12 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:40:12] indra_gpt.chat_curate.chat_curate - LLM call took 0.67 seconds\n",
      "INFO: [2025-07-01 09:40:12] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:40:12 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:40:12] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:40:14] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.69 seconds\n",
      "\u001b[92m09:40:14 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:40:14] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:40:14] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:40:14 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:40:14] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:40:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:40:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:40:14] indra_gpt.chat_curate.chat_curate - LLM call took 0.71 seconds\n",
      "\u001b[92m09:40:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:40:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:40:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:40:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:40:16] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.66 seconds\n",
      "\u001b[92m09:40:16 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:40:16] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:40:17] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:40:17 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:40:17] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:40:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:40:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:40:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:40:17] indra_gpt.chat_curate.chat_curate - LLM call took 0.69 seconds\n",
      "INFO: [2025-07-01 09:40:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:40:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:40:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:40:19] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.67 seconds\n",
      "\u001b[92m09:40:19 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:40:19] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:40:19] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:40:19 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:40:19] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:40:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:40:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:40:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:40:19] indra_gpt.chat_curate.chat_curate - LLM call took 0.65 seconds\n",
      "Curating statements with chat curation:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 43/89 [09:46<09:56, 12.97s/it]INFO: [2025-07-01 09:40:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:40:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:40:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:40:21] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.70 seconds\n",
      "\u001b[92m09:40:21 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:40:21] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:40:22] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:40:22 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:40:22] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:40:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:40:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:40:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:40:22] indra_gpt.chat_curate.chat_curate - LLM call took 0.63 seconds\n",
      "INFO: [2025-07-01 09:40:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:40:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:40:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:40:24] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.66 seconds\n",
      "\u001b[92m09:40:24 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:40:24] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:40:25] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:40:25 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:40:25] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:40:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:40:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:40:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:40:25] indra_gpt.chat_curate.chat_curate - LLM call took 0.76 seconds\n",
      "INFO: [2025-07-01 09:40:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:40:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:40:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:40:27] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.66 seconds\n",
      "\u001b[92m09:40:27 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:40:27] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:40:28] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:40:28 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:40:28] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:40:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:40:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:40:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:40:28] indra_gpt.chat_curate.chat_curate - LLM call took 1.34 seconds\n",
      "INFO: [2025-07-01 09:40:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:40:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:40:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:40:30] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.73 seconds\n",
      "\u001b[92m09:40:30 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:40:30] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:40:31] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:40:31 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:40:31] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:40:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:40:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:40:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:40:31] indra_gpt.chat_curate.chat_curate - LLM call took 0.71 seconds\n",
      "INFO: [2025-07-01 09:40:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:40:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:40:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:40:33] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.69 seconds\n",
      "\u001b[92m09:40:33 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:40:33] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:40:33] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:40:33 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:40:33] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:40:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:40:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:40:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:40:33] indra_gpt.chat_curate.chat_curate - LLM call took 0.80 seconds\n",
      "Curating statements with chat curation:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 44/89 [10:00<09:57, 13.28s/it]INFO: [2025-07-01 09:40:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:40:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:40:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:40:35] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.67 seconds\n",
      "\u001b[92m09:40:35 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:40:35] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:40:37] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:40:37 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:40:37] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:40:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:40:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:40:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:40:37] indra_gpt.chat_curate.chat_curate - LLM call took 1.80 seconds\n",
      "INFO: [2025-07-01 09:40:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:40:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:40:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:40:39] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.67 seconds\n",
      "\u001b[92m09:40:39 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:40:39] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:40:40] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:40:40 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:40:40] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:40:40 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:40:40] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:40:40 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:40:40] indra_gpt.chat_curate.chat_curate - LLM call took 0.67 seconds\n",
      "INFO: [2025-07-01 09:40:40] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:40:40 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:40:40] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:40:42] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.73 seconds\n",
      "\u001b[92m09:40:42 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:40:42] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:40:43] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:40:43 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:40:43] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:40:43 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:40:43] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:40:43 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:40:43] indra_gpt.chat_curate.chat_curate - LLM call took 0.73 seconds\n",
      "INFO: [2025-07-01 09:40:43] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:40:43 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:40:43] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:40:44] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.68 seconds\n",
      "\u001b[92m09:40:44 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:40:44] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:40:45] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:40:45 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:40:45] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:40:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:40:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:40:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:40:45] indra_gpt.chat_curate.chat_curate - LLM call took 0.50 seconds\n",
      "INFO: [2025-07-01 09:40:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:40:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:40:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:40:47] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.66 seconds\n",
      "\u001b[92m09:40:47 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:40:47] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:40:47] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:40:47 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:40:47] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:40:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:40:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:40:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:40:47] indra_gpt.chat_curate.chat_curate - LLM call took 0.54 seconds\n",
      "Curating statements with chat curation:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 45/89 [10:14<09:53, 13.48s/it]INFO: [2025-07-01 09:40:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:40:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:40:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:40:49] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.65 seconds\n",
      "\u001b[92m09:40:49 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:40:49] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:40:50] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:40:50 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:40:50] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:40:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:40:50] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:40:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:40:50] indra_gpt.chat_curate.chat_curate - LLM call took 0.69 seconds\n",
      "INFO: [2025-07-01 09:40:50] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:40:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:40:50] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:40:52] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.68 seconds\n",
      "\u001b[92m09:40:52 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:40:52] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:40:53] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:40:53 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:40:53] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:40:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:40:53] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:40:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:40:53] indra_gpt.chat_curate.chat_curate - LLM call took 0.58 seconds\n",
      "INFO: [2025-07-01 09:40:53] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:40:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:40:53] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:40:54] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.71 seconds\n",
      "\u001b[92m09:40:54 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:40:54] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:40:55] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:40:55 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:40:55] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:40:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:40:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:40:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:40:55] indra_gpt.chat_curate.chat_curate - LLM call took 0.58 seconds\n",
      "INFO: [2025-07-01 09:40:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:40:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:40:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:40:57] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.66 seconds\n",
      "\u001b[92m09:40:57 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:40:57] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:40:58] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:40:58 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:40:58] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:40:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:40:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:40:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:40:58] indra_gpt.chat_curate.chat_curate - LLM call took 0.76 seconds\n",
      "INFO: [2025-07-01 09:40:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:40:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:40:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:41:00] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.67 seconds\n",
      "\u001b[92m09:41:00 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:41:00] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:41:00] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:41:00 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:41:00] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:41:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:41:00] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:41:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:41:00] indra_gpt.chat_curate.chat_curate - LLM call took 0.58 seconds\n",
      "Curating statements with chat curation:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 46/89 [10:27<09:31, 13.30s/it]INFO: [2025-07-01 09:41:00] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:41:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:41:00] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:41:02] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.67 seconds\n",
      "\u001b[92m09:41:02 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:41:02] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:41:04] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:41:04 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:41:04] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:41:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:41:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:41:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:41:04] indra_gpt.chat_curate.chat_curate - LLM call took 1.77 seconds\n",
      "INFO: [2025-07-01 09:41:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:41:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:41:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:41:06] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.66 seconds\n",
      "\u001b[92m09:41:06 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:41:06] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:41:07] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:41:07 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:41:07] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:41:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:41:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:41:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:41:07] indra_gpt.chat_curate.chat_curate - LLM call took 1.26 seconds\n",
      "INFO: [2025-07-01 09:41:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:41:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:41:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:41:09] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.65 seconds\n",
      "\u001b[92m09:41:09 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:41:09] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:41:10] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:41:10 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:41:10] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:41:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:41:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:41:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:41:10] indra_gpt.chat_curate.chat_curate - LLM call took 0.85 seconds\n",
      "INFO: [2025-07-01 09:41:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:41:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:41:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:41:12] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.72 seconds\n",
      "\u001b[92m09:41:12 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:41:12] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:41:13] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:41:13 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:41:13] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:41:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:41:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:41:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:41:13] indra_gpt.chat_curate.chat_curate - LLM call took 1.48 seconds\n",
      "INFO: [2025-07-01 09:41:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:41:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:41:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:41:15] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.68 seconds\n",
      "\u001b[92m09:41:15 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:41:15] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:41:16] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:41:16 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:41:16] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:41:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:41:16] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:41:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:41:16] indra_gpt.chat_curate.chat_curate - LLM call took 0.58 seconds\n",
      "Curating statements with chat curation:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 47/89 [10:42<09:47, 13.99s/it]INFO: [2025-07-01 09:41:16] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:41:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:41:16] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:41:17] indra_gpt.chat_curate.chat_curate - Prompt generation took 0.90 seconds\n",
      "\u001b[92m09:41:17 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:41:17] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:41:18] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:41:18 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:41:18] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:41:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:41:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:41:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:41:18] indra_gpt.chat_curate.chat_curate - LLM call took 0.64 seconds\n",
      "INFO: [2025-07-01 09:41:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:41:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:41:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:41:19] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.01 seconds\n",
      "\u001b[92m09:41:19 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:41:19] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:41:20] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:41:20 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:41:20] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:41:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:41:20] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:41:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:41:20] indra_gpt.chat_curate.chat_curate - LLM call took 0.78 seconds\n",
      "INFO: [2025-07-01 09:41:20] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:41:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:41:20] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:41:21] indra_gpt.chat_curate.chat_curate - Prompt generation took 0.92 seconds\n",
      "\u001b[92m09:41:21 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:41:21] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:41:22] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:41:22 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:41:22] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:41:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:41:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:41:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:41:22] indra_gpt.chat_curate.chat_curate - LLM call took 0.75 seconds\n",
      "INFO: [2025-07-01 09:41:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:41:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:41:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:41:23] indra_gpt.chat_curate.chat_curate - Prompt generation took 0.90 seconds\n",
      "\u001b[92m09:41:23 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:41:23] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:41:24] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:41:24 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:41:24] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:41:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:41:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:41:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:41:24] indra_gpt.chat_curate.chat_curate - LLM call took 0.94 seconds\n",
      "INFO: [2025-07-01 09:41:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:41:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:41:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:41:25] indra_gpt.chat_curate.chat_curate - Prompt generation took 0.97 seconds\n",
      "\u001b[92m09:41:25 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:41:25] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:41:26] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:41:26 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:41:26] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:41:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:41:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:41:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:41:26] indra_gpt.chat_curate.chat_curate - LLM call took 0.62 seconds\n",
      "Curating statements with chat curation:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 48/89 [10:52<08:41, 12.71s/it]INFO: [2025-07-01 09:41:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:41:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:41:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:41:28] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.76 seconds\n",
      "\u001b[92m09:41:28 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:41:28] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:41:29] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:41:29 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:41:29] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:41:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:41:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:41:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:41:29] indra_gpt.chat_curate.chat_curate - LLM call took 1.03 seconds\n",
      "INFO: [2025-07-01 09:41:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:41:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:41:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:41:31] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.74 seconds\n",
      "\u001b[92m09:41:31 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:41:31] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:41:31] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:41:31 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:41:31] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:41:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:41:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:41:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:41:31] indra_gpt.chat_curate.chat_curate - LLM call took 0.54 seconds\n",
      "INFO: [2025-07-01 09:41:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:41:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:41:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:41:33] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.70 seconds\n",
      "\u001b[92m09:41:33 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:41:33] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:41:34] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:41:34 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:41:34] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:41:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:41:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:41:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:41:34] indra_gpt.chat_curate.chat_curate - LLM call took 0.65 seconds\n",
      "INFO: [2025-07-01 09:41:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:41:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:41:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:41:36] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.75 seconds\n",
      "\u001b[92m09:41:36 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:41:36] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:41:37] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:41:37 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:41:37] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:41:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:41:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:41:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:41:37] indra_gpt.chat_curate.chat_curate - LLM call took 0.93 seconds\n",
      "INFO: [2025-07-01 09:41:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:41:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:41:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:41:39] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.67 seconds\n",
      "\u001b[92m09:41:39 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:41:39] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:41:39] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:41:39 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:41:39] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:41:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:41:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:41:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:41:39] indra_gpt.chat_curate.chat_curate - LLM call took 0.63 seconds\n",
      "Curating statements with chat curation:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 49/89 [11:06<08:41, 13.04s/it]INFO: [2025-07-01 09:41:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:41:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:41:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:41:41] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.69 seconds\n",
      "\u001b[92m09:41:41 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:41:41] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:41:42] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:41:42 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:41:42] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:41:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:41:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:41:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:41:42] indra_gpt.chat_curate.chat_curate - LLM call took 0.87 seconds\n",
      "INFO: [2025-07-01 09:41:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:41:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:41:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:41:44] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.71 seconds\n",
      "\u001b[92m09:41:44 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:41:44] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:41:45] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:41:45 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:41:45] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:41:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:41:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:41:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:41:45] indra_gpt.chat_curate.chat_curate - LLM call took 0.65 seconds\n",
      "INFO: [2025-07-01 09:41:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:41:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:41:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:41:47] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.73 seconds\n",
      "\u001b[92m09:41:47 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:41:47] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:41:47] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:41:47 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:41:47] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:41:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:41:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:41:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:41:47] indra_gpt.chat_curate.chat_curate - LLM call took 0.54 seconds\n",
      "INFO: [2025-07-01 09:41:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:41:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:41:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:41:49] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.74 seconds\n",
      "\u001b[92m09:41:49 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:41:49] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:41:50] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:41:50 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:41:50] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:41:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:41:50] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:41:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:41:50] indra_gpt.chat_curate.chat_curate - LLM call took 0.69 seconds\n",
      "Curating statements with chat curation:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 50/89 [11:17<08:01, 12.35s/it]INFO: [2025-07-01 09:41:50] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:41:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:41:50] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:41:52] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.71 seconds\n",
      "\u001b[92m09:41:52 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:41:52] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:41:53] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:41:53 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:41:53] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:41:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:41:53] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:41:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:41:53] indra_gpt.chat_curate.chat_curate - LLM call took 0.62 seconds\n",
      "INFO: [2025-07-01 09:41:53] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:41:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:41:53] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:41:55] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.72 seconds\n",
      "\u001b[92m09:41:55 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:41:55] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:41:56] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:41:56 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:41:56] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:41:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:41:56] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:41:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:41:56] indra_gpt.chat_curate.chat_curate - LLM call took 0.78 seconds\n",
      "INFO: [2025-07-01 09:41:56] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:41:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:41:56] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:41:58] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.67 seconds\n",
      "\u001b[92m09:41:58 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:41:58] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:41:58] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:41:58 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:41:58] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:41:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:41:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:41:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:41:58] indra_gpt.chat_curate.chat_curate - LLM call took 0.75 seconds\n",
      "INFO: [2025-07-01 09:41:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:41:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:41:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:42:00] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.70 seconds\n",
      "\u001b[92m09:42:00 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:42:00] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:42:01] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:42:01 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:42:01] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:42:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:42:01] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:42:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:42:01] indra_gpt.chat_curate.chat_curate - LLM call took 1.01 seconds\n",
      "Curating statements with chat curation:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 51/89 [11:28<07:34, 11.96s/it]INFO: [2025-07-01 09:42:01] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:42:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:42:01] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:42:03] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.71 seconds\n",
      "\u001b[92m09:42:03 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:42:03] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:42:04] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:42:04 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:42:04] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:42:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:42:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:42:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:42:04] indra_gpt.chat_curate.chat_curate - LLM call took 0.62 seconds\n",
      "INFO: [2025-07-01 09:42:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:42:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:42:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:42:06] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.72 seconds\n",
      "\u001b[92m09:42:06 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:42:06] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:42:07] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:42:07 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:42:07] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:42:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:42:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:42:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:42:07] indra_gpt.chat_curate.chat_curate - LLM call took 0.72 seconds\n",
      "INFO: [2025-07-01 09:42:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:42:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:42:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:42:09] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.74 seconds\n",
      "\u001b[92m09:42:09 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:42:09] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:42:09] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:42:09 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:42:09] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:42:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:42:09] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:42:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:42:09] indra_gpt.chat_curate.chat_curate - LLM call took 0.65 seconds\n",
      "INFO: [2025-07-01 09:42:09] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:42:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:42:09] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:42:11] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.75 seconds\n",
      "\u001b[92m09:42:11 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:42:11] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:42:12] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:42:12 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:42:12] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:42:12 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:42:12] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:42:12 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:42:12] indra_gpt.chat_curate.chat_curate - LLM call took 0.68 seconds\n",
      "Curating statements with chat curation:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 52/89 [11:38<07:08, 11.59s/it]INFO: [2025-07-01 09:42:12] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:42:12 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:42:12] indra_gpt.chat_curate.chat_curate - Skipping evidence with no text for statement 2642167277518507: Evidence(source_api='biopax',\n",
      "         pmid='9707430',\n",
      "         source_id='http://pathwaycommons.org/pc12/Catalysis_5cb76d3bfe53f69e273a22ee1764f5da',\n",
      "         annotations={\n",
      "                      \"source_sub_id\": \"pid\",\n",
      "                      \"agents\": {\n",
      "                       \"raw_text\": [\n",
      "                        null,\n",
      "                        null\n",
      "                       ]\n",
      "                      },\n",
      "                      \"prior_uuids\": [\n",
      "                       \"51c7a851-9ac6-43a8-b109-517c70bb0a04\"\n",
      "                      ]\n",
      "                     },\n",
      "         epistemics={\n",
      "                     \"direct\": true\n",
      "                    },\n",
      "         text_refs={\n",
      "                    \"PMID\": \"9707430\"\n",
      "                   }\n",
      "         )\n",
      "\n",
      "\n",
      "INFO: [2025-07-01 09:42:12] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:42:14] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.72 seconds\n",
      "\u001b[92m09:42:14 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:42:14] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:42:15] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:42:15 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:42:15] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:42:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:42:15] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:42:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:42:15] indra_gpt.chat_curate.chat_curate - LLM call took 0.87 seconds\n",
      "INFO: [2025-07-01 09:42:15] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:42:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:42:15] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:42:17] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.67 seconds\n",
      "\u001b[92m09:42:17 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:42:17] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:42:17] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:42:17 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:42:17] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:42:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:42:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:42:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:42:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:42:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:42:17] indra_gpt.chat_curate.chat_curate - LLM call took 0.66 seconds\n",
      "INFO: [2025-07-01 09:42:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:42:19] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.67 seconds\n",
      "\u001b[92m09:42:19 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:42:19] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:42:20] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:42:20 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:42:20] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:42:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:42:20] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:42:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:42:20] indra_gpt.chat_curate.chat_curate - LLM call took 0.92 seconds\n",
      "Curating statements with chat curation:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 53/89 [11:47<06:22, 10.62s/it]INFO: [2025-07-01 09:42:20] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:42:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:42:20] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:42:22] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.74 seconds\n",
      "\u001b[92m09:42:22 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:42:22] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:42:23] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:42:23 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:42:23] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:42:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:42:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:42:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:42:23] indra_gpt.chat_curate.chat_curate - LLM call took 0.95 seconds\n",
      "INFO: [2025-07-01 09:42:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:42:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:42:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:42:25] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.67 seconds\n",
      "\u001b[92m09:42:25 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:42:25] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:42:26] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:42:26 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:42:26] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:42:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:42:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:42:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:42:26] indra_gpt.chat_curate.chat_curate - LLM call took 0.81 seconds\n",
      "INFO: [2025-07-01 09:42:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:42:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:42:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:42:28] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.68 seconds\n",
      "\u001b[92m09:42:28 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:42:28] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:42:28] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:42:28 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:42:28] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:42:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:42:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:42:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:42:28] indra_gpt.chat_curate.chat_curate - LLM call took 0.49 seconds\n",
      "INFO: [2025-07-01 09:42:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:42:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:42:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:42:31] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.71 seconds\n",
      "\u001b[92m09:42:31 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:42:31] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:42:31] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:42:31 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:42:31] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:42:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:42:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:42:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:42:31] indra_gpt.chat_curate.chat_curate - LLM call took 0.68 seconds\n",
      "Curating statements with chat curation:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 54/89 [11:58<06:14, 10.70s/it]INFO: [2025-07-01 09:42:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:42:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:42:31] indra_gpt.chat_curate.chat_curate - Skipping evidence with no text for statement 28063295869356555: Evidence(source_api='biopax',\n",
      "         source_id='http://www.phosphosite.org/phosphosite.owl#Catalysis_21895_630',\n",
      "         annotations={\n",
      "                      \"source_sub_id\": \"phosphositeplus\",\n",
      "                      \"agents\": {\n",
      "                       \"raw_text\": [\n",
      "                        null,\n",
      "                        null\n",
      "                       ]\n",
      "                      },\n",
      "                      \"prior_uuids\": [\n",
      "                       \"0b6af9ab-66a9-4dc5-b7a6-df81a0acb786\"\n",
      "                      ]\n",
      "                     },\n",
      "         epistemics={\n",
      "                     \"direct\": true\n",
      "                    }\n",
      "         )\n",
      "\n",
      "\n",
      "INFO: [2025-07-01 09:42:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:42:33] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.72 seconds\n",
      "\u001b[92m09:42:33 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:42:33] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:42:34] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:42:34 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:42:34] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:42:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:42:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:42:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:42:34] indra_gpt.chat_curate.chat_curate - LLM call took 0.53 seconds\n",
      "INFO: [2025-07-01 09:42:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:42:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:42:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:42:36] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.69 seconds\n",
      "\u001b[92m09:42:36 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:42:36] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:42:36] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:42:36 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:42:36] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:42:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:42:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:42:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:42:36] indra_gpt.chat_curate.chat_curate - LLM call took 0.67 seconds\n",
      "INFO: [2025-07-01 09:42:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:42:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:42:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:42:38] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.74 seconds\n",
      "\u001b[92m09:42:38 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:42:38] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:42:39] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:42:39 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:42:39] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:42:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:42:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:42:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:42:39] indra_gpt.chat_curate.chat_curate - LLM call took 0.74 seconds\n",
      "Curating statements with chat curation:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 55/89 [12:06<05:35,  9.87s/it]INFO: [2025-07-01 09:42:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:42:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:42:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:42:40] indra_gpt.chat_curate.chat_curate - Prompt generation took 0.91 seconds\n",
      "\u001b[92m09:42:40 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:42:40] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:42:41] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:42:41 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:42:41] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:42:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:42:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:42:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:42:41] indra_gpt.chat_curate.chat_curate - LLM call took 0.66 seconds\n",
      "INFO: [2025-07-01 09:42:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:42:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:42:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:42:42] indra_gpt.chat_curate.chat_curate - Prompt generation took 0.91 seconds\n",
      "\u001b[92m09:42:42 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:42:42] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:42:43] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:42:43 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:42:43] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:42:43 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:42:43] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:42:43 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:42:43] indra_gpt.chat_curate.chat_curate - LLM call took 0.63 seconds\n",
      "INFO: [2025-07-01 09:42:43] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:42:43 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:42:43] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:42:44] indra_gpt.chat_curate.chat_curate - Prompt generation took 0.92 seconds\n",
      "\u001b[92m09:42:44 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:42:44] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:42:45] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:42:45 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:42:45] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:42:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:42:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:42:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:42:45] indra_gpt.chat_curate.chat_curate - LLM call took 0.52 seconds\n",
      "Curating statements with chat curation:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 56/89 [12:11<04:41,  8.54s/it]INFO: [2025-07-01 09:42:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:42:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:42:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:42:47] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.68 seconds\n",
      "\u001b[92m09:42:47 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:42:47] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:42:47] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:42:47 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:42:47] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:42:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:42:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:42:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:42:47] indra_gpt.chat_curate.chat_curate - LLM call took 0.66 seconds\n",
      "INFO: [2025-07-01 09:42:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:42:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:42:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:42:49] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.69 seconds\n",
      "\u001b[92m09:42:49 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:42:49] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:42:50] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:42:50 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:42:50] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:42:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:42:50] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:42:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:42:50] indra_gpt.chat_curate.chat_curate - LLM call took 0.60 seconds\n",
      "INFO: [2025-07-01 09:42:50] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:42:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:42:50] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:42:52] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.67 seconds\n",
      "\u001b[92m09:42:52 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:42:52] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:42:52] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:42:52 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:42:52] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:42:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:42:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:42:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:42:52] indra_gpt.chat_curate.chat_curate - LLM call took 0.76 seconds\n",
      "Curating statements with chat curation:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 57/89 [12:19<04:27,  8.35s/it]INFO: [2025-07-01 09:42:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:42:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:42:53] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:42:54] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.71 seconds\n",
      "\u001b[92m09:42:54 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:42:54] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:42:55] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:42:55 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:42:55] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:42:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:42:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:42:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:42:55] indra_gpt.chat_curate.chat_curate - LLM call took 0.60 seconds\n",
      "INFO: [2025-07-01 09:42:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:42:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:42:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:42:57] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.66 seconds\n",
      "\u001b[92m09:42:57 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:42:57] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:42:58] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:42:58 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:42:58] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:42:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:42:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:42:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:42:58] indra_gpt.chat_curate.chat_curate - LLM call took 0.69 seconds\n",
      "INFO: [2025-07-01 09:42:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:42:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:42:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:43:00] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.67 seconds\n",
      "\u001b[92m09:43:00 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:43:00] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:43:00] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:43:00 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:43:00] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:43:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:43:00] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:43:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:43:00] indra_gpt.chat_curate.chat_curate - LLM call took 0.56 seconds\n",
      "Curating statements with chat curation:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 58/89 [12:27<04:13,  8.18s/it]INFO: [2025-07-01 09:43:00] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:43:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:43:00] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:43:02] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.67 seconds\n",
      "\u001b[92m09:43:02 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:43:02] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:43:03] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:43:03 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:43:03] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:43:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:43:03] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:43:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:43:03] indra_gpt.chat_curate.chat_curate - LLM call took 0.77 seconds\n",
      "INFO: [2025-07-01 09:43:03] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:43:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:43:03] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:43:05] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.67 seconds\n",
      "\u001b[92m09:43:05 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:43:05] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:43:06] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:43:06 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:43:06] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:43:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:43:06] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:43:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:43:06] indra_gpt.chat_curate.chat_curate - LLM call took 0.70 seconds\n",
      "Curating statements with chat curation:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 59/89 [12:32<03:40,  7.35s/it]INFO: [2025-07-01 09:43:06] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:43:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:43:06] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:43:08] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.68 seconds\n",
      "\u001b[92m09:43:08 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:43:08] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:43:09] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:43:09 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:43:09] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:43:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:43:09] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:43:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:43:09] indra_gpt.chat_curate.chat_curate - LLM call took 1.41 seconds\n",
      "INFO: [2025-07-01 09:43:09] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:43:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:43:09] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:43:11] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.66 seconds\n",
      "\u001b[92m09:43:11 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:43:11] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:43:12] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:43:12 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:43:12] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:43:12 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:43:12] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:43:12 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:43:12] indra_gpt.chat_curate.chat_curate - LLM call took 0.71 seconds\n",
      "Curating statements with chat curation:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 60/89 [12:38<03:21,  6.95s/it]INFO: [2025-07-01 09:43:12] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:43:12 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:43:12] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:43:13] indra_gpt.chat_curate.chat_curate - Prompt generation took 0.91 seconds\n",
      "\u001b[92m09:43:13 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:43:13] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:43:14] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:43:14 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:43:14] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:43:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:43:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:43:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:43:14] indra_gpt.chat_curate.chat_curate - LLM call took 0.76 seconds\n",
      "INFO: [2025-07-01 09:43:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:43:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:43:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:43:15] indra_gpt.chat_curate.chat_curate - Prompt generation took 0.95 seconds\n",
      "\u001b[92m09:43:15 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:43:15] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:43:15] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:43:15 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:43:15] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:43:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:43:15] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:43:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:43:15] indra_gpt.chat_curate.chat_curate - LLM call took 0.53 seconds\n",
      "Curating statements with chat curation:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 61/89 [12:42<02:47,  5.98s/it]INFO: [2025-07-01 09:43:15] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:43:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:43:15] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:43:17] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.65 seconds\n",
      "\u001b[92m09:43:17 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:43:17] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:43:18] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:43:18 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:43:18] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:43:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:43:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:43:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:43:18] indra_gpt.chat_curate.chat_curate - LLM call took 0.66 seconds\n",
      "INFO: [2025-07-01 09:43:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:43:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:43:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:43:20] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.66 seconds\n",
      "\u001b[92m09:43:20 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:43:20] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:43:21] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:43:21 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:43:21] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:43:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:43:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:43:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:43:21] indra_gpt.chat_curate.chat_curate - LLM call took 0.69 seconds\n",
      "Curating statements with chat curation:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 62/89 [12:47<02:35,  5.76s/it]INFO: [2025-07-01 09:43:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:43:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:43:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:43:23] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.68 seconds\n",
      "\u001b[92m09:43:23 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:43:23] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:43:23] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:43:23 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:43:23] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:43:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:43:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:43:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:43:23] indra_gpt.chat_curate.chat_curate - LLM call took 0.72 seconds\n",
      "INFO: [2025-07-01 09:43:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:43:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:43:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:43:25] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.69 seconds\n",
      "\u001b[92m09:43:25 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:43:25] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:43:26] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:43:26 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:43:26] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:43:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:43:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:43:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:43:26] indra_gpt.chat_curate.chat_curate - LLM call took 0.73 seconds\n",
      "Curating statements with chat curation:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 63/89 [12:52<02:26,  5.64s/it]INFO: [2025-07-01 09:43:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:43:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:43:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:43:28] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.67 seconds\n",
      "\u001b[92m09:43:28 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:43:28] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:43:29] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:43:29 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:43:29] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:43:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:43:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:43:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:43:29] indra_gpt.chat_curate.chat_curate - LLM call took 0.81 seconds\n",
      "INFO: [2025-07-01 09:43:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:43:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:43:29] indra_gpt.chat_curate.chat_curate - Skipping evidence with no text for statement 2078133867265037: Evidence(source_api='biopax',\n",
      "         source_id='http://www.phosphosite.org/phosphosite.owl#Catalysis_2192577_3655',\n",
      "         annotations={\n",
      "                      \"source_sub_id\": \"phosphositeplus\",\n",
      "                      \"agents\": {\n",
      "                       \"raw_text\": [\n",
      "                        null,\n",
      "                        null\n",
      "                       ]\n",
      "                      },\n",
      "                      \"prior_uuids\": [\n",
      "                       \"d5d6b42f-698e-41ff-9795-9baab2734bf8\"\n",
      "                      ]\n",
      "                     },\n",
      "         epistemics={\n",
      "                     \"direct\": true\n",
      "                    }\n",
      "         )\n",
      "\n",
      "\n",
      "Curating statements with chat curation:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 64/89 [12:55<01:59,  4.79s/it]INFO: [2025-07-01 09:43:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:43:31] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.68 seconds\n",
      "\u001b[92m09:43:31 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:43:31] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:43:32] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:43:32 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:43:32] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:43:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:43:32] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:43:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:43:32] indra_gpt.chat_curate.chat_curate - LLM call took 0.85 seconds\n",
      "INFO: [2025-07-01 09:43:32] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:43:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:43:32] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:43:34] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.68 seconds\n",
      "\u001b[92m09:43:34 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:43:34] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:43:34] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:43:34 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:43:34] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:43:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:43:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:43:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:43:34] indra_gpt.chat_curate.chat_curate - LLM call took 0.72 seconds\n",
      "Curating statements with chat curation:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 65/89 [13:01<02:00,  5.01s/it]INFO: [2025-07-01 09:43:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:43:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:43:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:43:36] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.74 seconds\n",
      "\u001b[92m09:43:36 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:43:36] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:43:37] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:43:37 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:43:37] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:43:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:43:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:43:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:43:37] indra_gpt.chat_curate.chat_curate - LLM call took 0.69 seconds\n",
      "INFO: [2025-07-01 09:43:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:43:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:43:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:43:39] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.72 seconds\n",
      "\u001b[92m09:43:39 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:43:39] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:43:40] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:43:40 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:43:40] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:43:40 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:43:40] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:43:40 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:43:40] indra_gpt.chat_curate.chat_curate - LLM call took 0.51 seconds\n",
      "Curating statements with chat curation:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 66/89 [13:06<01:56,  5.07s/it]INFO: [2025-07-01 09:43:40] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:43:40 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:43:40] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:43:42] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.73 seconds\n",
      "\u001b[92m09:43:42 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:43:42] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:43:42] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:43:42 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:43:42] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:43:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:43:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:43:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:43:42] indra_gpt.chat_curate.chat_curate - LLM call took 0.57 seconds\n",
      "INFO: [2025-07-01 09:43:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:43:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:43:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:43:44] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.74 seconds\n",
      "\u001b[92m09:43:44 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:43:44] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:43:45] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:43:45 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:43:45] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:43:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:43:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:43:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:43:45] indra_gpt.chat_curate.chat_curate - LLM call took 0.68 seconds\n",
      "Curating statements with chat curation:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 67/89 [13:11<01:53,  5.14s/it]INFO: [2025-07-01 09:43:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:43:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:43:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:43:47] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.70 seconds\n",
      "\u001b[92m09:43:47 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:43:47] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:43:48] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:43:48 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:43:48] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:43:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:43:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:43:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:43:48] indra_gpt.chat_curate.chat_curate - LLM call took 0.89 seconds\n",
      "INFO: [2025-07-01 09:43:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:43:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:43:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:43:50] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.70 seconds\n",
      "\u001b[92m09:43:50 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:43:50] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:43:51] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:43:51 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:43:51] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:43:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:43:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:43:51] indra_gpt.chat_curate.chat_curate - LLM call took 1.15 seconds\n",
      "\u001b[92m09:43:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 68/89 [13:17<01:53,  5.39s/it]INFO: [2025-07-01 09:43:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:43:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:43:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:43:52] indra_gpt.chat_curate.chat_curate - Prompt generation took 0.91 seconds\n",
      "\u001b[92m09:43:52 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:43:52] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:43:54] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:43:54 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:43:54] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:43:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:43:54] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:43:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:43:54] indra_gpt.chat_curate.chat_curate - LLM call took 1.82 seconds\n",
      "INFO: [2025-07-01 09:43:54] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:43:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:43:54] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:43:55] indra_gpt.chat_curate.chat_curate - Prompt generation took 0.89 seconds\n",
      "\u001b[92m09:43:55 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:43:55] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:43:56] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:43:56 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:43:56] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:43:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:43:56] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:43:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:43:56] indra_gpt.chat_curate.chat_curate - LLM call took 0.62 seconds\n",
      "Curating statements with chat curation:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 69/89 [13:22<01:44,  5.22s/it]INFO: [2025-07-01 09:43:56] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:43:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:43:56] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:43:58] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.70 seconds\n",
      "\u001b[92m09:43:58 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:43:58] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:43:58] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:43:58 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:43:58] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:43:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:43:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:43:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:43:58] indra_gpt.chat_curate.chat_curate - LLM call took 0.64 seconds\n",
      "INFO: [2025-07-01 09:43:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:43:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:43:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:44:00] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.68 seconds\n",
      "\u001b[92m09:44:00 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:44:00] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:44:01] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:44:01 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:44:01] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:44:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:44:01] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:44:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:44:01] indra_gpt.chat_curate.chat_curate - LLM call took 0.67 seconds\n",
      "Curating statements with chat curation:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 70/89 [13:27<01:39,  5.24s/it]INFO: [2025-07-01 09:44:01] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:44:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:44:01] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:44:02] indra_gpt.chat_curate.chat_curate - Prompt generation took 0.90 seconds\n",
      "\u001b[92m09:44:02 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:44:02] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:44:03] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:44:03 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:44:03] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:44:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:44:03] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:44:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:44:03] indra_gpt.chat_curate.chat_curate - LLM call took 1.10 seconds\n",
      "INFO: [2025-07-01 09:44:03] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:44:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:44:03] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:44:04] indra_gpt.chat_curate.chat_curate - Prompt generation took 0.95 seconds\n",
      "\u001b[92m09:44:04 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:44:04] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:44:05] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:44:05 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:44:05] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:44:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:44:05] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:44:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:44:05] indra_gpt.chat_curate.chat_curate - LLM call took 0.55 seconds\n",
      "Curating statements with chat curation:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 71/89 [13:31<01:27,  4.87s/it]INFO: [2025-07-01 09:44:05] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:44:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:44:05] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:44:07] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.66 seconds\n",
      "\u001b[92m09:44:07 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:44:07] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:44:08] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:44:08 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:44:08] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:44:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:44:08] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:44:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:44:08] indra_gpt.chat_curate.chat_curate - LLM call took 0.66 seconds\n",
      "INFO: [2025-07-01 09:44:08] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:44:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:44:08] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:44:10] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.74 seconds\n",
      "\u001b[92m09:44:10 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:44:10] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:44:10] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:44:10 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:44:10] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:44:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:44:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:44:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:44:10] indra_gpt.chat_curate.chat_curate - LLM call took 0.68 seconds\n",
      "Curating statements with chat curation:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 72/89 [13:37<01:24,  4.99s/it]INFO: [2025-07-01 09:44:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:44:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:44:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:44:12] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.66 seconds\n",
      "\u001b[92m09:44:12 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:44:12] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:44:13] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:44:13 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:44:13] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:44:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:44:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:44:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:44:13] indra_gpt.chat_curate.chat_curate - LLM call took 0.76 seconds\n",
      "Curating statements with chat curation:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 73/89 [13:39<01:08,  4.30s/it]INFO: [2025-07-01 09:44:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:44:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:44:13] indra_gpt.chat_curate.chat_curate - Skipping agent None with no db_refs or None value in the agent list.\n",
      "INFO: [2025-07-01 09:44:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:44:14] indra_gpt.chat_curate.chat_curate - Prompt generation took 0.84 seconds\n",
      "\u001b[92m09:44:14 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:44:14] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:44:15] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:44:15 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:44:15] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:44:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:44:15] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:44:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:44:15] indra_gpt.chat_curate.chat_curate - LLM call took 0.62 seconds\n",
      "Curating statements with chat curation:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 74/89 [13:41<00:52,  3.51s/it]INFO: [2025-07-01 09:44:15] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:44:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:44:15] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:44:17] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.76 seconds\n",
      "\u001b[92m09:44:17 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:44:17] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:44:18] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:44:18 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:44:18] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:44:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:44:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:44:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:44:18] indra_gpt.chat_curate.chat_curate - LLM call took 0.82 seconds\n",
      "Curating statements with chat curation:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 75/89 [13:44<00:46,  3.35s/it]INFO: [2025-07-01 09:44:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:44:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:44:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:44:20] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.74 seconds\n",
      "\u001b[92m09:44:20 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:44:20] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:44:20] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:44:20 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:44:20] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:44:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:44:20] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:44:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:44:20] indra_gpt.chat_curate.chat_curate - LLM call took 0.68 seconds\n",
      "Curating statements with chat curation:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 76/89 [13:47<00:41,  3.16s/it]INFO: [2025-07-01 09:44:20] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:44:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:44:20] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:44:22] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.67 seconds\n",
      "\u001b[92m09:44:22 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:44:22] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:44:23] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:44:23 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:44:23] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:44:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:44:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:44:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:44:23] indra_gpt.chat_curate.chat_curate - LLM call took 0.69 seconds\n",
      "Curating statements with chat curation:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 77/89 [13:49<00:36,  3.01s/it]INFO: [2025-07-01 09:44:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:44:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:44:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:44:25] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.74 seconds\n",
      "\u001b[92m09:44:25 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:44:25] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:44:26] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:44:26 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:44:26] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:44:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:44:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:44:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:44:26] indra_gpt.chat_curate.chat_curate - LLM call took 0.79 seconds\n",
      "Curating statements with chat curation:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 78/89 [13:52<00:32,  2.97s/it]INFO: [2025-07-01 09:44:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:44:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:44:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:44:28] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.70 seconds\n",
      "\u001b[92m09:44:28 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:44:28] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:44:29] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:44:29 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:44:29] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:44:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:44:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:44:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:44:29] indra_gpt.chat_curate.chat_curate - LLM call took 0.82 seconds\n",
      "Curating statements with chat curation:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 79/89 [13:55<00:29,  2.92s/it]INFO: [2025-07-01 09:44:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:44:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:44:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:44:31] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.72 seconds\n",
      "\u001b[92m09:44:31 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:44:31] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:44:31] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:44:31 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:44:31] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:44:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:44:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:44:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:44:31] indra_gpt.chat_curate.chat_curate - LLM call took 0.74 seconds\n",
      "Curating statements with chat curation:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 80/89 [13:58<00:25,  2.88s/it]INFO: [2025-07-01 09:44:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:44:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:44:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:44:33] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.72 seconds\n",
      "\u001b[92m09:44:33 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:44:33] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:44:34] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:44:34 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:44:34] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:44:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:44:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:44:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:44:34] indra_gpt.chat_curate.chat_curate - LLM call took 0.92 seconds\n",
      "Curating statements with chat curation:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 81/89 [14:01<00:23,  2.90s/it]INFO: [2025-07-01 09:44:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:44:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:44:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:44:35] indra_gpt.chat_curate.chat_curate - Skipping agent cellular sensitivity LF PA83 LF() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "INFO: [2025-07-01 09:44:35] indra_gpt.chat_curate.chat_curate - Prompt generation took 0.88 seconds\n",
      "\u001b[92m09:44:35 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:44:35] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:44:36] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:44:36 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:44:36] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:44:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:44:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:44:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:44:36] indra_gpt.chat_curate.chat_curate - LLM call took 1.06 seconds\n",
      "Curating statements with chat curation:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 82/89 [14:03<00:18,  2.67s/it]INFO: [2025-07-01 09:44:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:44:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:44:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:44:39] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.72 seconds\n",
      "\u001b[92m09:44:39 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:44:39] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:44:39] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:44:39 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:44:39] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:44:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:44:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:44:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:44:39] indra_gpt.chat_curate.chat_curate - LLM call took 0.58 seconds\n",
      "Curating statements with chat curation:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 83/89 [14:05<00:15,  2.65s/it]INFO: [2025-07-01 09:44:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:44:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:44:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:44:41] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.66 seconds\n",
      "\u001b[92m09:44:41 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:44:41] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:44:42] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:44:42 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:44:42] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:44:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:44:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:44:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:44:42] indra_gpt.chat_curate.chat_curate - LLM call took 0.78 seconds\n",
      "Curating statements with chat curation:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 84/89 [14:08<00:13,  2.69s/it]INFO: [2025-07-01 09:44:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:44:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:44:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:44:46] indra_gpt.chat_curate.chat_curate - Prompt generation took 3.89 seconds\n",
      "\u001b[92m09:44:46 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:44:46] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:44:49] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:44:49 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:44:49] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:44:49 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:44:49] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:44:49 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:44:49] indra_gpt.chat_curate.chat_curate - LLM call took 2.48 seconds\n",
      "Curating statements with chat curation:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 85/89 [14:15<00:15,  3.88s/it]INFO: [2025-07-01 09:44:49] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:44:49 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:44:49] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:44:51] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.69 seconds\n",
      "\u001b[92m09:44:51 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:44:51] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:44:51] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:44:51 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:44:51] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:44:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:44:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:44:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:44:51] indra_gpt.chat_curate.chat_curate - LLM call took 0.89 seconds\n",
      "Curating statements with chat curation:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 86/89 [14:18<00:10,  3.58s/it]INFO: [2025-07-01 09:44:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:44:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:44:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:44:54] indra_gpt.chat_curate.chat_curate - Prompt generation took 2.59 seconds\n",
      "\u001b[92m09:44:54 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:44:54] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:44:55] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:44:55 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:44:55] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:44:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:44:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:44:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:44:55] indra_gpt.chat_curate.chat_curate - LLM call took 0.70 seconds\n",
      "Curating statements with chat curation:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 87/89 [14:21<00:07,  3.61s/it]INFO: [2025-07-01 09:44:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:44:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:44:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:44:57] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.70 seconds\n",
      "\u001b[92m09:44:57 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:44:57] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:44:58] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:44:58 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:44:58] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:44:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:44:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:44:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:44:58] indra_gpt.chat_curate.chat_curate - LLM call took 0.56 seconds\n",
      "Curating statements with chat curation:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 88/89 [14:24<00:03,  3.29s/it]INFO: [2025-07-01 09:44:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:44:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:44:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:44:59] indra_gpt.chat_curate.chat_curate - Prompt generation took 0.96 seconds\n",
      "\u001b[92m09:44:59 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:44:59] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:45:00] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:45:00 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:45:00] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:45:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:45:00] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:45:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:45:00] indra_gpt.chat_curate.chat_curate - LLM call took 0.68 seconds\n",
      "Curating statements with chat curation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 89/89 [14:26<00:00,  2.87s/it]INFO: [2025-07-01 09:45:00] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 89/89 [14:26<00:00,  9.73s/it]\u001b[92m09:45:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\n",
      "INFO: [2025-07-01 09:45:00] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:   0%|          | 0/89 [00:00<?, ?it/s]INFO: [2025-07-01 09:45:33] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.66 seconds\n",
      "\u001b[92m09:45:33 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:45:33] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:45:34] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:45:34 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:45:34] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:45:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:45:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:45:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:45:34] indra_gpt.chat_curate.chat_curate - LLM call took 1.12 seconds\n",
      "INFO: [2025-07-01 09:45:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:45:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:45:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:45:36] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.66 seconds\n",
      "\u001b[92m09:45:36 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:45:36] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:45:36] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:45:36 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:45:36] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:45:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:45:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:45:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:45:36] indra_gpt.chat_curate.chat_curate - LLM call took 0.59 seconds\n",
      "INFO: [2025-07-01 09:45:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:45:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:45:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:45:38] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.66 seconds\n",
      "\u001b[92m09:45:38 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:45:38] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:45:39] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:45:39 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:45:39] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:45:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:45:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:45:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:45:39] indra_gpt.chat_curate.chat_curate - LLM call took 1.03 seconds\n",
      "INFO: [2025-07-01 09:45:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:45:40 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:45:40] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:45:41] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.65 seconds\n",
      "\u001b[92m09:45:41 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:45:41] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:45:42] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:45:42 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:45:42] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:45:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:45:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:45:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:45:42] indra_gpt.chat_curate.chat_curate - LLM call took 0.62 seconds\n",
      "INFO: [2025-07-01 09:45:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:45:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:45:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:45:44] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.68 seconds\n",
      "\u001b[92m09:45:44 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:45:44] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:45:45] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:45:45 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:45:45] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:45:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:45:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:45:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:45:45] indra_gpt.chat_curate.chat_curate - LLM call took 0.68 seconds\n",
      "Curating statements with chat curation:   1%|          | 1/89 [00:13<20:16, 13.82s/it]INFO: [2025-07-01 09:45:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:45:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:45:45] indra_gpt.chat_curate.chat_curate - Skipping agent None with no db_refs or None value in the agent list.\n",
      "INFO: [2025-07-01 09:45:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:45:46] indra_gpt.chat_curate.chat_curate - Prompt generation took 0.83 seconds\n",
      "\u001b[92m09:45:46 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:45:46] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:45:46] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:45:46 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:45:46] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:45:46 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:45:46] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:45:46 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:45:46] indra_gpt.chat_curate.chat_curate - LLM call took 0.58 seconds\n",
      "INFO: [2025-07-01 09:45:46] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:45:46 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:45:46] indra_gpt.chat_curate.chat_curate - Skipping agent None with no db_refs or None value in the agent list.\n",
      "INFO: [2025-07-01 09:45:46] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:45:47] indra_gpt.chat_curate.chat_curate - Prompt generation took 0.83 seconds\n",
      "\u001b[92m09:45:47 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:45:47] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:45:48] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:45:48 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:45:48] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:45:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:45:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:45:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:45:48] indra_gpt.chat_curate.chat_curate - LLM call took 0.79 seconds\n",
      "INFO: [2025-07-01 09:45:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:45:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:45:48] indra_gpt.chat_curate.chat_curate - Skipping agent None with no db_refs or None value in the agent list.\n",
      "INFO: [2025-07-01 09:45:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:45:49] indra_gpt.chat_curate.chat_curate - Prompt generation took 0.88 seconds\n",
      "\u001b[92m09:45:49 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:45:49] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:45:50] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:45:50 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:45:50] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:45:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:45:50] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:45:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:45:50] indra_gpt.chat_curate.chat_curate - LLM call took 0.57 seconds\n",
      "INFO: [2025-07-01 09:45:50] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:45:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:45:50] indra_gpt.chat_curate.chat_curate - Skipping agent None with no db_refs or None value in the agent list.\n",
      "INFO: [2025-07-01 09:45:50] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:45:51] indra_gpt.chat_curate.chat_curate - Prompt generation took 0.84 seconds\n",
      "\u001b[92m09:45:51 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:45:51] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:45:52] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:45:52 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:45:52] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:45:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:45:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:45:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:45:52] indra_gpt.chat_curate.chat_curate - LLM call took 1.36 seconds\n",
      "INFO: [2025-07-01 09:45:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:45:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:45:52] indra_gpt.chat_curate.chat_curate - Skipping agent None with no db_refs or None value in the agent list.\n",
      "INFO: [2025-07-01 09:45:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:45:53] indra_gpt.chat_curate.chat_curate - Prompt generation took 0.84 seconds\n",
      "\u001b[92m09:45:53 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:45:53] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:45:53] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:45:53 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:45:53] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:45:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:45:53] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:45:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:45:53] indra_gpt.chat_curate.chat_curate - LLM call took 0.57 seconds\n",
      "Curating statements with chat curation:   2%|‚ñè         | 2/89 [00:22<15:46, 10.88s/it]INFO: [2025-07-01 09:45:53] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:45:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:45:53] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:45:55] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.67 seconds\n",
      "\u001b[92m09:45:55 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:45:55] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:45:56] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:45:56 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:45:56] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:45:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:45:56] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:45:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:45:56] indra_gpt.chat_curate.chat_curate - LLM call took 0.69 seconds\n",
      "INFO: [2025-07-01 09:45:56] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:45:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:45:56] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:45:58] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.66 seconds\n",
      "\u001b[92m09:45:58 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:45:58] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:45:59] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:45:59 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:45:59] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:45:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:45:59] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:45:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:45:59] indra_gpt.chat_curate.chat_curate - LLM call took 0.68 seconds\n",
      "INFO: [2025-07-01 09:45:59] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:45:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:45:59] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:46:01] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.67 seconds\n",
      "\u001b[92m09:46:01 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:46:01] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:46:01] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:46:01 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:46:01] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:46:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:46:01] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:46:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:46:01] indra_gpt.chat_curate.chat_curate - LLM call took 0.64 seconds\n",
      "INFO: [2025-07-01 09:46:01] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:46:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:46:01] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:46:03] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.69 seconds\n",
      "\u001b[92m09:46:03 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:46:03] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:46:04] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:46:04 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:46:04] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:46:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:46:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:46:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:46:04] indra_gpt.chat_curate.chat_curate - LLM call took 1.01 seconds\n",
      "INFO: [2025-07-01 09:46:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:46:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:46:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:46:06] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.73 seconds\n",
      "\u001b[92m09:46:06 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:46:06] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:46:07] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:46:07 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:46:07] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:46:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:46:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:46:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:46:07] indra_gpt.chat_curate.chat_curate - LLM call took 0.61 seconds\n",
      "Curating statements with chat curation:   3%|‚ñé         | 3/89 [00:36<17:15, 12.04s/it]INFO: [2025-07-01 09:46:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:46:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:46:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:46:07] indra_gpt.chat_curate.chat_curate - Skipping agent p2() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "INFO: [2025-07-01 09:46:08] indra_gpt.chat_curate.chat_curate - Prompt generation took 0.83 seconds\n",
      "\u001b[92m09:46:08 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:46:08] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:46:08] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:46:08 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:46:08] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:46:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:46:08] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:46:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:46:08] indra_gpt.chat_curate.chat_curate - LLM call took 0.57 seconds\n",
      "INFO: [2025-07-01 09:46:08] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:46:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:46:09] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:46:09] indra_gpt.chat_curate.chat_curate - Skipping agent p2() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "INFO: [2025-07-01 09:46:09] indra_gpt.chat_curate.chat_curate - Prompt generation took 0.86 seconds\n",
      "\u001b[92m09:46:09 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:46:09] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:46:10] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:46:10 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:46:10] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:46:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:46:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:46:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:46:10] indra_gpt.chat_curate.chat_curate - LLM call took 0.92 seconds\n",
      "INFO: [2025-07-01 09:46:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:46:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:46:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:46:11] indra_gpt.chat_curate.chat_curate - Skipping agent p2() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "INFO: [2025-07-01 09:46:11] indra_gpt.chat_curate.chat_curate - Prompt generation took 0.82 seconds\n",
      "\u001b[92m09:46:11 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:46:11] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:46:13] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:46:13 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:46:13] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:46:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:46:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:46:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:46:13] indra_gpt.chat_curate.chat_curate - LLM call took 1.68 seconds\n",
      "INFO: [2025-07-01 09:46:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:46:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:46:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:46:13] indra_gpt.chat_curate.chat_curate - Skipping agent p2() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "INFO: [2025-07-01 09:46:14] indra_gpt.chat_curate.chat_curate - Prompt generation took 0.83 seconds\n",
      "\u001b[92m09:46:14 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:46:14] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:46:15] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:46:15 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:46:15] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:46:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:46:15] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:46:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:46:15] indra_gpt.chat_curate.chat_curate - LLM call took 0.56 seconds\n",
      "INFO: [2025-07-01 09:46:15] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:46:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:46:15] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:46:15] indra_gpt.chat_curate.chat_curate - Skipping agent p2() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "INFO: [2025-07-01 09:46:16] indra_gpt.chat_curate.chat_curate - Prompt generation took 0.83 seconds\n",
      "\u001b[92m09:46:16 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:46:16] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:46:16] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:46:16 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:46:16] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:46:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:46:16] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:46:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:46:16] indra_gpt.chat_curate.chat_curate - LLM call took 0.67 seconds\n",
      "Curating statements with chat curation:   4%|‚ñç         | 4/89 [00:45<15:30, 10.95s/it]INFO: [2025-07-01 09:46:16] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:46:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:46:16] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:46:18] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.72 seconds\n",
      "\u001b[92m09:46:18 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:46:18] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:46:19] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:46:19 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:46:19] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:46:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:46:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:46:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:46:19] indra_gpt.chat_curate.chat_curate - LLM call took 0.98 seconds\n",
      "INFO: [2025-07-01 09:46:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:46:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:46:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:46:21] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.71 seconds\n",
      "\u001b[92m09:46:21 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:46:21] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:46:22] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:46:22 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:46:22] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:46:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:46:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:46:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:46:22] indra_gpt.chat_curate.chat_curate - LLM call took 0.66 seconds\n",
      "INFO: [2025-07-01 09:46:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:46:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:46:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:46:24] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.71 seconds\n",
      "\u001b[92m09:46:24 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:46:24] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:46:25] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:46:25 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:46:25] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:46:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:46:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:46:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:46:25] indra_gpt.chat_curate.chat_curate - LLM call took 0.81 seconds\n",
      "INFO: [2025-07-01 09:46:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:46:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:46:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:46:27] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.71 seconds\n",
      "\u001b[92m09:46:27 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:46:27] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:46:27] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:46:27 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:46:27] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:46:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:46:27] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:46:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:46:27] indra_gpt.chat_curate.chat_curate - LLM call took 0.49 seconds\n",
      "INFO: [2025-07-01 09:46:27] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:46:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:46:27] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:46:29] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.72 seconds\n",
      "\u001b[92m09:46:29 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:46:29] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:46:30] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:46:30 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:46:30] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:46:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:46:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:46:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:46:30] indra_gpt.chat_curate.chat_curate - LLM call took 0.56 seconds\n",
      "Curating statements with chat curation:   6%|‚ñå         | 5/89 [00:58<16:36, 11.87s/it]INFO: [2025-07-01 09:46:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:46:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:46:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:46:32] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.65 seconds\n",
      "\u001b[92m09:46:32 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:46:32] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:46:32] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:46:32 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:46:32] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:46:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:46:32] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:46:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:46:32] indra_gpt.chat_curate.chat_curate - LLM call took 0.72 seconds\n",
      "INFO: [2025-07-01 09:46:32] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:46:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:46:32] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:46:34] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.65 seconds\n",
      "\u001b[92m09:46:34 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:46:34] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:46:35] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:46:35 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:46:35] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:46:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:46:35] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:46:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:46:35] indra_gpt.chat_curate.chat_curate - LLM call took 1.10 seconds\n",
      "INFO: [2025-07-01 09:46:35] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:46:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:46:35] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:46:37] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.65 seconds\n",
      "\u001b[92m09:46:37 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:46:37] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:46:38] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:46:38 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:46:38] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:46:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:46:38] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:46:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:46:38] indra_gpt.chat_curate.chat_curate - LLM call took 0.67 seconds\n",
      "INFO: [2025-07-01 09:46:38] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:46:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:46:38] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:46:40] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.68 seconds\n",
      "\u001b[92m09:46:40 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:46:40] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:46:40] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:46:40 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:46:40] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:46:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:46:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:46:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:46:41] indra_gpt.chat_curate.chat_curate - LLM call took 0.60 seconds\n",
      "INFO: [2025-07-01 09:46:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:46:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:46:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:46:42] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.66 seconds\n",
      "\u001b[92m09:46:42 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:46:42] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:46:43] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:46:43 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:46:43] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:46:43 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:46:43] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:46:43 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:46:43] indra_gpt.chat_curate.chat_curate - LLM call took 0.57 seconds\n",
      "Curating statements with chat curation:   7%|‚ñã         | 6/89 [01:12<17:05, 12.36s/it]INFO: [2025-07-01 09:46:43] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:46:43 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:46:43] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:46:45] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.74 seconds\n",
      "\u001b[92m09:46:45 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:46:45] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:46:46] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:46:46 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:46:46] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:46:46 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:46:46] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:46:46 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:46:46] indra_gpt.chat_curate.chat_curate - LLM call took 0.67 seconds\n",
      "INFO: [2025-07-01 09:46:46] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:46:46 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:46:46] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:46:48] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.74 seconds\n",
      "\u001b[92m09:46:48 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:46:48] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:46:48] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:46:48 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:46:48] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:46:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:46:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:46:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:46:48] indra_gpt.chat_curate.chat_curate - LLM call took 0.63 seconds\n",
      "INFO: [2025-07-01 09:46:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:46:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:46:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:46:50] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.74 seconds\n",
      "\u001b[92m09:46:50 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:46:50] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:46:51] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:46:51 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:46:51] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:46:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:46:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:46:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:46:51] indra_gpt.chat_curate.chat_curate - LLM call took 0.65 seconds\n",
      "INFO: [2025-07-01 09:46:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:46:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:46:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:46:53] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.78 seconds\n",
      "\u001b[92m09:46:53 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:46:53] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:46:54] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:46:54 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:46:54] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:46:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:46:54] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:46:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:46:54] indra_gpt.chat_curate.chat_curate - LLM call took 0.58 seconds\n",
      "INFO: [2025-07-01 09:46:54] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:46:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:46:54] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:46:56] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.75 seconds\n",
      "\u001b[92m09:46:56 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:46:56] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:46:56] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:46:56 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:46:56] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:46:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:46:56] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:46:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:46:56] indra_gpt.chat_curate.chat_curate - LLM call took 0.58 seconds\n",
      "Curating statements with chat curation:   8%|‚ñä         | 7/89 [01:25<17:15, 12.63s/it]INFO: [2025-07-01 09:46:56] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:46:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:46:56] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:46:58] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.68 seconds\n",
      "\u001b[92m09:46:58 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:46:58] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:46:59] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:46:59 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:46:59] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:46:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:46:59] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:46:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:46:59] indra_gpt.chat_curate.chat_curate - LLM call took 1.13 seconds\n",
      "INFO: [2025-07-01 09:46:59] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:46:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:46:59] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:47:01] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.66 seconds\n",
      "\u001b[92m09:47:01 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:47:01] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:47:02] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:47:02 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:47:02] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:47:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:47:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:47:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:47:02] indra_gpt.chat_curate.chat_curate - LLM call took 0.67 seconds\n",
      "INFO: [2025-07-01 09:47:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:47:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:47:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:47:04] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.66 seconds\n",
      "\u001b[92m09:47:04 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:47:04] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:47:04] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:47:04 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:47:04] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:47:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:47:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:47:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:47:04] indra_gpt.chat_curate.chat_curate - LLM call took 0.71 seconds\n",
      "INFO: [2025-07-01 09:47:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:47:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:47:05] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:47:06] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.70 seconds\n",
      "\u001b[92m09:47:06 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:47:06] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:47:07] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:47:07 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:47:07] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:47:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:47:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:47:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:47:07] indra_gpt.chat_curate.chat_curate - LLM call took 0.65 seconds\n",
      "INFO: [2025-07-01 09:47:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:47:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:47:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:47:09] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.70 seconds\n",
      "\u001b[92m09:47:09 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:47:09] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:47:10] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:47:10 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:47:10] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:47:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:47:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:47:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:47:10] indra_gpt.chat_curate.chat_curate - LLM call took 0.87 seconds\n",
      "Curating statements with chat curation:   9%|‚ñâ         | 8/89 [01:39<17:32, 12.99s/it]INFO: [2025-07-01 09:47:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:47:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:47:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:47:12] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.74 seconds\n",
      "\u001b[92m09:47:12 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:47:12] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:47:13] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:47:13 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:47:13] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:47:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:47:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:47:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:47:13] indra_gpt.chat_curate.chat_curate - LLM call took 0.58 seconds\n",
      "INFO: [2025-07-01 09:47:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:47:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:47:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:47:14] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.69 seconds\n",
      "\u001b[92m09:47:15 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:47:15] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:47:15] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:47:15 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:47:15] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:47:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:47:15] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:47:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:47:15] indra_gpt.chat_curate.chat_curate - LLM call took 0.67 seconds\n",
      "INFO: [2025-07-01 09:47:15] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:47:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:47:15] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:47:17] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.67 seconds\n",
      "\u001b[92m09:47:17 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:47:17] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:47:18] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:47:18 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:47:18] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:47:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:47:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:47:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:47:18] indra_gpt.chat_curate.chat_curate - LLM call took 0.84 seconds\n",
      "INFO: [2025-07-01 09:47:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:47:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:47:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:47:20] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.66 seconds\n",
      "\u001b[92m09:47:20 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:47:20] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:47:21] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:47:21 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:47:21] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:47:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:47:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:47:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:47:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:47:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:47:21] indra_gpt.chat_curate.chat_curate - LLM call took 0.68 seconds\n",
      "INFO: [2025-07-01 09:47:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:47:22] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.68 seconds\n",
      "\u001b[92m09:47:22 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:47:22] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:47:23] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:47:23 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:47:23] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:47:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:47:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:47:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:47:23] indra_gpt.chat_curate.chat_curate - LLM call took 0.52 seconds\n",
      "Curating statements with chat curation:  10%|‚ñà         | 9/89 [01:52<17:21, 13.02s/it]INFO: [2025-07-01 09:47:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:47:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:47:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:47:25] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.65 seconds\n",
      "\u001b[92m09:47:25 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:47:25] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:47:26] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:47:26 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:47:26] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:47:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:47:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:47:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:47:26] indra_gpt.chat_curate.chat_curate - LLM call took 1.25 seconds\n",
      "INFO: [2025-07-01 09:47:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:47:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:47:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:47:28] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.65 seconds\n",
      "\u001b[92m09:47:28 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:47:28] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:47:29] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:47:29 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:47:29] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:47:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:47:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:47:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:47:29] indra_gpt.chat_curate.chat_curate - LLM call took 0.59 seconds\n",
      "INFO: [2025-07-01 09:47:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:47:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:47:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:47:31] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.72 seconds\n",
      "\u001b[92m09:47:31 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:47:31] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:47:31] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:47:31 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:47:31] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:47:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:47:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:47:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:47:31] indra_gpt.chat_curate.chat_curate - LLM call took 0.63 seconds\n",
      "INFO: [2025-07-01 09:47:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:47:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:47:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:47:33] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.66 seconds\n",
      "\u001b[92m09:47:33 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:47:33] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:47:34] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:47:34 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:47:34] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:47:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:47:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:47:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:47:34] indra_gpt.chat_curate.chat_curate - LLM call took 0.83 seconds\n",
      "INFO: [2025-07-01 09:47:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:47:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:47:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:47:36] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.65 seconds\n",
      "\u001b[92m09:47:36 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:47:36] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:47:37] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:47:37 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:47:37] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:47:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:47:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:47:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:47:37] indra_gpt.chat_curate.chat_curate - LLM call took 0.69 seconds\n",
      "Curating statements with chat curation:  11%|‚ñà         | 10/89 [02:05<17:25, 13.23s/it]INFO: [2025-07-01 09:47:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:47:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:47:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:47:39] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.67 seconds\n",
      "\u001b[92m09:47:39 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:47:39] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:47:39] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:47:39 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:47:39] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:47:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:47:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:47:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:47:39] indra_gpt.chat_curate.chat_curate - LLM call took 0.66 seconds\n",
      "INFO: [2025-07-01 09:47:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:47:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:47:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:47:41] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.72 seconds\n",
      "\u001b[92m09:47:41 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:47:41] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:47:43] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:47:43 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:47:43] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:47:43 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:47:43] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:47:43 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:47:43] indra_gpt.chat_curate.chat_curate - LLM call took 1.19 seconds\n",
      "INFO: [2025-07-01 09:47:43] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:47:43 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:47:43] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:47:44] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.72 seconds\n",
      "\u001b[92m09:47:44 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:47:44] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:47:45] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:47:45 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:47:45] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:47:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:47:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:47:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:47:45] indra_gpt.chat_curate.chat_curate - LLM call took 0.60 seconds\n",
      "INFO: [2025-07-01 09:47:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:47:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:47:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:47:47] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.66 seconds\n",
      "\u001b[92m09:47:47 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:47:47] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:47:48] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:47:48 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:47:48] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:47:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:47:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:47:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:47:48] indra_gpt.chat_curate.chat_curate - LLM call took 0.69 seconds\n",
      "INFO: [2025-07-01 09:47:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:47:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:47:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:47:50] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.72 seconds\n",
      "\u001b[92m09:47:50 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:47:50] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:47:50] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:47:50 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:47:50] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:47:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:47:50] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:47:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:47:50] indra_gpt.chat_curate.chat_curate - LLM call took 0.67 seconds\n",
      "Curating statements with chat curation:  12%|‚ñà‚ñè        | 11/89 [02:19<17:21, 13.36s/it]INFO: [2025-07-01 09:47:50] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:47:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:47:50] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:47:52] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.72 seconds\n",
      "\u001b[92m09:47:52 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:47:52] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:47:53] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:47:53 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:47:53] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:47:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:47:53] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:47:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:47:53] indra_gpt.chat_curate.chat_curate - LLM call took 0.86 seconds\n",
      "INFO: [2025-07-01 09:47:53] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:47:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:47:53] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:47:55] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.67 seconds\n",
      "\u001b[92m09:47:55 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:47:55] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:47:56] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:47:56 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:47:56] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:47:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:47:56] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:47:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:47:56] indra_gpt.chat_curate.chat_curate - LLM call took 1.20 seconds\n",
      "INFO: [2025-07-01 09:47:56] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:47:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:47:56] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:47:58] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.68 seconds\n",
      "\u001b[92m09:47:58 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:47:58] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:47:59] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:47:59 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:47:59] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:47:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:47:59] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:47:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:47:59] indra_gpt.chat_curate.chat_curate - LLM call took 0.80 seconds\n",
      "INFO: [2025-07-01 09:47:59] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:47:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:47:59] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:48:01] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.68 seconds\n",
      "\u001b[92m09:48:01 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:48:01] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:48:02] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:48:02 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:48:02] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:48:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:48:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:48:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:48:02] indra_gpt.chat_curate.chat_curate - LLM call took 0.86 seconds\n",
      "INFO: [2025-07-01 09:48:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:48:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:48:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:48:04] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.70 seconds\n",
      "\u001b[92m09:48:04 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:48:04] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:48:05] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:48:05 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:48:05] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:48:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:48:05] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:48:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:48:05] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:48:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:48:05] indra_gpt.chat_curate.chat_curate - LLM call took 0.67 seconds\n",
      "Curating statements with chat curation:  13%|‚ñà‚ñé        | 12/89 [02:33<17:29, 13.62s/it]INFO: [2025-07-01 09:48:05] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:48:07] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.74 seconds\n",
      "\u001b[92m09:48:07 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:48:07] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:48:07] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:48:07 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:48:07] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:48:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:48:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:48:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:48:07] indra_gpt.chat_curate.chat_curate - LLM call took 0.59 seconds\n",
      "INFO: [2025-07-01 09:48:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:48:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:48:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:48:09] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.66 seconds\n",
      "\u001b[92m09:48:09 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:48:09] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:48:10] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:48:10 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:48:10] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:48:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:48:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:48:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:48:10] indra_gpt.chat_curate.chat_curate - LLM call took 0.77 seconds\n",
      "INFO: [2025-07-01 09:48:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:48:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:48:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:48:12] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.69 seconds\n",
      "\u001b[92m09:48:12 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:48:12] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:48:13] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:48:13 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:48:13] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:48:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:48:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:48:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:48:13] indra_gpt.chat_curate.chat_curate - LLM call took 0.82 seconds\n",
      "INFO: [2025-07-01 09:48:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:48:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:48:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:48:15] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.76 seconds\n",
      "\u001b[92m09:48:15 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:48:15] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:48:16] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:48:16 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:48:16] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:48:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:48:16] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:48:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:48:16] indra_gpt.chat_curate.chat_curate - LLM call took 0.73 seconds\n",
      "INFO: [2025-07-01 09:48:16] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:48:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:48:16] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:48:18] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.69 seconds\n",
      "\u001b[92m09:48:18 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:48:18] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:48:25] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:48:25 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:48:25] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:48:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:48:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:48:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:48:25] indra_gpt.chat_curate.chat_curate - LLM call took 7.34 seconds\n",
      "Curating statements with chat curation:  15%|‚ñà‚ñç        | 13/89 [02:54<19:47, 15.63s/it]INFO: [2025-07-01 09:48:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:48:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:48:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:48:27] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.78 seconds\n",
      "\u001b[92m09:48:27 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:48:27] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:48:28] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:48:28 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:48:28] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:48:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:48:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:48:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:48:28] indra_gpt.chat_curate.chat_curate - LLM call took 0.72 seconds\n",
      "INFO: [2025-07-01 09:48:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:48:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:48:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:48:30] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.71 seconds\n",
      "\u001b[92m09:48:30 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:48:30] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:48:30] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:48:30 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:48:30] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:48:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:48:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:48:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:48:30] indra_gpt.chat_curate.chat_curate - LLM call took 0.73 seconds\n",
      "INFO: [2025-07-01 09:48:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:48:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:48:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:48:32] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.72 seconds\n",
      "\u001b[92m09:48:32 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:48:32] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:48:33] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:48:33 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:48:33] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:48:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:48:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:48:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:48:33] indra_gpt.chat_curate.chat_curate - LLM call took 0.64 seconds\n",
      "INFO: [2025-07-01 09:48:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:48:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:48:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:48:35] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.72 seconds\n",
      "\u001b[92m09:48:35 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:48:35] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:48:36] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:48:36 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:48:36] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:48:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:48:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:48:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:48:36] indra_gpt.chat_curate.chat_curate - LLM call took 0.67 seconds\n",
      "INFO: [2025-07-01 09:48:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:48:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:48:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:48:38] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.72 seconds\n",
      "\u001b[92m09:48:38 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:48:38] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:48:38] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:48:38 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:48:38] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:48:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:48:38] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:48:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:48:38] indra_gpt.chat_curate.chat_curate - LLM call took 0.82 seconds\n",
      "Curating statements with chat curation:  16%|‚ñà‚ñå        | 14/89 [03:07<18:46, 15.02s/it]INFO: [2025-07-01 09:48:38] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:48:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:48:38] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:48:40] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.73 seconds\n",
      "\u001b[92m09:48:40 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:48:40] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:48:41] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:48:41 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:48:41] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:48:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:48:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:48:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:48:41] indra_gpt.chat_curate.chat_curate - LLM call took 0.81 seconds\n",
      "INFO: [2025-07-01 09:48:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:48:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:48:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:48:43] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.78 seconds\n",
      "\u001b[92m09:48:43 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:48:43] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:48:44] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:48:44 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:48:44] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:48:44 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:48:44] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:48:44 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:48:44] indra_gpt.chat_curate.chat_curate - LLM call took 0.68 seconds\n",
      "INFO: [2025-07-01 09:48:44] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:48:44 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:48:44] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:48:46] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.71 seconds\n",
      "\u001b[92m09:48:46 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:48:46] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:48:47] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:48:47 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:48:47] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:48:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:48:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:48:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:48:47] indra_gpt.chat_curate.chat_curate - LLM call took 0.86 seconds\n",
      "INFO: [2025-07-01 09:48:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:48:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:48:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:48:49] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.73 seconds\n",
      "\u001b[92m09:48:49 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:48:49] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:48:49] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:48:49 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:48:49] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:48:49 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:48:49] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:48:49 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:48:49] indra_gpt.chat_curate.chat_curate - LLM call took 0.56 seconds\n",
      "INFO: [2025-07-01 09:48:49] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:48:49 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:48:49] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:48:51] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.69 seconds\n",
      "\u001b[92m09:48:51 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:48:51] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:48:52] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:48:52 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:48:52] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:48:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:48:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:48:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:48:52] indra_gpt.chat_curate.chat_curate - LLM call took 1.11 seconds\n",
      "Curating statements with chat curation:  17%|‚ñà‚ñã        | 15/89 [03:21<18:08, 14.71s/it]INFO: [2025-07-01 09:48:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:48:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:48:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:48:54] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.72 seconds\n",
      "\u001b[92m09:48:54 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:48:54] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:48:55] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:48:55 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:48:55] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:48:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:48:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:48:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:48:55] indra_gpt.chat_curate.chat_curate - LLM call took 0.67 seconds\n",
      "INFO: [2025-07-01 09:48:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:48:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:48:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:48:57] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.70 seconds\n",
      "\u001b[92m09:48:57 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:48:57] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:48:58] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:48:58 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:48:58] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:48:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:48:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:48:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:48:58] indra_gpt.chat_curate.chat_curate - LLM call took 0.67 seconds\n",
      "INFO: [2025-07-01 09:48:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:48:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:48:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:49:00] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.66 seconds\n",
      "\u001b[92m09:49:00 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:49:00] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:49:01] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:49:01 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:49:01] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:49:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:49:01] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:49:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:49:01] indra_gpt.chat_curate.chat_curate - LLM call took 0.79 seconds\n",
      "INFO: [2025-07-01 09:49:01] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:49:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:49:01] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:49:03] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.71 seconds\n",
      "\u001b[92m09:49:03 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:49:03] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:49:03] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:49:03 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:49:03] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:49:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:49:03] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:49:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:49:03] indra_gpt.chat_curate.chat_curate - LLM call took 0.82 seconds\n",
      "INFO: [2025-07-01 09:49:03] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:49:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:49:03] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:49:05] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.66 seconds\n",
      "\u001b[92m09:49:05 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:49:05] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:49:06] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:49:06 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:49:06] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:49:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:49:06] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:49:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:49:06] indra_gpt.chat_curate.chat_curate - LLM call took 0.65 seconds\n",
      "Curating statements with chat curation:  18%|‚ñà‚ñä        | 16/89 [03:35<17:27, 14.35s/it]INFO: [2025-07-01 09:49:06] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:49:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:49:06] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:49:08] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.85 seconds\n",
      "\u001b[92m09:49:08 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:49:08] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:49:09] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:49:09 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:49:09] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:49:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:49:09] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:49:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:49:09] indra_gpt.chat_curate.chat_curate - LLM call took 0.62 seconds\n",
      "INFO: [2025-07-01 09:49:09] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:49:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:49:09] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:49:11] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.77 seconds\n",
      "\u001b[92m09:49:11 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:49:11] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:49:11] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:49:11 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:49:11] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:49:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:49:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:49:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:49:11] indra_gpt.chat_curate.chat_curate - LLM call took 0.70 seconds\n",
      "INFO: [2025-07-01 09:49:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:49:12 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:49:12] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:49:13] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.73 seconds\n",
      "\u001b[92m09:49:13 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:49:13] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:49:14] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:49:14 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:49:14] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:49:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:49:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:49:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:49:14] indra_gpt.chat_curate.chat_curate - LLM call took 0.86 seconds\n",
      "INFO: [2025-07-01 09:49:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:49:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:49:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:49:16] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.75 seconds\n",
      "\u001b[92m09:49:16 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:49:16] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:49:17] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:49:17 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:49:17] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:49:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:49:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:49:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:49:17] indra_gpt.chat_curate.chat_curate - LLM call took 0.56 seconds\n",
      "INFO: [2025-07-01 09:49:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:49:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:49:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:49:19] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.71 seconds\n",
      "\u001b[92m09:49:19 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:49:19] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:49:20] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:49:20 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:49:20] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:49:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:49:20] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:49:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:49:20] indra_gpt.chat_curate.chat_curate - LLM call took 0.98 seconds\n",
      "Curating statements with chat curation:  19%|‚ñà‚ñâ        | 17/89 [03:49<17:04, 14.22s/it]INFO: [2025-07-01 09:49:20] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:49:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:49:20] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:49:22] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.70 seconds\n",
      "\u001b[92m09:49:22 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:49:22] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:49:23] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:49:23 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:49:23] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:49:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:49:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:49:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:49:23] indra_gpt.chat_curate.chat_curate - LLM call took 0.70 seconds\n",
      "INFO: [2025-07-01 09:49:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:49:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:49:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:49:25] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.70 seconds\n",
      "\u001b[92m09:49:25 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:49:25] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:49:25] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:49:25 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:49:25] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:49:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:49:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:49:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:49:25] indra_gpt.chat_curate.chat_curate - LLM call took 0.61 seconds\n",
      "INFO: [2025-07-01 09:49:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:49:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:49:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:49:27] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.69 seconds\n",
      "\u001b[92m09:49:27 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:49:27] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:49:28] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:49:28 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:49:28] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:49:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:49:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:49:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:49:28] indra_gpt.chat_curate.chat_curate - LLM call took 0.79 seconds\n",
      "INFO: [2025-07-01 09:49:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:49:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:49:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:49:30] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.72 seconds\n",
      "\u001b[92m09:49:30 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:49:30] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:49:31] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:49:31 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:49:31] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:49:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:49:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:49:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:49:31] indra_gpt.chat_curate.chat_curate - LLM call took 1.01 seconds\n",
      "INFO: [2025-07-01 09:49:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:49:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:49:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:49:33] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.68 seconds\n",
      "\u001b[92m09:49:33 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:49:33] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:49:34] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:49:34 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:49:34] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:49:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:49:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:49:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:49:34] indra_gpt.chat_curate.chat_curate - LLM call took 0.60 seconds\n",
      "Curating statements with chat curation:  20%|‚ñà‚ñà        | 18/89 [04:02<16:38, 14.06s/it]INFO: [2025-07-01 09:49:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:49:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:49:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:49:36] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.71 seconds\n",
      "\u001b[92m09:49:36 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:49:36] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:49:36] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:49:36 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:49:36] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:49:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:49:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:49:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:49:36] indra_gpt.chat_curate.chat_curate - LLM call took 0.67 seconds\n",
      "INFO: [2025-07-01 09:49:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:49:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:49:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:49:38] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.68 seconds\n",
      "\u001b[92m09:49:38 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:49:38] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:49:39] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:49:39 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:49:39] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:49:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:49:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:49:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:49:39] indra_gpt.chat_curate.chat_curate - LLM call took 0.57 seconds\n",
      "INFO: [2025-07-01 09:49:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:49:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:49:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:49:41] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.73 seconds\n",
      "\u001b[92m09:49:41 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:49:41] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:49:42] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:49:42 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:49:42] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:49:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:49:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:49:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:49:42] indra_gpt.chat_curate.chat_curate - LLM call took 1.21 seconds\n",
      "INFO: [2025-07-01 09:49:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:49:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:49:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:49:44] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.71 seconds\n",
      "\u001b[92m09:49:44 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:49:44] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:49:45] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:49:45 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:49:45] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:49:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:49:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:49:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:49:45] indra_gpt.chat_curate.chat_curate - LLM call took 0.59 seconds\n",
      "INFO: [2025-07-01 09:49:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:49:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:49:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:49:46] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.67 seconds\n",
      "\u001b[92m09:49:46 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:49:46] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:49:47] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:49:47 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:49:47] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:49:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:49:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:49:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:49:47] indra_gpt.chat_curate.chat_curate - LLM call took 0.59 seconds\n",
      "Curating statements with chat curation:  21%|‚ñà‚ñà‚ñè       | 19/89 [04:16<16:12, 13.89s/it]INFO: [2025-07-01 09:49:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:49:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:49:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:49:49] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.75 seconds\n",
      "\u001b[92m09:49:49 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:49:49] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:49:50] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:49:50 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:49:50] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:49:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:49:50] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:49:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:49:50] indra_gpt.chat_curate.chat_curate - LLM call took 0.66 seconds\n",
      "INFO: [2025-07-01 09:49:50] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:49:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:49:50] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:49:52] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.74 seconds\n",
      "\u001b[92m09:49:52 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:49:52] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:49:52] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:49:52 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:49:52] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:49:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:49:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:49:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:49:52] indra_gpt.chat_curate.chat_curate - LLM call took 0.58 seconds\n",
      "INFO: [2025-07-01 09:49:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:49:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:49:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:49:54] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.67 seconds\n",
      "\u001b[92m09:49:54 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:49:54] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:49:55] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:49:55 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:49:55] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:49:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:49:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:49:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:49:55] indra_gpt.chat_curate.chat_curate - LLM call took 0.67 seconds\n",
      "INFO: [2025-07-01 09:49:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:49:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:49:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:49:57] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.67 seconds\n",
      "\u001b[92m09:49:57 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:49:57] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:49:59] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:49:59 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:49:59] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:49:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:49:59] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:49:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:49:59] indra_gpt.chat_curate.chat_curate - LLM call took 1.69 seconds\n",
      "INFO: [2025-07-01 09:49:59] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:49:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:49:59] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:50:01] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.69 seconds\n",
      "\u001b[92m09:50:01 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:50:01] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:50:01] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:50:01 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:50:01] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:50:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:50:01] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:50:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:50:01] indra_gpt.chat_curate.chat_curate - LLM call took 0.71 seconds\n",
      "Curating statements with chat curation:  22%|‚ñà‚ñà‚ñè       | 20/89 [04:30<16:07, 14.02s/it]INFO: [2025-07-01 09:50:01] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:50:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:50:01] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:50:03] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.71 seconds\n",
      "\u001b[92m09:50:03 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:50:03] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:50:04] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:50:04 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:50:04] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:50:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:50:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:50:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:50:04] indra_gpt.chat_curate.chat_curate - LLM call took 0.62 seconds\n",
      "INFO: [2025-07-01 09:50:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:50:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:50:04] indra_gpt.chat_curate.chat_curate - Skipping evidence with no text for statement -26186913902459663: Evidence(source_api='biogrid',\n",
      "         pmid='17314511',\n",
      "         source_id='564180',\n",
      "         annotations={\n",
      "                      \"biogrid_int_id\": \"564180\",\n",
      "                      \"entrez_a\": \"4609\",\n",
      "                      \"entrez_b\": \"86\",\n",
      "                      \"biogrid_a\": \"110694\",\n",
      "                      \"biogrid_b\": \"106601\",\n",
      "                      \"syst_name_a\": null,\n",
      "                      \"syst_name_b\": null,\n",
      "                      \"hgnc_a\": \"MYC\",\n",
      "                      \"hgnc_b\": \"ACTL6A\",\n",
      "                      \"syn_a\": \"MRTL|MYCC|bHLHe39|c-Myc\",\n",
      "                      \"syn_b\": \"ACTL6|ARPN-BETA|Arp4|BAF53A|INO80K\",\n",
      "                      \"exp_system\": \"Affinity Capture-MS\",\n",
      "                      \"exp_system_type\": \"physical\",\n",
      "                      \"author\": \"Koch HB (2007)\",\n",
      "                      \"pmid\": \"17314511\",\n",
      "                      \"organism_a\": \"9606\",\n",
      "                      \"organism_b\": \"9606\",\n",
      "                      \"throughput\": \"High Throughput\",\n",
      "                      \"score\": null,\n",
      "                      \"modification\": null,\n",
      "                      \"phenotypes\": null,\n",
      "                      \"qualifications\": null,\n",
      "                      \"tags\": null,\n",
      "                      \"source_db\": \"BIOGRID\",\n",
      "                      \"agents\": {\n",
      "                       \"raw_text\": [\n",
      "                        null,\n",
      "                        null\n",
      "                       ]\n",
      "                      },\n",
      "                      \"prior_uuids\": [\n",
      "                       \"f3caf670-50dc-48c9-92bc-47ee6600fa15\"\n",
      "                      ]\n",
      "                     },\n",
      "         text_refs={\n",
      "                    \"PMID\": \"17314511\"\n",
      "                   }\n",
      "         )\n",
      "\n",
      "\n",
      "INFO: [2025-07-01 09:50:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:50:06] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.77 seconds\n",
      "\u001b[92m09:50:06 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:50:06] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:50:07] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:50:07 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:50:07] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:50:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:50:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:50:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:50:07] indra_gpt.chat_curate.chat_curate - LLM call took 0.74 seconds\n",
      "INFO: [2025-07-01 09:50:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:50:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:50:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:50:09] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.70 seconds\n",
      "\u001b[92m09:50:09 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:50:09] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:50:09] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:50:09 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:50:09] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:50:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:50:09] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:50:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:50:09] indra_gpt.chat_curate.chat_curate - LLM call took 0.69 seconds\n",
      "INFO: [2025-07-01 09:50:09] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:50:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:50:09] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:50:11] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.72 seconds\n",
      "\u001b[92m09:50:11 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:50:11] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:50:12] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:50:12 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:50:12] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:50:12 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:50:12] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:50:12 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:50:12] indra_gpt.chat_curate.chat_curate - LLM call took 0.66 seconds\n",
      "Curating statements with chat curation:  24%|‚ñà‚ñà‚ñé       | 21/89 [04:41<14:45, 13.02s/it]INFO: [2025-07-01 09:50:12] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:50:12 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:50:12] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:50:14] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.74 seconds\n",
      "\u001b[92m09:50:14 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:50:14] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:50:15] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:50:15 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:50:15] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:50:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:50:15] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:50:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:50:15] indra_gpt.chat_curate.chat_curate - LLM call took 0.70 seconds\n",
      "INFO: [2025-07-01 09:50:15] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:50:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:50:15] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:50:17] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.72 seconds\n",
      "\u001b[92m09:50:17 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:50:17] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:50:18] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:50:18 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:50:18] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:50:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:50:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:50:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:50:18] indra_gpt.chat_curate.chat_curate - LLM call took 1.33 seconds\n",
      "INFO: [2025-07-01 09:50:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:50:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:50:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:50:20] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.71 seconds\n",
      "\u001b[92m09:50:20 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:50:20] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:50:21] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:50:21 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:50:21] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:50:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:50:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:50:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:50:21] indra_gpt.chat_curate.chat_curate - LLM call took 0.96 seconds\n",
      "INFO: [2025-07-01 09:50:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:50:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:50:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:50:23] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.74 seconds\n",
      "\u001b[92m09:50:23 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:50:23] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:50:24] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:50:24 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:50:24] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:50:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:50:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:50:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:50:24] indra_gpt.chat_curate.chat_curate - LLM call took 0.84 seconds\n",
      "INFO: [2025-07-01 09:50:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:50:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:50:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:50:26] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.71 seconds\n",
      "\u001b[92m09:50:26 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:50:26] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:50:27] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:50:27 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:50:27] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:50:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:50:27] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:50:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:50:27] indra_gpt.chat_curate.chat_curate - LLM call took 0.63 seconds\n",
      "Curating statements with chat curation:  25%|‚ñà‚ñà‚ñç       | 22/89 [04:55<15:03, 13.48s/it]INFO: [2025-07-01 09:50:27] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:50:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:50:27] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:50:29] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.77 seconds\n",
      "\u001b[92m09:50:29 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:50:29] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:50:29] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:50:29 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:50:29] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:50:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:50:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:50:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:50:29] indra_gpt.chat_curate.chat_curate - LLM call took 0.61 seconds\n",
      "INFO: [2025-07-01 09:50:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:50:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:50:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:50:31] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.67 seconds\n",
      "\u001b[92m09:50:31 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:50:31] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:50:32] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:50:32 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:50:32] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:50:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:50:32] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:50:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:50:32] indra_gpt.chat_curate.chat_curate - LLM call took 0.67 seconds\n",
      "INFO: [2025-07-01 09:50:32] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:50:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:50:32] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:50:34] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.74 seconds\n",
      "\u001b[92m09:50:34 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:50:34] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:50:34] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:50:34 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:50:34] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:50:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:50:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:50:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:50:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:50:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:50:34] indra_gpt.chat_curate.chat_curate - LLM call took 0.61 seconds\n",
      "INFO: [2025-07-01 09:50:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:50:36] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.66 seconds\n",
      "\u001b[92m09:50:36 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:50:36] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:50:37] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:50:37 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:50:37] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:50:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:50:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:50:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:50:37] indra_gpt.chat_curate.chat_curate - LLM call took 0.57 seconds\n",
      "INFO: [2025-07-01 09:50:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:50:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:50:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:50:39] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.66 seconds\n",
      "\u001b[92m09:50:39 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:50:39] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:50:40] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:50:40 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:50:40] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:50:40 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:50:40] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:50:40 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:50:40] indra_gpt.chat_curate.chat_curate - LLM call took 0.61 seconds\n",
      "Curating statements with chat curation:  26%|‚ñà‚ñà‚ñå       | 23/89 [05:08<14:38, 13.30s/it]INFO: [2025-07-01 09:50:40] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:50:40 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:50:40] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:50:41] indra_gpt.chat_curate.chat_curate - Prompt generation took 0.91 seconds\n",
      "\u001b[92m09:50:41 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:50:41] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:50:41] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:50:41 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:50:41] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:50:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:50:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:50:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:50:41] indra_gpt.chat_curate.chat_curate - LLM call took 0.68 seconds\n",
      "INFO: [2025-07-01 09:50:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:50:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:50:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:50:43] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.00 seconds\n",
      "\u001b[92m09:50:43 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:50:43] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:50:45] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:50:45 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:50:45] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:50:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:50:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:50:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:50:45] indra_gpt.chat_curate.chat_curate - LLM call took 1.88 seconds\n",
      "INFO: [2025-07-01 09:50:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:50:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:50:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:50:46] indra_gpt.chat_curate.chat_curate - Prompt generation took 0.89 seconds\n",
      "\u001b[92m09:50:46 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:50:46] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:50:46] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:50:46 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:50:46] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:50:46 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:50:46] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:50:46 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:50:46] indra_gpt.chat_curate.chat_curate - LLM call took 0.58 seconds\n",
      "INFO: [2025-07-01 09:50:46] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:50:46 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:50:46] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:50:47] indra_gpt.chat_curate.chat_curate - Prompt generation took 0.89 seconds\n",
      "\u001b[92m09:50:47 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:50:47] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:50:48] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:50:48 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:50:48] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:50:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:50:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:50:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:50:48] indra_gpt.chat_curate.chat_curate - LLM call took 0.49 seconds\n",
      "INFO: [2025-07-01 09:50:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:50:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:50:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:50:49] indra_gpt.chat_curate.chat_curate - Prompt generation took 0.90 seconds\n",
      "\u001b[92m09:50:49 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:50:49] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:50:50] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:50:50 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:50:50] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:50:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:50:50] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:50:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:50:50] indra_gpt.chat_curate.chat_curate - LLM call took 0.57 seconds\n",
      "Curating statements with chat curation:  27%|‚ñà‚ñà‚ñã       | 24/89 [05:18<13:24, 12.37s/it]INFO: [2025-07-01 09:50:50] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:50:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:50:50] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:50:52] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.66 seconds\n",
      "\u001b[92m09:50:52 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:50:52] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:50:52] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:50:52 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:50:52] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:50:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:50:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:50:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:50:52] indra_gpt.chat_curate.chat_curate - LLM call took 0.61 seconds\n",
      "INFO: [2025-07-01 09:50:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:50:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:50:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:50:54] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.69 seconds\n",
      "\u001b[92m09:50:54 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:50:54] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:50:55] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:50:55 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:50:55] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:50:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:50:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:50:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:50:55] indra_gpt.chat_curate.chat_curate - LLM call took 0.52 seconds\n",
      "INFO: [2025-07-01 09:50:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:50:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:50:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:50:57] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.69 seconds\n",
      "\u001b[92m09:50:57 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:50:57] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:50:57] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:50:57 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:50:57] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:50:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:50:57] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:50:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:50:57] indra_gpt.chat_curate.chat_curate - LLM call took 0.74 seconds\n",
      "INFO: [2025-07-01 09:50:57] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:50:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:50:57] indra_gpt.chat_curate.chat_curate - Skipping evidence with no text for statement -29615932207517012: Evidence(source_api='hprd',\n",
      "         pmid='15737636',\n",
      "         source_id='http://hprd.org/interactions?hprd_id=00105&isoform_id=00105_1&isoform_name=Isoform_1',\n",
      "         annotations={\n",
      "                      \"evidence\": [\n",
      "                       \"in vitro\",\n",
      "                       \"in vivo\",\n",
      "                       \"yeast 2-hybrid\"\n",
      "                      ],\n",
      "                      \"agents\": {\n",
      "                       \"raw_text\": [\n",
      "                        null,\n",
      "                        null\n",
      "                       ]\n",
      "                      },\n",
      "                      \"prior_uuids\": [\n",
      "                       \"010c9b5d-b2ad-4cfc-9685-1a36c73b0020\"\n",
      "                      ]\n",
      "                     },\n",
      "         text_refs={\n",
      "                    \"PMID\": \"15737636\"\n",
      "                   }\n",
      "         )\n",
      "\n",
      "\n",
      "INFO: [2025-07-01 09:50:57] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:50:59] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.75 seconds\n",
      "\u001b[92m09:50:59 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:50:59] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:51:00] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:51:00 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:51:00] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:51:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:51:00] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:51:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:51:00] indra_gpt.chat_curate.chat_curate - LLM call took 0.70 seconds\n",
      "Curating statements with chat curation:  28%|‚ñà‚ñà‚ñä       | 25/89 [05:29<12:35, 11.80s/it]INFO: [2025-07-01 09:51:00] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:51:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:51:00] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:51:02] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.66 seconds\n",
      "\u001b[92m09:51:02 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:51:02] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:51:03] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:51:03 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:51:03] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:51:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:51:03] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:51:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:51:03] indra_gpt.chat_curate.chat_curate - LLM call took 0.60 seconds\n",
      "INFO: [2025-07-01 09:51:03] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:51:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:51:03] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:51:05] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.71 seconds\n",
      "\u001b[92m09:51:05 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:51:05] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:51:05] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:51:05 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:51:05] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:51:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:51:05] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:51:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:51:05] indra_gpt.chat_curate.chat_curate - LLM call took 0.76 seconds\n",
      "INFO: [2025-07-01 09:51:05] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:51:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:51:06] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:51:07] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.66 seconds\n",
      "\u001b[92m09:51:07 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:51:07] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:51:09] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:51:09 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:51:09] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:51:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:51:09] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:51:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:51:09] indra_gpt.chat_curate.chat_curate - LLM call took 1.82 seconds\n",
      "INFO: [2025-07-01 09:51:09] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:51:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:51:09] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:51:11] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.68 seconds\n",
      "\u001b[92m09:51:11 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:51:11] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:51:12] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:51:12 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:51:12] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:51:12 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:51:12] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:51:12 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:51:12] indra_gpt.chat_curate.chat_curate - LLM call took 0.57 seconds\n",
      "INFO: [2025-07-01 09:51:12] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:51:12 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:51:12] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:51:14] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.66 seconds\n",
      "\u001b[92m09:51:14 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:51:14] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:51:14] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:51:14 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:51:14] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:51:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:51:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:51:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:51:14] indra_gpt.chat_curate.chat_curate - LLM call took 0.49 seconds\n",
      "Curating statements with chat curation:  29%|‚ñà‚ñà‚ñâ       | 26/89 [05:43<13:06, 12.48s/it]INFO: [2025-07-01 09:51:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:51:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:51:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:51:16] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.68 seconds\n",
      "\u001b[92m09:51:16 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:51:16] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:51:17] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:51:17 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:51:17] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:51:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:51:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:51:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:51:17] indra_gpt.chat_curate.chat_curate - LLM call took 0.85 seconds\n",
      "INFO: [2025-07-01 09:51:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:51:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:51:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:51:19] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.74 seconds\n",
      "\u001b[92m09:51:19 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:51:19] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:51:20] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:51:20 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:51:20] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:51:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:51:20] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:51:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:51:20] indra_gpt.chat_curate.chat_curate - LLM call took 1.37 seconds\n",
      "INFO: [2025-07-01 09:51:20] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:51:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:51:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:51:22] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.67 seconds\n",
      "\u001b[92m09:51:22 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:51:22] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:51:23] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:51:23 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:51:23] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:51:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:51:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:51:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:51:23] indra_gpt.chat_curate.chat_curate - LLM call took 0.68 seconds\n",
      "INFO: [2025-07-01 09:51:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:51:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:51:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:51:25] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.73 seconds\n",
      "\u001b[92m09:51:25 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:51:25] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:51:26] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:51:26 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:51:26] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:51:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:51:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:51:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:51:26] indra_gpt.chat_curate.chat_curate - LLM call took 0.68 seconds\n",
      "INFO: [2025-07-01 09:51:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:51:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:51:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:51:28] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.72 seconds\n",
      "\u001b[92m09:51:28 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:51:28] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:51:29] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:51:29 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:51:29] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:51:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:51:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:51:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:51:29] indra_gpt.chat_curate.chat_curate - LLM call took 1.09 seconds\n",
      "Curating statements with chat curation:  30%|‚ñà‚ñà‚ñà       | 27/89 [05:58<13:34, 13.14s/it]INFO: [2025-07-01 09:51:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:51:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:51:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:51:31] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.70 seconds\n",
      "\u001b[92m09:51:31 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:51:31] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:51:31] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:51:32 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:51:32] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:51:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:51:32] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:51:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:51:32] indra_gpt.chat_curate.chat_curate - LLM call took 0.58 seconds\n",
      "INFO: [2025-07-01 09:51:32] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:51:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:51:32] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:51:34] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.68 seconds\n",
      "\u001b[92m09:51:34 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:51:34] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:51:34] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:51:34 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:51:34] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:51:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:51:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:51:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:51:34] indra_gpt.chat_curate.chat_curate - LLM call took 0.50 seconds\n",
      "INFO: [2025-07-01 09:51:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:51:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:51:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:51:36] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.72 seconds\n",
      "\u001b[92m09:51:36 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:51:36] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:51:37] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:51:37 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:51:37] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:51:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:51:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:51:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:51:37] indra_gpt.chat_curate.chat_curate - LLM call took 0.59 seconds\n",
      "INFO: [2025-07-01 09:51:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:51:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:51:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:51:39] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.65 seconds\n",
      "\u001b[92m09:51:39 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:51:39] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:51:39] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:51:39 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:51:39] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:51:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:51:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:51:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:51:39] indra_gpt.chat_curate.chat_curate - LLM call took 0.67 seconds\n",
      "INFO: [2025-07-01 09:51:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:51:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:51:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:51:41] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.73 seconds\n",
      "\u001b[92m09:51:41 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:51:41] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:51:42] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:51:42 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:51:42] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:51:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:51:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:51:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:51:42] indra_gpt.chat_curate.chat_curate - LLM call took 0.73 seconds\n",
      "Curating statements with chat curation:  31%|‚ñà‚ñà‚ñà‚ñè      | 28/89 [06:11<13:19, 13.11s/it]INFO: [2025-07-01 09:51:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:51:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:51:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:51:44] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.71 seconds\n",
      "\u001b[92m09:51:44 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:51:44] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:51:45] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:51:45 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:51:45] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:51:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:51:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:51:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:51:45] indra_gpt.chat_curate.chat_curate - LLM call took 0.63 seconds\n",
      "INFO: [2025-07-01 09:51:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:51:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:51:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:51:47] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.66 seconds\n",
      "\u001b[92m09:51:47 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:51:47] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:51:47] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:51:47 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:51:47] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:51:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:51:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:51:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:51:47] indra_gpt.chat_curate.chat_curate - LLM call took 0.67 seconds\n",
      "INFO: [2025-07-01 09:51:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:51:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:51:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:51:49] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.67 seconds\n",
      "\u001b[92m09:51:49 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:51:49] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:51:50] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:51:50 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:51:50] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:51:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:51:50] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:51:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:51:50] indra_gpt.chat_curate.chat_curate - LLM call took 0.59 seconds\n",
      "INFO: [2025-07-01 09:51:50] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:51:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:51:50] indra_gpt.chat_curate.chat_curate - Skipping evidence with no text for statement 14461478333067931: Evidence(source_api='ubibrowser',\n",
      "         annotations={\n",
      "                      \"agents\": {\n",
      "                       \"raw_text\": [\n",
      "                        null,\n",
      "                        null\n",
      "                       ]\n",
      "                      },\n",
      "                      \"prior_uuids\": [\n",
      "                       \"8770d509-ea4a-43af-a5cd-c5e65c0fe4e1\"\n",
      "                      ]\n",
      "                     }\n",
      "         )\n",
      "\n",
      "\n",
      "INFO: [2025-07-01 09:51:50] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:51:52] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.73 seconds\n",
      "\u001b[92m09:51:52 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:51:52] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:51:53] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:51:53 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:51:53] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:51:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:51:53] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:51:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:51:53] indra_gpt.chat_curate.chat_curate - LLM call took 0.62 seconds\n",
      "Curating statements with chat curation:  33%|‚ñà‚ñà‚ñà‚ñé      | 29/89 [06:21<12:20, 12.35s/it]INFO: [2025-07-01 09:51:53] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:51:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:51:53] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:51:55] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.72 seconds\n",
      "\u001b[92m09:51:55 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:51:55] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:51:55] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:51:55 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:51:55] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:51:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:51:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:51:55] indra_gpt.chat_curate.chat_curate - LLM call took 0.75 seconds\n",
      "\u001b[92m09:51:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:51:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:51:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:51:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:51:57] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.71 seconds\n",
      "\u001b[92m09:51:57 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:51:57] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:51:58] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:51:58 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:51:58] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:51:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:51:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:51:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:51:58] indra_gpt.chat_curate.chat_curate - LLM call took 0.58 seconds\n",
      "INFO: [2025-07-01 09:51:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:51:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:51:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:52:00] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.70 seconds\n",
      "\u001b[92m09:52:00 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:52:00] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:52:01] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:52:01 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:52:01] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:52:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:52:01] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:52:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:52:01] indra_gpt.chat_curate.chat_curate - LLM call took 0.57 seconds\n",
      "INFO: [2025-07-01 09:52:01] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:52:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:52:01] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:52:03] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.69 seconds\n",
      "\u001b[92m09:52:03 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:52:03] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:52:04] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:52:04 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:52:04] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:52:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:52:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:52:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:52:04] indra_gpt.chat_curate.chat_curate - LLM call took 0.86 seconds\n",
      "INFO: [2025-07-01 09:52:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:52:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:52:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:52:06] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.68 seconds\n",
      "\u001b[92m09:52:06 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:52:06] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:52:06] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:52:06 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:52:06] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:52:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:52:06] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:52:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:52:06] indra_gpt.chat_curate.chat_curate - LLM call took 0.67 seconds\n",
      "Curating statements with chat curation:  34%|‚ñà‚ñà‚ñà‚ñé      | 30/89 [06:35<12:31, 12.74s/it]INFO: [2025-07-01 09:52:06] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:52:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:52:06] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:52:08] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.66 seconds\n",
      "\u001b[92m09:52:08 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:52:08] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:52:09] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:52:09 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:52:09] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:52:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:52:09] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:52:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:52:09] indra_gpt.chat_curate.chat_curate - LLM call took 0.70 seconds\n",
      "INFO: [2025-07-01 09:52:09] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:52:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:52:09] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:52:11] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.76 seconds\n",
      "\u001b[92m09:52:11 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:52:11] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:52:12] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:52:12 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:52:12] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:52:12 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:52:12] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:52:12 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:52:12] indra_gpt.chat_curate.chat_curate - LLM call took 0.69 seconds\n",
      "INFO: [2025-07-01 09:52:12] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:52:12 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:52:12] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:52:14] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.71 seconds\n",
      "\u001b[92m09:52:14 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:52:14] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:52:14] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:52:14 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:52:14] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:52:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:52:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:52:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:52:14] indra_gpt.chat_curate.chat_curate - LLM call took 0.67 seconds\n",
      "INFO: [2025-07-01 09:52:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:52:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:52:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:52:16] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.67 seconds\n",
      "\u001b[92m09:52:16 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:52:16] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:52:17] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:52:17 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:52:17] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:52:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:52:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:52:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:52:17] indra_gpt.chat_curate.chat_curate - LLM call took 0.57 seconds\n",
      "INFO: [2025-07-01 09:52:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:52:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:52:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:52:19] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.71 seconds\n",
      "\u001b[92m09:52:19 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:52:19] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:52:19] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:52:19 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:52:19] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:52:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:52:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:52:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:52:19] indra_gpt.chat_curate.chat_curate - LLM call took 0.69 seconds\n",
      "Curating statements with chat curation:  35%|‚ñà‚ñà‚ñà‚ñç      | 31/89 [06:48<12:27, 12.89s/it]INFO: [2025-07-01 09:52:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:52:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:52:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:52:21] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.71 seconds\n",
      "\u001b[92m09:52:21 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:52:21] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:52:23] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:52:23 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:52:23] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:52:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:52:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:52:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:52:23] indra_gpt.chat_curate.chat_curate - LLM call took 1.08 seconds\n",
      "INFO: [2025-07-01 09:52:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:52:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:52:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:52:25] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.75 seconds\n",
      "\u001b[92m09:52:25 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:52:25] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:52:25] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:52:25 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:52:25] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:52:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:52:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:52:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:52:25] indra_gpt.chat_curate.chat_curate - LLM call took 0.82 seconds\n",
      "INFO: [2025-07-01 09:52:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:52:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:52:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:52:27] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.77 seconds\n",
      "\u001b[92m09:52:27 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:52:27] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:52:29] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:52:29 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:52:29] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:52:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:52:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:52:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:52:29] indra_gpt.chat_curate.chat_curate - LLM call took 1.37 seconds\n",
      "INFO: [2025-07-01 09:52:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:52:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:52:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:52:31] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.70 seconds\n",
      "\u001b[92m09:52:31 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:52:31] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:52:32] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:52:32 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:52:32] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:52:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:52:32] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:52:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:52:32] indra_gpt.chat_curate.chat_curate - LLM call took 1.31 seconds\n",
      "INFO: [2025-07-01 09:52:32] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:52:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:52:32] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:52:34] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.75 seconds\n",
      "\u001b[92m09:52:34 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:52:34] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:52:35] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:52:35 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:52:35] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:52:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:52:35] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:52:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:52:35] indra_gpt.chat_curate.chat_curate - LLM call took 0.66 seconds\n",
      "Curating statements with chat curation:  36%|‚ñà‚ñà‚ñà‚ñå      | 32/89 [07:03<12:57, 13.64s/it]INFO: [2025-07-01 09:52:35] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:52:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:52:35] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:52:36] indra_gpt.chat_curate.chat_curate - Prompt generation took 0.91 seconds\n",
      "\u001b[92m09:52:36 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:52:36] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:52:37] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:52:37 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:52:37] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:52:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:52:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:52:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:52:37] indra_gpt.chat_curate.chat_curate - LLM call took 0.60 seconds\n",
      "INFO: [2025-07-01 09:52:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:52:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:52:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:52:38] indra_gpt.chat_curate.chat_curate - Prompt generation took 0.91 seconds\n",
      "\u001b[92m09:52:38 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:52:38] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:52:39] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:52:39 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:52:39] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:52:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:52:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:52:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:52:39] indra_gpt.chat_curate.chat_curate - LLM call took 1.01 seconds\n",
      "INFO: [2025-07-01 09:52:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:52:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:52:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:52:40] indra_gpt.chat_curate.chat_curate - Prompt generation took 0.91 seconds\n",
      "\u001b[92m09:52:40 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:52:40] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:52:41] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:52:41 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:52:41] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:52:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:52:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:52:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:52:41] indra_gpt.chat_curate.chat_curate - LLM call took 0.59 seconds\n",
      "INFO: [2025-07-01 09:52:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:52:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:52:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:52:42] indra_gpt.chat_curate.chat_curate - Prompt generation took 0.90 seconds\n",
      "\u001b[92m09:52:42 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:52:42] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:52:42] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:52:43 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:52:43] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:52:43 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:52:43] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:52:43 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:52:43] indra_gpt.chat_curate.chat_curate - LLM call took 0.68 seconds\n",
      "INFO: [2025-07-01 09:52:43] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:52:43 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:52:43] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:52:44] indra_gpt.chat_curate.chat_curate - Prompt generation took 0.91 seconds\n",
      "\u001b[92m09:52:44 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:52:44] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:52:44] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:52:44 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:52:44] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:52:44 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:52:44] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:52:44 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:52:44] indra_gpt.chat_curate.chat_curate - LLM call took 0.66 seconds\n",
      "Curating statements with chat curation:  37%|‚ñà‚ñà‚ñà‚ñã      | 33/89 [07:13<11:35, 12.42s/it]INFO: [2025-07-01 09:52:44] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:52:44 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:52:44] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:52:46] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.67 seconds\n",
      "\u001b[92m09:52:46 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:52:46] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:52:47] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:52:47 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:52:47] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:52:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:52:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:52:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:52:47] indra_gpt.chat_curate.chat_curate - LLM call took 0.64 seconds\n",
      "INFO: [2025-07-01 09:52:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:52:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:52:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:52:49] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.73 seconds\n",
      "\u001b[92m09:52:49 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:52:49] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:52:50] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:52:50 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:52:50] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:52:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:52:50] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:52:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:52:50] indra_gpt.chat_curate.chat_curate - LLM call took 0.64 seconds\n",
      "INFO: [2025-07-01 09:52:50] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:52:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:52:50] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:52:52] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.75 seconds\n",
      "\u001b[92m09:52:52 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:52:52] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:52:53] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:52:53 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:52:53] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:52:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:52:53] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:52:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:52:53] indra_gpt.chat_curate.chat_curate - LLM call took 1.37 seconds\n",
      "INFO: [2025-07-01 09:52:53] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:52:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:52:53] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:52:55] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.68 seconds\n",
      "\u001b[92m09:52:55 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:52:55] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:52:56] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:52:56 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:52:56] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:52:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:52:56] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:52:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:52:56] indra_gpt.chat_curate.chat_curate - LLM call took 0.64 seconds\n",
      "INFO: [2025-07-01 09:52:56] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:52:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:52:56] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:52:58] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.76 seconds\n",
      "\u001b[92m09:52:58 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:52:58] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:52:59] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:52:59 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:52:59] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:52:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:52:59] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:52:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:52:59] indra_gpt.chat_curate.chat_curate - LLM call took 1.36 seconds\n",
      "Curating statements with chat curation:  38%|‚ñà‚ñà‚ñà‚ñä      | 34/89 [07:28<12:01, 13.12s/it]INFO: [2025-07-01 09:52:59] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:52:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:52:59] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:53:01] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.71 seconds\n",
      "\u001b[92m09:53:01 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:53:01] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:53:02] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:53:02 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:53:02] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:53:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:53:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:53:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:53:02] indra_gpt.chat_curate.chat_curate - LLM call took 0.63 seconds\n",
      "INFO: [2025-07-01 09:53:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:53:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:53:02] indra_gpt.chat_curate.chat_curate - Skipping evidence with no text for statement -10558769985488922: Evidence(source_api='ctd',\n",
      "         pmid='26004626',\n",
      "         annotations={\n",
      "                      \"interaction_action\": \"increases^chemical synthesis\",\n",
      "                      \"agents\": {\n",
      "                       \"raw_text\": [\n",
      "                        null,\n",
      "                        null\n",
      "                       ]\n",
      "                      },\n",
      "                      \"prior_uuids\": [\n",
      "                       \"401a0189-dc6a-4b12-95e3-8a759226aa39\"\n",
      "                      ]\n",
      "                     },\n",
      "         context={\n",
      "                  \"species\": {\n",
      "                   \"name\": \"Homo sapiens\",\n",
      "                   \"db_refs\": {\n",
      "                    \"TAXONOMY\": \"9606\"\n",
      "                   }\n",
      "                  },\n",
      "                  \"type\": \"bio\"\n",
      "                 },\n",
      "         text_refs={\n",
      "                    \"PMID\": \"26004626\"\n",
      "                   }\n",
      "         )\n",
      "\n",
      "\n",
      "INFO: [2025-07-01 09:53:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:53:02] indra_gpt.chat_curate.chat_curate - Skipping evidence with no text for statement -10558769985488922: Evidence(source_api='ctd',\n",
      "         pmid='17327447',\n",
      "         annotations={\n",
      "                      \"interaction_action\": \"increases^abundance\",\n",
      "                      \"agents\": {\n",
      "                       \"raw_text\": [\n",
      "                        null,\n",
      "                        null\n",
      "                       ]\n",
      "                      },\n",
      "                      \"prior_uuids\": [\n",
      "                       \"1e0419a3-fcc4-436a-a946-f4f9faa2982e\"\n",
      "                      ]\n",
      "                     },\n",
      "         context={\n",
      "                  \"species\": {\n",
      "                   \"name\": \"Homo sapiens\",\n",
      "                   \"db_refs\": {\n",
      "                    \"TAXONOMY\": \"9606\"\n",
      "                   }\n",
      "                  },\n",
      "                  \"type\": \"bio\"\n",
      "                 },\n",
      "         text_refs={\n",
      "                    \"PMID\": \"17327447\"\n",
      "                   }\n",
      "         )\n",
      "\n",
      "\n",
      "INFO: [2025-07-01 09:53:04] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.72 seconds\n",
      "\u001b[92m09:53:04 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:53:04] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:53:04] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:53:04 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:53:04] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:53:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:53:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:53:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:53:04] indra_gpt.chat_curate.chat_curate - LLM call took 0.62 seconds\n",
      "INFO: [2025-07-01 09:53:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:53:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:53:04] indra_gpt.chat_curate.chat_curate - Skipping evidence with no text for statement -10558769985488922: Evidence(source_api='ctd',\n",
      "         pmid='16935842',\n",
      "         annotations={\n",
      "                      \"interaction_action\": \"increases^chemical synthesis\",\n",
      "                      \"agents\": {\n",
      "                       \"raw_text\": [\n",
      "                        null,\n",
      "                        null\n",
      "                       ]\n",
      "                      },\n",
      "                      \"prior_uuids\": [\n",
      "                       \"cae3f4a7-7105-4d72-baab-ac1af212082a\"\n",
      "                      ]\n",
      "                     },\n",
      "         text_refs={\n",
      "                    \"PMID\": \"16935842\"\n",
      "                   }\n",
      "         )\n",
      "\n",
      "\n",
      "Curating statements with chat curation:  39%|‚ñà‚ñà‚ñà‚ñâ      | 35/89 [07:33<09:41, 10.77s/it]INFO: [2025-07-01 09:53:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:53:06] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.77 seconds\n",
      "\u001b[92m09:53:06 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:53:06] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:53:07] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:53:07 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:53:07] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:53:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:53:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:53:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:53:07] indra_gpt.chat_curate.chat_curate - LLM call took 0.71 seconds\n",
      "INFO: [2025-07-01 09:53:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:53:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:53:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:53:09] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.67 seconds\n",
      "\u001b[92m09:53:09 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:53:09] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:53:10] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:53:10 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:53:10] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:53:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:53:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:53:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:53:10] indra_gpt.chat_curate.chat_curate - LLM call took 0.66 seconds\n",
      "INFO: [2025-07-01 09:53:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:53:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:53:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:53:12] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.72 seconds\n",
      "\u001b[92m09:53:12 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:53:12] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:53:13] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:53:13 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:53:13] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:53:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:53:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:53:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:53:13] indra_gpt.chat_curate.chat_curate - LLM call took 0.81 seconds\n",
      "INFO: [2025-07-01 09:53:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:53:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:53:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:53:15] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.65 seconds\n",
      "\u001b[92m09:53:15 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:53:15] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:53:15] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:53:15 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:53:15] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:53:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:53:15] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:53:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:53:15] indra_gpt.chat_curate.chat_curate - LLM call took 0.68 seconds\n",
      "INFO: [2025-07-01 09:53:15] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:53:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:53:15] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:53:17] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.67 seconds\n",
      "\u001b[92m09:53:17 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:53:17] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:53:18] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:53:18 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:53:18] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:53:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:53:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:53:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:53:18] indra_gpt.chat_curate.chat_curate - LLM call took 0.69 seconds\n",
      "Curating statements with chat curation:  40%|‚ñà‚ñà‚ñà‚ñà      | 36/89 [07:47<10:12, 11.56s/it]INFO: [2025-07-01 09:53:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:53:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:53:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:53:20] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.67 seconds\n",
      "\u001b[92m09:53:20 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:53:20] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:53:21] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:53:21 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:53:21] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:53:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:53:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:53:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:53:21] indra_gpt.chat_curate.chat_curate - LLM call took 1.32 seconds\n",
      "INFO: [2025-07-01 09:53:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:53:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:53:21] indra_gpt.chat_curate.chat_curate - Skipping evidence with no text for statement -24407073837268975: Evidence(source_api='biogrid',\n",
      "         pmid='19766626',\n",
      "         source_id='723969',\n",
      "         annotations={\n",
      "                      \"biogrid_int_id\": \"723969\",\n",
      "                      \"entrez_a\": \"10771\",\n",
      "                      \"entrez_b\": \"8554\",\n",
      "                      \"biogrid_a\": \"115989\",\n",
      "                      \"biogrid_b\": \"114124\",\n",
      "                      \"syst_name_a\": \"RP11-486H9.1\",\n",
      "                      \"syst_name_b\": null,\n",
      "                      \"hgnc_a\": \"ZMYND11\",\n",
      "                      \"hgnc_b\": \"PIAS1\",\n",
      "                      \"syn_a\": \"BRAM1|BS69|MRD30\",\n",
      "                      \"syn_b\": \"DDXBP1|GBP|GU/RH-II|ZMIZ3\",\n",
      "                      \"exp_system\": \"Two-hybrid\",\n",
      "                      \"exp_system_type\": \"physical\",\n",
      "                      \"author\": \"Yu B (2009)\",\n",
      "                      \"pmid\": \"19766626\",\n",
      "                      \"organism_a\": \"9606\",\n",
      "                      \"organism_b\": \"9606\",\n",
      "                      \"throughput\": \"Low Throughput\",\n",
      "                      \"score\": null,\n",
      "                      \"modification\": null,\n",
      "                      \"phenotypes\": null,\n",
      "                      \"qualifications\": null,\n",
      "                      \"tags\": null,\n",
      "                      \"source_db\": \"BIOGRID\",\n",
      "                      \"agents\": {\n",
      "                       \"raw_text\": [\n",
      "                        \"RP11-486H9.1\",\n",
      "                        null\n",
      "                       ]\n",
      "                      },\n",
      "                      \"prior_uuids\": [\n",
      "                       \"8406b4fb-ccf3-40fb-ab1a-901675bc3d38\"\n",
      "                      ]\n",
      "                     },\n",
      "         text_refs={\n",
      "                    \"PMID\": \"19766626\"\n",
      "                   }\n",
      "         )\n",
      "\n",
      "\n",
      "INFO: [2025-07-01 09:53:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:53:23] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.71 seconds\n",
      "\u001b[92m09:53:23 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:53:23] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:53:24] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:53:24 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:53:24] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:53:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:53:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:53:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:53:24] indra_gpt.chat_curate.chat_curate - LLM call took 1.10 seconds\n",
      "INFO: [2025-07-01 09:53:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:53:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:53:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:53:26] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.72 seconds\n",
      "\u001b[92m09:53:26 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:53:26] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:53:28] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:53:28 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:53:28] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:53:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:53:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:53:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:53:28] indra_gpt.chat_curate.chat_curate - LLM call took 1.31 seconds\n",
      "INFO: [2025-07-01 09:53:28] indra_gpt.chat_curate.chat_curate - Skipping evidence with no text for statement -24407073837268975: Evidence(source_api='biogrid',\n",
      "         pmid='19766626',\n",
      "         source_id='723971',\n",
      "         annotations={\n",
      "                      \"biogrid_int_id\": \"723971\",\n",
      "                      \"entrez_a\": \"10771\",\n",
      "                      \"entrez_b\": \"8554\",\n",
      "                      \"biogrid_a\": \"115989\",\n",
      "                      \"biogrid_b\": \"114124\",\n",
      "                      \"syst_name_a\": \"RP11-486H9.1\",\n",
      "                      \"syst_name_b\": null,\n",
      "                      \"hgnc_a\": \"ZMYND11\",\n",
      "                      \"hgnc_b\": \"PIAS1\",\n",
      "                      \"syn_a\": \"BRAM1|BS69|MRD30\",\n",
      "                      \"syn_b\": \"DDXBP1|GBP|GU/RH-II|ZMIZ3\",\n",
      "                      \"exp_system\": \"Affinity Capture-Western\",\n",
      "                      \"exp_system_type\": \"physical\",\n",
      "                      \"author\": \"Yu B (2009)\",\n",
      "                      \"pmid\": \"19766626\",\n",
      "                      \"organism_a\": \"9606\",\n",
      "                      \"organism_b\": \"9606\",\n",
      "                      \"throughput\": \"Low Throughput\",\n",
      "                      \"score\": null,\n",
      "                      \"modification\": null,\n",
      "                      \"phenotypes\": null,\n",
      "                      \"qualifications\": null,\n",
      "                      \"tags\": null,\n",
      "                      \"source_db\": \"BIOGRID\",\n",
      "                      \"agents\": {\n",
      "                       \"raw_text\": [\n",
      "                        \"RP11-486H9.1\",\n",
      "                        null\n",
      "                       ]\n",
      "                      },\n",
      "                      \"prior_uuids\": [\n",
      "                       \"1e78db56-ba7b-49d8-b3eb-7d6287d1ed53\"\n",
      "                      ]\n",
      "                     },\n",
      "         text_refs={\n",
      "                    \"PMID\": \"19766626\"\n",
      "                   }\n",
      "         )\n",
      "\n",
      "\n",
      "Curating statements with chat curation:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 37/89 [07:56<09:32, 11.00s/it]INFO: [2025-07-01 09:53:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:53:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:53:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:53:29] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.66 seconds\n",
      "\u001b[92m09:53:29 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:53:29] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:53:30] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:53:30 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:53:30] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:53:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:53:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:53:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:53:30] indra_gpt.chat_curate.chat_curate - LLM call took 0.69 seconds\n",
      "INFO: [2025-07-01 09:53:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:53:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:53:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:53:32] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.66 seconds\n",
      "\u001b[92m09:53:32 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:53:32] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:53:33] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:53:33 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:53:33] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:53:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:53:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:53:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:53:33] indra_gpt.chat_curate.chat_curate - LLM call took 0.69 seconds\n",
      "INFO: [2025-07-01 09:53:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:53:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:53:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:53:35] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.67 seconds\n",
      "\u001b[92m09:53:35 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:53:35] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:53:35] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:53:35 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:53:35] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:53:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:53:35] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:53:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:53:35] indra_gpt.chat_curate.chat_curate - LLM call took 0.57 seconds\n",
      "INFO: [2025-07-01 09:53:35] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:53:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:53:35] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:53:37] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.74 seconds\n",
      "\u001b[92m09:53:37 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:53:37] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:53:38] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:53:38 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:53:38] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:53:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:53:38] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:53:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:53:38] indra_gpt.chat_curate.chat_curate - LLM call took 0.73 seconds\n",
      "INFO: [2025-07-01 09:53:38] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:53:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:53:38] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:53:40] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.73 seconds\n",
      "\u001b[92m09:53:40 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:53:40] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:53:41] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:53:41 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:53:41] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:53:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:53:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:53:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:53:41] indra_gpt.chat_curate.chat_curate - LLM call took 0.66 seconds\n",
      "Curating statements with chat curation:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 38/89 [08:09<09:53, 11.64s/it]INFO: [2025-07-01 09:53:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:53:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:53:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:53:43] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.74 seconds\n",
      "\u001b[92m09:53:43 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:53:43] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:53:44] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:53:44 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:53:44] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:53:44 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:53:44] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:53:44 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:53:44] indra_gpt.chat_curate.chat_curate - LLM call took 0.82 seconds\n",
      "INFO: [2025-07-01 09:53:44] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:53:44 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:53:44] indra_gpt.chat_curate.chat_curate - Skipping evidence with no text for statement 17433662571000991: Evidence(source_api='biopax',\n",
      "         source_id='http://www.phosphosite.org/phosphosite.owl#Catalysis_31859080_678',\n",
      "         annotations={\n",
      "                      \"source_sub_id\": \"phosphositeplus\",\n",
      "                      \"agents\": {\n",
      "                       \"raw_text\": [\n",
      "                        null,\n",
      "                        null\n",
      "                       ]\n",
      "                      },\n",
      "                      \"prior_uuids\": [\n",
      "                       \"6a341495-cc35-4060-b091-8525ff8a3cd2\"\n",
      "                      ]\n",
      "                     },\n",
      "         epistemics={\n",
      "                     \"direct\": true\n",
      "                    }\n",
      "         )\n",
      "\n",
      "\n",
      "INFO: [2025-07-01 09:53:44] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:53:45] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.66 seconds\n",
      "\u001b[92m09:53:45 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:53:45] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:53:46] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:53:46 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:53:46] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:53:46 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:53:46] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:53:46 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:53:46] indra_gpt.chat_curate.chat_curate - LLM call took 0.66 seconds\n",
      "INFO: [2025-07-01 09:53:46] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:53:46 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:53:46] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:53:48] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.66 seconds\n",
      "\u001b[92m09:53:48 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:53:48] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:53:49] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:53:49 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:53:49] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:53:49 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:53:49] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:53:49 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:53:49] indra_gpt.chat_curate.chat_curate - LLM call took 0.58 seconds\n",
      "INFO: [2025-07-01 09:53:49] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:53:49 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:53:49] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:53:51] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.65 seconds\n",
      "\u001b[92m09:53:51 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:53:51] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:53:51] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:53:51 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:53:51] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:53:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:53:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:53:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:53:51] indra_gpt.chat_curate.chat_curate - LLM call took 0.63 seconds\n",
      "Curating statements with chat curation:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 39/89 [08:20<09:25, 11.31s/it]INFO: [2025-07-01 09:53:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:53:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:53:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:53:53] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.66 seconds\n",
      "\u001b[92m09:53:53 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:53:53] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:53:54] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:53:54 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:53:54] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:53:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:53:54] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:53:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:53:54] indra_gpt.chat_curate.chat_curate - LLM call took 0.61 seconds\n",
      "INFO: [2025-07-01 09:53:54] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:53:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:53:54] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:53:56] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.73 seconds\n",
      "\u001b[92m09:53:56 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:53:56] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:53:56] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:53:56 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:53:56] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:53:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:53:56] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:53:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:53:56] indra_gpt.chat_curate.chat_curate - LLM call took 0.62 seconds\n",
      "INFO: [2025-07-01 09:53:56] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:53:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:53:56] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:53:58] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.67 seconds\n",
      "\u001b[92m09:53:58 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:53:58] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:53:59] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:53:59 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:53:59] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:53:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:53:59] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:53:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:53:59] indra_gpt.chat_curate.chat_curate - LLM call took 0.68 seconds\n",
      "INFO: [2025-07-01 09:53:59] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:53:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:53:59] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:54:01] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.67 seconds\n",
      "\u001b[92m09:54:01 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:54:01] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:54:02] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:54:02 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:54:02] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:54:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:54:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:54:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:54:02] indra_gpt.chat_curate.chat_curate - LLM call took 1.58 seconds\n",
      "INFO: [2025-07-01 09:54:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:54:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:54:03] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:54:04] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.69 seconds\n",
      "\u001b[92m09:54:04 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:54:04] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:54:05] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:54:05 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:54:05] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:54:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:54:05] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:54:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:54:05] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:54:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:54:05] indra_gpt.chat_curate.chat_curate - LLM call took 0.86 seconds\n",
      "Curating statements with chat curation:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 40/89 [08:34<09:55, 12.15s/it]INFO: [2025-07-01 09:54:05] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:54:07] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.66 seconds\n",
      "\u001b[92m09:54:07 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:54:07] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:54:08] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:54:08 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:54:08] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:54:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:54:08] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:54:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:54:08] indra_gpt.chat_curate.chat_curate - LLM call took 0.56 seconds\n",
      "INFO: [2025-07-01 09:54:08] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:54:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:54:08] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:54:10] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.68 seconds\n",
      "\u001b[92m09:54:10 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:54:10] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:54:10] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:54:10 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:54:10] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:54:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:54:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:54:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:54:10] indra_gpt.chat_curate.chat_curate - LLM call took 0.62 seconds\n",
      "INFO: [2025-07-01 09:54:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:54:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:54:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:54:13] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.70 seconds\n",
      "\u001b[92m09:54:13 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:54:13] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:54:13] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:54:13 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:54:13] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:54:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:54:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:54:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:54:13] indra_gpt.chat_curate.chat_curate - LLM call took 0.74 seconds\n",
      "INFO: [2025-07-01 09:54:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:54:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:54:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:54:15] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.65 seconds\n",
      "\u001b[92m09:54:15 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:54:15] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:54:16] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:54:16 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:54:16] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:54:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:54:16] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:54:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:54:16] indra_gpt.chat_curate.chat_curate - LLM call took 1.03 seconds\n",
      "INFO: [2025-07-01 09:54:16] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:54:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:54:16] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:54:18] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.66 seconds\n",
      "\u001b[92m09:54:18 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:54:18] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:54:19] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:54:19 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:54:19] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:54:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:54:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:54:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:54:19] indra_gpt.chat_curate.chat_curate - LLM call took 0.65 seconds\n",
      "Curating statements with chat curation:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 41/89 [08:47<10:02, 12.54s/it]INFO: [2025-07-01 09:54:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:54:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:54:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:54:20] indra_gpt.chat_curate.chat_curate - Prompt generation took 0.91 seconds\n",
      "\u001b[92m09:54:20 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:54:20] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:54:21] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:54:21 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:54:21] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:54:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:54:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:54:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:54:21] indra_gpt.chat_curate.chat_curate - LLM call took 0.66 seconds\n",
      "INFO: [2025-07-01 09:54:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:54:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:54:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:54:22] indra_gpt.chat_curate.chat_curate - Prompt generation took 0.89 seconds\n",
      "\u001b[92m09:54:22 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:54:22] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:54:22] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:54:22 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:54:22] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:54:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:54:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:54:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:54:22] indra_gpt.chat_curate.chat_curate - LLM call took 0.69 seconds\n",
      "INFO: [2025-07-01 09:54:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:54:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:54:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:54:24] indra_gpt.chat_curate.chat_curate - Prompt generation took 0.90 seconds\n",
      "\u001b[92m09:54:24 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:54:24] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:54:24] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:54:24 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:54:24] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:54:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:54:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:54:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:54:24] indra_gpt.chat_curate.chat_curate - LLM call took 0.59 seconds\n",
      "INFO: [2025-07-01 09:54:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:54:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:54:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:54:25] indra_gpt.chat_curate.chat_curate - Prompt generation took 0.95 seconds\n",
      "\u001b[92m09:54:25 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:54:25] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:54:26] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:54:26 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:54:26] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:54:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:54:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:54:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:54:26] indra_gpt.chat_curate.chat_curate - LLM call took 0.66 seconds\n",
      "INFO: [2025-07-01 09:54:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:54:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:54:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:54:27] indra_gpt.chat_curate.chat_curate - Prompt generation took 0.90 seconds\n",
      "\u001b[92m09:54:27 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:54:27] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:54:28] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:54:28 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:54:28] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:54:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:54:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:54:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:54:28] indra_gpt.chat_curate.chat_curate - LLM call took 0.72 seconds\n",
      "Curating statements with chat curation:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 42/89 [08:57<09:03, 11.57s/it]INFO: [2025-07-01 09:54:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:54:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:54:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:54:30] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.66 seconds\n",
      "\u001b[92m09:54:30 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:54:30] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:54:31] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:54:31 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:54:31] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:54:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:54:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:54:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:54:31] indra_gpt.chat_curate.chat_curate - LLM call took 0.65 seconds\n",
      "INFO: [2025-07-01 09:54:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:54:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:54:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:54:33] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.68 seconds\n",
      "\u001b[92m09:54:33 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:54:33] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:54:33] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:54:33 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:54:33] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:54:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:54:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:54:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:54:33] indra_gpt.chat_curate.chat_curate - LLM call took 0.61 seconds\n",
      "INFO: [2025-07-01 09:54:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:54:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:54:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:54:35] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.65 seconds\n",
      "\u001b[92m09:54:35 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:54:35] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:54:36] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:54:36 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:54:36] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:54:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:54:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:54:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:54:36] indra_gpt.chat_curate.chat_curate - LLM call took 0.61 seconds\n",
      "INFO: [2025-07-01 09:54:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:54:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:54:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:54:38] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.66 seconds\n",
      "\u001b[92m09:54:38 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:54:38] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:54:38] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:54:38 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:54:38] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:54:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:54:38] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:54:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:54:38] indra_gpt.chat_curate.chat_curate - LLM call took 0.56 seconds\n",
      "INFO: [2025-07-01 09:54:38] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:54:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:54:38] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:54:40] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.70 seconds\n",
      "\u001b[92m09:54:40 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:54:40] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:54:41] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:54:41 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:54:41] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:54:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:54:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:54:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:54:41] indra_gpt.chat_curate.chat_curate - LLM call took 0.65 seconds\n",
      "Curating statements with chat curation:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 43/89 [09:10<09:09, 11.94s/it]INFO: [2025-07-01 09:54:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:54:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:54:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:54:43] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.65 seconds\n",
      "\u001b[92m09:54:43 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:54:43] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:54:43] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:54:43 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:54:43] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:54:43 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:54:43] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:54:43 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:54:43] indra_gpt.chat_curate.chat_curate - LLM call took 0.60 seconds\n",
      "INFO: [2025-07-01 09:54:43] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:54:44 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:54:44] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:54:45] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.67 seconds\n",
      "\u001b[92m09:54:45 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:54:45] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:54:46] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:54:46 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:54:46] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:54:46 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:54:46] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:54:46 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:54:46] indra_gpt.chat_curate.chat_curate - LLM call took 0.65 seconds\n",
      "INFO: [2025-07-01 09:54:46] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:54:46 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:54:46] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:54:48] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.67 seconds\n",
      "\u001b[92m09:54:48 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:54:48] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:54:49] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:54:49 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:54:49] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:54:49 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:54:49] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:54:49 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:54:49] indra_gpt.chat_curate.chat_curate - LLM call took 1.14 seconds\n",
      "INFO: [2025-07-01 09:54:49] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:54:49 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:54:49] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:54:51] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.69 seconds\n",
      "\u001b[92m09:54:51 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:54:51] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:54:52] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:54:52 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:54:52] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:54:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:54:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:54:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:54:52] indra_gpt.chat_curate.chat_curate - LLM call took 0.57 seconds\n",
      "INFO: [2025-07-01 09:54:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:54:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:54:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:54:54] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.74 seconds\n",
      "\u001b[92m09:54:54 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:54:54] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:54:54] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:54:54 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:54:54] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:54:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:54:54] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:54:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:54:54] indra_gpt.chat_curate.chat_curate - LLM call took 0.67 seconds\n",
      "Curating statements with chat curation:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 44/89 [09:23<09:18, 12.40s/it]INFO: [2025-07-01 09:54:54] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:54:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:54:54] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:54:56] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.70 seconds\n",
      "\u001b[92m09:54:56 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:54:56] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:54:57] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:54:57 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:54:57] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:54:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:54:57] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:54:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:54:57] indra_gpt.chat_curate.chat_curate - LLM call took 0.70 seconds\n",
      "INFO: [2025-07-01 09:54:57] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:54:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:54:57] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:54:59] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.67 seconds\n",
      "\u001b[92m09:54:59 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:54:59] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:55:00] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:55:00 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:55:00] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:55:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:55:00] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:55:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:55:00] indra_gpt.chat_curate.chat_curate - LLM call took 0.92 seconds\n",
      "INFO: [2025-07-01 09:55:00] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:55:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:55:00] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:55:02] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.74 seconds\n",
      "\u001b[92m09:55:02 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:55:02] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:55:03] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:55:03 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:55:03] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:55:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:55:03] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:55:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:55:03] indra_gpt.chat_curate.chat_curate - LLM call took 0.66 seconds\n",
      "INFO: [2025-07-01 09:55:03] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:55:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:55:03] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:55:05] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.73 seconds\n",
      "\u001b[92m09:55:05 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:55:05] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:55:05] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:55:05 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:55:05] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:55:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:55:05] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:55:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:55:05] indra_gpt.chat_curate.chat_curate - LLM call took 0.67 seconds\n",
      "INFO: [2025-07-01 09:55:05] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:55:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:55:05] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:55:07] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.73 seconds\n",
      "\u001b[92m09:55:07 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:55:07] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:55:09] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:55:09 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:55:09] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:55:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:55:09] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:55:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:55:09] indra_gpt.chat_curate.chat_curate - LLM call took 1.65 seconds\n",
      "Curating statements with chat curation:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 45/89 [09:38<09:34, 13.05s/it]INFO: [2025-07-01 09:55:09] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:55:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:55:09] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:55:11] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.71 seconds\n",
      "\u001b[92m09:55:11 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:55:11] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:55:12] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:55:12 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:55:12] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:55:12 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:55:12] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:55:12 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:55:12] indra_gpt.chat_curate.chat_curate - LLM call took 0.71 seconds\n",
      "INFO: [2025-07-01 09:55:12] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:55:12 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:55:12] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:55:14] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.69 seconds\n",
      "\u001b[92m09:55:14 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:55:14] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:55:14] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:55:14 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:55:14] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:55:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:55:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:55:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:55:14] indra_gpt.chat_curate.chat_curate - LLM call took 0.69 seconds\n",
      "INFO: [2025-07-01 09:55:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:55:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:55:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:55:16] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.66 seconds\n",
      "\u001b[92m09:55:16 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:55:16] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:55:17] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:55:17 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:55:17] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:55:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:55:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:55:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:55:17] indra_gpt.chat_curate.chat_curate - LLM call took 0.64 seconds\n",
      "INFO: [2025-07-01 09:55:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:55:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:55:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:55:19] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.66 seconds\n",
      "\u001b[92m09:55:19 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:55:19] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:55:19] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:55:19 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:55:19] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:55:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:55:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:55:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:55:19] indra_gpt.chat_curate.chat_curate - LLM call took 0.65 seconds\n",
      "INFO: [2025-07-01 09:55:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:55:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:55:20] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:55:21] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.68 seconds\n",
      "\u001b[92m09:55:21 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:55:21] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:55:23] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:55:23 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:55:23] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:55:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:55:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:55:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:55:23] indra_gpt.chat_curate.chat_curate - LLM call took 1.38 seconds\n",
      "Curating statements with chat curation:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 46/89 [09:52<09:32, 13.31s/it]INFO: [2025-07-01 09:55:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:55:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:55:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:55:25] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.71 seconds\n",
      "\u001b[92m09:55:25 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:55:25] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:55:25] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:55:25 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:55:25] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:55:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:55:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:55:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:55:25] indra_gpt.chat_curate.chat_curate - LLM call took 0.57 seconds\n",
      "INFO: [2025-07-01 09:55:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:55:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:55:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:55:27] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.66 seconds\n",
      "\u001b[92m09:55:27 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:55:27] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:55:28] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:55:28 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:55:28] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:55:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:55:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:55:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:55:28] indra_gpt.chat_curate.chat_curate - LLM call took 0.66 seconds\n",
      "INFO: [2025-07-01 09:55:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:55:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:55:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:55:30] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.70 seconds\n",
      "\u001b[92m09:55:30 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:55:30] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:55:31] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:55:31 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:55:31] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:55:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:55:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:55:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:55:31] indra_gpt.chat_curate.chat_curate - LLM call took 0.83 seconds\n",
      "INFO: [2025-07-01 09:55:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:55:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:55:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:55:33] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.78 seconds\n",
      "\u001b[92m09:55:33 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:55:33] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:55:34] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:55:34 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:55:34] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:55:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:55:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:55:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:55:34] indra_gpt.chat_curate.chat_curate - LLM call took 0.65 seconds\n",
      "INFO: [2025-07-01 09:55:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:55:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:55:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:55:36] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.66 seconds\n",
      "\u001b[92m09:55:36 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:55:36] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:55:36] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:55:36 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:55:36] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:55:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:55:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:55:36] indra_gpt.chat_curate.chat_curate - LLM call took 0.68 seconds\n",
      "\u001b[92m09:55:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 47/89 [10:05<09:19, 13.32s/it]INFO: [2025-07-01 09:55:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:55:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:55:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:55:37] indra_gpt.chat_curate.chat_curate - Prompt generation took 0.93 seconds\n",
      "\u001b[92m09:55:37 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:55:37] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:55:38] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:55:38 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:55:38] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:55:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:55:38] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:55:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:55:38] indra_gpt.chat_curate.chat_curate - LLM call took 0.71 seconds\n",
      "INFO: [2025-07-01 09:55:38] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:55:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:55:38] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:55:39] indra_gpt.chat_curate.chat_curate - Prompt generation took 0.90 seconds\n",
      "\u001b[92m09:55:39 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:55:39] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:55:40] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:55:40 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:55:40] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:55:40 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:55:40] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:55:40 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:55:40] indra_gpt.chat_curate.chat_curate - LLM call took 0.68 seconds\n",
      "INFO: [2025-07-01 09:55:40] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:55:40 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:55:40] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:55:41] indra_gpt.chat_curate.chat_curate - Prompt generation took 0.90 seconds\n",
      "\u001b[92m09:55:41 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:55:41] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:55:42] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:55:42 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:55:42] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:55:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:55:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:55:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:55:42] indra_gpt.chat_curate.chat_curate - LLM call took 0.76 seconds\n",
      "INFO: [2025-07-01 09:55:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:55:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:55:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:55:43] indra_gpt.chat_curate.chat_curate - Prompt generation took 0.96 seconds\n",
      "\u001b[92m09:55:43 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:55:43] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:55:44] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:55:44 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:55:44] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:55:44 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:55:44] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:55:44 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:55:44] indra_gpt.chat_curate.chat_curate - LLM call took 0.62 seconds\n",
      "INFO: [2025-07-01 09:55:44] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:55:44 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:55:44] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:55:45] indra_gpt.chat_curate.chat_curate - Prompt generation took 0.90 seconds\n",
      "\u001b[92m09:55:45 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:55:45] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:55:46] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:55:46 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:55:46] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:55:46 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:55:46] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:55:46 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:55:46] indra_gpt.chat_curate.chat_curate - LLM call took 0.66 seconds\n",
      "Curating statements with chat curation:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 48/89 [10:14<08:18, 12.15s/it]INFO: [2025-07-01 09:55:46] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:55:46 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:55:46] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:55:48] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.66 seconds\n",
      "\u001b[92m09:55:48 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:55:48] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:55:48] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:55:48 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:55:48] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:55:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:55:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:55:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:55:48] indra_gpt.chat_curate.chat_curate - LLM call took 0.66 seconds\n",
      "INFO: [2025-07-01 09:55:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:55:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:55:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:55:50] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.67 seconds\n",
      "\u001b[92m09:55:50 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:55:50] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:55:51] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:55:51 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:55:51] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:55:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:55:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:55:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:55:51] indra_gpt.chat_curate.chat_curate - LLM call took 0.57 seconds\n",
      "INFO: [2025-07-01 09:55:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:55:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:55:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:55:53] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.68 seconds\n",
      "\u001b[92m09:55:53 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:55:53] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:55:54] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:55:54 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:55:54] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:55:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:55:54] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:55:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:55:54] indra_gpt.chat_curate.chat_curate - LLM call took 0.85 seconds\n",
      "INFO: [2025-07-01 09:55:54] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:55:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:55:54] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:55:56] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.74 seconds\n",
      "\u001b[92m09:55:56 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:55:56] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:55:56] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:55:56 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:55:56] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:55:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:55:56] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:55:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:55:56] indra_gpt.chat_curate.chat_curate - LLM call took 0.58 seconds\n",
      "INFO: [2025-07-01 09:55:56] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:55:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:55:56] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:55:58] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.74 seconds\n",
      "\u001b[92m09:55:58 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:55:58] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:55:59] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:55:59 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:55:59] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:55:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:55:59] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:55:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:55:59] indra_gpt.chat_curate.chat_curate - LLM call took 0.53 seconds\n",
      "Curating statements with chat curation:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 49/89 [10:27<08:17, 12.43s/it]INFO: [2025-07-01 09:55:59] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:55:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:55:59] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:56:01] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.72 seconds\n",
      "\u001b[92m09:56:01 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:56:01] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:56:01] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:56:01 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:56:01] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:56:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:56:01] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:56:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:56:01] indra_gpt.chat_curate.chat_curate - LLM call took 0.62 seconds\n",
      "INFO: [2025-07-01 09:56:01] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:56:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:56:01] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:56:03] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.70 seconds\n",
      "\u001b[92m09:56:03 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:56:03] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:56:04] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:56:04 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:56:04] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:56:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:56:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:56:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:56:04] indra_gpt.chat_curate.chat_curate - LLM call took 0.75 seconds\n",
      "INFO: [2025-07-01 09:56:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:56:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:56:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:56:06] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.66 seconds\n",
      "\u001b[92m09:56:06 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:56:06] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:56:07] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:56:07 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:56:07] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:56:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:56:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:56:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:56:07] indra_gpt.chat_curate.chat_curate - LLM call took 0.56 seconds\n",
      "INFO: [2025-07-01 09:56:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:56:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:56:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:56:09] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.75 seconds\n",
      "\u001b[92m09:56:09 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:56:09] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:56:10] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:56:10 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:56:10] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:56:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:56:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:56:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:56:10] indra_gpt.chat_curate.chat_curate - LLM call took 0.95 seconds\n",
      "Curating statements with chat curation:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 50/89 [10:38<07:46, 11.96s/it]INFO: [2025-07-01 09:56:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:56:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:56:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:56:12] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.68 seconds\n",
      "\u001b[92m09:56:12 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:56:12] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:56:12] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:56:12 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:56:12] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:56:12 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:56:12] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:56:12 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:56:12] indra_gpt.chat_curate.chat_curate - LLM call took 0.79 seconds\n",
      "INFO: [2025-07-01 09:56:12] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:56:12 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:56:12] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:56:14] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.71 seconds\n",
      "\u001b[92m09:56:14 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:56:14] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:56:15] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:56:15 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:56:15] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:56:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:56:15] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:56:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:56:15] indra_gpt.chat_curate.chat_curate - LLM call took 0.78 seconds\n",
      "INFO: [2025-07-01 09:56:15] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:56:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:56:15] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:56:17] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.66 seconds\n",
      "\u001b[92m09:56:17 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:56:17] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:56:18] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:56:18 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:56:18] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:56:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:56:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:56:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:56:18] indra_gpt.chat_curate.chat_curate - LLM call took 0.73 seconds\n",
      "INFO: [2025-07-01 09:56:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:56:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:56:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:56:20] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.66 seconds\n",
      "\u001b[92m09:56:20 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:56:20] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:56:21] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:56:21 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:56:21] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:56:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:56:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:56:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:56:21] indra_gpt.chat_curate.chat_curate - LLM call took 1.32 seconds\n",
      "Curating statements with chat curation:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 51/89 [10:50<07:28, 11.81s/it]INFO: [2025-07-01 09:56:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:56:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:56:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:56:23] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.71 seconds\n",
      "\u001b[92m09:56:23 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:56:23] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:56:24] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:56:24 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:56:24] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:56:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:56:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:56:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:56:24] indra_gpt.chat_curate.chat_curate - LLM call took 1.19 seconds\n",
      "INFO: [2025-07-01 09:56:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:56:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:56:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:56:26] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.68 seconds\n",
      "\u001b[92m09:56:26 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:56:26] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:56:27] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:56:27 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:56:27] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:56:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:56:27] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:56:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:56:27] indra_gpt.chat_curate.chat_curate - LLM call took 0.63 seconds\n",
      "INFO: [2025-07-01 09:56:27] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:56:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:56:27] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:56:29] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.68 seconds\n",
      "\u001b[92m09:56:29 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:56:29] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:56:29] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:56:29 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:56:29] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:56:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:56:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:56:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:56:29] indra_gpt.chat_curate.chat_curate - LLM call took 0.57 seconds\n",
      "INFO: [2025-07-01 09:56:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:56:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:56:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:56:31] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.67 seconds\n",
      "\u001b[92m09:56:31 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:56:31] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:56:32] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:56:32 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:56:32] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:56:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:56:32] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:56:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:56:32] indra_gpt.chat_curate.chat_curate - LLM call took 0.99 seconds\n",
      "Curating statements with chat curation:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 52/89 [11:01<07:12, 11.68s/it]INFO: [2025-07-01 09:56:32] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:56:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:56:32] indra_gpt.chat_curate.chat_curate - Skipping evidence with no text for statement 2642167277518507: Evidence(source_api='biopax',\n",
      "         pmid='9707430',\n",
      "         source_id='http://pathwaycommons.org/pc12/Catalysis_5cb76d3bfe53f69e273a22ee1764f5da',\n",
      "         annotations={\n",
      "                      \"source_sub_id\": \"pid\",\n",
      "                      \"agents\": {\n",
      "                       \"raw_text\": [\n",
      "                        null,\n",
      "                        null\n",
      "                       ]\n",
      "                      },\n",
      "                      \"prior_uuids\": [\n",
      "                       \"51c7a851-9ac6-43a8-b109-517c70bb0a04\"\n",
      "                      ]\n",
      "                     },\n",
      "         epistemics={\n",
      "                     \"direct\": true\n",
      "                    },\n",
      "         text_refs={\n",
      "                    \"PMID\": \"9707430\"\n",
      "                   }\n",
      "         )\n",
      "\n",
      "\n",
      "INFO: [2025-07-01 09:56:32] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:56:34] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.75 seconds\n",
      "\u001b[92m09:56:34 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:56:34] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:56:35] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:56:35 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:56:35] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:56:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:56:35] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:56:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:56:35] indra_gpt.chat_curate.chat_curate - LLM call took 0.67 seconds\n",
      "INFO: [2025-07-01 09:56:35] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:56:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:56:35] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:56:37] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.75 seconds\n",
      "\u001b[92m09:56:37 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:56:37] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:56:39] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:56:39 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:56:39] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:56:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:56:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:56:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:56:39] indra_gpt.chat_curate.chat_curate - LLM call took 1.75 seconds\n",
      "INFO: [2025-07-01 09:56:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:56:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:56:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:56:41] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.66 seconds\n",
      "\u001b[92m09:56:41 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:56:41] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:56:42] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:56:42 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:56:42] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:56:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:56:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:56:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:56:42] indra_gpt.chat_curate.chat_curate - LLM call took 0.74 seconds\n",
      "Curating statements with chat curation:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 53/89 [11:10<06:33, 10.93s/it]INFO: [2025-07-01 09:56:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:56:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:56:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:56:44] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.66 seconds\n",
      "\u001b[92m09:56:44 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:56:44] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:56:44] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:56:44 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:56:44] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:56:44 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:56:44] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:56:44 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:56:44] indra_gpt.chat_curate.chat_curate - LLM call took 0.57 seconds\n",
      "INFO: [2025-07-01 09:56:44] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:56:44 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:56:44] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:56:46] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.66 seconds\n",
      "\u001b[92m09:56:46 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:56:46] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:56:47] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:56:47 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:56:47] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:56:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:56:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:56:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:56:47] indra_gpt.chat_curate.chat_curate - LLM call took 0.71 seconds\n",
      "INFO: [2025-07-01 09:56:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:56:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:56:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:56:49] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.66 seconds\n",
      "\u001b[92m09:56:49 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:56:49] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:56:50] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:56:50 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:56:50] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:56:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:56:50] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:56:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:56:50] indra_gpt.chat_curate.chat_curate - LLM call took 0.88 seconds\n",
      "INFO: [2025-07-01 09:56:50] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:56:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:56:50] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:56:52] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.70 seconds\n",
      "\u001b[92m09:56:52 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:56:52] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:56:52] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:56:52 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:56:52] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:56:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:56:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:56:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:56:52] indra_gpt.chat_curate.chat_curate - LLM call took 0.72 seconds\n",
      "Curating statements with chat curation:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 54/89 [11:21<06:19, 10.85s/it]INFO: [2025-07-01 09:56:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:56:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:56:52] indra_gpt.chat_curate.chat_curate - Skipping evidence with no text for statement 28063295869356555: Evidence(source_api='biopax',\n",
      "         source_id='http://www.phosphosite.org/phosphosite.owl#Catalysis_21895_630',\n",
      "         annotations={\n",
      "                      \"source_sub_id\": \"phosphositeplus\",\n",
      "                      \"agents\": {\n",
      "                       \"raw_text\": [\n",
      "                        null,\n",
      "                        null\n",
      "                       ]\n",
      "                      },\n",
      "                      \"prior_uuids\": [\n",
      "                       \"0b6af9ab-66a9-4dc5-b7a6-df81a0acb786\"\n",
      "                      ]\n",
      "                     },\n",
      "         epistemics={\n",
      "                     \"direct\": true\n",
      "                    }\n",
      "         )\n",
      "\n",
      "\n",
      "INFO: [2025-07-01 09:56:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:56:54] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.68 seconds\n",
      "\u001b[92m09:56:54 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:56:54] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:56:55] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:56:55 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:56:55] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:56:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:56:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:56:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:56:55] indra_gpt.chat_curate.chat_curate - LLM call took 0.68 seconds\n",
      "INFO: [2025-07-01 09:56:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:56:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:56:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:56:57] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.69 seconds\n",
      "\u001b[92m09:56:57 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:56:57] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:56:58] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:56:58 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:56:58] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:56:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:56:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:56:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:56:58] indra_gpt.chat_curate.chat_curate - LLM call took 0.70 seconds\n",
      "INFO: [2025-07-01 09:56:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:56:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:56:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:57:00] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.68 seconds\n",
      "\u001b[92m09:57:00 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:57:00] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:57:00] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:57:00 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:57:00] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:57:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:57:00] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:57:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:57:00] indra_gpt.chat_curate.chat_curate - LLM call took 0.66 seconds\n",
      "Curating statements with chat curation:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 55/89 [11:29<05:39,  9.98s/it]INFO: [2025-07-01 09:57:00] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:57:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:57:00] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:57:01] indra_gpt.chat_curate.chat_curate - Prompt generation took 0.91 seconds\n",
      "\u001b[92m09:57:01 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:57:01] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:57:02] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:57:02 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:57:02] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:57:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:57:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:57:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:57:02] indra_gpt.chat_curate.chat_curate - LLM call took 0.65 seconds\n",
      "INFO: [2025-07-01 09:57:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:57:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:57:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:57:03] indra_gpt.chat_curate.chat_curate - Prompt generation took 0.91 seconds\n",
      "\u001b[92m09:57:03 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:57:03] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:57:04] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:57:04 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:57:04] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:57:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:57:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:57:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:57:04] indra_gpt.chat_curate.chat_curate - LLM call took 0.67 seconds\n",
      "INFO: [2025-07-01 09:57:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:57:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:57:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:57:05] indra_gpt.chat_curate.chat_curate - Prompt generation took 0.91 seconds\n",
      "\u001b[92m09:57:05 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:57:05] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:57:06] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:57:06 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:57:06] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:57:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:57:06] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:57:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:57:06] indra_gpt.chat_curate.chat_curate - LLM call took 0.66 seconds\n",
      "Curating statements with chat curation:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 56/89 [11:34<04:46,  8.68s/it]INFO: [2025-07-01 09:57:06] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:57:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:57:06] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:57:08] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.66 seconds\n",
      "\u001b[92m09:57:08 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:57:08] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:57:08] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:57:08 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:57:08] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:57:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:57:08] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:57:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:57:08] indra_gpt.chat_curate.chat_curate - LLM call took 0.66 seconds\n",
      "INFO: [2025-07-01 09:57:08] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:57:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:57:09] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:57:10] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.66 seconds\n",
      "\u001b[92m09:57:10 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:57:10] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:57:11] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:57:11 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:57:11] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:57:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:57:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:57:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:57:11] indra_gpt.chat_curate.chat_curate - LLM call took 0.90 seconds\n",
      "INFO: [2025-07-01 09:57:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:57:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:57:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:57:13] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.67 seconds\n",
      "\u001b[92m09:57:13 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:57:13] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:57:14] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:57:14 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:57:14] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:57:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:57:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:57:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:57:14] indra_gpt.chat_curate.chat_curate - LLM call took 0.72 seconds\n",
      "Curating statements with chat curation:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 57/89 [11:43<04:32,  8.52s/it]INFO: [2025-07-01 09:57:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:57:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:57:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:57:16] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.74 seconds\n",
      "\u001b[92m09:57:16 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:57:16] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:57:17] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:57:17 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:57:17] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:57:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:57:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:57:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:57:17] indra_gpt.chat_curate.chat_curate - LLM call took 0.54 seconds\n",
      "INFO: [2025-07-01 09:57:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:57:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:57:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:57:18] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.68 seconds\n",
      "\u001b[92m09:57:18 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:57:18] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:57:19] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:57:19 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:57:19] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:57:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:57:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:57:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:57:19] indra_gpt.chat_curate.chat_curate - LLM call took 0.67 seconds\n",
      "INFO: [2025-07-01 09:57:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:57:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:57:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:57:21] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.68 seconds\n",
      "\u001b[92m09:57:21 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:57:21] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:57:22] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:57:22 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:57:22] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:57:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:57:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:57:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:57:22] indra_gpt.chat_curate.chat_curate - LLM call took 0.60 seconds\n",
      "Curating statements with chat curation:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 58/89 [11:50<04:16,  8.28s/it]INFO: [2025-07-01 09:57:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:57:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:57:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:57:24] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.70 seconds\n",
      "\u001b[92m09:57:24 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:57:24] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:57:24] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:57:24 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:57:24] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:57:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:57:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:57:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:57:24] indra_gpt.chat_curate.chat_curate - LLM call took 0.69 seconds\n",
      "INFO: [2025-07-01 09:57:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:57:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:57:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:57:26] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.68 seconds\n",
      "\u001b[92m09:57:26 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:57:26] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:57:27] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:57:27 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:57:27] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:57:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:57:27] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:57:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:57:27] indra_gpt.chat_curate.chat_curate - LLM call took 0.71 seconds\n",
      "Curating statements with chat curation:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 59/89 [11:56<03:42,  7.41s/it]INFO: [2025-07-01 09:57:27] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:57:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:57:27] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:57:29] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.69 seconds\n",
      "\u001b[92m09:57:29 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:57:29] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:57:32] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:57:32 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:57:32] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:57:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:57:32] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:57:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:57:32] indra_gpt.chat_curate.chat_curate - LLM call took 3.35 seconds\n",
      "INFO: [2025-07-01 09:57:32] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:57:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:57:32] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:57:34] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.74 seconds\n",
      "\u001b[92m09:57:34 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:57:34] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:57:35] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:57:35 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:57:35] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:57:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:57:35] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:57:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:57:35] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:57:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:57:35] indra_gpt.chat_curate.chat_curate - LLM call took 0.82 seconds\n",
      "Curating statements with chat curation:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 60/89 [12:04<03:41,  7.63s/it]INFO: [2025-07-01 09:57:35] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:57:36] indra_gpt.chat_curate.chat_curate - Prompt generation took 0.92 seconds\n",
      "\u001b[92m09:57:36 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:57:36] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:57:37] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:57:37 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:57:37] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:57:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:57:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:57:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:57:37] indra_gpt.chat_curate.chat_curate - LLM call took 1.01 seconds\n",
      "INFO: [2025-07-01 09:57:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:57:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:57:38] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:57:39] indra_gpt.chat_curate.chat_curate - Prompt generation took 0.90 seconds\n",
      "\u001b[92m09:57:39 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:57:39] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:57:39] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:57:39 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:57:39] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:57:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:57:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:57:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:57:39] indra_gpt.chat_curate.chat_curate - LLM call took 0.51 seconds\n",
      "Curating statements with chat curation:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 61/89 [12:08<03:02,  6.51s/it]INFO: [2025-07-01 09:57:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:57:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:57:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:57:41] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.71 seconds\n",
      "\u001b[92m09:57:41 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:57:41] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:57:42] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:57:42 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:57:42] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:57:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:57:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:57:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:57:42] indra_gpt.chat_curate.chat_curate - LLM call took 0.69 seconds\n",
      "INFO: [2025-07-01 09:57:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:57:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:57:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:57:44] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.68 seconds\n",
      "\u001b[92m09:57:44 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:57:44] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:57:44] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:57:44 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:57:44] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:57:44 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:57:44] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:57:44 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:57:44] indra_gpt.chat_curate.chat_curate - LLM call took 0.70 seconds\n",
      "Curating statements with chat curation:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 62/89 [12:13<02:46,  6.16s/it]INFO: [2025-07-01 09:57:44] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:57:44 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:57:44] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:57:46] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.67 seconds\n",
      "\u001b[92m09:57:46 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:57:46] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:57:47] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:57:47 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:57:47] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:57:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:57:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:57:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:57:47] indra_gpt.chat_curate.chat_curate - LLM call took 0.72 seconds\n",
      "INFO: [2025-07-01 09:57:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:57:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:57:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:57:49] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.72 seconds\n",
      "\u001b[92m09:57:49 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:57:49] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:57:50] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:57:50 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:57:50] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:57:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:57:50] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:57:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:57:50] indra_gpt.chat_curate.chat_curate - LLM call took 1.25 seconds\n",
      "Curating statements with chat curation:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 63/89 [12:19<02:38,  6.09s/it]INFO: [2025-07-01 09:57:50] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:57:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:57:50] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:57:52] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.76 seconds\n",
      "\u001b[92m09:57:52 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:57:52] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:57:53] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:57:53 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:57:53] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:57:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:57:53] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:57:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:57:53] indra_gpt.chat_curate.chat_curate - LLM call took 0.71 seconds\n",
      "INFO: [2025-07-01 09:57:53] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:57:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:57:53] indra_gpt.chat_curate.chat_curate - Skipping evidence with no text for statement 2078133867265037: Evidence(source_api='biopax',\n",
      "         source_id='http://www.phosphosite.org/phosphosite.owl#Catalysis_2192577_3655',\n",
      "         annotations={\n",
      "                      \"source_sub_id\": \"phosphositeplus\",\n",
      "                      \"agents\": {\n",
      "                       \"raw_text\": [\n",
      "                        null,\n",
      "                        null\n",
      "                       ]\n",
      "                      },\n",
      "                      \"prior_uuids\": [\n",
      "                       \"d5d6b42f-698e-41ff-9795-9baab2734bf8\"\n",
      "                      ]\n",
      "                     },\n",
      "         epistemics={\n",
      "                     \"direct\": true\n",
      "                    }\n",
      "         )\n",
      "\n",
      "\n",
      "Curating statements with chat curation:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 64/89 [12:22<02:07,  5.10s/it]INFO: [2025-07-01 09:57:53] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:57:55] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.66 seconds\n",
      "\u001b[92m09:57:55 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:57:55] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:57:56] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:57:56 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:57:56] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:57:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:57:56] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:57:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:57:56] indra_gpt.chat_curate.chat_curate - LLM call took 0.67 seconds\n",
      "INFO: [2025-07-01 09:57:56] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:57:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:57:56] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:57:58] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.68 seconds\n",
      "\u001b[92m09:57:58 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:57:58] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:57:59] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:57:59 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:57:59] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:57:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:57:59] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:57:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:57:59] indra_gpt.chat_curate.chat_curate - LLM call took 0.72 seconds\n",
      "Curating statements with chat curation:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 65/89 [12:27<02:04,  5.17s/it]INFO: [2025-07-01 09:57:59] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:57:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:57:59] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:58:01] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.75 seconds\n",
      "\u001b[92m09:58:01 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:58:01] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:58:01] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:58:01 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:58:01] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:58:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:58:01] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:58:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:58:01] indra_gpt.chat_curate.chat_curate - LLM call took 0.64 seconds\n",
      "INFO: [2025-07-01 09:58:01] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:58:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:58:01] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:58:03] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.76 seconds\n",
      "\u001b[92m09:58:03 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:58:03] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:58:04] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:58:04 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:58:04] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:58:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:58:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:58:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:58:04] indra_gpt.chat_curate.chat_curate - LLM call took 0.69 seconds\n",
      "Curating statements with chat curation:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 66/89 [12:33<02:00,  5.24s/it]INFO: [2025-07-01 09:58:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:58:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:58:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:58:06] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.71 seconds\n",
      "\u001b[92m09:58:06 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:58:06] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:58:07] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:58:07 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:58:07] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:58:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:58:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:58:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:58:07] indra_gpt.chat_curate.chat_curate - LLM call took 0.68 seconds\n",
      "INFO: [2025-07-01 09:58:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:58:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:58:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:58:09] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.73 seconds\n",
      "\u001b[92m09:58:09 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:58:09] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:58:10] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:58:10 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:58:10] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:58:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:58:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:58:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:58:10] indra_gpt.chat_curate.chat_curate - LLM call took 1.01 seconds\n",
      "Curating statements with chat curation:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 67/89 [12:38<01:58,  5.37s/it]INFO: [2025-07-01 09:58:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:58:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:58:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:58:12] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.66 seconds\n",
      "\u001b[92m09:58:12 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:58:12] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:58:13] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:58:13 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:58:13] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:58:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:58:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:58:13] indra_gpt.chat_curate.chat_curate - LLM call took 1.11 seconds\n",
      "\u001b[92m09:58:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:58:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:58:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:58:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:58:15] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.68 seconds\n",
      "\u001b[92m09:58:15 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:58:15] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:58:15] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:58:15 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:58:15] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:58:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:58:15] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:58:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:58:15] indra_gpt.chat_curate.chat_curate - LLM call took 0.87 seconds\n",
      "Curating statements with chat curation:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 68/89 [12:44<01:55,  5.52s/it]INFO: [2025-07-01 09:58:15] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:58:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:58:15] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:58:17] indra_gpt.chat_curate.chat_curate - Prompt generation took 0.91 seconds\n",
      "\u001b[92m09:58:17 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:58:17] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:58:18] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:58:18 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:58:18] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:58:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:58:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:58:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:58:18] indra_gpt.chat_curate.chat_curate - LLM call took 1.01 seconds\n",
      "INFO: [2025-07-01 09:58:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:58:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:58:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:58:19] indra_gpt.chat_curate.chat_curate - Prompt generation took 0.89 seconds\n",
      "\u001b[92m09:58:19 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:58:19] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:58:19] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:58:19 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:58:19] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:58:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:58:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:58:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:58:19] indra_gpt.chat_curate.chat_curate - LLM call took 0.58 seconds\n",
      "Curating statements with chat curation:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 69/89 [12:48<01:41,  5.06s/it]INFO: [2025-07-01 09:58:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:58:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:58:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:58:21] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.67 seconds\n",
      "\u001b[92m09:58:21 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:58:21] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:58:22] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:58:22 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:58:22] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:58:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:58:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:58:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:58:22] indra_gpt.chat_curate.chat_curate - LLM call took 0.60 seconds\n",
      "INFO: [2025-07-01 09:58:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:58:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:58:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:58:24] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.71 seconds\n",
      "\u001b[92m09:58:24 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:58:24] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:58:25] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:58:25 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:58:25] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:58:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:58:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:58:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:58:25] indra_gpt.chat_curate.chat_curate - LLM call took 0.62 seconds\n",
      "Curating statements with chat curation:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 70/89 [12:53<01:36,  5.09s/it]INFO: [2025-07-01 09:58:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:58:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:58:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:58:26] indra_gpt.chat_curate.chat_curate - Prompt generation took 0.91 seconds\n",
      "\u001b[92m09:58:26 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:58:26] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:58:27] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:58:27 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:58:27] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:58:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:58:27] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:58:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:58:27] indra_gpt.chat_curate.chat_curate - LLM call took 0.70 seconds\n",
      "INFO: [2025-07-01 09:58:27] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:58:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:58:27] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:58:28] indra_gpt.chat_curate.chat_curate - Prompt generation took 0.97 seconds\n",
      "\u001b[92m09:58:28 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:58:28] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:58:28] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:58:28 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:58:28] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:58:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:58:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:58:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:58:28] indra_gpt.chat_curate.chat_curate - LLM call took 0.64 seconds\n",
      "Curating statements with chat curation:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 71/89 [12:57<01:24,  4.70s/it]INFO: [2025-07-01 09:58:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:58:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:58:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:58:30] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.68 seconds\n",
      "\u001b[92m09:58:30 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:58:30] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:58:31] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:58:31 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:58:31] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:58:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:58:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:58:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:58:31] indra_gpt.chat_curate.chat_curate - LLM call took 0.73 seconds\n",
      "INFO: [2025-07-01 09:58:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:58:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:58:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:58:33] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.67 seconds\n",
      "\u001b[92m09:58:33 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:58:33] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:58:34] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:58:34 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:58:34] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:58:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:58:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:58:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:58:34] indra_gpt.chat_curate.chat_curate - LLM call took 0.73 seconds\n",
      "Curating statements with chat curation:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 72/89 [13:02<01:23,  4.91s/it]INFO: [2025-07-01 09:58:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:58:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:58:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:58:36] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.66 seconds\n",
      "\u001b[92m09:58:36 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:58:36] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:58:36] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:58:36 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:58:36] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:58:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:58:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:58:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:58:36] indra_gpt.chat_curate.chat_curate - LLM call took 0.66 seconds\n",
      "Curating statements with chat curation:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 73/89 [13:05<01:07,  4.22s/it]INFO: [2025-07-01 09:58:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:58:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:58:36] indra_gpt.chat_curate.chat_curate - Skipping agent None with no db_refs or None value in the agent list.\n",
      "INFO: [2025-07-01 09:58:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:58:37] indra_gpt.chat_curate.chat_curate - Prompt generation took 0.85 seconds\n",
      "\u001b[92m09:58:37 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:58:37] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:58:38] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:58:38 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:58:38] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:58:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:58:38] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:58:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:58:38] indra_gpt.chat_curate.chat_curate - LLM call took 0.80 seconds\n",
      "Curating statements with chat curation:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 74/89 [13:07<00:52,  3.50s/it]INFO: [2025-07-01 09:58:38] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:58:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:58:38] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:58:40] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.75 seconds\n",
      "\u001b[92m09:58:40 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:58:40] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:58:41] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:58:41 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:58:41] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:58:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:58:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:58:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:58:41] indra_gpt.chat_curate.chat_curate - LLM call took 0.79 seconds\n",
      "Curating statements with chat curation:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 75/89 [13:10<00:46,  3.34s/it]INFO: [2025-07-01 09:58:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:58:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:58:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:58:43] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.65 seconds\n",
      "\u001b[92m09:58:43 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:58:43] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:58:44] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:58:44 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:58:44] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:58:44 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:58:44] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:58:44 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:58:44] indra_gpt.chat_curate.chat_curate - LLM call took 0.78 seconds\n",
      "Curating statements with chat curation:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 76/89 [13:13<00:41,  3.17s/it]INFO: [2025-07-01 09:58:44] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:58:44 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:58:44] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:58:46] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.70 seconds\n",
      "\u001b[92m09:58:46 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:58:46] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:58:47] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:58:47 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:58:47] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:58:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:58:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:58:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:58:47] indra_gpt.chat_curate.chat_curate - LLM call took 0.58 seconds\n",
      "Curating statements with chat curation:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 77/89 [13:15<00:36,  3.01s/it]INFO: [2025-07-01 09:58:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:58:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:58:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:58:49] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.69 seconds\n",
      "\u001b[92m09:58:49 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:58:49] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:58:49] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:58:49 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:58:49] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:58:49 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:58:49] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:58:49 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:58:49] indra_gpt.chat_curate.chat_curate - LLM call took 0.71 seconds\n",
      "Curating statements with chat curation:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 78/89 [13:18<00:32,  2.92s/it]INFO: [2025-07-01 09:58:49] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:58:49 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:58:49] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:58:51] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.68 seconds\n",
      "\u001b[92m09:58:51 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:58:51] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:58:52] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:58:52 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:58:52] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:58:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:58:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:58:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:58:52] indra_gpt.chat_curate.chat_curate - LLM call took 0.66 seconds\n",
      "Curating statements with chat curation:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 79/89 [13:21<00:28,  2.84s/it]INFO: [2025-07-01 09:58:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:58:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:58:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:58:54] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.72 seconds\n",
      "\u001b[92m09:58:54 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:58:54] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:58:55] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:58:55 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:58:55] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:58:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:58:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:58:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:58:55] indra_gpt.chat_curate.chat_curate - LLM call took 0.55 seconds\n",
      "Curating statements with chat curation:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 80/89 [13:23<00:24,  2.76s/it]INFO: [2025-07-01 09:58:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:58:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:58:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:58:57] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.68 seconds\n",
      "\u001b[92m09:58:57 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:58:57] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:58:58] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:58:58 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:58:58] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:58:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:58:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:58:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:58:58] indra_gpt.chat_curate.chat_curate - LLM call took 1.42 seconds\n",
      "Curating statements with chat curation:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 81/89 [13:27<00:23,  2.95s/it]INFO: [2025-07-01 09:58:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:58:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:58:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:58:58] indra_gpt.chat_curate.chat_curate - Skipping agent cellular sensitivity LF PA83 LF() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "INFO: [2025-07-01 09:58:59] indra_gpt.chat_curate.chat_curate - Prompt generation took 0.87 seconds\n",
      "\u001b[92m09:58:59 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:58:59] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:59:00] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:59:00 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:59:00] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:59:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:59:00] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:59:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:59:00] indra_gpt.chat_curate.chat_curate - LLM call took 0.61 seconds\n",
      "Curating statements with chat curation:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 82/89 [13:28<00:17,  2.56s/it]INFO: [2025-07-01 09:59:00] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:59:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:59:00] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:59:02] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.71 seconds\n",
      "\u001b[92m09:59:02 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:59:02] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:59:03] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:59:03 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:59:03] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:59:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:59:03] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:59:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:59:03] indra_gpt.chat_curate.chat_curate - LLM call took 0.92 seconds\n",
      "Curating statements with chat curation:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 83/89 [13:31<00:16,  2.67s/it]INFO: [2025-07-01 09:59:03] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:59:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:59:03] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:59:04] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.67 seconds\n",
      "\u001b[92m09:59:04 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:59:04] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:59:05] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:59:05 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:59:05] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:59:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:59:05] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:59:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:59:05] indra_gpt.chat_curate.chat_curate - LLM call took 0.62 seconds\n",
      "Curating statements with chat curation:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 84/89 [13:34<00:13,  2.64s/it]INFO: [2025-07-01 09:59:05] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:59:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:59:05] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:59:07] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.66 seconds\n",
      "\u001b[92m09:59:07 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:59:07] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:59:08] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:59:08 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:59:08] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:59:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:59:08] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:59:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:59:08] indra_gpt.chat_curate.chat_curate - LLM call took 0.63 seconds\n",
      "Curating statements with chat curation:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 85/89 [13:36<00:10,  2.63s/it]INFO: [2025-07-01 09:59:08] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:59:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:59:08] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:59:10] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.67 seconds\n",
      "\u001b[92m09:59:10 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:59:10] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:59:10] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:59:10 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:59:10] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:59:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:59:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:59:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:59:10] indra_gpt.chat_curate.chat_curate - LLM call took 0.49 seconds\n",
      "Curating statements with chat curation:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 86/89 [13:39<00:07,  2.57s/it]INFO: [2025-07-01 09:59:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:59:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:59:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:59:13] indra_gpt.chat_curate.chat_curate - Prompt generation took 2.52 seconds\n",
      "\u001b[92m09:59:13 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:59:13] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:59:14] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:59:14 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:59:14] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:59:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:59:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:59:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:59:14] indra_gpt.chat_curate.chat_curate - LLM call took 0.81 seconds\n",
      "Curating statements with chat curation:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 87/89 [13:43<00:05,  2.93s/it]INFO: [2025-07-01 09:59:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:59:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:59:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:59:16] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.73 seconds\n",
      "\u001b[92m09:59:16 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:59:16] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:59:17] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:59:17 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:59:17] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:59:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:59:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:59:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:59:17] indra_gpt.chat_curate.chat_curate - LLM call took 0.74 seconds\n",
      "Curating statements with chat curation:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 88/89 [13:45<00:02,  2.89s/it]INFO: [2025-07-01 09:59:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:59:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:59:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:59:18] indra_gpt.chat_curate.chat_curate - Prompt generation took 0.91 seconds\n",
      "\u001b[92m09:59:18 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:59:18] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 09:59:18] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:59:18 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:59:18] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:59:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:59:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m09:59:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 09:59:18] indra_gpt.chat_curate.chat_curate - LLM call took 0.57 seconds\n",
      "Curating statements with chat curation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 89/89 [13:47<00:00,  2.55s/it]INFO: [2025-07-01 09:59:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 89/89 [13:47<00:00,  9.30s/it]\u001b[92m09:59:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\n",
      "INFO: [2025-07-01 09:59:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:   0%|          | 0/89 [00:00<?, ?it/s]INFO: [2025-07-01 09:59:48] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.68 seconds\n",
      "\u001b[92m09:59:48 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 09:59:48] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 09:59:49] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:59:49 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:59:49] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:59:49 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 09:59:49] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m09:59:49 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 09:59:49] indra_gpt.chat_curate.chat_curate - LLM call took 0.67 seconds\n",
      "INFO: [2025-07-01 09:59:49] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m09:59:49 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 09:59:49] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 09:59:51] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.68 seconds\n",
      "\u001b[92m09:59:51 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 09:59:51] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 09:59:52] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:59:52 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:59:52] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:59:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 09:59:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m09:59:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 09:59:52] indra_gpt.chat_curate.chat_curate - LLM call took 1.23 seconds\n",
      "INFO: [2025-07-01 09:59:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m09:59:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 09:59:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 09:59:54] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.70 seconds\n",
      "\u001b[92m09:59:54 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 09:59:54] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 09:59:55] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:59:55 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:59:55] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:59:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 09:59:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m09:59:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 09:59:55] indra_gpt.chat_curate.chat_curate - LLM call took 0.87 seconds\n",
      "INFO: [2025-07-01 09:59:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m09:59:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 09:59:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 09:59:57] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.67 seconds\n",
      "\u001b[92m09:59:57 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 09:59:57] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 09:59:58] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:59:58 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 09:59:58] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:59:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 09:59:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m09:59:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 09:59:58] indra_gpt.chat_curate.chat_curate - LLM call took 0.78 seconds\n",
      "INFO: [2025-07-01 09:59:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m09:59:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 09:59:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:00:00] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.73 seconds\n",
      "\u001b[92m10:00:00 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:00:00] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:00:00] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:00:00 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:00:00] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:00:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:00:00] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:00:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:00:00] indra_gpt.chat_curate.chat_curate - LLM call took 0.48 seconds\n",
      "Curating statements with chat curation:   1%|          | 1/89 [00:14<20:37, 14.06s/it]INFO: [2025-07-01 10:00:00] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:00:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:00:00] indra_gpt.chat_curate.chat_curate - Skipping agent None with no db_refs or None value in the agent list.\n",
      "INFO: [2025-07-01 10:00:00] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:00:01] indra_gpt.chat_curate.chat_curate - Prompt generation took 0.83 seconds\n",
      "\u001b[92m10:00:01 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:00:01] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:00:02] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:00:02 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:00:02] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:00:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:00:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:00:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:00:02] indra_gpt.chat_curate.chat_curate - LLM call took 0.75 seconds\n",
      "INFO: [2025-07-01 10:00:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:00:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:00:02] indra_gpt.chat_curate.chat_curate - Skipping agent None with no db_refs or None value in the agent list.\n",
      "INFO: [2025-07-01 10:00:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:00:03] indra_gpt.chat_curate.chat_curate - Prompt generation took 0.86 seconds\n",
      "\u001b[92m10:00:03 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:00:03] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:00:04] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:00:04 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:00:04] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:00:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:00:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:00:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:00:04] indra_gpt.chat_curate.chat_curate - LLM call took 0.88 seconds\n",
      "INFO: [2025-07-01 10:00:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:00:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:00:04] indra_gpt.chat_curate.chat_curate - Skipping agent None with no db_refs or None value in the agent list.\n",
      "INFO: [2025-07-01 10:00:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:00:05] indra_gpt.chat_curate.chat_curate - Prompt generation took 0.84 seconds\n",
      "\u001b[92m10:00:05 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:00:05] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:00:06] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:00:06 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:00:06] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:00:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:00:06] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:00:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:00:06] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:00:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:00:06] indra_gpt.chat_curate.chat_curate - LLM call took 0.59 seconds\n",
      "INFO: [2025-07-01 10:00:06] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:00:06] indra_gpt.chat_curate.chat_curate - Skipping agent None with no db_refs or None value in the agent list.\n",
      "INFO: [2025-07-01 10:00:07] indra_gpt.chat_curate.chat_curate - Prompt generation took 0.83 seconds\n",
      "\u001b[92m10:00:07 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:00:07] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:00:07] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:00:07 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:00:07] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:00:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:00:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:00:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:00:07] indra_gpt.chat_curate.chat_curate - LLM call took 0.65 seconds\n",
      "INFO: [2025-07-01 10:00:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:00:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:00:07] indra_gpt.chat_curate.chat_curate - Skipping agent None with no db_refs or None value in the agent list.\n",
      "INFO: [2025-07-01 10:00:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:00:08] indra_gpt.chat_curate.chat_curate - Prompt generation took 0.86 seconds\n",
      "\u001b[92m10:00:08 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:00:08] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:00:09] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:00:09 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:00:09] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:00:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:00:09] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:00:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:00:09] indra_gpt.chat_curate.chat_curate - LLM call took 1.14 seconds\n",
      "Curating statements with chat curation:   2%|‚ñè         | 2/89 [00:23<16:07, 11.12s/it]INFO: [2025-07-01 10:00:09] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:00:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:00:09] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:00:11] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.69 seconds\n",
      "\u001b[92m10:00:11 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:00:11] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:00:12] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:00:12 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:00:12] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:00:12 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:00:12] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:00:12] indra_gpt.chat_curate.chat_curate - LLM call took 0.59 seconds\n",
      "\u001b[92m10:00:12 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:00:12] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:00:12 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:00:12] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:00:14] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.66 seconds\n",
      "\u001b[92m10:00:14 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:00:14] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:00:14] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:00:14 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:00:14] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:00:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:00:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:00:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:00:14] indra_gpt.chat_curate.chat_curate - LLM call took 0.53 seconds\n",
      "INFO: [2025-07-01 10:00:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:00:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:00:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:00:16] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.77 seconds\n",
      "\u001b[92m10:00:16 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:00:16] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:00:17] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:00:17 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:00:17] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:00:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:00:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:00:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:00:17] indra_gpt.chat_curate.chat_curate - LLM call took 0.70 seconds\n",
      "INFO: [2025-07-01 10:00:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:00:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:00:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:00:19] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.68 seconds\n",
      "\u001b[92m10:00:19 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:00:19] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:00:20] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:00:20 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:00:20] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:00:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:00:20] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:00:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:00:20] indra_gpt.chat_curate.chat_curate - LLM call took 0.65 seconds\n",
      "INFO: [2025-07-01 10:00:20] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:00:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:00:20] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:00:22] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.68 seconds\n",
      "\u001b[92m10:00:22 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:00:22] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:00:22] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:00:22 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:00:22] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:00:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:00:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:00:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:00:22] indra_gpt.chat_curate.chat_curate - LLM call took 0.60 seconds\n",
      "Curating statements with chat curation:   3%|‚ñé         | 3/89 [00:36<17:07, 11.95s/it]INFO: [2025-07-01 10:00:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:00:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:00:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:00:22] indra_gpt.chat_curate.chat_curate - Skipping agent p2() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "INFO: [2025-07-01 10:00:23] indra_gpt.chat_curate.chat_curate - Prompt generation took 0.84 seconds\n",
      "\u001b[92m10:00:23 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:00:23] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:00:24] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:00:24 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:00:24] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:00:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:00:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:00:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:00:24] indra_gpt.chat_curate.chat_curate - LLM call took 1.00 seconds\n",
      "INFO: [2025-07-01 10:00:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:00:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:00:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:00:25] indra_gpt.chat_curate.chat_curate - Skipping agent p2() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "INFO: [2025-07-01 10:00:25] indra_gpt.chat_curate.chat_curate - Prompt generation took 0.83 seconds\n",
      "\u001b[92m10:00:25 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:00:25] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:00:26] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:00:26 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:00:26] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:00:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:00:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:00:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:00:26] indra_gpt.chat_curate.chat_curate - LLM call took 0.62 seconds\n",
      "INFO: [2025-07-01 10:00:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:00:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:00:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:00:26] indra_gpt.chat_curate.chat_curate - Skipping agent p2() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "INFO: [2025-07-01 10:00:27] indra_gpt.chat_curate.chat_curate - Prompt generation took 0.83 seconds\n",
      "\u001b[92m10:00:27 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:00:27] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:00:27] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:00:27 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:00:27] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:00:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:00:27] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:00:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:00:27] indra_gpt.chat_curate.chat_curate - LLM call took 0.46 seconds\n",
      "INFO: [2025-07-01 10:00:27] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:00:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:00:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:00:28] indra_gpt.chat_curate.chat_curate - Skipping agent p2() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "INFO: [2025-07-01 10:00:28] indra_gpt.chat_curate.chat_curate - Prompt generation took 0.83 seconds\n",
      "\u001b[92m10:00:28 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:00:28] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:00:29] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:00:29 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:00:29] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:00:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:00:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:00:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:00:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:00:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:00:29] indra_gpt.chat_curate.chat_curate - LLM call took 0.61 seconds\n",
      "INFO: [2025-07-01 10:00:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:00:29] indra_gpt.chat_curate.chat_curate - Skipping agent p2() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "INFO: [2025-07-01 10:00:30] indra_gpt.chat_curate.chat_curate - Prompt generation took 0.83 seconds\n",
      "\u001b[92m10:00:30 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:00:30] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:00:31] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:00:31 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:00:31] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:00:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:00:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:00:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:00:31] indra_gpt.chat_curate.chat_curate - LLM call took 1.01 seconds\n",
      "Curating statements with chat curation:   4%|‚ñç         | 4/89 [00:44<15:07, 10.67s/it]INFO: [2025-07-01 10:00:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:00:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:00:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:00:33] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.74 seconds\n",
      "\u001b[92m10:00:33 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:00:33] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:00:34] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:00:34 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:00:34] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:00:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:00:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:00:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:00:34] indra_gpt.chat_curate.chat_curate - LLM call took 0.51 seconds\n",
      "INFO: [2025-07-01 10:00:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:00:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:00:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:00:36] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.74 seconds\n",
      "\u001b[92m10:00:36 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:00:36] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:00:36] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:00:36 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:00:36] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:00:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:00:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:00:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:00:36] indra_gpt.chat_curate.chat_curate - LLM call took 0.54 seconds\n",
      "INFO: [2025-07-01 10:00:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:00:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:00:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:00:38] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.72 seconds\n",
      "\u001b[92m10:00:38 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:00:38] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:00:39] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:00:39 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:00:39] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:00:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:00:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:00:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:00:39] indra_gpt.chat_curate.chat_curate - LLM call took 0.95 seconds\n",
      "INFO: [2025-07-01 10:00:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:00:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:00:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:00:41] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.74 seconds\n",
      "\u001b[92m10:00:41 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:00:41] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:00:42] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:00:42 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:00:42] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:00:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:00:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:00:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:00:42] indra_gpt.chat_curate.chat_curate - LLM call took 0.97 seconds\n",
      "INFO: [2025-07-01 10:00:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:00:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:00:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:00:44] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.76 seconds\n",
      "\u001b[92m10:00:44 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:00:44] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:00:45] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:00:45 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:00:45] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:00:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:00:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:00:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:00:45] indra_gpt.chat_curate.chat_curate - LLM call took 0.77 seconds\n",
      "Curating statements with chat curation:   6%|‚ñå         | 5/89 [00:58<16:31, 11.81s/it]INFO: [2025-07-01 10:00:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:00:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:00:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:00:47] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.66 seconds\n",
      "\u001b[92m10:00:47 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:00:47] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:00:47] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:00:47 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:00:47] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:00:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:00:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:00:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:00:47] indra_gpt.chat_curate.chat_curate - LLM call took 0.50 seconds\n",
      "INFO: [2025-07-01 10:00:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:00:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:00:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:00:49] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.68 seconds\n",
      "\u001b[92m10:00:49 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:00:49] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:00:50] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:00:50 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:00:50] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:00:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:00:50] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:00:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:00:50] indra_gpt.chat_curate.chat_curate - LLM call took 0.55 seconds\n",
      "INFO: [2025-07-01 10:00:50] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:00:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:00:50] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:00:52] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.68 seconds\n",
      "\u001b[92m10:00:52 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:00:52] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:00:52] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:00:52 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:00:52] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:00:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:00:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:00:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:00:52] indra_gpt.chat_curate.chat_curate - LLM call took 0.52 seconds\n",
      "INFO: [2025-07-01 10:00:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:00:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:00:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:00:54] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.70 seconds\n",
      "\u001b[92m10:00:54 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:00:54] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:00:55] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:00:55 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:00:55] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:00:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:00:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:00:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:00:55] indra_gpt.chat_curate.chat_curate - LLM call took 0.65 seconds\n",
      "INFO: [2025-07-01 10:00:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:00:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:00:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:00:57] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.70 seconds\n",
      "\u001b[92m10:00:57 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:00:57] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:00:58] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:00:58 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:00:58] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:00:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:00:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:00:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:00:58] indra_gpt.chat_curate.chat_curate - LLM call took 0.65 seconds\n",
      "Curating statements with chat curation:   7%|‚ñã         | 6/89 [01:11<16:45, 12.11s/it]INFO: [2025-07-01 10:00:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:00:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:00:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:01:00] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.90 seconds\n",
      "\u001b[92m10:01:00 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:01:00] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:01:00] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:01:00 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:01:00] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:01:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:01:00] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:01:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:01:00] indra_gpt.chat_curate.chat_curate - LLM call took 0.46 seconds\n",
      "INFO: [2025-07-01 10:01:00] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:01:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:01:00] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:01:02] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.76 seconds\n",
      "\u001b[92m10:01:02 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:01:02] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:01:04] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:01:04 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:01:04] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:01:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:01:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:01:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:01:04] indra_gpt.chat_curate.chat_curate - LLM call took 1.71 seconds\n",
      "INFO: [2025-07-01 10:01:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:01:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:01:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:01:06] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.83 seconds\n",
      "\u001b[92m10:01:06 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:01:06] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:01:07] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:01:07 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:01:07] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:01:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:01:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:01:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:01:07] indra_gpt.chat_curate.chat_curate - LLM call took 0.67 seconds\n",
      "INFO: [2025-07-01 10:01:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:01:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:01:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:01:09] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.86 seconds\n",
      "\u001b[92m10:01:09 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:01:09] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:01:10] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:01:10 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:01:10] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:01:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:01:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:01:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:01:10] indra_gpt.chat_curate.chat_curate - LLM call took 1.16 seconds\n",
      "INFO: [2025-07-01 10:01:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:01:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:01:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:01:12] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.80 seconds\n",
      "\u001b[92m10:01:12 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:01:12] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:01:13] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:01:13 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:01:13] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:01:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:01:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:01:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:01:13] indra_gpt.chat_curate.chat_curate - LLM call took 1.15 seconds\n",
      "Curating statements with chat curation:   8%|‚ñä         | 7/89 [01:27<18:10, 13.30s/it]INFO: [2025-07-01 10:01:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:01:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:01:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:01:15] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.68 seconds\n",
      "\u001b[92m10:01:15 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:01:15] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:01:16] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:01:16 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:01:16] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:01:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:01:16] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:01:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:01:16] indra_gpt.chat_curate.chat_curate - LLM call took 0.61 seconds\n",
      "INFO: [2025-07-01 10:01:16] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:01:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:01:16] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:01:18] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.67 seconds\n",
      "\u001b[92m10:01:18 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:01:18] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:01:18] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:01:18 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:01:18] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:01:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:01:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:01:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:01:18] indra_gpt.chat_curate.chat_curate - LLM call took 0.47 seconds\n",
      "INFO: [2025-07-01 10:01:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:01:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:01:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:01:20] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.67 seconds\n",
      "\u001b[92m10:01:20 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:01:20] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:01:21] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:01:21 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:01:21] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:01:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:01:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:01:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:01:21] indra_gpt.chat_curate.chat_curate - LLM call took 0.56 seconds\n",
      "INFO: [2025-07-01 10:01:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:01:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:01:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:01:23] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.72 seconds\n",
      "\u001b[92m10:01:23 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:01:23] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:01:23] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:01:23 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:01:23] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:01:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:01:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:01:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:01:23] indra_gpt.chat_curate.chat_curate - LLM call took 0.60 seconds\n",
      "INFO: [2025-07-01 10:01:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:01:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:01:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:01:25] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.69 seconds\n",
      "\u001b[92m10:01:25 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:01:25] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:01:26] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:01:26 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:01:26] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:01:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:01:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:01:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:01:26] indra_gpt.chat_curate.chat_curate - LLM call took 0.50 seconds\n",
      "Curating statements with chat curation:   9%|‚ñâ         | 8/89 [01:39<17:38, 13.07s/it]INFO: [2025-07-01 10:01:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:01:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:01:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:01:28] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.76 seconds\n",
      "\u001b[92m10:01:28 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:01:28] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:01:29] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:01:29 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:01:29] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:01:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:01:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:01:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:01:29] indra_gpt.chat_curate.chat_curate - LLM call took 0.84 seconds\n",
      "INFO: [2025-07-01 10:01:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:01:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:01:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:01:31] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.75 seconds\n",
      "\u001b[92m10:01:31 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:01:31] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:01:31] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:01:31 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:01:31] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:01:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:01:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:01:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:01:31] indra_gpt.chat_curate.chat_curate - LLM call took 0.51 seconds\n",
      "INFO: [2025-07-01 10:01:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:01:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:01:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:01:33] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.68 seconds\n",
      "\u001b[92m10:01:33 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:01:33] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:01:34] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:01:34 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:01:34] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:01:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:01:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:01:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:01:34] indra_gpt.chat_curate.chat_curate - LLM call took 0.51 seconds\n",
      "INFO: [2025-07-01 10:01:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:01:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:01:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:01:36] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.66 seconds\n",
      "\u001b[92m10:01:36 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:01:36] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:01:36] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:01:36 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:01:36] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:01:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:01:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:01:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:01:36] indra_gpt.chat_curate.chat_curate - LLM call took 0.49 seconds\n",
      "INFO: [2025-07-01 10:01:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:01:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:01:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:01:38] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.70 seconds\n",
      "\u001b[92m10:01:38 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:01:38] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:01:39] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:01:39 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:01:39] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:01:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:01:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:01:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:01:39] indra_gpt.chat_curate.chat_curate - LLM call took 0.54 seconds\n",
      "Curating statements with chat curation:  10%|‚ñà         | 9/89 [01:52<17:19, 12.99s/it]INFO: [2025-07-01 10:01:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:01:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:01:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:01:41] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.70 seconds\n",
      "\u001b[92m10:01:41 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:01:41] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:01:41] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:01:41 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:01:41] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:01:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:01:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:01:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:01:41] indra_gpt.chat_curate.chat_curate - LLM call took 0.65 seconds\n",
      "INFO: [2025-07-01 10:01:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:01:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:01:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:01:43] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.77 seconds\n",
      "\u001b[92m10:01:43 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:01:43] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:01:44] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:01:44 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:01:44] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:01:44 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:01:44] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:01:44 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:01:44] indra_gpt.chat_curate.chat_curate - LLM call took 0.64 seconds\n",
      "INFO: [2025-07-01 10:01:44] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:01:44 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:01:44] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:01:46] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.74 seconds\n",
      "\u001b[92m10:01:46 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:01:46] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:01:47] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:01:47 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:01:47] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:01:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:01:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:01:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:01:47] indra_gpt.chat_curate.chat_curate - LLM call took 0.71 seconds\n",
      "INFO: [2025-07-01 10:01:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:01:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:01:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:01:49] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.68 seconds\n",
      "\u001b[92m10:01:49 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:01:49] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:01:49] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:01:49 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:01:49] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:01:49 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:01:49] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:01:49 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:01:49] indra_gpt.chat_curate.chat_curate - LLM call took 0.45 seconds\n",
      "INFO: [2025-07-01 10:01:49] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:01:49 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:01:49] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:01:51] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.66 seconds\n",
      "\u001b[92m10:01:51 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:01:51] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:01:52] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:01:52 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:01:52] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:01:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:01:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:01:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:01:52] indra_gpt.chat_curate.chat_curate - LLM call took 0.47 seconds\n",
      "Curating statements with chat curation:  11%|‚ñà         | 10/89 [02:05<17:03, 12.96s/it]INFO: [2025-07-01 10:01:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:01:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:01:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:01:54] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.70 seconds\n",
      "\u001b[92m10:01:54 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:01:54] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:01:54] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:01:54 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:01:54] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:01:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:01:54] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:01:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:01:54] indra_gpt.chat_curate.chat_curate - LLM call took 0.58 seconds\n",
      "INFO: [2025-07-01 10:01:54] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:01:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:01:54] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:01:56] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.67 seconds\n",
      "\u001b[92m10:01:56 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:01:56] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:01:57] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:01:57 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:01:57] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:01:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:01:57] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:01:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:01:57] indra_gpt.chat_curate.chat_curate - LLM call took 0.48 seconds\n",
      "INFO: [2025-07-01 10:01:57] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:01:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:01:57] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:01:59] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.72 seconds\n",
      "\u001b[92m10:01:59 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:01:59] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:02:00] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:02:00 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:02:00] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:02:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:02:00] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:02:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:02:00] indra_gpt.chat_curate.chat_curate - LLM call took 1.20 seconds\n",
      "INFO: [2025-07-01 10:02:00] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:02:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:02:00] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:02:02] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.72 seconds\n",
      "\u001b[92m10:02:02 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:02:02] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:02:03] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:02:03 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:02:03] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:02:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:02:03] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:02:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:02:03] indra_gpt.chat_curate.chat_curate - LLM call took 0.81 seconds\n",
      "INFO: [2025-07-01 10:02:03] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:02:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:02:03] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:02:05] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.69 seconds\n",
      "\u001b[92m10:02:05 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:02:05] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:02:05] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:02:05 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:02:05] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:02:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:02:05] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:02:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:02:05] indra_gpt.chat_curate.chat_curate - LLM call took 0.81 seconds\n",
      "Curating statements with chat curation:  12%|‚ñà‚ñè        | 11/89 [02:19<17:11, 13.22s/it]INFO: [2025-07-01 10:02:05] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:02:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:02:05] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:02:07] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.67 seconds\n",
      "\u001b[92m10:02:07 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:02:07] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:02:08] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:02:08 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:02:08] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:02:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:02:08] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:02:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:02:08] indra_gpt.chat_curate.chat_curate - LLM call took 0.52 seconds\n",
      "INFO: [2025-07-01 10:02:08] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:02:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:02:08] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:02:10] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.67 seconds\n",
      "\u001b[92m10:02:10 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:02:10] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:02:10] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:02:10 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:02:10] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:02:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:02:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:02:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:02:10] indra_gpt.chat_curate.chat_curate - LLM call took 0.48 seconds\n",
      "INFO: [2025-07-01 10:02:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:02:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:02:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:02:12] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.74 seconds\n",
      "\u001b[92m10:02:12 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:02:12] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:02:13] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:02:13 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:02:13] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:02:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:02:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:02:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:02:13] indra_gpt.chat_curate.chat_curate - LLM call took 0.81 seconds\n",
      "INFO: [2025-07-01 10:02:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:02:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:02:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:02:15] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.75 seconds\n",
      "\u001b[92m10:02:15 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:02:15] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:02:16] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:02:16 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:02:16] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:02:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:02:16] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:02:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:02:16] indra_gpt.chat_curate.chat_curate - LLM call took 0.62 seconds\n",
      "INFO: [2025-07-01 10:02:16] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:02:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:02:16] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:02:18] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.75 seconds\n",
      "\u001b[92m10:02:18 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:02:18] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:02:19] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:02:19 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:02:19] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:02:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:02:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:02:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:02:19] indra_gpt.chat_curate.chat_curate - LLM call took 1.05 seconds\n",
      "Curating statements with chat curation:  13%|‚ñà‚ñé        | 12/89 [02:32<17:05, 13.32s/it]INFO: [2025-07-01 10:02:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:02:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:02:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:02:21] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.68 seconds\n",
      "\u001b[92m10:02:21 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:02:21] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:02:22] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:02:22 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:02:22] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:02:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:02:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:02:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:02:22] indra_gpt.chat_curate.chat_curate - LLM call took 1.01 seconds\n",
      "INFO: [2025-07-01 10:02:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:02:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:02:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:02:24] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.71 seconds\n",
      "\u001b[92m10:02:24 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:02:24] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:02:25] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:02:25 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:02:25] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:02:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:02:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:02:25] indra_gpt.chat_curate.chat_curate - LLM call took 1.01 seconds\n",
      "\u001b[92m10:02:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:02:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:02:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:02:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:02:27] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.67 seconds\n",
      "\u001b[92m10:02:27 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:02:27] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:02:28] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:02:28 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:02:28] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:02:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:02:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:02:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:02:28] indra_gpt.chat_curate.chat_curate - LLM call took 0.81 seconds\n",
      "INFO: [2025-07-01 10:02:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:02:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:02:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:02:30] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.66 seconds\n",
      "\u001b[92m10:02:30 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:02:30] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:02:31] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:02:31 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:02:31] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:02:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:02:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:02:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:02:31] indra_gpt.chat_curate.chat_curate - LLM call took 1.20 seconds\n",
      "INFO: [2025-07-01 10:02:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:02:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:02:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:02:33] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.67 seconds\n",
      "\u001b[92m10:02:33 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:02:33] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:02:33] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:02:33 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:02:33] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:02:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:02:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:02:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:02:33] indra_gpt.chat_curate.chat_curate - LLM call took 0.66 seconds\n",
      "Curating statements with chat curation:  15%|‚ñà‚ñç        | 13/89 [02:47<17:20, 13.69s/it]INFO: [2025-07-01 10:02:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:02:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:02:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:02:36] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.81 seconds\n",
      "\u001b[92m10:02:36 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:02:36] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:02:36] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:02:36 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:02:36] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:02:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:02:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:02:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:02:36] indra_gpt.chat_curate.chat_curate - LLM call took 0.58 seconds\n",
      "INFO: [2025-07-01 10:02:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:02:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:02:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:02:38] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.74 seconds\n",
      "\u001b[92m10:02:38 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:02:38] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:02:39] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:02:39 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:02:39] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:02:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:02:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:02:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:02:39] indra_gpt.chat_curate.chat_curate - LLM call took 0.46 seconds\n",
      "INFO: [2025-07-01 10:02:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:02:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:02:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:02:41] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.71 seconds\n",
      "\u001b[92m10:02:41 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:02:41] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:02:41] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:02:41 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:02:41] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:02:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:02:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:02:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:02:41] indra_gpt.chat_curate.chat_curate - LLM call took 0.57 seconds\n",
      "INFO: [2025-07-01 10:02:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:02:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:02:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:02:43] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.79 seconds\n",
      "\u001b[92m10:02:43 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:02:43] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:02:44] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:02:44 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:02:44] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:02:44 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:02:44] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:02:44 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:02:44] indra_gpt.chat_curate.chat_curate - LLM call took 0.46 seconds\n",
      "INFO: [2025-07-01 10:02:44] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:02:44 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:02:44] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:02:46] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.72 seconds\n",
      "\u001b[92m10:02:46 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:02:46] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:02:46] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:02:46 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:02:46] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:02:46 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:02:46] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:02:46 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:02:46] indra_gpt.chat_curate.chat_curate - LLM call took 0.62 seconds\n",
      "Curating statements with chat curation:  16%|‚ñà‚ñå        | 14/89 [03:00<16:48, 13.44s/it]INFO: [2025-07-01 10:02:46] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:02:46 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:02:46] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:02:48] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.68 seconds\n",
      "\u001b[92m10:02:48 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:02:48] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:02:49] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:02:49 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:02:49] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:02:49 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:02:49] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:02:49 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:02:49] indra_gpt.chat_curate.chat_curate - LLM call took 0.51 seconds\n",
      "INFO: [2025-07-01 10:02:49] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:02:49 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:02:49] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:02:51] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.71 seconds\n",
      "\u001b[92m10:02:51 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:02:51] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:02:52] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:02:52 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:02:52] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:02:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:02:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:02:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:02:52] indra_gpt.chat_curate.chat_curate - LLM call took 1.21 seconds\n",
      "INFO: [2025-07-01 10:02:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:02:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:02:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:02:54] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.69 seconds\n",
      "\u001b[92m10:02:54 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:02:54] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:02:55] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:02:55 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:02:55] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:02:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:02:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:02:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:02:55] indra_gpt.chat_curate.chat_curate - LLM call took 0.81 seconds\n",
      "INFO: [2025-07-01 10:02:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:02:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:02:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:02:57] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.65 seconds\n",
      "\u001b[92m10:02:57 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:02:57] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:02:57] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:02:57 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:02:57] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:02:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:02:57] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:02:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:02:57] indra_gpt.chat_curate.chat_curate - LLM call took 0.49 seconds\n",
      "INFO: [2025-07-01 10:02:57] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:02:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:02:57] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:02:59] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.71 seconds\n",
      "\u001b[92m10:02:59 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:02:59] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:03:00] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:03:00 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:03:00] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:03:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:03:00] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:03:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:03:00] indra_gpt.chat_curate.chat_curate - LLM call took 0.51 seconds\n",
      "Curating statements with chat curation:  17%|‚ñà‚ñã        | 15/89 [03:13<16:34, 13.44s/it]INFO: [2025-07-01 10:03:00] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:03:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:03:00] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:03:02] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.69 seconds\n",
      "\u001b[92m10:03:02 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:03:02] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:03:03] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:03:03 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:03:03] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:03:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:03:03] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:03:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:03:03] indra_gpt.chat_curate.chat_curate - LLM call took 0.80 seconds\n",
      "INFO: [2025-07-01 10:03:03] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:03:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:03:03] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:03:05] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.72 seconds\n",
      "\u001b[92m10:03:05 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:03:05] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:03:05] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:03:05 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:03:05] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:03:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:03:05] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:03:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:03:05] indra_gpt.chat_curate.chat_curate - LLM call took 0.81 seconds\n",
      "INFO: [2025-07-01 10:03:05] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:03:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:03:05] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:03:07] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.66 seconds\n",
      "\u001b[92m10:03:07 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:03:07] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:03:08] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:03:08 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:03:08] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:03:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:03:08] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:03:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:03:08] indra_gpt.chat_curate.chat_curate - LLM call took 0.59 seconds\n",
      "INFO: [2025-07-01 10:03:08] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:03:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:03:08] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:03:10] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.70 seconds\n",
      "\u001b[92m10:03:10 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:03:10] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:03:11] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:03:11 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:03:11] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:03:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:03:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:03:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:03:11] indra_gpt.chat_curate.chat_curate - LLM call took 0.91 seconds\n",
      "INFO: [2025-07-01 10:03:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:03:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:03:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:03:13] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.67 seconds\n",
      "\u001b[92m10:03:13 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:03:13] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:03:13] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:03:13 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:03:13] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:03:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:03:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:03:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:03:13] indra_gpt.chat_curate.chat_curate - LLM call took 0.70 seconds\n",
      "Curating statements with chat curation:  18%|‚ñà‚ñä        | 16/89 [03:27<16:26, 13.52s/it]INFO: [2025-07-01 10:03:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:03:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:03:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:03:16] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.72 seconds\n",
      "\u001b[92m10:03:16 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:03:16] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:03:16] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:03:16 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:03:16] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:03:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:03:16] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:03:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:03:16] indra_gpt.chat_curate.chat_curate - LLM call took 0.81 seconds\n",
      "INFO: [2025-07-01 10:03:16] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:03:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:03:16] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:03:18] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.72 seconds\n",
      "\u001b[92m10:03:18 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:03:18] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:03:19] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:03:19 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:03:19] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:03:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:03:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:03:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:03:19] indra_gpt.chat_curate.chat_curate - LLM call took 0.71 seconds\n",
      "INFO: [2025-07-01 10:03:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:03:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:03:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:03:21] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.71 seconds\n",
      "\u001b[92m10:03:21 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:03:21] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:03:22] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:03:22 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:03:22] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:03:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:03:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:03:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:03:22] indra_gpt.chat_curate.chat_curate - LLM call took 0.72 seconds\n",
      "INFO: [2025-07-01 10:03:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:03:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:03:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:03:24] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.81 seconds\n",
      "\u001b[92m10:03:24 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:03:24] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:03:24] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:03:24 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:03:24] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:03:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:03:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:03:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:03:24] indra_gpt.chat_curate.chat_curate - LLM call took 0.57 seconds\n",
      "INFO: [2025-07-01 10:03:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:03:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:03:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:03:27] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.81 seconds\n",
      "\u001b[92m10:03:27 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:03:27] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:03:27] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:03:27 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:03:27] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:03:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:03:27] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:03:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:03:27] indra_gpt.chat_curate.chat_curate - LLM call took 0.56 seconds\n",
      "Curating statements with chat curation:  19%|‚ñà‚ñâ        | 17/89 [03:40<16:14, 13.54s/it]INFO: [2025-07-01 10:03:27] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:03:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:03:27] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:03:29] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.70 seconds\n",
      "\u001b[92m10:03:29 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:03:29] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:03:30] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:03:30 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:03:30] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:03:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:03:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:03:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:03:30] indra_gpt.chat_curate.chat_curate - LLM call took 0.67 seconds\n",
      "INFO: [2025-07-01 10:03:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:03:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:03:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:03:32] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.66 seconds\n",
      "\u001b[92m10:03:32 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:03:32] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:03:33] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:03:33 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:03:33] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:03:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:03:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:03:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:03:33] indra_gpt.chat_curate.chat_curate - LLM call took 1.56 seconds\n",
      "INFO: [2025-07-01 10:03:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:03:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:03:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:03:35] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.74 seconds\n",
      "\u001b[92m10:03:35 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:03:35] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:03:36] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:03:36 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:03:36] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:03:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:03:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:03:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:03:36] indra_gpt.chat_curate.chat_curate - LLM call took 0.52 seconds\n",
      "INFO: [2025-07-01 10:03:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:03:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:03:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:03:38] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.69 seconds\n",
      "\u001b[92m10:03:38 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:03:38] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:03:39] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:03:39 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:03:39] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:03:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:03:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:03:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:03:39] indra_gpt.chat_curate.chat_curate - LLM call took 0.92 seconds\n",
      "INFO: [2025-07-01 10:03:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:03:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:03:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:03:41] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.67 seconds\n",
      "\u001b[92m10:03:41 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:03:41] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:03:41] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:03:41 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:03:41] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:03:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:03:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:03:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:03:41] indra_gpt.chat_curate.chat_curate - LLM call took 0.53 seconds\n",
      "Curating statements with chat curation:  20%|‚ñà‚ñà        | 18/89 [03:54<16:13, 13.71s/it]INFO: [2025-07-01 10:03:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:03:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:03:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:03:43] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.68 seconds\n",
      "\u001b[92m10:03:43 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:03:43] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:03:44] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:03:44 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:03:44] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:03:44 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:03:44] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:03:44 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:03:44] indra_gpt.chat_curate.chat_curate - LLM call took 0.51 seconds\n",
      "INFO: [2025-07-01 10:03:44] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:03:44 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:03:44] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:03:46] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.67 seconds\n",
      "\u001b[92m10:03:46 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:03:46] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:03:46] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:03:46 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:03:46] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:03:46 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:03:46] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:03:46 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:03:46] indra_gpt.chat_curate.chat_curate - LLM call took 0.75 seconds\n",
      "INFO: [2025-07-01 10:03:46] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:03:46 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:03:46] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:03:48] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.72 seconds\n",
      "\u001b[92m10:03:48 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:03:48] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:03:49] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:03:49 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:03:49] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:03:49 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:03:49] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:03:49 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:03:49] indra_gpt.chat_curate.chat_curate - LLM call took 0.49 seconds\n",
      "INFO: [2025-07-01 10:03:49] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:03:49 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:03:49] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:03:51] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.73 seconds\n",
      "\u001b[92m10:03:51 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:03:51] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:03:51] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:03:51 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:03:51] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:03:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:03:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:03:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:03:51] indra_gpt.chat_curate.chat_curate - LLM call took 0.51 seconds\n",
      "INFO: [2025-07-01 10:03:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:03:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:03:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:03:53] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.72 seconds\n",
      "\u001b[92m10:03:53 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:03:53] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:03:54] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:03:54 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:03:54] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:03:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:03:54] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:03:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:03:54] indra_gpt.chat_curate.chat_curate - LLM call took 0.45 seconds\n",
      "Curating statements with chat curation:  21%|‚ñà‚ñà‚ñè       | 19/89 [04:07<15:37, 13.40s/it]INFO: [2025-07-01 10:03:54] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:03:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:03:54] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:03:56] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.75 seconds\n",
      "\u001b[92m10:03:56 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:03:56] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:03:56] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:03:56 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:03:56] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:03:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:03:56] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:03:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:03:56] indra_gpt.chat_curate.chat_curate - LLM call took 0.55 seconds\n",
      "INFO: [2025-07-01 10:03:56] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:03:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:03:57] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:03:58] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.68 seconds\n",
      "\u001b[92m10:03:58 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:03:58] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:03:59] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:03:59 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:03:59] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:03:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:03:59] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:03:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:03:59] indra_gpt.chat_curate.chat_curate - LLM call took 0.66 seconds\n",
      "INFO: [2025-07-01 10:03:59] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:03:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:03:59] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:04:01] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.73 seconds\n",
      "\u001b[92m10:04:01 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:04:01] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:04:02] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:04:02 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:04:02] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:04:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:04:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:04:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:04:02] indra_gpt.chat_curate.chat_curate - LLM call took 1.20 seconds\n",
      "INFO: [2025-07-01 10:04:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:04:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:04:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:04:04] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.73 seconds\n",
      "\u001b[92m10:04:04 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:04:04] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:04:05] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:04:05 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:04:05] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:04:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:04:05] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:04:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:04:05] indra_gpt.chat_curate.chat_curate - LLM call took 0.61 seconds\n",
      "INFO: [2025-07-01 10:04:05] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:04:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:04:05] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:04:07] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.69 seconds\n",
      "\u001b[92m10:04:07 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:04:07] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:04:08] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:04:08 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:04:08] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:04:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:04:08] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:04:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:04:08] indra_gpt.chat_curate.chat_curate - LLM call took 0.92 seconds\n",
      "Curating statements with chat curation:  22%|‚ñà‚ñà‚ñè       | 20/89 [04:21<15:35, 13.56s/it]INFO: [2025-07-01 10:04:08] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:04:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:04:08] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:04:10] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.68 seconds\n",
      "\u001b[92m10:04:10 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:04:10] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:04:10] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:04:10 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:04:10] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:04:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:04:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:04:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:04:10] indra_gpt.chat_curate.chat_curate - LLM call took 0.56 seconds\n",
      "INFO: [2025-07-01 10:04:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:04:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:04:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:04:12] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.68 seconds\n",
      "\u001b[92m10:04:12 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:04:12] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:04:13] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:04:13 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:04:13] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:04:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:04:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:04:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:04:13] indra_gpt.chat_curate.chat_curate - LLM call took 0.47 seconds\n",
      "INFO: [2025-07-01 10:04:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:04:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:04:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:04:15] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.75 seconds\n",
      "\u001b[92m10:04:15 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:04:15] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:04:16] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:04:16 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:04:16] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:04:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:04:16] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:04:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:04:16] indra_gpt.chat_curate.chat_curate - LLM call took 0.73 seconds\n",
      "INFO: [2025-07-01 10:04:16] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:04:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:04:16] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:04:18] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.74 seconds\n",
      "\u001b[92m10:04:18 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:04:18] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:04:19] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:04:19 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:04:19] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:04:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:04:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:04:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:04:19] indra_gpt.chat_curate.chat_curate - LLM call took 0.96 seconds\n",
      "INFO: [2025-07-01 10:04:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:04:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:04:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:04:21] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.67 seconds\n",
      "\u001b[92m10:04:21 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:04:21] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:04:21] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:04:21 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:04:21] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:04:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:04:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:04:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:04:21] indra_gpt.chat_curate.chat_curate - LLM call took 0.45 seconds\n",
      "Curating statements with chat curation:  24%|‚ñà‚ñà‚ñé       | 21/89 [04:34<15:14, 13.45s/it]INFO: [2025-07-01 10:04:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:04:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:04:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:04:23] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.73 seconds\n",
      "\u001b[92m10:04:23 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:04:23] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:04:24] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:04:24 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:04:24] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:04:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:04:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:04:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:04:24] indra_gpt.chat_curate.chat_curate - LLM call took 0.51 seconds\n",
      "INFO: [2025-07-01 10:04:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:04:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:04:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:04:26] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.72 seconds\n",
      "\u001b[92m10:04:26 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:04:26] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:04:26] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:04:26 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:04:26] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:04:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:04:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:04:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:04:26] indra_gpt.chat_curate.chat_curate - LLM call took 0.65 seconds\n",
      "INFO: [2025-07-01 10:04:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:04:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:04:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:04:28] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.67 seconds\n",
      "\u001b[92m10:04:28 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:04:28] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:04:29] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:04:29 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:04:29] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:04:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:04:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:04:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:04:29] indra_gpt.chat_curate.chat_curate - LLM call took 0.49 seconds\n",
      "INFO: [2025-07-01 10:04:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:04:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:04:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:04:31] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.70 seconds\n",
      "\u001b[92m10:04:31 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:04:31] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:04:32] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:04:32 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:04:32] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:04:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:04:32] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:04:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:04:32] indra_gpt.chat_curate.chat_curate - LLM call took 1.66 seconds\n",
      "INFO: [2025-07-01 10:04:32] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:04:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:04:32] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:04:34] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.71 seconds\n",
      "\u001b[92m10:04:34 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:04:34] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:04:35] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:04:35 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:04:35] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:04:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:04:35] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:04:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:04:35] indra_gpt.chat_curate.chat_curate - LLM call took 0.50 seconds\n",
      "Curating statements with chat curation:  25%|‚ñà‚ñà‚ñç       | 22/89 [04:48<15:10, 13.60s/it]INFO: [2025-07-01 10:04:35] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:04:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:04:35] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:04:37] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.72 seconds\n",
      "\u001b[92m10:04:37 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:04:37] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:04:37] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:04:37 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:04:37] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:04:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:04:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:04:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:04:37] indra_gpt.chat_curate.chat_curate - LLM call took 0.48 seconds\n",
      "INFO: [2025-07-01 10:04:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:04:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:04:38] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:04:39] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.72 seconds\n",
      "\u001b[92m10:04:39 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:04:39] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:04:40] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:04:40 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:04:40] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:04:40 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:04:40] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:04:40 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:04:40] indra_gpt.chat_curate.chat_curate - LLM call took 0.50 seconds\n",
      "INFO: [2025-07-01 10:04:40] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:04:40 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:04:40] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:04:42] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.70 seconds\n",
      "\u001b[92m10:04:42 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:04:42] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:04:42] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:04:42 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:04:42] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:04:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:04:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:04:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:04:42] indra_gpt.chat_curate.chat_curate - LLM call took 0.47 seconds\n",
      "INFO: [2025-07-01 10:04:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:04:43 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:04:43] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:04:44] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.71 seconds\n",
      "\u001b[92m10:04:44 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:04:44] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:04:45] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:04:45 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:04:45] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:04:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:04:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:04:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:04:45] indra_gpt.chat_curate.chat_curate - LLM call took 0.77 seconds\n",
      "INFO: [2025-07-01 10:04:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:04:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:04:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:04:47] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.75 seconds\n",
      "\u001b[92m10:04:47 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:04:47] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:04:48] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:04:48 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:04:48] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:04:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:04:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:04:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:04:48] indra_gpt.chat_curate.chat_curate - LLM call took 0.44 seconds\n",
      "Curating statements with chat curation:  26%|‚ñà‚ñà‚ñå       | 23/89 [05:01<14:41, 13.36s/it]INFO: [2025-07-01 10:04:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:04:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:04:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:04:49] indra_gpt.chat_curate.chat_curate - Prompt generation took 0.90 seconds\n",
      "\u001b[92m10:04:49 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:04:49] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:04:49] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:04:49 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:04:49] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:04:49 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:04:49] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:04:49 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:04:49] indra_gpt.chat_curate.chat_curate - LLM call took 0.47 seconds\n",
      "INFO: [2025-07-01 10:04:49] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:04:49 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:04:49] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:04:51] indra_gpt.chat_curate.chat_curate - Prompt generation took 0.90 seconds\n",
      "\u001b[92m10:04:51 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:04:51] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:04:51] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:04:51 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:04:51] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:04:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:04:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:04:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:04:51] indra_gpt.chat_curate.chat_curate - LLM call took 0.52 seconds\n",
      "INFO: [2025-07-01 10:04:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:04:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:04:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:04:52] indra_gpt.chat_curate.chat_curate - Prompt generation took 0.91 seconds\n",
      "\u001b[92m10:04:52 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:04:52] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:04:53] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:04:53 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:04:53] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:04:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:04:53] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:04:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:04:53] indra_gpt.chat_curate.chat_curate - LLM call took 0.94 seconds\n",
      "INFO: [2025-07-01 10:04:53] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:04:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:04:53] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:04:54] indra_gpt.chat_curate.chat_curate - Prompt generation took 0.92 seconds\n",
      "\u001b[92m10:04:54 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:04:54] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:04:55] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:04:55 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:04:55] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:04:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:04:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:04:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:04:55] indra_gpt.chat_curate.chat_curate - LLM call took 0.62 seconds\n",
      "INFO: [2025-07-01 10:04:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:04:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:04:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:04:56] indra_gpt.chat_curate.chat_curate - Prompt generation took 0.91 seconds\n",
      "\u001b[92m10:04:56 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:04:56] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:04:57] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:04:57 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:04:57] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:04:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:04:57] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:04:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:04:57] indra_gpt.chat_curate.chat_curate - LLM call took 0.94 seconds\n",
      "Curating statements with chat curation:  27%|‚ñà‚ñà‚ñã       | 24/89 [05:10<13:12, 12.19s/it]INFO: [2025-07-01 10:04:57] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:04:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:04:57] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:04:59] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.72 seconds\n",
      "\u001b[92m10:04:59 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:04:59] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:05:00] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:05:00 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:05:00] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:05:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:05:00] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:05:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:05:00] indra_gpt.chat_curate.chat_curate - LLM call took 0.55 seconds\n",
      "INFO: [2025-07-01 10:05:00] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:05:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:05:00] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:05:02] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.68 seconds\n",
      "\u001b[92m10:05:02 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:05:02] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:05:02] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:05:02 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:05:02] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:05:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:05:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:05:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:05:02] indra_gpt.chat_curate.chat_curate - LLM call took 0.57 seconds\n",
      "INFO: [2025-07-01 10:05:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:05:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:05:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:05:04] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.68 seconds\n",
      "\u001b[92m10:05:04 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:05:04] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:05:05] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:05:05 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:05:05] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:05:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:05:05] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:05:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:05:05] indra_gpt.chat_curate.chat_curate - LLM call took 0.52 seconds\n",
      "INFO: [2025-07-01 10:05:05] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:05:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:05:05] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:05:07] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.66 seconds\n",
      "\u001b[92m10:05:07 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:05:07] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:05:07] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:05:07 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:05:07] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:05:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:05:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:05:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:05:07] indra_gpt.chat_curate.chat_curate - LLM call took 0.45 seconds\n",
      "INFO: [2025-07-01 10:05:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:05:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:05:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:05:09] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.74 seconds\n",
      "\u001b[92m10:05:09 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:05:09] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:05:10] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:05:10 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:05:10] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:05:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:05:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:05:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:05:10] indra_gpt.chat_curate.chat_curate - LLM call took 0.56 seconds\n",
      "Curating statements with chat curation:  28%|‚ñà‚ñà‚ñä       | 25/89 [05:23<13:07, 12.31s/it]INFO: [2025-07-01 10:05:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:05:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:05:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:05:12] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.67 seconds\n",
      "\u001b[92m10:05:12 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:05:12] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:05:12] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:05:12 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:05:12] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:05:12 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:05:12] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:05:12 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:05:12] indra_gpt.chat_curate.chat_curate - LLM call took 0.43 seconds\n",
      "INFO: [2025-07-01 10:05:12] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:05:12 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:05:12] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:05:14] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.67 seconds\n",
      "\u001b[92m10:05:14 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:05:14] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:05:15] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:05:15 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:05:15] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:05:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:05:15] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:05:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:05:15] indra_gpt.chat_curate.chat_curate - LLM call took 0.84 seconds\n",
      "INFO: [2025-07-01 10:05:15] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:05:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:05:15] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:05:17] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.70 seconds\n",
      "\u001b[92m10:05:17 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:05:17] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:05:17] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:05:17 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:05:17] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:05:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:05:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:05:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:05:17] indra_gpt.chat_curate.chat_curate - LLM call took 0.43 seconds\n",
      "INFO: [2025-07-01 10:05:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:05:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:05:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:05:19] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.73 seconds\n",
      "\u001b[92m10:05:19 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:05:19] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:05:20] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:05:20 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:05:20] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:05:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:05:20] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:05:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:05:20] indra_gpt.chat_curate.chat_curate - LLM call took 0.52 seconds\n",
      "INFO: [2025-07-01 10:05:20] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:05:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:05:20] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:05:22] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.72 seconds\n",
      "\u001b[92m10:05:22 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:05:22] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:05:23] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:05:23 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:05:23] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:05:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:05:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:05:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:05:23] indra_gpt.chat_curate.chat_curate - LLM call took 0.51 seconds\n",
      "Curating statements with chat curation:  29%|‚ñà‚ñà‚ñâ       | 26/89 [05:36<13:03, 12.44s/it]INFO: [2025-07-01 10:05:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:05:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:05:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:05:25] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.71 seconds\n",
      "\u001b[92m10:05:25 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:05:25] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:05:25] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:05:25 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:05:25] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:05:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:05:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:05:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:05:25] indra_gpt.chat_curate.chat_curate - LLM call took 0.43 seconds\n",
      "INFO: [2025-07-01 10:05:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:05:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:05:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:05:27] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.67 seconds\n",
      "\u001b[92m10:05:27 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:05:27] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:05:27] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:05:27 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:05:27] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:05:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:05:27] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:05:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:05:27] indra_gpt.chat_curate.chat_curate - LLM call took 0.41 seconds\n",
      "INFO: [2025-07-01 10:05:27] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:05:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:05:27] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:05:29] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.66 seconds\n",
      "\u001b[92m10:05:29 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:05:29] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:05:30] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:05:30 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:05:30] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:05:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:05:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:05:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:05:30] indra_gpt.chat_curate.chat_curate - LLM call took 0.47 seconds\n",
      "INFO: [2025-07-01 10:05:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:05:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:05:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:05:32] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.70 seconds\n",
      "\u001b[92m10:05:32 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:05:32] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:05:33] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:05:33 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:05:33] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:05:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:05:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:05:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:05:33] indra_gpt.chat_curate.chat_curate - LLM call took 1.04 seconds\n",
      "INFO: [2025-07-01 10:05:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:05:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:05:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:05:35] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.67 seconds\n",
      "\u001b[92m10:05:35 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:05:35] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:05:35] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:05:35 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:05:35] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:05:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:05:35] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:05:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:05:35] indra_gpt.chat_curate.chat_curate - LLM call took 0.56 seconds\n",
      "Curating statements with chat curation:  30%|‚ñà‚ñà‚ñà       | 27/89 [05:49<12:57, 12.54s/it]INFO: [2025-07-01 10:05:35] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:05:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:05:35] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:05:37] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.67 seconds\n",
      "\u001b[92m10:05:37 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:05:37] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:05:38] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:05:38 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:05:38] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:05:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:05:38] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:05:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:05:38] indra_gpt.chat_curate.chat_curate - LLM call took 0.42 seconds\n",
      "INFO: [2025-07-01 10:05:38] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:05:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:05:38] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:05:40] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.66 seconds\n",
      "\u001b[92m10:05:40 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:05:40] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:05:43] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:05:43 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:05:43] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:05:43 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:05:43] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:05:43 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:05:43] indra_gpt.chat_curate.chat_curate - LLM call took 3.84 seconds\n",
      "INFO: [2025-07-01 10:05:43] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:05:44 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:05:44] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:05:45] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.70 seconds\n",
      "\u001b[92m10:05:45 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:05:45] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:05:46] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:05:46 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:05:46] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:05:46 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:05:46] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:05:46 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:05:46] indra_gpt.chat_curate.chat_curate - LLM call took 0.53 seconds\n",
      "INFO: [2025-07-01 10:05:46] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:05:46 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:05:46] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:05:48] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.74 seconds\n",
      "\u001b[92m10:05:48 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:05:48] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:05:48] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:05:48 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:05:48] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:05:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:05:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:05:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:05:48] indra_gpt.chat_curate.chat_curate - LLM call took 0.43 seconds\n",
      "INFO: [2025-07-01 10:05:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:05:49 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:05:49] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:05:50] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.66 seconds\n",
      "\u001b[92m10:05:50 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:05:50] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:05:51] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:05:51 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:05:51] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:05:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:05:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:05:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:05:51] indra_gpt.chat_curate.chat_curate - LLM call took 0.42 seconds\n",
      "Curating statements with chat curation:  31%|‚ñà‚ñà‚ñà‚ñè      | 28/89 [06:04<13:38, 13.42s/it]INFO: [2025-07-01 10:05:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:05:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:05:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:05:53] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.74 seconds\n",
      "\u001b[92m10:05:53 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:05:53] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:05:53] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:05:53 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:05:53] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:05:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:05:53] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:05:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:05:53] indra_gpt.chat_curate.chat_curate - LLM call took 0.50 seconds\n",
      "INFO: [2025-07-01 10:05:53] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:05:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:05:53] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:05:55] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.74 seconds\n",
      "\u001b[92m10:05:55 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:05:55] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:05:56] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:05:56 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:05:56] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:05:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:05:56] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:05:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:05:56] indra_gpt.chat_curate.chat_curate - LLM call took 0.65 seconds\n",
      "INFO: [2025-07-01 10:05:56] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:05:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:05:56] indra_gpt.chat_curate.chat_curate - Skipping evidence with no text for statement 14461478333067931: Evidence(source_api='ubibrowser',\n",
      "         annotations={\n",
      "                      \"agents\": {\n",
      "                       \"raw_text\": [\n",
      "                        null,\n",
      "                        null\n",
      "                       ]\n",
      "                      },\n",
      "                      \"prior_uuids\": [\n",
      "                       \"8770d509-ea4a-43af-a5cd-c5e65c0fe4e1\"\n",
      "                      ]\n",
      "                     }\n",
      "         )\n",
      "\n",
      "\n",
      "INFO: [2025-07-01 10:05:56] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:05:58] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.77 seconds\n",
      "\u001b[92m10:05:58 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:05:58] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:05:59] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:05:59 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:05:59] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:05:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:05:59] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:05:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:05:59] indra_gpt.chat_curate.chat_curate - LLM call took 0.62 seconds\n",
      "INFO: [2025-07-01 10:05:59] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:05:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:05:59] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:06:01] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.68 seconds\n",
      "\u001b[92m10:06:01 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:06:01] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:06:01] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:06:01 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:06:01] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:06:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:06:01] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:06:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:06:01] indra_gpt.chat_curate.chat_curate - LLM call took 0.47 seconds\n",
      "Curating statements with chat curation:  33%|‚ñà‚ñà‚ñà‚ñé      | 29/89 [06:14<12:30, 12.51s/it]INFO: [2025-07-01 10:06:01] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:06:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:06:01] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:06:03] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.68 seconds\n",
      "\u001b[92m10:06:03 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:06:03] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:06:04] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:06:04 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:06:04] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:06:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:06:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:06:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:06:04] indra_gpt.chat_curate.chat_curate - LLM call took 0.41 seconds\n",
      "INFO: [2025-07-01 10:06:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:06:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:06:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:06:06] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.70 seconds\n",
      "\u001b[92m10:06:06 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:06:06] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:06:06] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:06:07 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:06:07] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:06:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:06:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:06:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:06:07] indra_gpt.chat_curate.chat_curate - LLM call took 0.92 seconds\n",
      "INFO: [2025-07-01 10:06:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:06:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:06:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:06:09] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.72 seconds\n",
      "\u001b[92m10:06:09 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:06:09] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:06:09] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:06:09 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:06:09] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:06:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:06:09] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:06:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:06:09] indra_gpt.chat_curate.chat_curate - LLM call took 0.50 seconds\n",
      "INFO: [2025-07-01 10:06:09] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:06:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:06:09] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:06:11] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.67 seconds\n",
      "\u001b[92m10:06:11 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:06:11] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:06:11] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:06:11 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:06:11] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:06:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:06:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:06:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:06:11] indra_gpt.chat_curate.chat_curate - LLM call took 0.50 seconds\n",
      "INFO: [2025-07-01 10:06:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:06:12 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:06:12] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:06:13] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.67 seconds\n",
      "\u001b[92m10:06:13 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:06:13] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:06:14] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:06:14 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:06:14] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:06:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:06:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:06:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:06:14] indra_gpt.chat_curate.chat_curate - LLM call took 0.84 seconds\n",
      "Curating statements with chat curation:  34%|‚ñà‚ñà‚ñà‚ñé      | 30/89 [06:28<12:28, 12.69s/it]INFO: [2025-07-01 10:06:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:06:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:06:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:06:16] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.66 seconds\n",
      "\u001b[92m10:06:16 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:06:16] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:06:17] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:06:17 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:06:17] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:06:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:06:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:06:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:06:17] indra_gpt.chat_curate.chat_curate - LLM call took 0.48 seconds\n",
      "INFO: [2025-07-01 10:06:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:06:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:06:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:06:19] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.66 seconds\n",
      "\u001b[92m10:06:19 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:06:19] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:06:19] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:06:19 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:06:19] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:06:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:06:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:06:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:06:19] indra_gpt.chat_curate.chat_curate - LLM call took 0.44 seconds\n",
      "INFO: [2025-07-01 10:06:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:06:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:06:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:06:21] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.67 seconds\n",
      "\u001b[92m10:06:21 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:06:21] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:06:22] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:06:22 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:06:22] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:06:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:06:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:06:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:06:22] indra_gpt.chat_curate.chat_curate - LLM call took 0.56 seconds\n",
      "INFO: [2025-07-01 10:06:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:06:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:06:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:06:24] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.67 seconds\n",
      "\u001b[92m10:06:24 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:06:24] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:06:24] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:06:24 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:06:24] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:06:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:06:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:06:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:06:24] indra_gpt.chat_curate.chat_curate - LLM call took 0.67 seconds\n",
      "INFO: [2025-07-01 10:06:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:06:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:06:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:06:26] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.72 seconds\n",
      "\u001b[92m10:06:26 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:06:26] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:06:27] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:06:27 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:06:27] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:06:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:06:27] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:06:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:06:27] indra_gpt.chat_curate.chat_curate - LLM call took 0.51 seconds\n",
      "Curating statements with chat curation:  35%|‚ñà‚ñà‚ñà‚ñç      | 31/89 [06:40<12:15, 12.68s/it]INFO: [2025-07-01 10:06:27] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:06:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:06:27] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:06:29] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.74 seconds\n",
      "\u001b[92m10:06:29 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:06:29] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:06:30] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:06:30 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:06:30] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:06:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:06:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:06:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:06:30] indra_gpt.chat_curate.chat_curate - LLM call took 0.52 seconds\n",
      "INFO: [2025-07-01 10:06:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:06:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:06:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:06:32] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.75 seconds\n",
      "\u001b[92m10:06:32 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:06:32] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:06:32] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:06:32 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:06:32] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:06:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:06:32] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:06:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:06:32] indra_gpt.chat_curate.chat_curate - LLM call took 0.47 seconds\n",
      "INFO: [2025-07-01 10:06:32] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:06:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:06:32] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:06:34] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.71 seconds\n",
      "\u001b[92m10:06:34 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:06:34] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:06:34] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:06:34 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:06:34] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:06:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:06:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:06:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:06:34] indra_gpt.chat_curate.chat_curate - LLM call took 0.48 seconds\n",
      "INFO: [2025-07-01 10:06:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:06:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:06:35] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:06:36] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.71 seconds\n",
      "\u001b[92m10:06:36 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:06:36] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:06:37] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:06:37 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:06:37] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:06:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:06:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:06:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:06:37] indra_gpt.chat_curate.chat_curate - LLM call took 0.51 seconds\n",
      "INFO: [2025-07-01 10:06:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:06:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:06:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:06:39] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.71 seconds\n",
      "\u001b[92m10:06:39 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:06:39] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:06:39] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:06:39 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:06:39] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:06:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:06:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:06:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:06:39] indra_gpt.chat_curate.chat_curate - LLM call took 0.46 seconds\n",
      "Curating statements with chat curation:  36%|‚ñà‚ñà‚ñà‚ñå      | 32/89 [06:53<12:00, 12.64s/it]INFO: [2025-07-01 10:06:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:06:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:06:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:06:41] indra_gpt.chat_curate.chat_curate - Prompt generation took 0.90 seconds\n",
      "\u001b[92m10:06:41 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:06:41] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:06:41] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:06:41 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:06:41] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:06:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:06:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:06:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:06:41] indra_gpt.chat_curate.chat_curate - LLM call took 0.58 seconds\n",
      "INFO: [2025-07-01 10:06:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:06:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:06:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:06:42] indra_gpt.chat_curate.chat_curate - Prompt generation took 0.90 seconds\n",
      "\u001b[92m10:06:42 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:06:42] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:06:43] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:06:43 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:06:43] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:06:43 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:06:43] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:06:43 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:06:43] indra_gpt.chat_curate.chat_curate - LLM call took 0.43 seconds\n",
      "INFO: [2025-07-01 10:06:43] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:06:43 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:06:43] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:06:44] indra_gpt.chat_curate.chat_curate - Prompt generation took 0.90 seconds\n",
      "\u001b[92m10:06:44 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:06:44] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:06:45] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:06:45 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:06:45] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:06:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:06:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:06:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:06:45] indra_gpt.chat_curate.chat_curate - LLM call took 0.55 seconds\n",
      "INFO: [2025-07-01 10:06:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:06:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:06:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:06:46] indra_gpt.chat_curate.chat_curate - Prompt generation took 0.90 seconds\n",
      "\u001b[92m10:06:46 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:06:46] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:06:46] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:06:46 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:06:46] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:06:46 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:06:46] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:06:46 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:06:46] indra_gpt.chat_curate.chat_curate - LLM call took 0.57 seconds\n",
      "INFO: [2025-07-01 10:06:46] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:06:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:06:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:06:48] indra_gpt.chat_curate.chat_curate - Prompt generation took 0.90 seconds\n",
      "\u001b[92m10:06:48 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:06:48] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:06:48] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:06:48 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:06:48] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:06:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:06:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:06:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:06:48] indra_gpt.chat_curate.chat_curate - LLM call took 0.43 seconds\n",
      "Curating statements with chat curation:  37%|‚ñà‚ñà‚ñà‚ñã      | 33/89 [07:01<10:40, 11.43s/it]INFO: [2025-07-01 10:06:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:06:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:06:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:06:50] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.66 seconds\n",
      "\u001b[92m10:06:50 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:06:50] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:06:51] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:06:51 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:06:51] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:06:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:06:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:06:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:06:51] indra_gpt.chat_curate.chat_curate - LLM call took 0.83 seconds\n",
      "INFO: [2025-07-01 10:06:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:06:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:06:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:06:53] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.69 seconds\n",
      "\u001b[92m10:06:53 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:06:53] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:06:53] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:06:53 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:06:53] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:06:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:06:53] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:06:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:06:53] indra_gpt.chat_curate.chat_curate - LLM call took 0.45 seconds\n",
      "INFO: [2025-07-01 10:06:53] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:06:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:06:53] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:06:55] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.77 seconds\n",
      "\u001b[92m10:06:55 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:06:55] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:06:56] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:06:56 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:06:56] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:06:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:06:56] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:06:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:06:56] indra_gpt.chat_curate.chat_curate - LLM call took 0.83 seconds\n",
      "INFO: [2025-07-01 10:06:56] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:06:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:06:56] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:06:58] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.76 seconds\n",
      "\u001b[92m10:06:58 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:06:58] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:06:59] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:06:59 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:06:59] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:06:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:06:59] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:06:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:06:59] indra_gpt.chat_curate.chat_curate - LLM call took 0.51 seconds\n",
      "INFO: [2025-07-01 10:06:59] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:06:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:06:59] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:07:01] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.67 seconds\n",
      "\u001b[92m10:07:01 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:07:01] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:07:01] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:07:01 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:07:01] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:07:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:07:01] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:07:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:07:01] indra_gpt.chat_curate.chat_curate - LLM call took 0.41 seconds\n",
      "Curating statements with chat curation:  38%|‚ñà‚ñà‚ñà‚ñä      | 34/89 [07:14<10:55, 11.92s/it]INFO: [2025-07-01 10:07:01] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:07:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:07:01] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:07:03] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.74 seconds\n",
      "\u001b[92m10:07:03 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:07:03] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:07:04] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:07:04 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:07:04] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:07:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:07:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:07:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:07:04] indra_gpt.chat_curate.chat_curate - LLM call took 0.48 seconds\n",
      "INFO: [2025-07-01 10:07:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:07:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:07:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:07:06] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.70 seconds\n",
      "\u001b[92m10:07:06 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:07:06] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:07:06] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:07:06 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:07:06] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:07:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:07:06] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:07:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:07:06] indra_gpt.chat_curate.chat_curate - LLM call took 0.49 seconds\n",
      "INFO: [2025-07-01 10:07:06] indra_gpt.chat_curate.chat_curate - Skipping evidence with no text for statement -10558769985488922: Evidence(source_api='ctd',\n",
      "         pmid='26004626',\n",
      "         annotations={\n",
      "                      \"interaction_action\": \"increases^chemical synthesis\",\n",
      "                      \"agents\": {\n",
      "                       \"raw_text\": [\n",
      "                        null,\n",
      "                        null\n",
      "                       ]\n",
      "                      },\n",
      "                      \"prior_uuids\": [\n",
      "                       \"401a0189-dc6a-4b12-95e3-8a759226aa39\"\n",
      "                      ]\n",
      "                     },\n",
      "         context={\n",
      "                  \"species\": {\n",
      "                   \"name\": \"Homo sapiens\",\n",
      "                   \"db_refs\": {\n",
      "                    \"TAXONOMY\": \"9606\"\n",
      "                   }\n",
      "                  },\n",
      "                  \"type\": \"bio\"\n",
      "                 },\n",
      "         text_refs={\n",
      "                    \"PMID\": \"26004626\"\n",
      "                   }\n",
      "         )\n",
      "\n",
      "\n",
      "INFO: [2025-07-01 10:07:06] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:07:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:07:06] indra_gpt.chat_curate.chat_curate - Skipping evidence with no text for statement -10558769985488922: Evidence(source_api='ctd',\n",
      "         pmid='17327447',\n",
      "         annotations={\n",
      "                      \"interaction_action\": \"increases^abundance\",\n",
      "                      \"agents\": {\n",
      "                       \"raw_text\": [\n",
      "                        null,\n",
      "                        null\n",
      "                       ]\n",
      "                      },\n",
      "                      \"prior_uuids\": [\n",
      "                       \"1e0419a3-fcc4-436a-a946-f4f9faa2982e\"\n",
      "                      ]\n",
      "                     },\n",
      "         context={\n",
      "                  \"species\": {\n",
      "                   \"name\": \"Homo sapiens\",\n",
      "                   \"db_refs\": {\n",
      "                    \"TAXONOMY\": \"9606\"\n",
      "                   }\n",
      "                  },\n",
      "                  \"type\": \"bio\"\n",
      "                 },\n",
      "         text_refs={\n",
      "                    \"PMID\": \"17327447\"\n",
      "                   }\n",
      "         )\n",
      "\n",
      "\n",
      "INFO: [2025-07-01 10:07:06] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:07:06] indra_gpt.chat_curate.chat_curate - Skipping evidence with no text for statement -10558769985488922: Evidence(source_api='ctd',\n",
      "         pmid='21212296',\n",
      "         annotations={\n",
      "                      \"interaction_action\": \"increases^expression\",\n",
      "                      \"agents\": {\n",
      "                       \"raw_text\": [\n",
      "                        null,\n",
      "                        null\n",
      "                       ]\n",
      "                      },\n",
      "                      \"prior_uuids\": [\n",
      "                       \"640af7e4-fdf9-40ed-a017-ccecd5d97a65\"\n",
      "                      ]\n",
      "                     },\n",
      "         context={\n",
      "                  \"species\": {\n",
      "                   \"name\": \"Gallus gallus\",\n",
      "                   \"db_refs\": {\n",
      "                    \"TAXONOMY\": \"9031\"\n",
      "                   }\n",
      "                  },\n",
      "                  \"type\": \"bio\"\n",
      "                 },\n",
      "         text_refs={\n",
      "                    \"PMID\": \"21212296\"\n",
      "                   }\n",
      "         )\n",
      "\n",
      "\n",
      "Curating statements with chat curation:  39%|‚ñà‚ñà‚ñà‚ñâ      | 35/89 [07:19<08:51,  9.85s/it]INFO: [2025-07-01 10:07:08] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.66 seconds\n",
      "\u001b[92m10:07:08 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:07:08] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:07:09] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:07:09 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:07:09] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:07:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:07:09] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:07:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:07:09] indra_gpt.chat_curate.chat_curate - LLM call took 1.05 seconds\n",
      "INFO: [2025-07-01 10:07:09] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:07:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:07:09] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:07:11] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.69 seconds\n",
      "\u001b[92m10:07:11 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:07:11] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:07:12] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:07:12 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:07:12] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:07:12 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:07:12] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:07:12 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:07:12] indra_gpt.chat_curate.chat_curate - LLM call took 0.51 seconds\n",
      "INFO: [2025-07-01 10:07:12] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:07:12 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:07:12] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:07:14] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.67 seconds\n",
      "\u001b[92m10:07:14 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:07:14] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:07:14] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:07:14 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:07:14] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:07:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:07:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:07:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:07:14] indra_gpt.chat_curate.chat_curate - LLM call took 0.55 seconds\n",
      "INFO: [2025-07-01 10:07:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:07:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:07:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:07:16] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.72 seconds\n",
      "\u001b[92m10:07:16 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:07:16] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:07:17] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:07:17 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:07:17] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:07:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:07:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:07:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:07:17] indra_gpt.chat_curate.chat_curate - LLM call took 0.45 seconds\n",
      "INFO: [2025-07-01 10:07:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:07:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:07:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:07:19] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.67 seconds\n",
      "\u001b[92m10:07:19 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:07:19] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:07:19] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:07:19 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:07:19] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:07:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:07:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:07:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:07:19] indra_gpt.chat_curate.chat_curate - LLM call took 0.60 seconds\n",
      "Curating statements with chat curation:  40%|‚ñà‚ñà‚ñà‚ñà      | 36/89 [07:32<09:33, 10.83s/it]INFO: [2025-07-01 10:07:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:07:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:07:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:07:21] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.70 seconds\n",
      "\u001b[92m10:07:21 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:07:21] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:07:22] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:07:22 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:07:22] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:07:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:07:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:07:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:07:22] indra_gpt.chat_curate.chat_curate - LLM call took 0.68 seconds\n",
      "INFO: [2025-07-01 10:07:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:07:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:07:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:07:24] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.72 seconds\n",
      "\u001b[92m10:07:24 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:07:24] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:07:25] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:07:25 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:07:25] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:07:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:07:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:07:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:07:25] indra_gpt.chat_curate.chat_curate - LLM call took 0.83 seconds\n",
      "INFO: [2025-07-01 10:07:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:07:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:07:25] indra_gpt.chat_curate.chat_curate - Skipping evidence with no text for statement -24407073837268975: Evidence(source_api='biogrid',\n",
      "         pmid='19766626',\n",
      "         source_id='723969',\n",
      "         annotations={\n",
      "                      \"biogrid_int_id\": \"723969\",\n",
      "                      \"entrez_a\": \"10771\",\n",
      "                      \"entrez_b\": \"8554\",\n",
      "                      \"biogrid_a\": \"115989\",\n",
      "                      \"biogrid_b\": \"114124\",\n",
      "                      \"syst_name_a\": \"RP11-486H9.1\",\n",
      "                      \"syst_name_b\": null,\n",
      "                      \"hgnc_a\": \"ZMYND11\",\n",
      "                      \"hgnc_b\": \"PIAS1\",\n",
      "                      \"syn_a\": \"BRAM1|BS69|MRD30\",\n",
      "                      \"syn_b\": \"DDXBP1|GBP|GU/RH-II|ZMIZ3\",\n",
      "                      \"exp_system\": \"Two-hybrid\",\n",
      "                      \"exp_system_type\": \"physical\",\n",
      "                      \"author\": \"Yu B (2009)\",\n",
      "                      \"pmid\": \"19766626\",\n",
      "                      \"organism_a\": \"9606\",\n",
      "                      \"organism_b\": \"9606\",\n",
      "                      \"throughput\": \"Low Throughput\",\n",
      "                      \"score\": null,\n",
      "                      \"modification\": null,\n",
      "                      \"phenotypes\": null,\n",
      "                      \"qualifications\": null,\n",
      "                      \"tags\": null,\n",
      "                      \"source_db\": \"BIOGRID\",\n",
      "                      \"agents\": {\n",
      "                       \"raw_text\": [\n",
      "                        \"RP11-486H9.1\",\n",
      "                        null\n",
      "                       ]\n",
      "                      },\n",
      "                      \"prior_uuids\": [\n",
      "                       \"8406b4fb-ccf3-40fb-ab1a-901675bc3d38\"\n",
      "                      ]\n",
      "                     },\n",
      "         text_refs={\n",
      "                    \"PMID\": \"19766626\"\n",
      "                   }\n",
      "         )\n",
      "\n",
      "\n",
      "INFO: [2025-07-01 10:07:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:07:27] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.71 seconds\n",
      "\u001b[92m10:07:27 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:07:27] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:07:27] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:07:27 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:07:27] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:07:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:07:27] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:07:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:07:27] indra_gpt.chat_curate.chat_curate - LLM call took 0.52 seconds\n",
      "INFO: [2025-07-01 10:07:27] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:07:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:07:27] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:07:29] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.68 seconds\n",
      "\u001b[92m10:07:29 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:07:29] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:07:30] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:07:30 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:07:30] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:07:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:07:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:07:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:07:30] indra_gpt.chat_curate.chat_curate - LLM call took 0.49 seconds\n",
      "Curating statements with chat curation:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 37/89 [07:43<09:18, 10.75s/it]INFO: [2025-07-01 10:07:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:07:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:07:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:07:32] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.68 seconds\n",
      "\u001b[92m10:07:32 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:07:32] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:07:33] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:07:33 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:07:33] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:07:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:07:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:07:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:07:33] indra_gpt.chat_curate.chat_curate - LLM call took 1.21 seconds\n",
      "INFO: [2025-07-01 10:07:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:07:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:07:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:07:35] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.69 seconds\n",
      "\u001b[92m10:07:35 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:07:35] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:07:35] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:07:35 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:07:35] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:07:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:07:35] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:07:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:07:35] indra_gpt.chat_curate.chat_curate - LLM call took 0.46 seconds\n",
      "INFO: [2025-07-01 10:07:35] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:07:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:07:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:07:38] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.69 seconds\n",
      "\u001b[92m10:07:38 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:07:38] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:07:38] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:07:38 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:07:38] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:07:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:07:38] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:07:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:07:38] indra_gpt.chat_curate.chat_curate - LLM call took 0.57 seconds\n",
      "INFO: [2025-07-01 10:07:38] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:07:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:07:38] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:07:40] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.72 seconds\n",
      "\u001b[92m10:07:40 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:07:40] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:07:41] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:07:41 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:07:41] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:07:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:07:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:07:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:07:41] indra_gpt.chat_curate.chat_curate - LLM call took 0.42 seconds\n",
      "INFO: [2025-07-01 10:07:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:07:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:07:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:07:43] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.72 seconds\n",
      "\u001b[92m10:07:43 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:07:43] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:07:43] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:07:43 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:07:43] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:07:43 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:07:43] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:07:43 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:07:43] indra_gpt.chat_curate.chat_curate - LLM call took 0.74 seconds\n",
      "Curating statements with chat curation:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 38/89 [07:56<09:49, 11.55s/it]INFO: [2025-07-01 10:07:43] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:07:43 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:07:43] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:07:45] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.67 seconds\n",
      "\u001b[92m10:07:45 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:07:45] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:07:46] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:07:46 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:07:46] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:07:46 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:07:46] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:07:46 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:07:46] indra_gpt.chat_curate.chat_curate - LLM call took 0.51 seconds\n",
      "INFO: [2025-07-01 10:07:46] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:07:46 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:07:46] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:07:48] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.75 seconds\n",
      "\u001b[92m10:07:48 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:07:48] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:07:49] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:07:49 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:07:49] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:07:49 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:07:49] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:07:49 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:07:49] indra_gpt.chat_curate.chat_curate - LLM call took 1.05 seconds\n",
      "INFO: [2025-07-01 10:07:49] indra_gpt.chat_curate.chat_curate - Skipping evidence with no text for statement 17433662571000991: Evidence(source_api='biopax',\n",
      "         source_id='http://www.phosphosite.org/phosphosite.owl#Catalysis_31859080_678',\n",
      "         annotations={\n",
      "                      \"source_sub_id\": \"phosphositeplus\",\n",
      "                      \"agents\": {\n",
      "                       \"raw_text\": [\n",
      "                        null,\n",
      "                        null\n",
      "                       ]\n",
      "                      },\n",
      "                      \"prior_uuids\": [\n",
      "                       \"6a341495-cc35-4060-b091-8525ff8a3cd2\"\n",
      "                      ]\n",
      "                     },\n",
      "         epistemics={\n",
      "                     \"direct\": true\n",
      "                    }\n",
      "         )\n",
      "\n",
      "\n",
      "INFO: [2025-07-01 10:07:49] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:07:49 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:07:49] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:07:51] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.66 seconds\n",
      "\u001b[92m10:07:51 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:07:51] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:07:51] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:07:51 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:07:51] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:07:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:07:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:07:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:07:51] indra_gpt.chat_curate.chat_curate - LLM call took 0.45 seconds\n",
      "INFO: [2025-07-01 10:07:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:07:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:07:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:07:53] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.73 seconds\n",
      "\u001b[92m10:07:53 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:07:53] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:07:54] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:07:54 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:07:54] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:07:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:07:54] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:07:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:07:54] indra_gpt.chat_curate.chat_curate - LLM call took 0.51 seconds\n",
      "Curating statements with chat curation:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 39/89 [08:07<09:23, 11.27s/it]INFO: [2025-07-01 10:07:54] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:07:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:07:54] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:07:56] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.68 seconds\n",
      "\u001b[92m10:07:56 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:07:56] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:07:56] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:07:56 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:07:56] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:07:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:07:56] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:07:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:07:56] indra_gpt.chat_curate.chat_curate - LLM call took 0.54 seconds\n",
      "INFO: [2025-07-01 10:07:56] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:07:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:07:56] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:07:58] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.68 seconds\n",
      "\u001b[92m10:07:58 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:07:58] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:07:59] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:07:59 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:07:59] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:07:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:07:59] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:07:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:07:59] indra_gpt.chat_curate.chat_curate - LLM call took 0.51 seconds\n",
      "INFO: [2025-07-01 10:07:59] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:07:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:07:59] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:08:01] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.69 seconds\n",
      "\u001b[92m10:08:01 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:08:01] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:08:02] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:08:02 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:08:02] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:08:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:08:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:08:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:08:02] indra_gpt.chat_curate.chat_curate - LLM call took 0.67 seconds\n",
      "INFO: [2025-07-01 10:08:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:08:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:08:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:08:04] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.68 seconds\n",
      "\u001b[92m10:08:04 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:08:04] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:08:04] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:08:04 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:08:04] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:08:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:08:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:08:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:08:04] indra_gpt.chat_curate.chat_curate - LLM call took 0.46 seconds\n",
      "INFO: [2025-07-01 10:08:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:08:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:08:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:08:06] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.69 seconds\n",
      "\u001b[92m10:08:06 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:08:06] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:08:07] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:08:07 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:08:07] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:08:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:08:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:08:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:08:07] indra_gpt.chat_curate.chat_curate - LLM call took 0.71 seconds\n",
      "Curating statements with chat curation:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 40/89 [08:20<09:36, 11.76s/it]INFO: [2025-07-01 10:08:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:08:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:08:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:08:09] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.72 seconds\n",
      "\u001b[92m10:08:09 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:08:09] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:08:09] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:08:09 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:08:09] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:08:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:08:09] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:08:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:08:09] indra_gpt.chat_curate.chat_curate - LLM call took 0.51 seconds\n",
      "INFO: [2025-07-01 10:08:09] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:08:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:08:09] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:08:11] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.72 seconds\n",
      "\u001b[92m10:08:11 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:08:11] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:08:12] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:08:12 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:08:12] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:08:12 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:08:12] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:08:12 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:08:12] indra_gpt.chat_curate.chat_curate - LLM call took 0.67 seconds\n",
      "INFO: [2025-07-01 10:08:12] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:08:12 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:08:12] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:08:14] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.66 seconds\n",
      "\u001b[92m10:08:14 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:08:14] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:08:14] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:08:15 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:08:15] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:08:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:08:15] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:08:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:08:15] indra_gpt.chat_curate.chat_curate - LLM call took 0.50 seconds\n",
      "INFO: [2025-07-01 10:08:15] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:08:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:08:15] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:08:17] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.69 seconds\n",
      "\u001b[92m10:08:17 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:08:17] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:08:17] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:08:17 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:08:17] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:08:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:08:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:08:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:08:17] indra_gpt.chat_curate.chat_curate - LLM call took 0.48 seconds\n",
      "INFO: [2025-07-01 10:08:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:08:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:08:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:08:19] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.74 seconds\n",
      "\u001b[92m10:08:19 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:08:19] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:08:20] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:08:20 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:08:20] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:08:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:08:20] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:08:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:08:20] indra_gpt.chat_curate.chat_curate - LLM call took 0.75 seconds\n",
      "Curating statements with chat curation:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 41/89 [08:33<09:42, 12.14s/it]INFO: [2025-07-01 10:08:20] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:08:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:08:20] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:08:21] indra_gpt.chat_curate.chat_curate - Prompt generation took 0.95 seconds\n",
      "\u001b[92m10:08:21 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:08:21] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:08:21] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:08:21 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:08:21] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:08:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:08:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:08:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:08:21] indra_gpt.chat_curate.chat_curate - LLM call took 0.39 seconds\n",
      "INFO: [2025-07-01 10:08:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:08:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:08:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:08:23] indra_gpt.chat_curate.chat_curate - Prompt generation took 0.91 seconds\n",
      "\u001b[92m10:08:23 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:08:23] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:08:23] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:08:23 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:08:23] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:08:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:08:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:08:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:08:23] indra_gpt.chat_curate.chat_curate - LLM call took 0.45 seconds\n",
      "INFO: [2025-07-01 10:08:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:08:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:08:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:08:24] indra_gpt.chat_curate.chat_curate - Prompt generation took 0.91 seconds\n",
      "\u001b[92m10:08:24 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:08:24] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:08:25] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:08:25 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:08:25] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:08:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:08:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:08:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:08:25] indra_gpt.chat_curate.chat_curate - LLM call took 0.52 seconds\n",
      "INFO: [2025-07-01 10:08:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:08:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:08:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:08:26] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.02 seconds\n",
      "\u001b[92m10:08:26 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:08:26] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:08:27] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:08:27 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:08:27] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:08:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:08:27] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:08:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:08:27] indra_gpt.chat_curate.chat_curate - LLM call took 0.42 seconds\n",
      "INFO: [2025-07-01 10:08:27] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:08:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:08:27] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:08:28] indra_gpt.chat_curate.chat_curate - Prompt generation took 0.91 seconds\n",
      "\u001b[92m10:08:28 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:08:28] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:08:28] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:08:28 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:08:28] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:08:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:08:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:08:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:08:28] indra_gpt.chat_curate.chat_curate - LLM call took 0.60 seconds\n",
      "Curating statements with chat curation:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 42/89 [08:42<08:41, 11.09s/it]INFO: [2025-07-01 10:08:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:08:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:08:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:08:30] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.68 seconds\n",
      "\u001b[92m10:08:30 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:08:30] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:08:31] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m10:08:31 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 10:08:31] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m10:08:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:08:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:08:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:08:31] indra_gpt.chat_curate.chat_curate - LLM call took 0.74 seconds\n",
      "INFO: [2025-07-01 10:08:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m10:08:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:08:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-07-01 10:08:33] indra_gpt.chat_curate.chat_curate - Prompt generation took 1.67 seconds\n",
      "\u001b[92m10:08:33 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:08:33] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-07-01 10:08:33] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO: [2025-07-01 10:08:33] openai._base_client - Retrying request to /chat/completions in 0.487842 seconds\n",
      "INFO: [2025-07-01 10:08:34] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO: [2025-07-01 10:08:34] openai._base_client - Retrying request to /chat/completions in 0.874821 seconds\n",
      "INFO: [2025-07-01 10:08:35] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n"
     ]
    },
    {
     "ename": "RateLimitError",
     "evalue": "litellm.RateLimitError: RateLimitError: OpenAIException - You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/indra_gpt/lib/python3.11/site-packages/litellm/llms/openai/openai.py:725\u001b[0m, in \u001b[0;36mOpenAIChatCompletion.completion\u001b[0;34m(self, model_response, timeout, optional_params, litellm_params, logging_obj, model, messages, print_verbose, api_key, api_base, api_version, dynamic_params, azure_ad_token, acompletion, logger_fn, headers, custom_prompt_dict, client, organization, custom_llm_provider, drop_params)\u001b[0m\n\u001b[1;32m    724\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 725\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    726\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m OpenAIError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/envs/indra_gpt/lib/python3.11/site-packages/litellm/llms/openai/openai.py:653\u001b[0m, in \u001b[0;36mOpenAIChatCompletion.completion\u001b[0;34m(self, model_response, timeout, optional_params, litellm_params, logging_obj, model, messages, print_verbose, api_key, api_base, api_version, dynamic_params, azure_ad_token, acompletion, logger_fn, headers, custom_prompt_dict, client, organization, custom_llm_provider, drop_params)\u001b[0m\n\u001b[1;32m    639\u001b[0m logging_obj\u001b[38;5;241m.\u001b[39mpre_call(\n\u001b[1;32m    640\u001b[0m     \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39mmessages,\n\u001b[1;32m    641\u001b[0m     api_key\u001b[38;5;241m=\u001b[39mopenai_client\u001b[38;5;241m.\u001b[39mapi_key,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    647\u001b[0m     },\n\u001b[1;32m    648\u001b[0m )\n\u001b[1;32m    650\u001b[0m (\n\u001b[1;32m    651\u001b[0m     headers,\n\u001b[1;32m    652\u001b[0m     response,\n\u001b[0;32m--> 653\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_sync_openai_chat_completion_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    654\u001b[0m \u001b[43m    \u001b[49m\u001b[43mopenai_client\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopenai_client\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    655\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    656\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    657\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogging_obj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogging_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    658\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    660\u001b[0m logging_obj\u001b[38;5;241m.\u001b[39mmodel_call_details[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m headers\n",
      "File \u001b[0;32m~/miniconda3/envs/indra_gpt/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py:149\u001b[0m, in \u001b[0;36mtrack_llm_api_timing.<locals>.decorator.<locals>.sync_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 149\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniconda3/envs/indra_gpt/lib/python3.11/site-packages/litellm/llms/openai/openai.py:471\u001b[0m, in \u001b[0;36mOpenAIChatCompletion.make_sync_openai_chat_completion_request\u001b[0;34m(self, openai_client, data, timeout, logging_obj)\u001b[0m\n\u001b[1;32m    470\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 471\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[0;32m~/miniconda3/envs/indra_gpt/lib/python3.11/site-packages/litellm/llms/openai/openai.py:453\u001b[0m, in \u001b[0;36mOpenAIChatCompletion.make_sync_openai_chat_completion_request\u001b[0;34m(self, openai_client, data, timeout, logging_obj)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 453\u001b[0m     raw_response \u001b[38;5;241m=\u001b[39m \u001b[43mopenai_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwith_raw_response\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    457\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(raw_response, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/miniconda3/envs/indra_gpt/lib/python3.11/site-packages/openai/_legacy_response.py:364\u001b[0m, in \u001b[0;36mto_raw_response_wrapper.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    362\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mextra_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m extra_headers\n\u001b[0;32m--> 364\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cast(LegacyAPIResponse[R], \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/indra_gpt/lib/python3.11/site-packages/openai/_utils/_utils.py:279\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 279\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/indra_gpt/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py:914\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    913\u001b[0m validate_response_format(response_format)\n\u001b[0;32m--> 914\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    915\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    916\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maudio\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    921\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    922\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    923\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    924\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    925\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_completion_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    928\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    929\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodalities\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    930\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    931\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    932\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprediction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    933\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    934\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreasoning_effort\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    935\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    936\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    937\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    938\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    939\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    940\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    941\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    942\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    947\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    948\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweb_search_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    949\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    950\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParamsStreaming\u001b[49m\n\u001b[1;32m    951\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[1;32m    952\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    953\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    954\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    955\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    956\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    957\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    959\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/indra_gpt/lib/python3.11/site-packages/openai/_base_client.py:1247\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1244\u001b[0m opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1245\u001b[0m     method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1246\u001b[0m )\n\u001b[0;32m-> 1247\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/indra_gpt/lib/python3.11/site-packages/openai/_base_client.py:920\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    918\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 920\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    921\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    922\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    923\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    924\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    925\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/indra_gpt/lib/python3.11/site-packages/openai/_base_client.py:1013\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m-> 1013\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1014\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1015\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1017\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1018\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1019\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1020\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1022\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[1;32m   1023\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/indra_gpt/lib/python3.11/site-packages/openai/_base_client.py:1062\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[0;34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1060\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[0;32m-> 1062\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1063\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1064\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1065\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1066\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1067\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1068\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/indra_gpt/lib/python3.11/site-packages/openai/_base_client.py:1013\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m-> 1013\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1014\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1015\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1017\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1018\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1019\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1020\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1022\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[1;32m   1023\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/indra_gpt/lib/python3.11/site-packages/openai/_base_client.py:1062\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[0;34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1060\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[0;32m-> 1062\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1063\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1064\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1065\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1066\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1067\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1068\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/indra_gpt/lib/python3.11/site-packages/openai/_base_client.py:1028\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1027\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1028\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1030\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[1;32m   1031\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m   1032\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1036\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[1;32m   1037\u001b[0m )\n",
      "\u001b[0;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOpenAIError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/indra_gpt/lib/python3.11/site-packages/litellm/main.py:1854\u001b[0m, in \u001b[0;36mcompletion\u001b[0;34m(model, messages, timeout, temperature, top_p, n, stream, stream_options, stop, max_completion_tokens, max_tokens, modalities, prediction, audio, presence_penalty, frequency_penalty, logit_bias, user, reasoning_effort, response_format, seed, tools, tool_choice, logprobs, top_logprobs, parallel_tool_calls, web_search_options, deployment_id, extra_headers, functions, function_call, base_url, api_version, api_key, model_list, thinking, **kwargs)\u001b[0m\n\u001b[1;32m   1848\u001b[0m     logging\u001b[38;5;241m.\u001b[39mpost_call(\n\u001b[1;32m   1849\u001b[0m         \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39mmessages,\n\u001b[1;32m   1850\u001b[0m         api_key\u001b[38;5;241m=\u001b[39mapi_key,\n\u001b[1;32m   1851\u001b[0m         original_response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m   1852\u001b[0m         additional_args\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m\"\u001b[39m: headers},\n\u001b[1;32m   1853\u001b[0m     )\n\u001b[0;32m-> 1854\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m   1856\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m optional_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m   1857\u001b[0m     \u001b[38;5;66;03m## LOGGING\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/indra_gpt/lib/python3.11/site-packages/litellm/main.py:1827\u001b[0m, in \u001b[0;36mcompletion\u001b[0;34m(model, messages, timeout, temperature, top_p, n, stream, stream_options, stop, max_completion_tokens, max_tokens, modalities, prediction, audio, presence_penalty, frequency_penalty, logit_bias, user, reasoning_effort, response_format, seed, tools, tool_choice, logprobs, top_logprobs, parallel_tool_calls, web_search_options, deployment_id, extra_headers, functions, function_call, base_url, api_version, api_key, model_list, thinking, **kwargs)\u001b[0m\n\u001b[1;32m   1826\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1827\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mopenai_chat_completions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletion\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1828\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1829\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1830\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1831\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_response\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_response\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1832\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprint_verbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprint_verbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1833\u001b[0m \u001b[43m        \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapi_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1834\u001b[0m \u001b[43m        \u001b[49m\u001b[43mapi_base\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapi_base\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1835\u001b[0m \u001b[43m        \u001b[49m\u001b[43macompletion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43macompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1836\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogging_obj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogging\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1837\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptional_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptional_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1838\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlitellm_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlitellm_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1839\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogger_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogger_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1840\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[1;32m   1841\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcustom_prompt_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_prompt_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1842\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pass AsyncOpenAI, OpenAI client\u001b[39;49;00m\n\u001b[1;32m   1843\u001b[0m \u001b[43m        \u001b[49m\u001b[43morganization\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morganization\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1844\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcustom_llm_provider\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_llm_provider\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1845\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1847\u001b[0m     \u001b[38;5;66;03m## LOGGING - log the original exception returned\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/indra_gpt/lib/python3.11/site-packages/litellm/llms/openai/openai.py:736\u001b[0m, in \u001b[0;36mOpenAIChatCompletion.completion\u001b[0;34m(self, model_response, timeout, optional_params, litellm_params, logging_obj, model, messages, print_verbose, api_key, api_base, api_version, dynamic_params, azure_ad_token, acompletion, logger_fn, headers, custom_prompt_dict, client, organization, custom_llm_provider, drop_params)\u001b[0m\n\u001b[1;32m    735\u001b[0m     error_headers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(error_response, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 736\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m OpenAIError(\n\u001b[1;32m    737\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mstatus_code,\n\u001b[1;32m    738\u001b[0m     message\u001b[38;5;241m=\u001b[39merror_text,\n\u001b[1;32m    739\u001b[0m     headers\u001b[38;5;241m=\u001b[39merror_headers,\n\u001b[1;32m    740\u001b[0m     body\u001b[38;5;241m=\u001b[39merror_body,\n\u001b[1;32m    741\u001b[0m )\n",
      "\u001b[0;31mOpenAIError\u001b[0m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m models \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgpt-4o-mini\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgpt-4o\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m models:\n\u001b[0;32m----> 7\u001b[0m     llm_curations_binary \u001b[38;5;241m=\u001b[39m \u001b[43mchat_curate_stmts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatements\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mn_evidence_to_curate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mdecision_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mbinary_classification\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m                                    \u001b[49m\u001b[38;5;66;43;03m#ignore_tags=['incorrect'],\u001b[39;49;00m\n\u001b[1;32m     12\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mn_fewshot_examples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mget_ex_per_tag\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mschema_output_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m     llm_curations_multiclass \u001b[38;5;241m=\u001b[39m chat_curate_stmts(statements,\n\u001b[1;32m     17\u001b[0m                                     n_evidence_to_curate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,\n\u001b[1;32m     18\u001b[0m                                     decision_threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     23\u001b[0m                                     schema_output_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     24\u001b[0m                                     model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m RESULTS_DIR\u001b[38;5;241m.\u001b[39mjoinpath(model)\u001b[38;5;241m.\u001b[39mexists():\n",
      "File \u001b[0;32m~/gyorilab/indra_gpt/indra_gpt/chat_curate/chat_curate.py:982\u001b[0m, in \u001b[0;36mchat_curate_stmts\u001b[0;34m(indra_stmts, n_evidence_to_curate, decision_threshold, binary_classification, ignore_tags, n_fewshot_examples, get_ex_per_tag, pos_examples_path, neg_examples_path, schema_output_mode, model)\u001b[0m\n\u001b[1;32m    977\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    978\u001b[0m     neg_ex_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 982\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m[\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchat_curate_stmt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstmt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    984\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mn_evidence_to_curate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_evidence_to_curate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    985\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mdecision_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecision_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    986\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mbinary_classification\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbinary_classification\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    987\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mignore_tags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_tags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    988\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mpos_ex_str\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_ex_str\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    989\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mneg_ex_str\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mneg_ex_str\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    990\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mschema_output_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema_output_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    991\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mllm_client\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    992\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m               \u001b[49m\n\u001b[1;32m    993\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstmt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindra_stmts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCurating statements with chat curation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    994\u001b[0m \u001b[43m\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/gyorilab/indra_gpt/indra_gpt/chat_curate/chat_curate.py:983\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    977\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    978\u001b[0m     neg_ex_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    982\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m--> 983\u001b[0m     \u001b[43mchat_curate_stmt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstmt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    984\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mn_evidence_to_curate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_evidence_to_curate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    985\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mdecision_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecision_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    986\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mbinary_classification\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbinary_classification\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    987\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mignore_tags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_tags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    988\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mpos_ex_str\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_ex_str\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    989\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mneg_ex_str\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mneg_ex_str\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    990\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mschema_output_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema_output_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    991\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mllm_client\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    992\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m               \n\u001b[1;32m    993\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m stmt \u001b[38;5;129;01min\u001b[39;00m tqdm(indra_stmts, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCurating statements with chat curation\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    994\u001b[0m ]\n",
      "File \u001b[0;32m~/gyorilab/indra_gpt/indra_gpt/chat_curate/chat_curate.py:877\u001b[0m, in \u001b[0;36mchat_curate_stmt\u001b[0;34m(stmt, n_evidence_to_curate, decision_threshold, binary_classification, ignore_tags, pos_ex_str, neg_ex_str, schema_output_mode, client)\u001b[0m\n\u001b[1;32m    874\u001b[0m schema_wrapped_prompt \u001b[38;5;241m=\u001b[39m get_schema_wrapped_prompt(prompt, CURATION_TAGS_JSON_SCHEMA)\n\u001b[1;32m    876\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 877\u001b[0m raw_response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[43mschema_wrapped_prompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    878\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    879\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLLM call took \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mend_time\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mstart_time\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/gyorilab/indra_gpt/indra_gpt/clients/llm_client.py:45\u001b[0m, in \u001b[0;36mLitellmClient.call\u001b[0;34m(self, prompt, history, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m max_tokens \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_tokens)\n\u001b[1;32m     43\u001b[0m temperature \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtemperature)\n\u001b[0;32m---> 45\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mlitellm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletion\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_llm_provider\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcustom_llm_provider\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m    \u001b[49m\u001b[43mapi_base\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapi_base\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m    \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapi_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# now safe\u001b[39;49;00m\n\u001b[1;32m     54\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/indra_gpt/lib/python3.11/site-packages/litellm/utils.py:1283\u001b[0m, in \u001b[0;36mclient.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1279\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m logging_obj:\n\u001b[1;32m   1280\u001b[0m     logging_obj\u001b[38;5;241m.\u001b[39mfailure_handler(\n\u001b[1;32m   1281\u001b[0m         e, traceback_exception, start_time, end_time\n\u001b[1;32m   1282\u001b[0m     )  \u001b[38;5;66;03m# DO NOT MAKE THREADED - router retry fallback relies on this!\u001b[39;00m\n\u001b[0;32m-> 1283\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[0;32m~/miniconda3/envs/indra_gpt/lib/python3.11/site-packages/litellm/utils.py:1161\u001b[0m, in \u001b[0;36mclient.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1159\u001b[0m         print_verbose(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError while checking max token limit: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1160\u001b[0m \u001b[38;5;66;03m# MODEL CALL\u001b[39;00m\n\u001b[0;32m-> 1161\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43moriginal_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1162\u001b[0m end_time \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow()\n\u001b[1;32m   1163\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/indra_gpt/lib/python3.11/site-packages/litellm/main.py:3241\u001b[0m, in \u001b[0;36mcompletion\u001b[0;34m(model, messages, timeout, temperature, top_p, n, stream, stream_options, stop, max_completion_tokens, max_tokens, modalities, prediction, audio, presence_penalty, frequency_penalty, logit_bias, user, reasoning_effort, response_format, seed, tools, tool_choice, logprobs, top_logprobs, parallel_tool_calls, web_search_options, deployment_id, extra_headers, functions, function_call, base_url, api_version, api_key, model_list, thinking, **kwargs)\u001b[0m\n\u001b[1;32m   3238\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n\u001b[1;32m   3239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   3240\u001b[0m     \u001b[38;5;66;03m## Map to OpenAI Exception\u001b[39;00m\n\u001b[0;32m-> 3241\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mexception_type\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3243\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcustom_llm_provider\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_llm_provider\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3244\u001b[0m \u001b[43m        \u001b[49m\u001b[43moriginal_exception\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3245\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompletion_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3246\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3247\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/indra_gpt/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py:2239\u001b[0m, in \u001b[0;36mexception_type\u001b[0;34m(model, original_exception, custom_llm_provider, completion_kwargs, extra_kwargs)\u001b[0m\n\u001b[1;32m   2237\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exception_mapping_worked:\n\u001b[1;32m   2238\u001b[0m     \u001b[38;5;28msetattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlitellm_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, litellm_response_headers)\n\u001b[0;32m-> 2239\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m   2240\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2241\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m error_type \u001b[38;5;129;01min\u001b[39;00m litellm\u001b[38;5;241m.\u001b[39mLITELLM_EXCEPTION_TYPES:\n",
      "File \u001b[0;32m~/miniconda3/envs/indra_gpt/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py:279\u001b[0m, in \u001b[0;36mexception_type\u001b[0;34m(model, original_exception, custom_llm_provider, completion_kwargs, extra_kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m429\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m error_str:\n\u001b[1;32m    278\u001b[0m     exception_mapping_worked \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 279\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RateLimitError(\n\u001b[1;32m    280\u001b[0m         message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRateLimitError: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexception_provider\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmessage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    281\u001b[0m         model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m    282\u001b[0m         llm_provider\u001b[38;5;241m=\u001b[39mcustom_llm_provider,\n\u001b[1;32m    283\u001b[0m         response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mgetattr\u001b[39m(original_exception, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m    284\u001b[0m     )\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis model\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms maximum context length is\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m error_str\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstring too long. Expected a string with maximum length\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    288\u001b[0m     \u001b[38;5;129;01min\u001b[39;00m error_str\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms maximum context limit\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m error_str\n\u001b[1;32m    290\u001b[0m ):\n\u001b[1;32m    291\u001b[0m     exception_mapping_worked \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mRateLimitError\u001b[0m: litellm.RateLimitError: RateLimitError: OpenAIException - You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors."
     ]
    }
   ],
   "source": [
    "statements = pickle.load(\n",
    "    open(RESULTS_DIR.joinpath(\"statements.pkl\"), \"rb\")\n",
    ")\n",
    "statements = statements\n",
    "models = ['gpt-4o-mini']\n",
    "for model in models:\n",
    "    llm_curations_binary = chat_curate_stmts(statements, \n",
    "                                    n_evidence_to_curate=5,\n",
    "                                    decision_threshold=0.5,\n",
    "                                    binary_classification=True,\n",
    "                                    #ignore_tags=['incorrect'],\n",
    "                                    n_fewshot_examples=2,\n",
    "                                    get_ex_per_tag=True,\n",
    "                                    schema_output_mode=True,\n",
    "                                    model=model)\n",
    "    llm_curations_multiclass = chat_curate_stmts(statements,\n",
    "                                    n_evidence_to_curate=5,\n",
    "                                    decision_threshold=0.5,\n",
    "                                    binary_classification=False,\n",
    "                                    ignore_tags=['incorrect'],\n",
    "                                    n_fewshot_examples=2,\n",
    "                                    get_ex_per_tag=True,\n",
    "                                    schema_output_mode=True,\n",
    "                                    model=model)\n",
    "\n",
    "    if not RESULTS_DIR.joinpath(model).exists():\n",
    "        RESULTS_DIR.joinpath(model).mkdir(parents=True)\n",
    "        \n",
    "    with open(RESULTS_DIR / model / \"chat_curation_binary_classification.json\", \"w\") as f:\n",
    "        json.dump(llm_curations_binary, f, indent=2)\n",
    "    with open(RESULTS_DIR / model / \"chat_curation_multiclass_classification.json\", \"w\") as f:\n",
    "        json.dump(llm_curations_multiclass, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23533fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing LLM curations:   0%|          | 0/93 [00:00<?, ?it/s]INFO: [2025-06-30 21:48:57] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:57] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:57] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:57] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:57] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:57] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:57] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:57] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:57] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:57] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:57] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:57] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:57] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:57] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:57] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:57] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:57] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:57] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:57] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:57] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:57] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:57] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:57] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:57] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:57] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:57] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:57] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:57] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:57] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:57] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:57] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:57] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:57] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:57] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:57] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:57] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:57] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:57] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:57] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:57] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:57] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:57] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:57] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:57] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:57] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:57] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:57] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:57] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:57] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:57] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:57] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:57] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:57] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:57] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:57] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:57] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:57] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:57] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:57] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:57] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:57] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:57] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:57] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:57] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:57] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:57] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:57] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "Processing LLM curations:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 49/93 [00:00<00:00, 482.74it/s]INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:48:58] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "Processing LLM curations: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 93/93 [00:00<00:00, 468.36it/s]\n",
      "Processing LLM curations:   0%|          | 0/93 [00:00<?, ?it/s]INFO: [2025-06-30 21:48:58] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-27178959702299212\n",
      "INFO: [2025-06-30 21:48:58] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:48:58] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:   1%|          | 1/93 [00:00<00:53,  1.70it/s]INFO: [2025-06-30 21:48:58] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-19509266375111713\n",
      "INFO: [2025-06-30 21:48:58] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:48:58] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:   2%|‚ñè         | 2/93 [00:00<00:35,  2.54it/s]INFO: [2025-06-30 21:48:59] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/31183949835825955\n",
      "INFO: [2025-06-30 21:48:59] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:48:59] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:   3%|‚ñé         | 3/93 [00:01<00:37,  2.41it/s]INFO: [2025-06-30 21:48:59] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-920869035786162\n",
      "INFO: [2025-06-30 21:48:59] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:48:59] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:   4%|‚ñç         | 4/93 [00:01<00:31,  2.81it/s]INFO: [2025-06-30 21:48:59] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/24957834887591847\n",
      "INFO: [2025-06-30 21:48:59] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:48:59] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:   5%|‚ñå         | 5/93 [00:01<00:27,  3.17it/s]INFO: [2025-06-30 21:48:59] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-33418178478117880\n",
      "INFO: [2025-06-30 21:48:59] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:48:59] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:   6%|‚ñã         | 6/93 [00:02<00:30,  2.85it/s]INFO: [2025-06-30 21:49:00] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/35857458895716258\n",
      "INFO: [2025-06-30 21:49:00] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:00] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:   8%|‚ñä         | 7/93 [00:02<00:27,  3.14it/s]INFO: [2025-06-30 21:49:00] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-26431974494844569\n",
      "INFO: [2025-06-30 21:49:00] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:00] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:   9%|‚ñä         | 8/93 [00:02<00:28,  3.02it/s]INFO: [2025-06-30 21:49:01] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/32773248379568006\n",
      "INFO: [2025-06-30 21:49:01] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:01] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  10%|‚ñâ         | 9/93 [00:03<00:25,  3.29it/s]INFO: [2025-06-30 21:49:01] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-13164323043334385\n",
      "INFO: [2025-06-30 21:49:01] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:01] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  11%|‚ñà         | 10/93 [00:03<00:23,  3.50it/s]INFO: [2025-06-30 21:49:01] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/32159499136500804\n",
      "INFO: [2025-06-30 21:49:01] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:01] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  12%|‚ñà‚ñè        | 11/93 [00:03<00:22,  3.65it/s]INFO: [2025-06-30 21:49:01] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/26774703427840154\n",
      "INFO: [2025-06-30 21:49:01] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:01] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  13%|‚ñà‚ñé        | 12/93 [00:03<00:21,  3.74it/s]INFO: [2025-06-30 21:49:01] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-14556452501867428\n",
      "INFO: [2025-06-30 21:49:01] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:01] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  14%|‚ñà‚ñç        | 13/93 [00:04<00:23,  3.35it/s]INFO: [2025-06-30 21:49:02] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/18943901803073221\n",
      "INFO: [2025-06-30 21:49:02] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:02] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  15%|‚ñà‚ñå        | 14/93 [00:04<00:22,  3.54it/s]INFO: [2025-06-30 21:49:02] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/13785179510421349\n",
      "INFO: [2025-06-30 21:49:02] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:02] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  16%|‚ñà‚ñå        | 15/93 [00:04<00:21,  3.70it/s]INFO: [2025-06-30 21:49:02] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-19037816720378235\n",
      "INFO: [2025-06-30 21:49:02] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:02] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  17%|‚ñà‚ñã        | 16/93 [00:04<00:20,  3.74it/s]INFO: [2025-06-30 21:49:03] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-24566439914598834\n",
      "INFO: [2025-06-30 21:49:03] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:03] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  18%|‚ñà‚ñä        | 17/93 [00:05<00:20,  3.78it/s]INFO: [2025-06-30 21:49:03] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-1936440077119914\n",
      "INFO: [2025-06-30 21:49:03] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:03] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  19%|‚ñà‚ñâ        | 18/93 [00:05<00:25,  2.97it/s]INFO: [2025-06-30 21:49:03] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/11566565080383602\n",
      "INFO: [2025-06-30 21:49:03] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:03] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  20%|‚ñà‚ñà        | 19/93 [00:05<00:23,  3.19it/s]INFO: [2025-06-30 21:49:04] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/11586602714543979\n",
      "INFO: [2025-06-30 21:49:04] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:04] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  22%|‚ñà‚ñà‚ñè       | 20/93 [00:06<00:21,  3.38it/s]INFO: [2025-06-30 21:49:04] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/21648553749456228\n",
      "INFO: [2025-06-30 21:49:04] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:04] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  23%|‚ñà‚ñà‚ñé       | 21/93 [00:06<00:20,  3.54it/s]INFO: [2025-06-30 21:49:04] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/4724524981516770\n",
      "INFO: [2025-06-30 21:49:04] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:04] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  24%|‚ñà‚ñà‚ñé       | 22/93 [00:06<00:19,  3.71it/s]INFO: [2025-06-30 21:49:04] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-20949930044320929\n",
      "INFO: [2025-06-30 21:49:04] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:04] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  25%|‚ñà‚ñà‚ñç       | 23/93 [00:07<00:22,  3.17it/s]INFO: [2025-06-30 21:49:05] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/10656611432677873\n",
      "INFO: [2025-06-30 21:49:05] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:05] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  26%|‚ñà‚ñà‚ñå       | 24/93 [00:07<00:20,  3.37it/s]INFO: [2025-06-30 21:49:05] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/26447517437851099\n",
      "INFO: [2025-06-30 21:49:05] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:05] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  27%|‚ñà‚ñà‚ñã       | 25/93 [00:07<00:19,  3.56it/s]INFO: [2025-06-30 21:49:05] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/14303941633313044\n",
      "INFO: [2025-06-30 21:49:05] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:05] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  28%|‚ñà‚ñà‚ñä       | 26/93 [00:07<00:18,  3.70it/s]INFO: [2025-06-30 21:49:06] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/21028179654389070\n",
      "INFO: [2025-06-30 21:49:06] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:06] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  29%|‚ñà‚ñà‚ñâ       | 27/93 [00:08<00:17,  3.80it/s]INFO: [2025-06-30 21:49:06] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/34743744846379781\n",
      "INFO: [2025-06-30 21:49:06] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:06] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  30%|‚ñà‚ñà‚ñà       | 28/93 [00:08<00:20,  3.14it/s]INFO: [2025-06-30 21:49:06] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/8624259220739988\n",
      "INFO: [2025-06-30 21:49:06] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:06] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  31%|‚ñà‚ñà‚ñà       | 29/93 [00:08<00:18,  3.37it/s]INFO: [2025-06-30 21:49:06] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/32377238858127591\n",
      "INFO: [2025-06-30 21:49:06] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:06] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  32%|‚ñà‚ñà‚ñà‚ñè      | 30/93 [00:09<00:17,  3.58it/s]INFO: [2025-06-30 21:49:07] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-34994047816870295\n",
      "INFO: [2025-06-30 21:49:07] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:07] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  33%|‚ñà‚ñà‚ñà‚ñé      | 31/93 [00:09<00:16,  3.73it/s]INFO: [2025-06-30 21:49:07] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-12271565811912238\n",
      "INFO: [2025-06-30 21:49:07] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:07] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  34%|‚ñà‚ñà‚ñà‚ñç      | 32/93 [00:09<00:15,  3.85it/s]INFO: [2025-06-30 21:49:07] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-26871800485543379\n",
      "INFO: [2025-06-30 21:49:07] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:07] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  35%|‚ñà‚ñà‚ñà‚ñå      | 33/93 [00:09<00:19,  3.11it/s]INFO: [2025-06-30 21:49:08] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/3318841584498159\n",
      "INFO: [2025-06-30 21:49:08] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:08] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  37%|‚ñà‚ñà‚ñà‚ñã      | 34/93 [00:10<00:17,  3.36it/s]INFO: [2025-06-30 21:49:08] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/31623977566147927\n",
      "INFO: [2025-06-30 21:49:08] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:08] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  38%|‚ñà‚ñà‚ñà‚ñä      | 35/93 [00:10<00:16,  3.54it/s]INFO: [2025-06-30 21:49:08] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/32706502424195028\n",
      "INFO: [2025-06-30 21:49:08] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:08] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  39%|‚ñà‚ñà‚ñà‚ñä      | 36/93 [00:10<00:15,  3.70it/s]INFO: [2025-06-30 21:49:08] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-11644103489591043\n",
      "INFO: [2025-06-30 21:49:08] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:08] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  40%|‚ñà‚ñà‚ñà‚ñâ      | 37/93 [00:10<00:14,  3.78it/s]INFO: [2025-06-30 21:49:09] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-27389475588438153\n",
      "INFO: [2025-06-30 21:49:09] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:09] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  41%|‚ñà‚ñà‚ñà‚ñà      | 38/93 [00:11<00:14,  3.69it/s]INFO: [2025-06-30 21:49:09] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/21472557419519824\n",
      "INFO: [2025-06-30 21:49:09] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:09] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 39/93 [00:11<00:17,  3.02it/s]INFO: [2025-06-30 21:49:09] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-19649511627914971\n",
      "INFO: [2025-06-30 21:49:09] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:09] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 40/93 [00:11<00:16,  3.27it/s]INFO: [2025-06-30 21:49:10] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/12577334723163994\n",
      "INFO: [2025-06-30 21:49:10] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:10] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 41/93 [00:12<00:15,  3.42it/s]INFO: [2025-06-30 21:49:10] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-6895415621598192\n",
      "INFO: [2025-06-30 21:49:10] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:10] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 42/93 [00:12<00:14,  3.59it/s]INFO: [2025-06-30 21:49:10] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-485932016041862\n",
      "INFO: [2025-06-30 21:49:10] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:10] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 43/93 [00:12<00:13,  3.66it/s]INFO: [2025-06-30 21:49:10] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/17938020806565298\n",
      "INFO: [2025-06-30 21:49:10] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:10] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 44/93 [00:13<00:15,  3.15it/s]INFO: [2025-06-30 21:49:11] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/33824349687802512\n",
      "INFO: [2025-06-30 21:49:11] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:11] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 45/93 [00:13<00:14,  3.35it/s]INFO: [2025-06-30 21:49:11] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-33947966598417533\n",
      "INFO: [2025-06-30 21:49:11] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:11] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 46/93 [00:13<00:13,  3.54it/s]INFO: [2025-06-30 21:49:11] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-29655436866179624\n",
      "INFO: [2025-06-30 21:49:11] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:11] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 47/93 [00:13<00:12,  3.73it/s]INFO: [2025-06-30 21:49:12] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-17175494830033935\n",
      "INFO: [2025-06-30 21:49:12] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:12] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 48/93 [00:14<00:11,  3.86it/s]INFO: [2025-06-30 21:49:12] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-13199747933845394\n",
      "INFO: [2025-06-30 21:49:12] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:12] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 49/93 [00:14<00:13,  3.37it/s]INFO: [2025-06-30 21:49:12] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-3369492957696618\n",
      "INFO: [2025-06-30 21:49:12] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:12] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 50/93 [00:14<00:12,  3.56it/s]INFO: [2025-06-30 21:49:12] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-2236737361566990\n",
      "INFO: [2025-06-30 21:49:12] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:12] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 51/93 [00:15<00:11,  3.68it/s]INFO: [2025-06-30 21:49:13] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/8984465254997982\n",
      "INFO: [2025-06-30 21:49:13] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:13] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 52/93 [00:15<00:10,  3.76it/s]INFO: [2025-06-30 21:49:13] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/34378681930619692\n",
      "INFO: [2025-06-30 21:49:13] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:13] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 53/93 [00:15<00:10,  3.88it/s]INFO: [2025-06-30 21:49:13] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-6218818935340723\n",
      "INFO: [2025-06-30 21:49:13] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:13] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 54/93 [00:15<00:12,  3.24it/s]INFO: [2025-06-30 21:49:14] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/15710041033319852\n",
      "INFO: [2025-06-30 21:49:14] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:14] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 55/93 [00:16<00:11,  3.45it/s]INFO: [2025-06-30 21:49:14] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/24936382034801481\n",
      "INFO: [2025-06-30 21:49:14] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:14] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 56/93 [00:16<00:10,  3.62it/s]INFO: [2025-06-30 21:49:14] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/26164874326231702\n",
      "INFO: [2025-06-30 21:49:14] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:14] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 57/93 [00:16<00:09,  3.74it/s]INFO: [2025-06-30 21:49:14] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-31655492632823057\n",
      "INFO: [2025-06-30 21:49:14] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:14] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 58/93 [00:16<00:09,  3.85it/s]INFO: [2025-06-30 21:49:15] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-23683650049842135\n",
      "INFO: [2025-06-30 21:49:15] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:15] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 59/93 [00:17<00:10,  3.36it/s]INFO: [2025-06-30 21:49:15] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-9969581778460163\n",
      "INFO: [2025-06-30 21:49:15] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:15] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 60/93 [00:17<00:09,  3.54it/s]INFO: [2025-06-30 21:49:15] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-8638049287075364\n",
      "INFO: [2025-06-30 21:49:15] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:15] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 61/93 [00:17<00:08,  3.67it/s]INFO: [2025-06-30 21:49:15] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/6608566428303438\n",
      "INFO: [2025-06-30 21:49:15] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:15] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 62/93 [00:18<00:08,  3.77it/s]INFO: [2025-06-30 21:49:16] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/16805525748654600\n",
      "INFO: [2025-06-30 21:49:16] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:16] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 63/93 [00:18<00:07,  3.82it/s]INFO: [2025-06-30 21:49:16] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/32661404256967902\n",
      "INFO: [2025-06-30 21:49:16] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:16] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 64/93 [00:18<00:07,  3.90it/s]INFO: [2025-06-30 21:49:16] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-32244093775178354\n",
      "INFO: [2025-06-30 21:49:16] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:16] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 65/93 [00:18<00:07,  3.94it/s]INFO: [2025-06-30 21:49:16] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-10021087834226700\n",
      "INFO: [2025-06-30 21:49:16] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:16] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 66/93 [00:19<00:08,  3.30it/s]INFO: [2025-06-30 21:49:17] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-2133246301027277\n",
      "INFO: [2025-06-30 21:49:17] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:17] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 67/93 [00:19<00:07,  3.52it/s]INFO: [2025-06-30 21:49:17] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-2069452773758641\n",
      "INFO: [2025-06-30 21:49:17] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:17] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 68/93 [00:19<00:06,  3.64it/s]INFO: [2025-06-30 21:49:17] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/1164537692928586\n",
      "INFO: [2025-06-30 21:49:17] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:17] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 69/93 [00:19<00:06,  3.82it/s]INFO: [2025-06-30 21:49:18] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/2263006480531827\n",
      "INFO: [2025-06-30 21:49:18] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:18] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 70/93 [00:20<00:06,  3.72it/s]INFO: [2025-06-30 21:49:18] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/7569162649893756\n",
      "INFO: [2025-06-30 21:49:18] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:18] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 71/93 [00:20<00:06,  3.29it/s]INFO: [2025-06-30 21:49:18] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/10718272922581743\n",
      "INFO: [2025-06-30 21:49:18] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:18] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 72/93 [00:20<00:05,  3.51it/s]INFO: [2025-06-30 21:49:19] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/19593248734621443\n",
      "INFO: [2025-06-30 21:49:19] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:19] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 73/93 [00:21<00:05,  3.63it/s]INFO: [2025-06-30 21:49:19] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/28630162558138671\n",
      "INFO: [2025-06-30 21:49:19] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:19] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 74/93 [00:21<00:05,  3.80it/s]INFO: [2025-06-30 21:49:19] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-29619449833500674\n",
      "INFO: [2025-06-30 21:49:19] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:19] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 75/93 [00:21<00:04,  3.85it/s]INFO: [2025-06-30 21:49:19] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-24329292593271143\n",
      "INFO: [2025-06-30 21:49:19] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:19] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 76/93 [00:22<00:05,  3.03it/s]INFO: [2025-06-30 21:49:20] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-16927679215920559\n",
      "INFO: [2025-06-30 21:49:20] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:20] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 77/93 [00:22<00:04,  3.24it/s]INFO: [2025-06-30 21:49:20] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-14487224197960867\n",
      "INFO: [2025-06-30 21:49:20] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:20] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 78/93 [00:22<00:04,  3.44it/s]INFO: [2025-06-30 21:49:20] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-13395121870981465\n",
      "INFO: [2025-06-30 21:49:20] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:20] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 79/93 [00:22<00:03,  3.57it/s]INFO: [2025-06-30 21:49:21] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-12292476614970820\n",
      "INFO: [2025-06-30 21:49:21] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:21] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 80/93 [00:23<00:03,  3.68it/s]INFO: [2025-06-30 21:49:21] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-6454779301185040\n",
      "INFO: [2025-06-30 21:49:21] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:21] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 81/93 [00:23<00:03,  3.80it/s]INFO: [2025-06-30 21:49:21] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-5382220701144721\n",
      "INFO: [2025-06-30 21:49:21] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:21] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 82/93 [00:23<00:02,  3.89it/s]INFO: [2025-06-30 21:49:21] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-1675123172097724\n",
      "INFO: [2025-06-30 21:49:21] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:21] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 83/93 [00:24<00:03,  3.19it/s]INFO: [2025-06-30 21:49:22] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-1409606189539046\n",
      "INFO: [2025-06-30 21:49:22] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:22] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 84/93 [00:24<00:03,  2.48it/s]INFO: [2025-06-30 21:49:22] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/1809577373025591\n",
      "INFO: [2025-06-30 21:49:22] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:22] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 85/93 [00:24<00:02,  2.80it/s]INFO: [2025-06-30 21:49:23] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/5640957775123881\n",
      "INFO: [2025-06-30 21:49:23] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:23] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 86/93 [00:25<00:02,  3.09it/s]INFO: [2025-06-30 21:49:23] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/14209416812158648\n",
      "INFO: [2025-06-30 21:49:23] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:23] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 87/93 [00:25<00:01,  3.37it/s]INFO: [2025-06-30 21:49:23] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/20857841531996883\n",
      "INFO: [2025-06-30 21:49:23] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:23] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 88/93 [00:25<00:01,  3.51it/s]INFO: [2025-06-30 21:49:23] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/21066814703750909\n",
      "INFO: [2025-06-30 21:49:23] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:23] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 89/93 [00:26<00:01,  2.99it/s]INFO: [2025-06-30 21:49:24] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/26850960593724298\n",
      "INFO: [2025-06-30 21:49:24] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:24] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 90/93 [00:26<00:00,  3.20it/s]INFO: [2025-06-30 21:49:24] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/28430530457626809\n",
      "INFO: [2025-06-30 21:49:24] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:24] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 91/93 [00:26<00:00,  3.45it/s]INFO: [2025-06-30 21:49:24] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/29558632034096135\n",
      "INFO: [2025-06-30 21:49:24] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:24] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 92/93 [00:26<00:00,  3.63it/s]INFO: [2025-06-30 21:49:24] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/33628940232530458\n",
      "INFO: [2025-06-30 21:49:24] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:24] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 93/93 [00:27<00:00,  3.44it/s]\n",
      "Processing LLM curations:   0%|          | 0/93 [00:00<?, ?it/s]INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "Processing LLM curations:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 54/93 [00:00<00:00, 538.78it/s]INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "INFO: [2025-06-30 21:49:25] indra_gpt.chat_curate.eval - Error processing evidence curation: 'explanation'skipping this curation\n",
      "Processing LLM curations: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 93/93 [00:00<00:00, 789.66it/s]\n",
      "Processing LLM curations:   0%|          | 0/93 [00:00<?, ?it/s]INFO: [2025-06-30 21:49:25] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-27178959702299212\n",
      "INFO: [2025-06-30 21:49:25] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:25] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:   1%|          | 1/93 [00:00<00:25,  3.65it/s]INFO: [2025-06-30 21:49:25] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-19509266375111713\n",
      "INFO: [2025-06-30 21:49:25] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:25] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:   2%|‚ñè         | 2/93 [00:00<00:26,  3.49it/s]INFO: [2025-06-30 21:49:25] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/31183949835825955\n",
      "INFO: [2025-06-30 21:49:25] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:25] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:   3%|‚ñé         | 3/93 [00:00<00:25,  3.52it/s]INFO: [2025-06-30 21:49:26] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-920869035786162\n",
      "INFO: [2025-06-30 21:49:26] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:26] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:   4%|‚ñç         | 4/93 [00:01<00:25,  3.56it/s]INFO: [2025-06-30 21:49:26] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/24957834887591847\n",
      "INFO: [2025-06-30 21:49:26] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:26] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:   5%|‚ñå         | 5/93 [00:01<00:24,  3.62it/s]INFO: [2025-06-30 21:49:26] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-33418178478117880\n",
      "INFO: [2025-06-30 21:49:26] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:26] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:   6%|‚ñã         | 6/93 [00:01<00:32,  2.68it/s]INFO: [2025-06-30 21:49:27] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/35857458895716258\n",
      "INFO: [2025-06-30 21:49:27] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:27] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:   8%|‚ñä         | 7/93 [00:02<00:29,  2.93it/s]INFO: [2025-06-30 21:49:27] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-26431974494844569\n",
      "INFO: [2025-06-30 21:49:27] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:27] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:   9%|‚ñä         | 8/93 [00:02<00:27,  3.09it/s]INFO: [2025-06-30 21:49:27] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/32773248379568006\n",
      "INFO: [2025-06-30 21:49:27] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:27] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  10%|‚ñâ         | 9/93 [00:02<00:25,  3.25it/s]INFO: [2025-06-30 21:49:28] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-13164323043334385\n",
      "INFO: [2025-06-30 21:49:28] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:28] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  11%|‚ñà         | 10/93 [00:03<00:24,  3.40it/s]INFO: [2025-06-30 21:49:28] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/32159499136500804\n",
      "INFO: [2025-06-30 21:49:28] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:28] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  12%|‚ñà‚ñè        | 11/93 [00:03<00:23,  3.47it/s]INFO: [2025-06-30 21:49:28] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/26774703427840154\n",
      "INFO: [2025-06-30 21:49:28] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:28] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  13%|‚ñà‚ñé        | 12/93 [00:03<00:23,  3.52it/s]INFO: [2025-06-30 21:49:28] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-14556452501867428\n",
      "INFO: [2025-06-30 21:49:28] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:28] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  14%|‚ñà‚ñç        | 13/93 [00:04<00:30,  2.62it/s]INFO: [2025-06-30 21:49:29] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/18943901803073221\n",
      "INFO: [2025-06-30 21:49:29] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:29] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  15%|‚ñà‚ñå        | 14/93 [00:04<00:28,  2.75it/s]INFO: [2025-06-30 21:49:29] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/13785179510421349\n",
      "INFO: [2025-06-30 21:49:29] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:29] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  16%|‚ñà‚ñå        | 15/93 [00:04<00:26,  2.94it/s]INFO: [2025-06-30 21:49:30] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-19037816720378235\n",
      "INFO: [2025-06-30 21:49:30] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:30] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  17%|‚ñà‚ñã        | 16/93 [00:05<00:24,  3.16it/s]INFO: [2025-06-30 21:49:30] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-24566439914598834\n",
      "INFO: [2025-06-30 21:49:30] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:30] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  18%|‚ñà‚ñä        | 17/93 [00:05<00:23,  3.27it/s]INFO: [2025-06-30 21:49:30] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-1936440077119914\n",
      "INFO: [2025-06-30 21:49:30] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:30] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  19%|‚ñà‚ñâ        | 18/93 [00:05<00:22,  3.36it/s]INFO: [2025-06-30 21:49:31] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/11566565080383602\n",
      "INFO: [2025-06-30 21:49:31] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:31] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  20%|‚ñà‚ñà        | 19/93 [00:05<00:21,  3.37it/s]INFO: [2025-06-30 21:49:31] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/11586602714543979\n",
      "INFO: [2025-06-30 21:49:31] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:31] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  22%|‚ñà‚ñà‚ñè       | 20/93 [00:06<00:28,  2.52it/s]INFO: [2025-06-30 21:49:31] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/21648553749456228\n",
      "INFO: [2025-06-30 21:49:31] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:31] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  23%|‚ñà‚ñà‚ñé       | 21/93 [00:06<00:28,  2.52it/s]INFO: [2025-06-30 21:49:32] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/4724524981516770\n",
      "INFO: [2025-06-30 21:49:32] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:32] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  24%|‚ñà‚ñà‚ñé       | 22/93 [00:07<00:25,  2.79it/s]INFO: [2025-06-30 21:49:32] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-20949930044320929\n",
      "INFO: [2025-06-30 21:49:32] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:32] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  25%|‚ñà‚ñà‚ñç       | 23/93 [00:07<00:23,  3.02it/s]INFO: [2025-06-30 21:49:32] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/10656611432677873\n",
      "INFO: [2025-06-30 21:49:32] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:32] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  26%|‚ñà‚ñà‚ñå       | 24/93 [00:07<00:21,  3.17it/s]INFO: [2025-06-30 21:49:33] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/26447517437851099\n",
      "INFO: [2025-06-30 21:49:33] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:33] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  27%|‚ñà‚ñà‚ñã       | 25/93 [00:08<00:20,  3.28it/s]INFO: [2025-06-30 21:49:33] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/14303941633313044\n",
      "INFO: [2025-06-30 21:49:33] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:33] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  28%|‚ñà‚ñà‚ñä       | 26/93 [00:08<00:19,  3.39it/s]INFO: [2025-06-30 21:49:33] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/21028179654389070\n",
      "INFO: [2025-06-30 21:49:33] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:33] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  29%|‚ñà‚ñà‚ñâ       | 27/93 [00:08<00:21,  3.11it/s]INFO: [2025-06-30 21:49:34] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/34743744846379781\n",
      "INFO: [2025-06-30 21:49:34] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:34] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  30%|‚ñà‚ñà‚ñà       | 28/93 [00:09<00:26,  2.44it/s]INFO: [2025-06-30 21:49:34] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/8624259220739988\n",
      "INFO: [2025-06-30 21:49:34] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:34] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  31%|‚ñà‚ñà‚ñà       | 29/93 [00:09<00:26,  2.44it/s]INFO: [2025-06-30 21:49:35] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/32377238858127591\n",
      "INFO: [2025-06-30 21:49:35] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:35] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  32%|‚ñà‚ñà‚ñà‚ñè      | 30/93 [00:09<00:22,  2.76it/s]INFO: [2025-06-30 21:49:35] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-34994047816870295\n",
      "INFO: [2025-06-30 21:49:35] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:35] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  33%|‚ñà‚ñà‚ñà‚ñé      | 31/93 [00:10<00:20,  2.97it/s]INFO: [2025-06-30 21:49:35] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-12271565811912238\n",
      "INFO: [2025-06-30 21:49:35] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:35] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  34%|‚ñà‚ñà‚ñà‚ñç      | 32/93 [00:10<00:19,  3.11it/s]INFO: [2025-06-30 21:49:35] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-26871800485543379\n",
      "INFO: [2025-06-30 21:49:35] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:35] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  35%|‚ñà‚ñà‚ñà‚ñå      | 33/93 [00:10<00:18,  3.26it/s]INFO: [2025-06-30 21:49:36] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/3318841584498159\n",
      "INFO: [2025-06-30 21:49:36] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:36] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  37%|‚ñà‚ñà‚ñà‚ñã      | 34/93 [00:11<00:17,  3.38it/s]INFO: [2025-06-30 21:49:36] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/31623977566147927\n",
      "INFO: [2025-06-30 21:49:36] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:36] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  38%|‚ñà‚ñà‚ñà‚ñä      | 35/93 [00:11<00:16,  3.57it/s]INFO: [2025-06-30 21:49:36] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/32706502424195028\n",
      "INFO: [2025-06-30 21:49:36] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:36] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  39%|‚ñà‚ñà‚ñà‚ñä      | 36/93 [00:11<00:15,  3.70it/s]INFO: [2025-06-30 21:49:36] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-11644103489591043\n",
      "INFO: [2025-06-30 21:49:36] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:36] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  40%|‚ñà‚ñà‚ñà‚ñâ      | 37/93 [00:11<00:15,  3.71it/s]INFO: [2025-06-30 21:49:37] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-27389475588438153\n",
      "INFO: [2025-06-30 21:49:37] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:37] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  41%|‚ñà‚ñà‚ñà‚ñà      | 38/93 [00:12<00:21,  2.61it/s]INFO: [2025-06-30 21:49:37] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/21472557419519824\n",
      "INFO: [2025-06-30 21:49:37] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:37] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 39/93 [00:12<00:19,  2.84it/s]INFO: [2025-06-30 21:49:38] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-19649511627914971\n",
      "INFO: [2025-06-30 21:49:38] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:38] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 40/93 [00:13<00:17,  3.03it/s]INFO: [2025-06-30 21:49:38] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/12577334723163994\n",
      "INFO: [2025-06-30 21:49:38] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:38] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 41/93 [00:13<00:15,  3.32it/s]INFO: [2025-06-30 21:49:38] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-6895415621598192\n",
      "INFO: [2025-06-30 21:49:38] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:38] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 42/93 [00:13<00:14,  3.55it/s]INFO: [2025-06-30 21:49:38] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-485932016041862\n",
      "INFO: [2025-06-30 21:49:38] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:38] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 43/93 [00:13<00:14,  3.43it/s]INFO: [2025-06-30 21:49:39] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/17938020806565298\n",
      "INFO: [2025-06-30 21:49:39] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:39] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 44/93 [00:14<00:13,  3.53it/s]INFO: [2025-06-30 21:49:39] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/33824349687802512\n",
      "INFO: [2025-06-30 21:49:39] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:39] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 45/93 [00:14<00:13,  3.58it/s]INFO: [2025-06-30 21:49:39] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-33947966598417533\n",
      "INFO: [2025-06-30 21:49:39] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:39] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 46/93 [00:14<00:13,  3.44it/s]INFO: [2025-06-30 21:49:40] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-29655436866179624\n",
      "INFO: [2025-06-30 21:49:40] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:40] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 47/93 [00:15<00:18,  2.46it/s]INFO: [2025-06-30 21:49:40] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-17175494830033935\n",
      "INFO: [2025-06-30 21:49:40] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:40] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 48/93 [00:15<00:16,  2.68it/s]INFO: [2025-06-30 21:49:41] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-13199747933845394\n",
      "INFO: [2025-06-30 21:49:41] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:41] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 49/93 [00:15<00:15,  2.93it/s]INFO: [2025-06-30 21:49:41] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-3369492957696618\n",
      "INFO: [2025-06-30 21:49:41] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:41] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 50/93 [00:16<00:13,  3.08it/s]INFO: [2025-06-30 21:49:41] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-2236737361566990\n",
      "INFO: [2025-06-30 21:49:41] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:41] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 51/93 [00:16<00:14,  2.84it/s]INFO: [2025-06-30 21:49:41] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/8984465254997982\n",
      "INFO: [2025-06-30 21:49:41] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:41] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 52/93 [00:16<00:13,  3.09it/s]INFO: [2025-06-30 21:49:42] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/34378681930619692\n",
      "INFO: [2025-06-30 21:49:42] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:42] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 53/93 [00:17<00:12,  3.30it/s]INFO: [2025-06-30 21:49:42] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-6218818935340723\n",
      "INFO: [2025-06-30 21:49:42] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:42] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 54/93 [00:17<00:11,  3.50it/s]INFO: [2025-06-30 21:49:42] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/15710041033319852\n",
      "INFO: [2025-06-30 21:49:42] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:42] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 55/93 [00:17<00:10,  3.68it/s]INFO: [2025-06-30 21:49:42] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/24936382034801481\n",
      "INFO: [2025-06-30 21:49:42] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:42] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 56/93 [00:17<00:09,  3.76it/s]INFO: [2025-06-30 21:49:43] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/26164874326231702\n",
      "INFO: [2025-06-30 21:49:43] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:43] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 57/93 [00:18<00:09,  3.75it/s]INFO: [2025-06-30 21:49:43] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-31655492632823057\n",
      "INFO: [2025-06-30 21:49:43] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:43] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 58/93 [00:18<00:09,  3.71it/s]INFO: [2025-06-30 21:49:43] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-23683650049842135\n",
      "INFO: [2025-06-30 21:49:43] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:43] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 59/93 [00:18<00:09,  3.66it/s]INFO: [2025-06-30 21:49:44] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-9969581778460163\n",
      "INFO: [2025-06-30 21:49:44] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:44] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 60/93 [00:19<00:12,  2.58it/s]INFO: [2025-06-30 21:49:44] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-8638049287075364\n",
      "INFO: [2025-06-30 21:49:44] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:44] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 61/93 [00:19<00:11,  2.85it/s]INFO: [2025-06-30 21:49:44] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/6608566428303438\n",
      "INFO: [2025-06-30 21:49:44] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:44] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 62/93 [00:19<00:10,  3.02it/s]INFO: [2025-06-30 21:49:45] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/16805525748654600\n",
      "INFO: [2025-06-30 21:49:45] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:45] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 63/93 [00:20<00:09,  3.17it/s]INFO: [2025-06-30 21:49:45] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/32661404256967902\n",
      "INFO: [2025-06-30 21:49:45] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:45] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 64/93 [00:20<00:08,  3.26it/s]INFO: [2025-06-30 21:49:45] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-32244093775178354\n",
      "INFO: [2025-06-30 21:49:45] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:45] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 65/93 [00:20<00:08,  3.39it/s]INFO: [2025-06-30 21:49:46] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-10021087834226700\n",
      "INFO: [2025-06-30 21:49:46] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:46] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 66/93 [00:21<00:07,  3.51it/s]INFO: [2025-06-30 21:49:46] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-2133246301027277\n",
      "INFO: [2025-06-30 21:49:46] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:46] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 67/93 [00:21<00:09,  2.62it/s]INFO: [2025-06-30 21:49:46] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-2069452773758641\n",
      "INFO: [2025-06-30 21:49:46] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:46] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 68/93 [00:21<00:08,  2.87it/s]INFO: [2025-06-30 21:49:47] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/1164537692928586\n",
      "INFO: [2025-06-30 21:49:47] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:47] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 69/93 [00:22<00:07,  3.07it/s]INFO: [2025-06-30 21:49:47] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/2263006480531827\n",
      "INFO: [2025-06-30 21:49:47] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:47] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 70/93 [00:22<00:07,  3.21it/s]INFO: [2025-06-30 21:49:47] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/7569162649893756\n",
      "INFO: [2025-06-30 21:49:47] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:47] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 71/93 [00:22<00:06,  3.33it/s]INFO: [2025-06-30 21:49:48] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/10718272922581743\n",
      "INFO: [2025-06-30 21:49:48] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:48] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 72/93 [00:22<00:06,  3.44it/s]INFO: [2025-06-30 21:49:48] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/19593248734621443\n",
      "INFO: [2025-06-30 21:49:48] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:48] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 73/93 [00:23<00:05,  3.48it/s]INFO: [2025-06-30 21:49:48] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/28630162558138671\n",
      "INFO: [2025-06-30 21:49:48] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:48] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 74/93 [00:23<00:07,  2.60it/s]INFO: [2025-06-30 21:49:49] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-29619449833500674\n",
      "INFO: [2025-06-30 21:49:49] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:49] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 75/93 [00:24<00:06,  2.85it/s]INFO: [2025-06-30 21:49:49] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-24329292593271143\n",
      "INFO: [2025-06-30 21:49:49] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:49] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 76/93 [00:24<00:05,  3.06it/s]INFO: [2025-06-30 21:49:49] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-16927679215920559\n",
      "INFO: [2025-06-30 21:49:49] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:49] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 77/93 [00:24<00:05,  3.19it/s]INFO: [2025-06-30 21:49:50] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-14487224197960867\n",
      "INFO: [2025-06-30 21:49:50] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:50] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 78/93 [00:24<00:04,  3.33it/s]INFO: [2025-06-30 21:49:50] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-13395121870981465\n",
      "INFO: [2025-06-30 21:49:50] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:50] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 79/93 [00:25<00:04,  3.41it/s]INFO: [2025-06-30 21:49:50] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-12292476614970820\n",
      "INFO: [2025-06-30 21:49:50] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:50] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 80/93 [00:25<00:05,  2.46it/s]INFO: [2025-06-30 21:49:51] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-6454779301185040\n",
      "INFO: [2025-06-30 21:49:51] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:51] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 81/93 [00:26<00:04,  2.71it/s]INFO: [2025-06-30 21:49:51] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-5382220701144721\n",
      "INFO: [2025-06-30 21:49:51] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:51] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 82/93 [00:26<00:03,  2.93it/s]INFO: [2025-06-30 21:49:51] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-1675123172097724\n",
      "INFO: [2025-06-30 21:49:51] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:51] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 83/93 [00:26<00:03,  3.11it/s]INFO: [2025-06-30 21:49:52] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-1409606189539046\n",
      "INFO: [2025-06-30 21:49:52] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:52] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 84/93 [00:27<00:02,  3.27it/s]INFO: [2025-06-30 21:49:52] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/1809577373025591\n",
      "INFO: [2025-06-30 21:49:52] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:52] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 85/93 [00:27<00:02,  3.37it/s]INFO: [2025-06-30 21:49:52] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/5640957775123881\n",
      "INFO: [2025-06-30 21:49:52] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:52] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 86/93 [00:27<00:02,  3.43it/s]INFO: [2025-06-30 21:49:52] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/14209416812158648\n",
      "INFO: [2025-06-30 21:49:52] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:52] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 87/93 [00:28<00:02,  2.61it/s]INFO: [2025-06-30 21:49:53] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/20857841531996883\n",
      "INFO: [2025-06-30 21:49:53] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:53] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 88/93 [00:28<00:01,  2.84it/s]INFO: [2025-06-30 21:49:53] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/21066814703750909\n",
      "INFO: [2025-06-30 21:49:53] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:53] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 89/93 [00:28<00:01,  3.05it/s]INFO: [2025-06-30 21:49:54] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/26850960593724298\n",
      "INFO: [2025-06-30 21:49:54] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:54] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 90/93 [00:28<00:00,  3.23it/s]INFO: [2025-06-30 21:49:54] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/28430530457626809\n",
      "INFO: [2025-06-30 21:49:54] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:54] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 91/93 [00:29<00:00,  3.35it/s]INFO: [2025-06-30 21:49:54] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/29558632034096135\n",
      "INFO: [2025-06-30 21:49:54] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:54] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 92/93 [00:29<00:00,  3.40it/s]INFO: [2025-06-30 21:49:54] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/33628940232530458\n",
      "INFO: [2025-06-30 21:49:54] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-30 21:49:54] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 93/93 [00:29<00:00,  3.12it/s]\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    with open(RESULTS_DIR / model / \"chat_curation_binary_classification.json\", \"r\") as f:\n",
    "        chat_curation_binary_classification = json.load(f)\n",
    "    with open(RESULTS_DIR / model / \"chat_curation_multiclass_classification.json\", \"r\") as f:\n",
    "        chat_curation_multiclass_classification = json.load(f)\n",
    "\n",
    "    eval_stmt_ev_pair_binary = curation_statement_evidence_pair_comparison_json(chat_curation_binary_classification)\n",
    "    with open(RESULTS_DIR / model / \"eval_stmt_ev_pair_chat_curation_binary_classification.json\", \"w\") as f:\n",
    "        json.dump(eval_stmt_ev_pair_binary, f, indent=2)\n",
    "\n",
    "    eval_stmt_binary = curation_statement_comparison_json(chat_curation_binary_classification)\n",
    "    with open(RESULTS_DIR / model / \"eval_stmt_chat_curation_binary_classification.json\", \"w\") as f:\n",
    "        json.dump(eval_stmt_binary, f, indent=2)\n",
    "\n",
    "    eval_stmt_ev_pair_multi = curation_statement_evidence_pair_comparison_json(chat_curation_multiclass_classification)\n",
    "    with open(RESULTS_DIR / model / \"eval_stmt_ev_pair_chat_curation_multiclass_classification.json\", \"w\") as f:\n",
    "        json.dump(eval_stmt_ev_pair_multi, f, indent=2)\n",
    "\n",
    "    eval_stmt_multi = curation_statement_comparison_json(chat_curation_multiclass_classification)\n",
    "    with open(RESULTS_DIR / model / \"eval_stmt_chat_curation_multiclass_classification.json\", \"w\") as f:\n",
    "        json.dump(eval_stmt_multi, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef96cc00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: gpt-4o-mini\n",
      "binary_classification - Accuracy: 0.8387\n",
      "multiclass_classification - Accuracy: 0.7742\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "for model in models:\n",
    "    print(f\"Model: {model}\")\n",
    "    for eval_strat in ['binary_classification', 'multiclass_classification']:\n",
    "        with open(RESULTS_DIR / model / f\"eval_stmt_chat_curation_{eval_strat}.json\", \"r\") as f:\n",
    "            res = json.load(f)\n",
    "        preds = [res_item['llm_overall_prediction'] for res_item in res]\n",
    "        labels = [res_item['indra_curation'] for res_item in res]\n",
    "        acc = accuracy_score(labels, preds)\n",
    "        print(f\"{eval_strat} - Accuracy: {acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cdfc0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'eng_stmt': 'BAX activates cell death.',\n",
       "  'pa_hash': -27178959702299212,\n",
       "  'llm_overall_prediction': 'correct',\n",
       "  'indra_curation': 'correct'},\n",
       " {'eng_stmt': 'MTOR activates translation.',\n",
       "  'pa_hash': -19509266375111713,\n",
       "  'llm_overall_prediction': 'correct',\n",
       "  'indra_curation': 'correct'},\n",
       " {'eng_stmt': 'ACE2 inhibits Angiotensin-2.',\n",
       "  'pa_hash': 31183949835825955,\n",
       "  'llm_overall_prediction': 'correct',\n",
       "  'indra_curation': 'incorrect'},\n",
       " {'eng_stmt': 'RELA binds RELA.',\n",
       "  'pa_hash': -920869035786162,\n",
       "  'llm_overall_prediction': 'correct',\n",
       "  'indra_curation': 'incorrect'},\n",
       " {'eng_stmt': 'EGF activates RAS.',\n",
       "  'pa_hash': 24957834887591847,\n",
       "  'llm_overall_prediction': 'correct',\n",
       "  'indra_curation': 'correct'},\n",
       " {'eng_stmt': 'Cocaine activates NLRP1.',\n",
       "  'pa_hash': -33418178478117880,\n",
       "  'llm_overall_prediction': 'incorrect',\n",
       "  'indra_curation': 'incorrect'},\n",
       " {'eng_stmt': 'SOCS1 inhibits JAK.',\n",
       "  'pa_hash': 35857458895716258,\n",
       "  'llm_overall_prediction': 'correct',\n",
       "  'indra_curation': 'correct'},\n",
       " {'eng_stmt': 'Camostat inhibits SARS-CoV-2.',\n",
       "  'pa_hash': -26431974494844569,\n",
       "  'llm_overall_prediction': 'correct',\n",
       "  'indra_curation': 'correct'},\n",
       " {'eng_stmt': 'SRC activates JNK.',\n",
       "  'pa_hash': 32773248379568006,\n",
       "  'llm_overall_prediction': 'incorrect',\n",
       "  'indra_curation': 'correct'},\n",
       " {'eng_stmt': 'MTOR phosphorylates EIF4E.',\n",
       "  'pa_hash': -13164323043334385,\n",
       "  'llm_overall_prediction': 'correct',\n",
       "  'indra_curation': 'correct'},\n",
       " {'eng_stmt': 'APP increases the amount of calcium(2+).',\n",
       "  'pa_hash': 32159499136500804,\n",
       "  'llm_overall_prediction': 'incorrect',\n",
       "  'indra_curation': 'incorrect'},\n",
       " {'eng_stmt': 'CSF3 leads to the phosphorylation of STAT3.',\n",
       "  'pa_hash': 26774703427840154,\n",
       "  'llm_overall_prediction': 'correct',\n",
       "  'indra_curation': 'correct'},\n",
       " {'eng_stmt': 'RCHY1 inhibits TP53.',\n",
       "  'pa_hash': -14556452501867428,\n",
       "  'llm_overall_prediction': 'incorrect',\n",
       "  'indra_curation': 'correct'},\n",
       " {'eng_stmt': 'IGF1R phosphorylates IRS1.',\n",
       "  'pa_hash': 18943901803073221,\n",
       "  'llm_overall_prediction': 'correct',\n",
       "  'indra_curation': 'correct'},\n",
       " {'eng_stmt': 'PTEN dephosphorylates PTK2.',\n",
       "  'pa_hash': 13785179510421349,\n",
       "  'llm_overall_prediction': 'correct',\n",
       "  'indra_curation': 'correct'},\n",
       " {'eng_stmt': 'Multiple Sclerosis binds NCIT:C121977.',\n",
       "  'pa_hash': -19037816720378235,\n",
       "  'llm_overall_prediction': 'incorrect',\n",
       "  'indra_curation': 'incorrect'},\n",
       " {'eng_stmt': 'FAS activates FADD.',\n",
       "  'pa_hash': -24566439914598834,\n",
       "  'llm_overall_prediction': 'correct',\n",
       "  'indra_curation': 'correct'},\n",
       " {'eng_stmt': 'STIM1 binds TRPV4.',\n",
       "  'pa_hash': -1936440077119914,\n",
       "  'llm_overall_prediction': 'correct',\n",
       "  'indra_curation': 'correct'},\n",
       " {'eng_stmt': 'FGF4 activates ERK.',\n",
       "  'pa_hash': 11566565080383602,\n",
       "  'llm_overall_prediction': 'correct',\n",
       "  'indra_curation': 'correct'},\n",
       " {'eng_stmt': 'SPHK1 activates NFkappaB.',\n",
       "  'pa_hash': 11586602714543979,\n",
       "  'llm_overall_prediction': 'correct',\n",
       "  'indra_curation': 'correct'},\n",
       " {'eng_stmt': 'RET activates GDNF.',\n",
       "  'pa_hash': 21648553749456228,\n",
       "  'llm_overall_prediction': 'incorrect',\n",
       "  'indra_curation': 'incorrect'},\n",
       " {'eng_stmt': 'SMO binds HGS.',\n",
       "  'pa_hash': 4724524981516770,\n",
       "  'llm_overall_prediction': 'incorrect',\n",
       "  'indra_curation': 'correct'},\n",
       " {'eng_stmt': 'YAP1 binds LAT.',\n",
       "  'pa_hash': -20949930044320929,\n",
       "  'llm_overall_prediction': 'incorrect',\n",
       "  'indra_curation': 'incorrect'},\n",
       " {'eng_stmt': 'BRCC3 deubiquitinates NLRP3.',\n",
       "  'pa_hash': 10656611432677873,\n",
       "  'llm_overall_prediction': 'correct',\n",
       "  'indra_curation': 'correct'},\n",
       " {'eng_stmt': 'AXL activates EGFR.',\n",
       "  'pa_hash': 26447517437851099,\n",
       "  'llm_overall_prediction': 'incorrect',\n",
       "  'indra_curation': 'correct'},\n",
       " {'eng_stmt': 'TGFB binds TP53.',\n",
       "  'pa_hash': 14303941633313044,\n",
       "  'llm_overall_prediction': 'incorrect',\n",
       "  'indra_curation': 'incorrect'},\n",
       " {'eng_stmt': 'INS activates STAT5B.',\n",
       "  'pa_hash': 21028179654389070,\n",
       "  'llm_overall_prediction': 'correct',\n",
       "  'indra_curation': 'correct'},\n",
       " {'eng_stmt': 'Ubiquitin binds ATG16L1.',\n",
       "  'pa_hash': 34743744846379781,\n",
       "  'llm_overall_prediction': 'correct',\n",
       "  'indra_curation': 'correct'},\n",
       " {'eng_stmt': 'CTNNA1 binds JUP.',\n",
       "  'pa_hash': 8624259220739988,\n",
       "  'llm_overall_prediction': 'correct',\n",
       "  'indra_curation': 'correct'},\n",
       " {'eng_stmt': 'RAP1 translocates to the plasma membrane.',\n",
       "  'pa_hash': 32377238858127591,\n",
       "  'llm_overall_prediction': 'correct',\n",
       "  'indra_curation': 'correct'},\n",
       " {'eng_stmt': 'PTPRB activates CDH5.',\n",
       "  'pa_hash': -34994047816870295,\n",
       "  'llm_overall_prediction': 'correct',\n",
       "  'indra_curation': 'correct'},\n",
       " {'eng_stmt': 'CDK1 phosphorylates HIF1A on S668.',\n",
       "  'pa_hash': -12271565811912238,\n",
       "  'llm_overall_prediction': 'correct',\n",
       "  'indra_curation': 'correct'},\n",
       " {'eng_stmt': 'THBS1 binds VLDLR.',\n",
       "  'pa_hash': -26871800485543379,\n",
       "  'llm_overall_prediction': 'correct',\n",
       "  'indra_curation': 'correct'},\n",
       " {'eng_stmt': 'ITCH ubiquitinates FOXO1.',\n",
       "  'pa_hash': 3318841584498159,\n",
       "  'llm_overall_prediction': 'correct',\n",
       "  'indra_curation': 'correct'},\n",
       " {'eng_stmt': 'MEN1 inhibits ERK.',\n",
       "  'pa_hash': 31623977566147927,\n",
       "  'llm_overall_prediction': 'correct',\n",
       "  'indra_curation': 'correct'},\n",
       " {'eng_stmt': 'HUWE1 inhibits ATOH1.',\n",
       "  'pa_hash': 32706502424195028,\n",
       "  'llm_overall_prediction': 'correct',\n",
       "  'indra_curation': 'correct'},\n",
       " {'eng_stmt': 'TGFB activates superoxide.',\n",
       "  'pa_hash': -11644103489591043,\n",
       "  'llm_overall_prediction': 'incorrect',\n",
       "  'indra_curation': 'incorrect'},\n",
       " {'eng_stmt': 'EDN1 leads to the phosphorylation of GSK3B.',\n",
       "  'pa_hash': -27389475588438153,\n",
       "  'llm_overall_prediction': 'correct',\n",
       "  'indra_curation': 'correct'},\n",
       " {'eng_stmt': 'HDAC3 decreases the amount of BBC3.',\n",
       "  'pa_hash': 21472557419519824,\n",
       "  'llm_overall_prediction': 'correct',\n",
       "  'indra_curation': 'correct'},\n",
       " {'eng_stmt': 'GSK3B phosphorylates SOX10.',\n",
       "  'pa_hash': -19649511627914971,\n",
       "  'llm_overall_prediction': 'correct',\n",
       "  'indra_curation': 'correct'},\n",
       " {'eng_stmt': 'VDAC1 binds PLAT.',\n",
       "  'pa_hash': 12577334723163994,\n",
       "  'llm_overall_prediction': 'incorrect',\n",
       "  'indra_curation': 'correct'},\n",
       " {'eng_stmt': \"TNF activates diphenylmethane-4,4'-diisocyanate.\",\n",
       "  'pa_hash': -6895415621598192,\n",
       "  'llm_overall_prediction': 'incorrect',\n",
       "  'indra_curation': 'incorrect'},\n",
       " {'eng_stmt': 'SYVN1 ubiquitinates PTEN.',\n",
       "  'pa_hash': -485932016041862,\n",
       "  'llm_overall_prediction': 'correct',\n",
       "  'indra_curation': 'correct'},\n",
       " {'eng_stmt': 'ERK inhibits NF1.',\n",
       "  'pa_hash': 17938020806565298,\n",
       "  'llm_overall_prediction': 'incorrect',\n",
       "  'indra_curation': 'incorrect'},\n",
       " {'eng_stmt': 'TLR2 increases the amount of CSF2.',\n",
       "  'pa_hash': 33824349687802512,\n",
       "  'llm_overall_prediction': 'correct',\n",
       "  'indra_curation': 'correct'},\n",
       " {'eng_stmt': 'ANXA1 decreases the amount of IL1B.',\n",
       "  'pa_hash': -33947966598417533,\n",
       "  'llm_overall_prediction': 'correct',\n",
       "  'indra_curation': 'correct'},\n",
       " {'eng_stmt': 'EGFR_ligand leads to the phosphorylation of EGFR.',\n",
       "  'pa_hash': -29655436866179624,\n",
       "  'llm_overall_prediction': 'correct',\n",
       "  'indra_curation': 'correct'},\n",
       " {'eng_stmt': 'EGFR increases the amount of AURKA.',\n",
       "  'pa_hash': -17175494830033935,\n",
       "  'llm_overall_prediction': 'correct',\n",
       "  'indra_curation': 'correct'},\n",
       " {'eng_stmt': 'SRC phosphorylates PRKCD.',\n",
       "  'pa_hash': -13199747933845394,\n",
       "  'llm_overall_prediction': 'correct',\n",
       "  'indra_curation': 'correct'},\n",
       " {'eng_stmt': 'SYVN1 inhibits CDKN1B.',\n",
       "  'pa_hash': -3369492957696618,\n",
       "  'llm_overall_prediction': 'correct',\n",
       "  'indra_curation': 'correct'},\n",
       " {'eng_stmt': 'CDC14A inhibits CDC25A.',\n",
       "  'pa_hash': -2236737361566990,\n",
       "  'llm_overall_prediction': 'correct',\n",
       "  'indra_curation': 'correct'},\n",
       " {'eng_stmt': 'SRC inhibits RUNX3.',\n",
       "  'pa_hash': 8984465254997982,\n",
       "  'llm_overall_prediction': 'correct',\n",
       "  'indra_curation': 'correct'},\n",
       " {'eng_stmt': 'KDR phosphorylates itself on tyrosine.',\n",
       "  'pa_hash': 34378681930619692,\n",
       "  'llm_overall_prediction': 'correct',\n",
       "  'indra_curation': 'correct'},\n",
       " {'eng_stmt': 'Glyceraldehyde 3-phosphate inhibits GAPDH.',\n",
       "  'pa_hash': -6218818935340723,\n",
       "  'llm_overall_prediction': 'incorrect',\n",
       "  'indra_curation': 'incorrect'},\n",
       " {'eng_stmt': 'AKT increases the amount of IFITM1.',\n",
       "  'pa_hash': 15710041033319852,\n",
       "  'llm_overall_prediction': 'incorrect',\n",
       "  'indra_curation': 'correct'},\n",
       " {'eng_stmt': 'RHEB binds RASGRP1.',\n",
       "  'pa_hash': 24936382034801481,\n",
       "  'llm_overall_prediction': 'correct',\n",
       "  'indra_curation': 'correct'},\n",
       " {'eng_stmt': 'PDPK1 phosphorylates PGK1 on T243.',\n",
       "  'pa_hash': 26164874326231702,\n",
       "  'llm_overall_prediction': 'correct',\n",
       "  'indra_curation': 'correct'},\n",
       " {'eng_stmt': 'TP53 inhibits NF2.',\n",
       "  'pa_hash': -31655492632823057,\n",
       "  'llm_overall_prediction': 'incorrect',\n",
       "  'indra_curation': 'incorrect'},\n",
       " {'eng_stmt': 'IKBKB activates RPS3.',\n",
       "  'pa_hash': -23683650049842135,\n",
       "  'llm_overall_prediction': 'correct',\n",
       "  'indra_curation': 'correct'},\n",
       " {'eng_stmt': 'SYNJ1 leads to the dephosphorylation of MAPT.',\n",
       "  'pa_hash': -9969581778460163,\n",
       "  'llm_overall_prediction': 'incorrect',\n",
       "  'indra_curation': 'incorrect'},\n",
       " {'eng_stmt': 'AKT leads to the dephosphorylation of CHEK1.',\n",
       "  'pa_hash': -8638049287075364,\n",
       "  'llm_overall_prediction': 'incorrect',\n",
       "  'indra_curation': 'correct'},\n",
       " {'eng_stmt': 'CLDN2 binds YBX3.',\n",
       "  'pa_hash': 6608566428303438,\n",
       "  'llm_overall_prediction': 'incorrect',\n",
       "  'indra_curation': 'correct'},\n",
       " {'eng_stmt': 'MiR-200c-3p increases the amount of ACE2.',\n",
       "  'pa_hash': 16805525748654600,\n",
       "  'llm_overall_prediction': 'incorrect',\n",
       "  'indra_curation': 'incorrect'},\n",
       " {'eng_stmt': 'PTP4A1 dephosphorylates SRC.',\n",
       "  'pa_hash': 32661404256967902,\n",
       "  'llm_overall_prediction': 'incorrect',\n",
       "  'indra_curation': 'incorrect'},\n",
       " {'eng_stmt': 'SIK1 binds TP53.',\n",
       "  'pa_hash': -32244093775178354,\n",
       "  'llm_overall_prediction': 'correct',\n",
       "  'indra_curation': 'correct'},\n",
       " {'eng_stmt': 'HUWE1 decreases the amount of TBP.',\n",
       "  'pa_hash': -10021087834226700,\n",
       "  'llm_overall_prediction': 'correct',\n",
       "  'indra_curation': 'correct'},\n",
       " {'eng_stmt': 'CXCL12 bound to ACKR3 activates AKT.',\n",
       "  'pa_hash': -2133246301027277,\n",
       "  'llm_overall_prediction': 'correct',\n",
       "  'indra_curation': 'correct'},\n",
       " {'eng_stmt': 'PIM3 phosphorylates CXCR4 on S339.',\n",
       "  'pa_hash': -2069452773758641,\n",
       "  'llm_overall_prediction': 'correct',\n",
       "  'indra_curation': 'correct'},\n",
       " {'eng_stmt': '(S)-nicotine inhibits STORM.',\n",
       "  'pa_hash': 1164537692928586,\n",
       "  'llm_overall_prediction': 'incorrect',\n",
       "  'indra_curation': 'incorrect'},\n",
       " {'eng_stmt': 'NEDD4 decreases the amount of GRIA1.',\n",
       "  'pa_hash': 2263006480531827,\n",
       "  'llm_overall_prediction': 'correct',\n",
       "  'indra_curation': 'correct'},\n",
       " {'eng_stmt': 'TNF binds CD4 and IFNG.',\n",
       "  'pa_hash': 7569162649893756,\n",
       "  'llm_overall_prediction': 'incorrect',\n",
       "  'indra_curation': 'incorrect'},\n",
       " {'eng_stmt': 'PRKCE phosphorylates NSF on T461.',\n",
       "  'pa_hash': 10718272922581743,\n",
       "  'llm_overall_prediction': 'correct',\n",
       "  'indra_curation': 'correct'},\n",
       " {'eng_stmt': 'ATM decreases the amount of EZH2.',\n",
       "  'pa_hash': 19593248734621443,\n",
       "  'llm_overall_prediction': 'correct',\n",
       "  'indra_curation': 'correct'},\n",
       " {'eng_stmt': 'AHCY activates DNMT3B.',\n",
       "  'pa_hash': 28630162558138671,\n",
       "  'llm_overall_prediction': 'correct',\n",
       "  'indra_curation': 'incorrect'},\n",
       " {'eng_stmt': 'RAS binds CDKN1A and NF1.',\n",
       "  'pa_hash': -29619449833500674,\n",
       "  'llm_overall_prediction': 'incorrect',\n",
       "  'indra_curation': 'incorrect'},\n",
       " {'eng_stmt': 'Mood Disorders inhibits Appetite.',\n",
       "  'pa_hash': -24329292593271143,\n",
       "  'llm_overall_prediction': 'incorrect',\n",
       "  'indra_curation': 'correct'},\n",
       " {'eng_stmt': 'Database increases the amount of STAT5B.',\n",
       "  'pa_hash': -16927679215920559,\n",
       "  'llm_overall_prediction': 'incorrect',\n",
       "  'indra_curation': 'incorrect'},\n",
       " {'eng_stmt': 'NF2 leads to the dephosphorylation of ELK1.',\n",
       "  'pa_hash': -14487224197960867,\n",
       "  'llm_overall_prediction': 'correct',\n",
       "  'indra_curation': 'correct'},\n",
       " {'eng_stmt': 'NEK2 activates CDC20.',\n",
       "  'pa_hash': -13395121870981465,\n",
       "  'llm_overall_prediction': 'correct',\n",
       "  'indra_curation': 'correct'},\n",
       " {'eng_stmt': 'Phosphorylated ATM leads to the ubiquitination of BCL10.',\n",
       "  'pa_hash': -12292476614970820,\n",
       "  'llm_overall_prediction': 'correct',\n",
       "  'indra_curation': 'correct'},\n",
       " {'eng_stmt': 'Nitrite binds IL6.',\n",
       "  'pa_hash': -6454779301185040,\n",
       "  'llm_overall_prediction': 'incorrect',\n",
       "  'indra_curation': 'incorrect'},\n",
       " {'eng_stmt': 'PRKCA inhibits RAB37.',\n",
       "  'pa_hash': -5382220701144721,\n",
       "  'llm_overall_prediction': 'correct',\n",
       "  'indra_curation': 'correct'},\n",
       " {'eng_stmt': 'TLR2 binds TLR4 and OLR1.',\n",
       "  'pa_hash': -1675123172097724,\n",
       "  'llm_overall_prediction': 'incorrect',\n",
       "  'indra_curation': 'incorrect'},\n",
       " {'eng_stmt': 'FERMT2 inhibits CDH2.',\n",
       "  'pa_hash': -1409606189539046,\n",
       "  'llm_overall_prediction': 'correct',\n",
       "  'indra_curation': 'incorrect'},\n",
       " {'eng_stmt': 'Steroid activates ribavirin.',\n",
       "  'pa_hash': 1809577373025591,\n",
       "  'llm_overall_prediction': 'incorrect',\n",
       "  'indra_curation': 'incorrect'},\n",
       " {'eng_stmt': 'TGFB1 activates SRC.',\n",
       "  'pa_hash': 5640957775123881,\n",
       "  'llm_overall_prediction': 'correct',\n",
       "  'indra_curation': 'correct'},\n",
       " {'eng_stmt': 'RAF1 activates CASP9.',\n",
       "  'pa_hash': 14209416812158648,\n",
       "  'llm_overall_prediction': 'correct',\n",
       "  'indra_curation': 'incorrect'},\n",
       " {'eng_stmt': 'ESRRA increases the amount of LDHA.',\n",
       "  'pa_hash': 20857841531996883,\n",
       "  'llm_overall_prediction': 'correct',\n",
       "  'indra_curation': 'correct'},\n",
       " {'eng_stmt': 'ECRG4 increases the amount of UBE2C.',\n",
       "  'pa_hash': 21066814703750909,\n",
       "  'llm_overall_prediction': 'incorrect',\n",
       "  'indra_curation': 'incorrect'},\n",
       " {'eng_stmt': 'Modified MAP3K7 leads to the phosphorylation of SMAD1 on S463.',\n",
       "  'pa_hash': 26850960593724298,\n",
       "  'llm_overall_prediction': 'correct',\n",
       "  'indra_curation': 'correct'},\n",
       " {'eng_stmt': 'PTEN activates GRIN2B.',\n",
       "  'pa_hash': 28430530457626809,\n",
       "  'llm_overall_prediction': 'incorrect',\n",
       "  'indra_curation': 'incorrect'},\n",
       " {'eng_stmt': 'Nucleus Pulposus activates NOG.',\n",
       "  'pa_hash': 29558632034096135,\n",
       "  'llm_overall_prediction': 'correct',\n",
       "  'indra_curation': 'incorrect'},\n",
       " {'eng_stmt': 'CEBPA phosphorylates AKT.',\n",
       "  'pa_hash': 33628940232530458,\n",
       "  'llm_overall_prediction': 'incorrect',\n",
       "  'indra_curation': 'incorrect'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_stmt_binary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba7065e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import confusion_matrix\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "\n",
    "# # Extract tags\n",
    "# tags = [c['tag'] for c in curation_comp_json]\n",
    "# predicted_tags = [c['predicted_tag'] for c in curation_comp_json]\n",
    "\n",
    "# # Compute accuracy\n",
    "# accuracy = np.mean([t == p for t, p in zip(tags, predicted_tags)])\n",
    "# accuracy_bin = np.mean([t == p or (t != 'correct' and p == 'incorrect') for t, p in zip(tags, predicted_tags)])\n",
    "# print(f\"Accuracy: {accuracy:.2%}\")\n",
    "# print(f\"Binary Accuracy: {accuracy_bin:.2%}\")\n",
    "\n",
    "# # Define tag label set\n",
    "# tag_set = list(set(tags).union(set(predicted_tags)))\n",
    "\n",
    "# # Compute confusion matrix\n",
    "# cm = confusion_matrix(tags, predicted_tags, labels=tag_set)\n",
    "# cm_df = pd.DataFrame(cm, index=tag_set, columns=tag_set)\n",
    "\n",
    "# # Plot\n",
    "# plt.figure(figsize=(12, 10))\n",
    "# sns.heatmap(cm_df, annot=True, fmt='d', cmap='Blues', cbar=True, linewidths=0.5)\n",
    "# plt.title(\"Confusion Matrix (Binary Classification - Model only predicts 'correct' or 'incorrect')\")\n",
    "# plt.xlabel(\"Predicted Label\")\n",
    "# plt.ylabel(\"True Label\")\n",
    "# plt.xticks(rotation=45, ha='right')\n",
    "# plt.yticks(rotation=0)\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd5fcb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "indra_gpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
