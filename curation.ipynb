{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bca64466",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thomaslim/miniconda3/envs/indra_gpt/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "INFO: [2025-07-01 15:59:10] httpx - HTTP Request: GET https://raw.githubusercontent.com/BerriAI/litellm/main/model_prices_and_context_window.json \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "\n",
    "import indra_gpt.chat_curate.chat_curate\n",
    "importlib.reload(indra_gpt.chat_curate.chat_curate)\n",
    "from indra_gpt.chat_curate.chat_curate import *\n",
    "\n",
    "import indra_gpt.chat_curate.eval\n",
    "importlib.reload(indra_gpt.chat_curate.eval)\n",
    "from indra_gpt.chat_curate.eval import (curation_statement_evidence_pair_comparison_json, \n",
    "                                        curation_statement_comparison_json)\n",
    "\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59caf037",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_DIR = Path.cwd().joinpath(\"output/curated_statements_sample_100\")\n",
    "if not RESULTS_DIR.exists():\n",
    "    RESULTS_DIR.mkdir(parents=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a574e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: [2025-07-01 15:59:10] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list\n",
      "INFO: [2025-07-01 15:59:10] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-07-01 15:59:10] indra.sources.indra_db_rest.util - data: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• Fetching all curations from INDRA DB...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: [2025-07-01 15:59:13] indra_db_rest.query_processor - Retrieving statements that have hash -10696017837805828, -1162888745937699, -12050220369461530, -12574145668536275, -12944136297237273, -13147497679311368, -14588987079463894, -14764107808671838, -15863948540513568, -17373651143639655, -18095852377820217, -18667508778466798, -1916462889756496, -20244182315148832, -20439687097155111, -20640874941404826, -20791049881816836, -20985125539701186, -21063384413635512, -2182577807754994, -22009960213009794, -22089542127820184, -23718381701315206, -24740057688017751, -25687087307736153, -2625142319587850, -28384846765651217, -2925848004089621, -29688714989318986, -29986805880581274, -3014753613862379, -30959821747830391, -31860267491149818, -32408403954411470, -33367977155272434, -33486202106927870, -33901162732123095, -4128417463538137, -4590487136733302, -5222353769539775, -6639728410780169, -6752041385298834, -7750304401378705, -7973912508330969, 1189041814265976, 13315061906556808, 1340780628001419, 13944643035032078, 14075206521735007, 1573692190207755, 17432404528669006, 17817207634495231, 20175682236984731, 20922393039769332, 21188674984709313, 21300101027330568, 21321689889868872, 21476735281067726, 22005300240956600, 22455622806643474, 22494993188547055, 22571634540105862, 22646098348623491, 22747263410138512, 22804791756293781, 2295877906536253, 22981941226636705, 24621944116777285, 25335335402393963, 26895935294565856, 26901312588220432, 27051856722807140, 27544563157386421, 28195789580781675, 28228652957437326, 28437804037781153, 28637737575858329, 28913319916172234, 28962624393260336, 30634204597194783, 30762673865828958, 31022259608647999, 31891799552219777, 318957165602844, 31898465631028388, 31942529200997933, 31969276987844226, 33445349301865455, 33628735336547396, 33650843436339196, 34109660692159627, 34159281409457006, 34588089512525337, 5143982737666729, 5262532979187612, 5290918231915647, 5841245771488405, 6498720312267456, 8337293419659358, or 9696500918257169.\n",
      "INFO: [2025-07-01 15:59:13] indra_db_rest.request_logs - Running 0th request for statements\n",
      "INFO: [2025-07-01 15:59:13] indra_db_rest.request_logs -   LIMIT: None\n",
      "INFO: [2025-07-01 15:59:13] indra_db_rest.request_logs -   OFFSET: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßπ Extracting unique statement hashes...\n",
      "üîç Fetching 100 curated statements from INDRA DB...\n",
      "‚úÖ Saved 87 curated statements to: /Users/thomaslim/gyorilab/indra_gpt/output/curated_statements_sample_100/statements.pkl\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from indra.sources import indra_db_rest\n",
    "\n",
    "# Step 1: Get all curations from the INDRA DB\n",
    "print(\"üì• Fetching all curations from INDRA DB...\")\n",
    "curations = indra_db_rest.get_curations()\n",
    "\n",
    "# Step 2: Extract unique statement hashes from curations\n",
    "print(\"üßπ Extracting unique statement hashes...\")\n",
    "unique_hashes = list({c['pa_hash'] for c in curations if 'pa_hash' in c})\n",
    "\n",
    "# Step 3: Randomly sample up to 100 curated statement hashes\n",
    "rng = random.Random(42)  # For reproducibility\n",
    "sample_size = min(100, len(unique_hashes))\n",
    "sampled_hashes = rng.sample(unique_hashes, sample_size)\n",
    "\n",
    "# Step 4: Fetch full statements by hash (including all evidences)\n",
    "print(f\"üîç Fetching {sample_size} curated statements from INDRA DB...\")\n",
    "stmt_proc = indra_db_rest.get_statements_by_hash(sampled_hashes, ev_limit=1000)\n",
    "curated_statements = stmt_proc.statements\n",
    "\n",
    "# Step 5: Save to pickle\n",
    "output_path = RESULTS_DIR / \"statements.pkl\"\n",
    "\n",
    "with open(output_path, \"wb\") as f:\n",
    "    pickle.dump(curated_statements, f)\n",
    "\n",
    "print(f\"‚úÖ Saved {len(curated_statements)} curated statements to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e8b436a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating prompts...:  20%|‚ñà‚ñà        | 1/5 [00:14<00:57, 14.49s/it]INFO: [2025-07-01 16:00:13] indra_gpt.chat_curate.chat_curate - Skipping evidence with no text for statement -2182577807754994: Evidence(source_api='biogrid',\n",
      "         pmid='11313979',\n",
      "         source_id='327840',\n",
      "         annotations={\n",
      "                      \"biogrid_int_id\": \"327840\",\n",
      "                      \"entrez_a\": \"5111\",\n",
      "                      \"entrez_b\": \"1026\",\n",
      "                      \"biogrid_a\": \"111142\",\n",
      "                      \"biogrid_b\": \"107460\",\n",
      "                      \"syst_name_a\": null,\n",
      "                      \"syst_name_b\": null,\n",
      "                      \"hgnc_a\": \"PCNA\",\n",
      "                      \"hgnc_b\": \"CDKN1A\",\n",
      "                      \"syn_a\": \"ATLD2\",\n",
      "                      \"syn_b\": \"CAP20|CDKN1|CIP1|MDA-6|P21|SDI1|WAF1|p21CIP1\",\n",
      "                      \"exp_system\": \"Two-hybrid\",\n",
      "                      \"exp_system_type\": \"physical\",\n",
      "                      \"author\": \"Yu P (2001)\",\n",
      "                      \"pmid\": \"11313979\",\n",
      "                      \"organism_a\": \"9606\",\n",
      "                      \"organism_b\": \"9606\",\n",
      "                      \"throughput\": \"Low Throughput\",\n",
      "                      \"score\": null,\n",
      "                      \"modification\": null,\n",
      "                      \"phenotypes\": null,\n",
      "                      \"qualifications\": null,\n",
      "                      \"tags\": null,\n",
      "                      \"source_db\": \"BIOGRID\",\n",
      "                      \"agents\": {\n",
      "                       \"raw_text\": [\n",
      "                        null,\n",
      "                        null\n",
      "                       ]\n",
      "                      },\n",
      "                      \"prior_uuids\": [\n",
      "                       \"6593f025-fcb7-44a4-946f-bc57eb31bab6\"\n",
      "                      ]\n",
      "                     },\n",
      "         text_refs={\n",
      "                    \"PMID\": \"11313979\"\n",
      "                   }\n",
      "         )\n",
      "\n",
      "\n",
      "Generating prompts...:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4/5 [00:19<00:03,  3.47s/it]INFO: [2025-07-01 16:00:16] indra_gpt.chat_curate.chat_curate - Skipping agent glycoprotein() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "INFO: [2025-07-01 16:00:17] indra_gpt.chat_curate.chat_curate - Skipping agent glycoprotein() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "Generating prompts...: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:21<00:00,  4.29s/it]\n",
      "Sending prompts to LLM:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[92m16:00:18 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:00:18] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:00:19] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:00:19 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:00:19] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:00:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:00:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:00:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:00:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:00:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:00:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:00:19 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:00:19] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:00:19] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:00:19 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:00:19] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:00:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:00:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:00:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Sending prompts to LLM:  20%|‚ñà‚ñà        | 1/5 [00:01<00:05,  1.48s/it]INFO: [2025-07-01 16:00:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:00:19 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:00:19] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:00:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:00:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:00:20] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:00:20 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:00:20] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:00:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:00:20] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:00:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Sending prompts to LLM:  40%|‚ñà‚ñà‚ñà‚ñà      | 2/5 [00:02<00:03,  1.15s/it]INFO: [2025-07-01 16:00:20] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:00:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:00:20] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:00:20 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:00:20] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:00:21] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:00:21 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:00:21] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:00:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:00:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:00:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:00:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:00:21 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:00:21] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:00:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:00:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:00:22] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:00:22 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:00:22] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:00:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:00:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:00:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Sending prompts to LLM:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3/5 [00:03<00:02,  1.22s/it]INFO: [2025-07-01 16:00:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:00:22 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:00:22] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:00:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:00:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:00:22] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:00:22 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:00:22] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:00:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:00:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:00:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:00:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:00:22 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:00:22] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:00:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:00:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:00:23] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:00:23 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:00:23] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:00:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:00:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:00:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Sending prompts to LLM:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4/5 [00:05<00:01,  1.37s/it]INFO: [2025-07-01 16:00:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:00:23 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:00:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:00:23] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:00:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:00:24] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:00:24 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:00:24] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:00:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:00:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:00:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:00:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:00:24 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:00:24] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:00:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:00:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:00:25] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:00:25 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:00:25] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:00:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:00:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:00:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Sending prompts to LLM: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:06<00:00,  1.41s/it]INFO: [2025-07-01 16:00:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Sending prompts to LLM: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:06<00:00,  1.36s/it]\u001b[92m16:00:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\n",
      "INFO: [2025-07-01 16:00:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Aggregating results: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 60090.32it/s]\n",
      "Generating prompts...:  20%|‚ñà‚ñà        | 1/5 [00:04<00:16,  4.01s/it]INFO: [2025-07-01 16:01:17] indra_gpt.chat_curate.chat_curate - Skipping evidence with no text for statement -2182577807754994: Evidence(source_api='biogrid',\n",
      "         pmid='11313979',\n",
      "         source_id='327840',\n",
      "         annotations={\n",
      "                      \"biogrid_int_id\": \"327840\",\n",
      "                      \"entrez_a\": \"5111\",\n",
      "                      \"entrez_b\": \"1026\",\n",
      "                      \"biogrid_a\": \"111142\",\n",
      "                      \"biogrid_b\": \"107460\",\n",
      "                      \"syst_name_a\": null,\n",
      "                      \"syst_name_b\": null,\n",
      "                      \"hgnc_a\": \"PCNA\",\n",
      "                      \"hgnc_b\": \"CDKN1A\",\n",
      "                      \"syn_a\": \"ATLD2\",\n",
      "                      \"syn_b\": \"CAP20|CDKN1|CIP1|MDA-6|P21|SDI1|WAF1|p21CIP1\",\n",
      "                      \"exp_system\": \"Two-hybrid\",\n",
      "                      \"exp_system_type\": \"physical\",\n",
      "                      \"author\": \"Yu P (2001)\",\n",
      "                      \"pmid\": \"11313979\",\n",
      "                      \"organism_a\": \"9606\",\n",
      "                      \"organism_b\": \"9606\",\n",
      "                      \"throughput\": \"Low Throughput\",\n",
      "                      \"score\": null,\n",
      "                      \"modification\": null,\n",
      "                      \"phenotypes\": null,\n",
      "                      \"qualifications\": null,\n",
      "                      \"tags\": null,\n",
      "                      \"source_db\": \"BIOGRID\",\n",
      "                      \"agents\": {\n",
      "                       \"raw_text\": [\n",
      "                        null,\n",
      "                        null\n",
      "                       ]\n",
      "                      },\n",
      "                      \"prior_uuids\": [\n",
      "                       \"6593f025-fcb7-44a4-946f-bc57eb31bab6\"\n",
      "                      ]\n",
      "                     },\n",
      "         text_refs={\n",
      "                    \"PMID\": \"11313979\"\n",
      "                   }\n",
      "         )\n",
      "\n",
      "\n",
      "Generating prompts...:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4/5 [00:09<00:02,  2.06s/it]INFO: [2025-07-01 16:01:21] indra_gpt.chat_curate.chat_curate - Skipping agent glycoprotein() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "INFO: [2025-07-01 16:01:21] indra_gpt.chat_curate.chat_curate - Skipping agent glycoprotein() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "Generating prompts...: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:11<00:00,  2.21s/it]\n",
      "Sending prompts to LLM:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[92m16:01:22 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:01:22] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:01:23] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:01:23 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:01:23] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:01:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:01:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:01:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:01:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:01:23 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:01:23] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:01:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:01:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:01:24] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:01:24 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:01:24] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:01:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:01:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:01:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Sending prompts to LLM:  20%|‚ñà‚ñà        | 1/5 [00:01<00:06,  1.66s/it]INFO: [2025-07-01 16:01:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:01:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:01:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:01:24 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:01:24] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:01:25] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:01:25 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:01:25] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:01:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:01:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:01:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Sending prompts to LLM:  40%|‚ñà‚ñà‚ñà‚ñà      | 2/5 [00:02<00:03,  1.08s/it]INFO: [2025-07-01 16:01:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:01:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:01:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:01:25 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:01:25] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:01:25] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:01:25 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:01:25] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:01:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:01:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:01:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:01:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:01:25 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:01:25] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:01:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:01:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:01:26] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:01:26 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:01:26] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:01:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:01:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:01:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Sending prompts to LLM:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3/5 [00:03<00:02,  1.19s/it]INFO: [2025-07-01 16:01:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:01:26 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:01:26] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:01:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:01:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:01:27] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:01:27 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:01:27] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:01:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:01:27] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:01:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:01:27] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:01:27 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:01:27] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:01:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:01:27] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:01:27] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:01:27 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:01:27] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:01:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:01:27] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:01:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Sending prompts to LLM:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4/5 [00:05<00:01,  1.25s/it]INFO: [2025-07-01 16:01:27] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:01:27 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:01:27] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:01:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:01:27] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:01:28] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:01:28 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:01:28] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:01:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:01:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:01:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:01:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:01:28 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:01:28] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:01:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:01:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:01:29] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:01:29 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:01:29] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:01:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:01:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:01:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Sending prompts to LLM: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:06<00:00,  1.29s/it]INFO: [2025-07-01 16:01:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Sending prompts to LLM: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:06<00:00,  1.27s/it]\u001b[92m16:01:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\n",
      "INFO: [2025-07-01 16:01:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Aggregating results: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 62601.55it/s]\n",
      "Generating prompts...:  20%|‚ñà‚ñà        | 1/5 [00:07<00:31,  7.79s/it]INFO: [2025-07-01 16:02:22] indra_gpt.chat_curate.chat_curate - Skipping evidence with no text for statement -2182577807754994: Evidence(source_api='biogrid',\n",
      "         pmid='11313979',\n",
      "         source_id='327840',\n",
      "         annotations={\n",
      "                      \"biogrid_int_id\": \"327840\",\n",
      "                      \"entrez_a\": \"5111\",\n",
      "                      \"entrez_b\": \"1026\",\n",
      "                      \"biogrid_a\": \"111142\",\n",
      "                      \"biogrid_b\": \"107460\",\n",
      "                      \"syst_name_a\": null,\n",
      "                      \"syst_name_b\": null,\n",
      "                      \"hgnc_a\": \"PCNA\",\n",
      "                      \"hgnc_b\": \"CDKN1A\",\n",
      "                      \"syn_a\": \"ATLD2\",\n",
      "                      \"syn_b\": \"CAP20|CDKN1|CIP1|MDA-6|P21|SDI1|WAF1|p21CIP1\",\n",
      "                      \"exp_system\": \"Two-hybrid\",\n",
      "                      \"exp_system_type\": \"physical\",\n",
      "                      \"author\": \"Yu P (2001)\",\n",
      "                      \"pmid\": \"11313979\",\n",
      "                      \"organism_a\": \"9606\",\n",
      "                      \"organism_b\": \"9606\",\n",
      "                      \"throughput\": \"Low Throughput\",\n",
      "                      \"score\": null,\n",
      "                      \"modification\": null,\n",
      "                      \"phenotypes\": null,\n",
      "                      \"qualifications\": null,\n",
      "                      \"tags\": null,\n",
      "                      \"source_db\": \"BIOGRID\",\n",
      "                      \"agents\": {\n",
      "                       \"raw_text\": [\n",
      "                        null,\n",
      "                        null\n",
      "                       ]\n",
      "                      },\n",
      "                      \"prior_uuids\": [\n",
      "                       \"6593f025-fcb7-44a4-946f-bc57eb31bab6\"\n",
      "                      ]\n",
      "                     },\n",
      "         text_refs={\n",
      "                    \"PMID\": \"11313979\"\n",
      "                   }\n",
      "         )\n",
      "\n",
      "\n",
      "Generating prompts...:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4/5 [00:19<00:04,  4.44s/it]INFO: [2025-07-01 16:02:30] indra_gpt.chat_curate.chat_curate - Skipping agent glycoprotein() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "INFO: [2025-07-01 16:02:31] indra_gpt.chat_curate.chat_curate - Skipping agent glycoprotein() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "INFO: [2025-07-01 16:02:32] indra_gpt.chat_curate.chat_curate - Skipping agent glycoprotein() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "INFO: [2025-07-01 16:02:33] indra_gpt.chat_curate.chat_curate - Skipping agent glycoprotein() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "Generating prompts...: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:23<00:00,  4.73s/it]\n",
      "Sending prompts to LLM:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[92m16:02:34 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:02:34] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:02:35] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:02:35 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:02:35] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:02:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:02:35] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:02:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:02:35] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:02:35 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:02:35] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:02:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:02:35] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:02:35] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:02:35 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:02:35] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:02:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:02:35] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:02:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:02:35] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:02:35 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:02:35] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:02:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:02:35] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:02:36] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:02:36 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:02:36] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:02:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:02:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:02:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:02:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:02:36 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:02:36] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:02:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:02:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:02:37] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:02:37 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:02:37] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:02:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:02:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:02:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Sending prompts to LLM:  20%|‚ñà‚ñà        | 1/5 [00:02<00:11,  2.88s/it]INFO: [2025-07-01 16:02:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:02:37 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:02:37] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:02:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:02:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:02:38] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:02:38 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:02:38] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:02:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:02:38] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:02:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:02:38] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:02:38 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:02:38] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:02:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:02:38] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:02:39] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:02:39 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:02:39] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:02:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:02:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:02:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:02:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:02:39 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:02:39] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:02:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:02:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:02:39] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:02:39 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:02:39] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:02:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:02:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:02:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Sending prompts to LLM:  40%|‚ñà‚ñà‚ñà‚ñà      | 2/5 [00:05<00:07,  2.57s/it]INFO: [2025-07-01 16:02:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:02:39 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:02:39] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:02:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:02:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:02:40] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:02:40 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:02:40] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:02:40 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:02:40] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:02:40 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:02:40] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:02:40 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:02:40] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:02:40 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:02:40] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:02:40] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:02:40 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:02:40] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:02:40 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:02:40] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:02:40 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:02:40] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:02:40 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:02:40] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:02:40 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:02:40] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:02:41] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:02:41 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:02:41] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:02:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:02:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:02:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:02:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:02:41 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:02:41] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:02:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:02:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:02:42] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:02:42 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:02:42] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:02:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:02:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:02:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Sending prompts to LLM:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3/5 [00:07<00:04,  2.45s/it]INFO: [2025-07-01 16:02:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:02:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:02:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:02:42 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:02:42] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:02:42] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:02:42 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:02:42] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:02:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:02:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:02:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:02:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:02:42 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:02:42] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:02:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:02:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:02:43] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:02:43 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:02:43] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:02:43 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:02:43] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:02:43 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:02:43] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:02:43 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:02:43] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:02:43 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:02:43] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:02:44] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:02:44 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:02:44] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:02:44 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:02:44] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:02:44 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:02:44] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:02:44 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:02:44] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:02:44 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:02:44] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:02:44] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:02:44 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:02:44] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:02:44 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:02:44] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:02:44 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Sending prompts to LLM:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4/5 [00:10<00:02,  2.61s/it]INFO: [2025-07-01 16:02:44] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:02:44 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:02:44] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:02:44 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:02:44] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:02:45] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:02:45 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:02:45] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:02:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:02:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:02:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:02:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:02:45 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:02:45] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:02:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:02:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:02:46] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:02:46 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:02:46] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:02:46 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:02:46] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:02:46 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:02:46] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:02:46 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:02:46] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:02:46 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:02:46] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:02:47] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:02:47 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:02:47] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:02:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:02:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:02:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:02:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:02:47 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:02:47] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:02:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:02:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:02:47] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:02:47 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:02:47] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:02:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:02:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:02:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Sending prompts to LLM: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:13<00:00,  2.73s/it]INFO: [2025-07-01 16:02:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Sending prompts to LLM: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:13<00:00,  2.67s/it]\u001b[92m16:02:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\n",
      "INFO: [2025-07-01 16:02:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Aggregating results: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 119156.36it/s]\n",
      "Generating prompts...:  20%|‚ñà‚ñà        | 1/5 [00:07<00:31,  7.84s/it]INFO: [2025-07-01 16:03:46] indra_gpt.chat_curate.chat_curate - Skipping evidence with no text for statement -2182577807754994: Evidence(source_api='biogrid',\n",
      "         pmid='11313979',\n",
      "         source_id='327840',\n",
      "         annotations={\n",
      "                      \"biogrid_int_id\": \"327840\",\n",
      "                      \"entrez_a\": \"5111\",\n",
      "                      \"entrez_b\": \"1026\",\n",
      "                      \"biogrid_a\": \"111142\",\n",
      "                      \"biogrid_b\": \"107460\",\n",
      "                      \"syst_name_a\": null,\n",
      "                      \"syst_name_b\": null,\n",
      "                      \"hgnc_a\": \"PCNA\",\n",
      "                      \"hgnc_b\": \"CDKN1A\",\n",
      "                      \"syn_a\": \"ATLD2\",\n",
      "                      \"syn_b\": \"CAP20|CDKN1|CIP1|MDA-6|P21|SDI1|WAF1|p21CIP1\",\n",
      "                      \"exp_system\": \"Two-hybrid\",\n",
      "                      \"exp_system_type\": \"physical\",\n",
      "                      \"author\": \"Yu P (2001)\",\n",
      "                      \"pmid\": \"11313979\",\n",
      "                      \"organism_a\": \"9606\",\n",
      "                      \"organism_b\": \"9606\",\n",
      "                      \"throughput\": \"Low Throughput\",\n",
      "                      \"score\": null,\n",
      "                      \"modification\": null,\n",
      "                      \"phenotypes\": null,\n",
      "                      \"qualifications\": null,\n",
      "                      \"tags\": null,\n",
      "                      \"source_db\": \"BIOGRID\",\n",
      "                      \"agents\": {\n",
      "                       \"raw_text\": [\n",
      "                        null,\n",
      "                        null\n",
      "                       ]\n",
      "                      },\n",
      "                      \"prior_uuids\": [\n",
      "                       \"6593f025-fcb7-44a4-946f-bc57eb31bab6\"\n",
      "                      ]\n",
      "                     },\n",
      "         text_refs={\n",
      "                    \"PMID\": \"11313979\"\n",
      "                   }\n",
      "         )\n",
      "\n",
      "\n",
      "Generating prompts...:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4/5 [00:19<00:04,  4.45s/it]INFO: [2025-07-01 16:03:54] indra_gpt.chat_curate.chat_curate - Skipping agent glycoprotein() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "INFO: [2025-07-01 16:03:55] indra_gpt.chat_curate.chat_curate - Skipping agent glycoprotein() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "INFO: [2025-07-01 16:03:56] indra_gpt.chat_curate.chat_curate - Skipping agent glycoprotein() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "INFO: [2025-07-01 16:03:57] indra_gpt.chat_curate.chat_curate - Skipping agent glycoprotein() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "Generating prompts...: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:23<00:00,  4.76s/it]\n",
      "Sending prompts to LLM:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[92m16:03:58 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:03:58] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:03:58] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:03:58 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:03:58] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:03:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:03:59] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:03:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:03:59] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:03:59 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:03:59] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:03:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:03:59] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:04:00] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:04:00 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:04:00] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:04:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:04:00] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:04:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:04:00] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:04:00 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:04:00] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:04:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:04:00] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:04:02] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:04:02 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:04:02] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:04:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:04:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:04:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:04:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:04:02 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:04:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:04:02] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:04:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:04:03] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:04:03 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:04:03] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:04:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:04:03] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:04:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Sending prompts to LLM:  20%|‚ñà‚ñà        | 1/5 [00:04<00:19,  4.93s/it]INFO: [2025-07-01 16:04:03] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:04:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:04:03] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:04:03 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:04:03] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:04:04] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:04:04 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:04:04] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:04:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:04:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:04:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:04:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:04:04 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:04:04] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:04:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:04:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:04:04] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:04:04 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:04:04] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:04:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:04:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:04:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:04:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:04:04 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:04:04] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:04:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:04:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:04:06] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:04:06 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:04:06] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:04:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:04:06] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:04:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Sending prompts to LLM:  40%|‚ñà‚ñà‚ñà‚ñà      | 2/5 [00:07<00:11,  3.79s/it]INFO: [2025-07-01 16:04:06] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:04:06 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:04:06] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:04:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:04:06] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:04:06] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:04:06 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:04:06] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:04:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:04:06] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:04:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:04:06] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:04:06 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:04:06] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:04:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:04:06] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:04:07] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:04:07 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:04:07] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:04:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:04:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:04:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:04:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:04:07 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:04:07] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:04:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:04:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:04:08] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:04:08 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:04:08] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:04:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:04:08] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:04:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:04:08] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:04:08 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:04:08] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:04:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:04:08] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:04:08] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:04:08 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:04:08] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:04:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:04:08] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:04:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Sending prompts to LLM:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3/5 [00:10<00:06,  3.27s/it]INFO: [2025-07-01 16:04:08] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:04:08 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:04:08] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:04:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:04:08] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:04:09] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:04:09 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:04:09] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:04:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:04:09] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:04:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:04:09] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:04:09 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:04:09] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:04:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:04:09] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:04:10] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:04:10 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:04:10] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:04:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:04:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:04:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:04:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:04:10 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:04:10] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:04:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:04:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:04:11] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:04:11 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:04:11] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:04:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:04:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:04:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:04:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:04:11 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:04:11] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:04:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:04:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:04:12] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:04:12 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:04:12] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:04:12 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:04:12] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:04:12 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Sending prompts to LLM:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4/5 [00:13<00:03,  3.18s/it]INFO: [2025-07-01 16:04:12] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:04:12 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:04:12 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:04:12] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:04:12] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:04:12] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:04:12 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:04:12] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:04:12 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:04:12] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:04:12 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:04:12] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:04:12 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:04:12] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:04:12 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:04:12] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:04:13] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:04:13 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:04:13] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:04:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:04:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:04:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:04:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:04:13 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:04:13] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:04:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:04:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:04:14] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:04:14 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:04:14] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:04:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:04:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:04:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:04:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:04:14 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:04:14] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:04:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:04:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:04:14] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:04:14 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:04:14] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:04:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:04:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:04:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Sending prompts to LLM: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:16<00:00,  3.00s/it]INFO: [2025-07-01 16:04:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Sending prompts to LLM: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:16<00:00,  3.26s/it]\u001b[92m16:04:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\n",
      "INFO: [2025-07-01 16:04:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Aggregating results: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 113359.57it/s]\n",
      "Generating prompts...:  20%|‚ñà‚ñà        | 1/5 [00:11<00:46, 11.66s/it]INFO: [2025-07-01 16:05:17] indra_gpt.chat_curate.chat_curate - Skipping evidence with no text for statement -2182577807754994: Evidence(source_api='biogrid',\n",
      "         pmid='11313979',\n",
      "         source_id='327840',\n",
      "         annotations={\n",
      "                      \"biogrid_int_id\": \"327840\",\n",
      "                      \"entrez_a\": \"5111\",\n",
      "                      \"entrez_b\": \"1026\",\n",
      "                      \"biogrid_a\": \"111142\",\n",
      "                      \"biogrid_b\": \"107460\",\n",
      "                      \"syst_name_a\": null,\n",
      "                      \"syst_name_b\": null,\n",
      "                      \"hgnc_a\": \"PCNA\",\n",
      "                      \"hgnc_b\": \"CDKN1A\",\n",
      "                      \"syn_a\": \"ATLD2\",\n",
      "                      \"syn_b\": \"CAP20|CDKN1|CIP1|MDA-6|P21|SDI1|WAF1|p21CIP1\",\n",
      "                      \"exp_system\": \"Two-hybrid\",\n",
      "                      \"exp_system_type\": \"physical\",\n",
      "                      \"author\": \"Yu P (2001)\",\n",
      "                      \"pmid\": \"11313979\",\n",
      "                      \"organism_a\": \"9606\",\n",
      "                      \"organism_b\": \"9606\",\n",
      "                      \"throughput\": \"Low Throughput\",\n",
      "                      \"score\": null,\n",
      "                      \"modification\": null,\n",
      "                      \"phenotypes\": null,\n",
      "                      \"qualifications\": null,\n",
      "                      \"tags\": null,\n",
      "                      \"source_db\": \"BIOGRID\",\n",
      "                      \"agents\": {\n",
      "                       \"raw_text\": [\n",
      "                        null,\n",
      "                        null\n",
      "                       ]\n",
      "                      },\n",
      "                      \"prior_uuids\": [\n",
      "                       \"6593f025-fcb7-44a4-946f-bc57eb31bab6\"\n",
      "                      ]\n",
      "                     },\n",
      "         text_refs={\n",
      "                    \"PMID\": \"11313979\"\n",
      "                   }\n",
      "         )\n",
      "\n",
      "\n",
      "Generating prompts...:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4/5 [00:30<00:06,  6.82s/it]INFO: [2025-07-01 16:05:26] indra_gpt.chat_curate.chat_curate - Skipping agent glycoprotein() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "INFO: [2025-07-01 16:05:27] indra_gpt.chat_curate.chat_curate - Skipping agent glycoprotein() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "INFO: [2025-07-01 16:05:28] indra_gpt.chat_curate.chat_curate - Skipping agent glycoprotein() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "INFO: [2025-07-01 16:05:29] indra_gpt.chat_curate.chat_curate - Skipping agent glycoprotein() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "INFO: [2025-07-01 16:05:30] indra_gpt.chat_curate.chat_curate - Skipping agent glycoprotein() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "INFO: [2025-07-01 16:05:31] indra_gpt.chat_curate.chat_curate - Skipping agent glycoprotein() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "Generating prompts...: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:36<00:00,  7.29s/it]\n",
      "Sending prompts to LLM:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[92m16:05:32 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:05:32] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:05:33] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:05:33 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:05:33] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:05:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:05:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:05:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:05:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:05:33 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:05:33] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:05:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:05:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:05:34] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:05:34 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:05:34] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:05:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:05:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:05:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:05:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:05:34 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:05:34] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:05:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:05:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:05:35] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:05:35 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:05:35] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:05:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:05:35] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:05:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:05:35] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:05:35 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:05:35] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:05:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:05:35] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:05:36] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:05:36 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:05:36] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:05:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:05:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:05:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:05:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:05:36 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:05:36] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:05:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:05:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:05:37] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:05:37 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:05:37] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:05:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:05:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:05:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:05:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:05:37 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:05:37] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:05:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:05:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:05:37] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:05:37 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:05:37] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:05:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:05:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:05:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Sending prompts to LLM:  20%|‚ñà‚ñà        | 1/5 [00:05<00:22,  5.64s/it]INFO: [2025-07-01 16:05:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:05:37 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:05:37] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:05:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:05:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:05:38] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:05:38 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:05:38] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:05:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:05:38] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:05:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:05:38] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:05:38 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:05:38] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:05:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:05:38] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:05:39] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:05:39 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:05:39] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:05:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:05:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:05:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:05:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:05:39 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:05:39] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:05:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:05:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:05:39] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:05:39 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:05:39] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:05:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:05:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:05:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:05:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:05:39 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:05:39] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:05:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:05:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:05:40] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:05:40 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:05:40] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:05:40 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:05:40] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:05:40 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:05:40] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:05:40 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:05:40] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:05:40 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:05:40] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:05:41] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:05:41 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:05:41] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:05:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:05:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:05:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Sending prompts to LLM:  40%|‚ñà‚ñà‚ñà‚ñà      | 2/5 [00:08<00:12,  4.20s/it]INFO: [2025-07-01 16:05:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:05:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:05:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:05:41 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:05:41] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:05:41] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:05:41 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:05:41] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:05:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:05:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:05:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:05:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:05:41 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:05:41] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:05:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:05:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:05:42] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:05:42 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:05:42] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:05:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:05:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:05:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:05:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:05:42 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:05:42] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:05:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:05:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:05:43] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:05:43 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:05:43] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:05:43 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:05:43] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:05:43 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:05:43] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:05:43 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:05:43] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:05:43 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:05:43] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:05:43] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:05:43 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:05:43] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:05:43 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:05:43] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:05:43 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:05:43] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:05:43 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:05:43] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:05:43 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:05:43] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:05:44] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:05:44 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:05:44] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:05:44 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:05:44] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:05:44 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:05:44] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:05:44 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:05:44] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:05:44 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:05:44] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:05:45] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:05:45 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:05:45] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:05:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:05:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:05:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Sending prompts to LLM:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3/5 [00:12<00:08,  4.14s/it]INFO: [2025-07-01 16:05:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:05:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:05:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:05:45 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:05:45] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:05:45] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:05:45 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:05:45] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:05:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:05:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:05:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:05:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:05:45 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:05:45] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:05:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:05:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:05:47] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:05:47 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:05:47] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:05:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:05:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:05:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:05:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:05:47 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:05:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:05:47] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:05:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:05:47] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:05:47 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:05:47] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:05:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:05:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:05:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:05:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:05:47 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:05:47] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:05:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:05:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:05:48] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:05:48 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:05:48] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:05:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:05:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:05:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:05:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:05:48 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:05:48] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:05:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:05:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:05:49] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:05:49 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:05:49] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:05:49 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:05:49] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:05:49 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:05:49 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:05:49] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:05:49 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:05:49] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:05:49] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:05:50] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:05:50 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:05:50] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:05:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:05:50] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:05:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Sending prompts to LLM:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4/5 [00:17<00:04,  4.44s/it]INFO: [2025-07-01 16:05:50] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:05:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:05:50] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:05:50 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:05:50] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:05:50] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:05:50 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:05:50] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:05:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:05:50] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:05:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:05:50] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:05:50 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:05:50] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:05:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:05:50] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:05:51] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:05:51 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:05:51] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:05:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:05:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:05:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:05:51 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:05:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:05:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:05:51] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:05:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:05:51] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:05:51 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:05:51] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:05:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:05:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:05:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:05:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:05:51 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:05:51] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:05:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:05:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:05:52] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:05:52 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:05:52] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:05:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:05:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:05:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:05:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:05:52 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:05:52] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:05:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:05:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:05:53] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:05:53 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:05:53] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:05:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:05:53] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:05:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:05:53] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:05:53 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:05:53] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:05:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:05:53] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:05:54] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:05:54 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:05:54] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:05:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:05:54] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:05:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Sending prompts to LLM: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:21<00:00,  4.32s/it]INFO: [2025-07-01 16:05:54] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Sending prompts to LLM: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:21<00:00,  4.39s/it]\u001b[92m16:05:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\n",
      "INFO: [2025-07-01 16:05:54] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Aggregating results: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 48657.82it/s]\n",
      "Generating prompts...:  20%|‚ñà‚ñà        | 1/5 [00:11<00:46, 11.74s/it]INFO: [2025-07-01 16:07:02] indra_gpt.chat_curate.chat_curate - Skipping evidence with no text for statement -2182577807754994: Evidence(source_api='biogrid',\n",
      "         pmid='11313979',\n",
      "         source_id='327840',\n",
      "         annotations={\n",
      "                      \"biogrid_int_id\": \"327840\",\n",
      "                      \"entrez_a\": \"5111\",\n",
      "                      \"entrez_b\": \"1026\",\n",
      "                      \"biogrid_a\": \"111142\",\n",
      "                      \"biogrid_b\": \"107460\",\n",
      "                      \"syst_name_a\": null,\n",
      "                      \"syst_name_b\": null,\n",
      "                      \"hgnc_a\": \"PCNA\",\n",
      "                      \"hgnc_b\": \"CDKN1A\",\n",
      "                      \"syn_a\": \"ATLD2\",\n",
      "                      \"syn_b\": \"CAP20|CDKN1|CIP1|MDA-6|P21|SDI1|WAF1|p21CIP1\",\n",
      "                      \"exp_system\": \"Two-hybrid\",\n",
      "                      \"exp_system_type\": \"physical\",\n",
      "                      \"author\": \"Yu P (2001)\",\n",
      "                      \"pmid\": \"11313979\",\n",
      "                      \"organism_a\": \"9606\",\n",
      "                      \"organism_b\": \"9606\",\n",
      "                      \"throughput\": \"Low Throughput\",\n",
      "                      \"score\": null,\n",
      "                      \"modification\": null,\n",
      "                      \"phenotypes\": null,\n",
      "                      \"qualifications\": null,\n",
      "                      \"tags\": null,\n",
      "                      \"source_db\": \"BIOGRID\",\n",
      "                      \"agents\": {\n",
      "                       \"raw_text\": [\n",
      "                        null,\n",
      "                        null\n",
      "                       ]\n",
      "                      },\n",
      "                      \"prior_uuids\": [\n",
      "                       \"6593f025-fcb7-44a4-946f-bc57eb31bab6\"\n",
      "                      ]\n",
      "                     },\n",
      "         text_refs={\n",
      "                    \"PMID\": \"11313979\"\n",
      "                   }\n",
      "         )\n",
      "\n",
      "\n",
      "Generating prompts...:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4/5 [00:30<00:06,  6.87s/it]INFO: [2025-07-01 16:07:11] indra_gpt.chat_curate.chat_curate - Skipping agent glycoprotein() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "INFO: [2025-07-01 16:07:12] indra_gpt.chat_curate.chat_curate - Skipping agent glycoprotein() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "INFO: [2025-07-01 16:07:13] indra_gpt.chat_curate.chat_curate - Skipping agent glycoprotein() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "INFO: [2025-07-01 16:07:14] indra_gpt.chat_curate.chat_curate - Skipping agent glycoprotein() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "INFO: [2025-07-01 16:07:15] indra_gpt.chat_curate.chat_curate - Skipping agent glycoprotein() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "INFO: [2025-07-01 16:07:16] indra_gpt.chat_curate.chat_curate - Skipping agent glycoprotein() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "Generating prompts...: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:36<00:00,  7.34s/it]\n",
      "Sending prompts to LLM:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[92m16:07:17 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:07:17] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:07:17] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:07:17 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:07:17] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:07:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:07:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:07:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:07:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:07:17 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:07:17] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:07:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:07:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:07:18] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:07:18 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:07:18] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:07:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:07:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:07:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:07:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:07:18 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:07:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:07:18] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:07:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:07:19] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:07:19 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:07:19] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:07:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:07:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:07:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:07:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:07:19 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:07:19] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:07:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:07:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:07:19] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:07:19 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:07:19] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:07:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:07:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:07:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:07:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:07:19 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:07:19] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:07:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:07:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:07:20] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:07:20 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:07:20] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:07:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:07:20] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:07:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:07:20] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:07:20 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:07:20] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:07:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:07:20] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:07:21] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:07:21 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:07:21] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:07:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:07:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:07:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Sending prompts to LLM:  20%|‚ñà‚ñà        | 1/5 [00:04<00:16,  4.03s/it]INFO: [2025-07-01 16:07:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:07:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:07:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:07:21 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:07:21] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:07:21] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:07:21 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:07:21] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:07:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:07:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:07:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:07:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:07:21 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:07:21] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:07:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:07:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:07:22] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:07:22 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:07:22] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:07:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:07:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:07:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:07:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:07:22 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:07:22] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:07:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:07:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:07:23] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:07:23 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:07:23] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:07:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:07:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:07:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:07:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:07:23 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:07:23] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:07:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:07:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:07:24] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:07:24 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:07:24] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:07:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:07:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:07:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:07:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:07:24 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:07:24] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:07:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:07:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:07:24] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:07:24 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:07:24] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:07:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:07:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:07:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Sending prompts to LLM:  40%|‚ñà‚ñà‚ñà‚ñà      | 2/5 [00:07<00:11,  3.67s/it]INFO: [2025-07-01 16:07:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:07:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:07:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:07:24 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:07:24] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:07:25] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:07:25 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:07:25] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:07:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:07:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:07:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:07:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:07:25 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:07:25] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:07:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:07:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:07:27] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:07:27 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:07:27] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:07:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:07:27] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:07:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:07:27] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:07:27 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:07:27] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:07:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:07:27] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:07:27] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:07:27 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:07:27] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:07:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:07:27] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:07:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:07:27] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:07:27 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:07:27] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:07:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:07:27] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:07:28] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:07:28 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:07:28] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:07:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:07:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:07:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:07:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:07:28 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:07:28] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:07:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:07:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:07:29] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:07:29 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:07:29] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:07:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:07:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:07:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:07:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:07:29 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:07:29] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:07:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:07:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:07:30] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:07:30 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:07:30] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:07:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:07:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:07:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Sending prompts to LLM:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3/5 [00:12<00:08,  4.44s/it]INFO: [2025-07-01 16:07:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:07:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:07:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:07:30 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:07:30] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:07:30] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:07:30 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:07:30] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:07:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:07:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:07:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:07:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:07:30 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:07:30] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:07:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:07:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:07:31] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:07:31 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:07:31] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:07:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:07:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:07:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:07:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:07:31 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:07:31] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:07:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:07:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:07:32] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:07:32 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:07:32] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:07:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:07:32] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:07:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:07:32] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:07:32 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:07:32] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:07:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:07:32] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:07:33] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:07:33 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:07:33] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:07:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:07:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:07:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:07:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:07:33 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:07:33] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:07:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:07:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:07:33] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:07:33 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:07:33] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:07:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:07:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:07:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:07:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:07:33 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:07:33] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:07:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:07:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:07:34] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:07:34 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:07:34] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:07:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:07:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:07:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Sending prompts to LLM:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4/5 [00:17<00:04,  4.39s/it]INFO: [2025-07-01 16:07:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:07:34 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:07:34] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:07:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:07:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:07:35] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:07:35 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:07:35] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:07:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:07:35] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:07:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:07:35] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:07:35 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:07:35] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:07:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:07:35] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:07:35] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:07:35 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:07:35] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:07:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:07:35] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:07:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:07:35] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:07:35 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:07:35] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:07:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:07:35] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:07:36] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:07:36 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:07:36] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:07:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:07:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:07:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:07:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:07:36 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:07:36] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:07:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:07:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:07:37] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:07:37 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:07:37] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:07:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:07:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:07:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:07:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:07:37 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:07:37] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:07:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:07:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:07:37] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:07:37 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:07:37] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:07:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:07:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:07:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:07:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:07:37 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:07:37] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:07:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:07:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:07:38] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:07:38 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:07:38] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:07:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:07:38] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:07:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Sending prompts to LLM: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:21<00:00,  4.30s/it]INFO: [2025-07-01 16:07:38] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Sending prompts to LLM: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:21<00:00,  4.25s/it]\u001b[92m16:07:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:07:38] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\n",
      "Aggregating results: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 56073.58it/s]\n",
      "Generating prompts...:  20%|‚ñà‚ñà        | 1/5 [00:15<01:02, 15.72s/it]INFO: [2025-07-01 16:08:49] indra_gpt.chat_curate.chat_curate - Skipping evidence with no text for statement -2182577807754994: Evidence(source_api='biogrid',\n",
      "         pmid='11313979',\n",
      "         source_id='327840',\n",
      "         annotations={\n",
      "                      \"biogrid_int_id\": \"327840\",\n",
      "                      \"entrez_a\": \"5111\",\n",
      "                      \"entrez_b\": \"1026\",\n",
      "                      \"biogrid_a\": \"111142\",\n",
      "                      \"biogrid_b\": \"107460\",\n",
      "                      \"syst_name_a\": null,\n",
      "                      \"syst_name_b\": null,\n",
      "                      \"hgnc_a\": \"PCNA\",\n",
      "                      \"hgnc_b\": \"CDKN1A\",\n",
      "                      \"syn_a\": \"ATLD2\",\n",
      "                      \"syn_b\": \"CAP20|CDKN1|CIP1|MDA-6|P21|SDI1|WAF1|p21CIP1\",\n",
      "                      \"exp_system\": \"Two-hybrid\",\n",
      "                      \"exp_system_type\": \"physical\",\n",
      "                      \"author\": \"Yu P (2001)\",\n",
      "                      \"pmid\": \"11313979\",\n",
      "                      \"organism_a\": \"9606\",\n",
      "                      \"organism_b\": \"9606\",\n",
      "                      \"throughput\": \"Low Throughput\",\n",
      "                      \"score\": null,\n",
      "                      \"modification\": null,\n",
      "                      \"phenotypes\": null,\n",
      "                      \"qualifications\": null,\n",
      "                      \"tags\": null,\n",
      "                      \"source_db\": \"BIOGRID\",\n",
      "                      \"agents\": {\n",
      "                       \"raw_text\": [\n",
      "                        null,\n",
      "                        null\n",
      "                       ]\n",
      "                      },\n",
      "                      \"prior_uuids\": [\n",
      "                       \"6593f025-fcb7-44a4-946f-bc57eb31bab6\"\n",
      "                      ]\n",
      "                     },\n",
      "         text_refs={\n",
      "                    \"PMID\": \"11313979\"\n",
      "                   }\n",
      "         )\n",
      "\n",
      "\n",
      "Generating prompts...:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4/5 [00:41<00:09,  9.39s/it]INFO: [2025-07-01 16:09:01] indra_gpt.chat_curate.chat_curate - Skipping agent glycoprotein() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "INFO: [2025-07-01 16:09:02] indra_gpt.chat_curate.chat_curate - Skipping agent glycoprotein() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "INFO: [2025-07-01 16:09:03] indra_gpt.chat_curate.chat_curate - Skipping agent glycoprotein() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "INFO: [2025-07-01 16:09:04] indra_gpt.chat_curate.chat_curate - Skipping agent glycoprotein() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "INFO: [2025-07-01 16:09:05] indra_gpt.chat_curate.chat_curate - Skipping agent glycoprotein() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "INFO: [2025-07-01 16:09:06] indra_gpt.chat_curate.chat_curate - Skipping agent glycoprotein() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "INFO: [2025-07-01 16:09:07] indra_gpt.chat_curate.chat_curate - Skipping agent glycoprotein() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "INFO: [2025-07-01 16:09:08] indra_gpt.chat_curate.chat_curate - Skipping agent glycoprotein() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "Generating prompts...: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:49<00:00,  9.96s/it]\n",
      "Sending prompts to LLM:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[92m16:09:09 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:09:09] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:09:10] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:09:10 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:09:10] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:09:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:09:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:09:10 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:09:10] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:09:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:11] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:09:11 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:09:11] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:09:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:09:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:09:11 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:09:11] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:09:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:11] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:09:11 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:09:11] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:09:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:09:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:09:11 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:09:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:11] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:09:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:12] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:09:12 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:09:12] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:09:12 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:12] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:09:12 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:12] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:09:12 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:09:12] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:09:12 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:12] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:12] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:09:12 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:09:12] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:09:12 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:12] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:09:12 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:12] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:09:12 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:09:12] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:09:12 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:12] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:13] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:09:13 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:09:13] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:09:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:09:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:09:13 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:09:13] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:09:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:14] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:09:14 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:09:14] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:09:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:09:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:09:14 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:09:14] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:09:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:14] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:09:14 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:09:14] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:09:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:09:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Sending prompts to LLM:  20%|‚ñà‚ñà        | 1/5 [00:05<00:20,  5.21s/it]INFO: [2025-07-01 16:09:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:09:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:09:14 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:09:14] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:09:15] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:09:15 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:09:15] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:09:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:15] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:09:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:15] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:09:15 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:09:15] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:09:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:15] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:16] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:09:16 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:09:16] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:09:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:16] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:09:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:16] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:09:16 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:09:16] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:09:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:16] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:16] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:09:16 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:09:16] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:09:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:16] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:09:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:16] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:09:16 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:09:16] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:09:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:16] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:17] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:09:17 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:09:17] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:09:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:09:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:09:17 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:09:17] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:09:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:18] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:09:18 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:09:18] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:09:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:09:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:09:18 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:09:18] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:09:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:18] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:09:18 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:09:18] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:09:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:09:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:09:18 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:09:18] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:09:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:19] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:09:19 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:09:19] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:09:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:09:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Sending prompts to LLM:  40%|‚ñà‚ñà‚ñà‚ñà      | 2/5 [00:09<00:14,  4.80s/it]INFO: [2025-07-01 16:09:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:09:19 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:09:19] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:09:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:19] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:09:19 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:09:19] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:09:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:09:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:09:19 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:09:19] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:09:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:21] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:09:21 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:09:21] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:09:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:09:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:09:21 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:09:21] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:09:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:21] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:09:21 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:09:21] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:09:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:09:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:09:21 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:09:21] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:09:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:22] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:09:22 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:09:22] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:09:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:09:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:09:22 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:09:22] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:09:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:23] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:09:23 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:09:23] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:09:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:09:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:09:23 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:09:23] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:09:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:23] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:09:23 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:09:23] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:09:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:09:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:09:23 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:09:23] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:09:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:24] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:09:24 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:09:24] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:09:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:09:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:09:24 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:09:24] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:09:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:24] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:09:24 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:09:24] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:09:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:09:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Sending prompts to LLM:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3/5 [00:15<00:10,  5.21s/it]INFO: [2025-07-01 16:09:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:09:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:09:24 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:09:24] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:09:25] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:09:25 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:09:25] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:09:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:09:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:09:25 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:09:25] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:09:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:26] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:09:26 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:09:26] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:09:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:09:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:09:26 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:09:26] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:09:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:27] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:09:27 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:09:27] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:09:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:27] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:09:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:27] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:09:27 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:09:27] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:09:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:27] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:28] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:09:28 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:09:28] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:09:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:09:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:09:28 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:09:28] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:09:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:29] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:09:29 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:09:29] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:09:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:09:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:09:29 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:09:29] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:09:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:29] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:09:29 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:09:29] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:09:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:09:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:09:29 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:09:29] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:09:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:30] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:09:30 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:09:30] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:09:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:09:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:09:30 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:09:30] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:09:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:31] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:09:31 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:09:31] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:09:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:09:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Sending prompts to LLM:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4/5 [00:21<00:05,  5.57s/it]INFO: [2025-07-01 16:09:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:09:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:09:31 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:09:31] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:09:31] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:09:31 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:09:31] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:09:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:09:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:09:31 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:09:31] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:09:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:32] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:09:32 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:09:32] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:09:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:32] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:09:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:32] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:09:32 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:09:32] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:09:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:32] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:33] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:09:33 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:09:33] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:09:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:09:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:09:33 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:09:33] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:09:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:34] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:09:34 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:09:34] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:09:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:09:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:09:34 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:09:34] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:09:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:34] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:09:34 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:09:34] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:09:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:09:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:09:34 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:09:34] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:09:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:36] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:09:36 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:09:36] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:09:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:09:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:09:36 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:09:36] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:09:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:37] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:09:37 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:09:37] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:09:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:09:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:09:37 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:09:37] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:09:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:37] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:09:37 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:09:37] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:09:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:09:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:09:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Sending prompts to LLM: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:28<00:00,  6.06s/it]INFO: [2025-07-01 16:09:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Sending prompts to LLM: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:28<00:00,  5.70s/it]\u001b[92m16:09:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\n",
      "INFO: [2025-07-01 16:09:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Aggregating results: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 38130.04it/s]\n",
      "Generating prompts...:  20%|‚ñà‚ñà        | 1/5 [00:15<01:02, 15.66s/it]INFO: [2025-07-01 16:10:53] indra_gpt.chat_curate.chat_curate - Skipping evidence with no text for statement -2182577807754994: Evidence(source_api='biogrid',\n",
      "         pmid='11313979',\n",
      "         source_id='327840',\n",
      "         annotations={\n",
      "                      \"biogrid_int_id\": \"327840\",\n",
      "                      \"entrez_a\": \"5111\",\n",
      "                      \"entrez_b\": \"1026\",\n",
      "                      \"biogrid_a\": \"111142\",\n",
      "                      \"biogrid_b\": \"107460\",\n",
      "                      \"syst_name_a\": null,\n",
      "                      \"syst_name_b\": null,\n",
      "                      \"hgnc_a\": \"PCNA\",\n",
      "                      \"hgnc_b\": \"CDKN1A\",\n",
      "                      \"syn_a\": \"ATLD2\",\n",
      "                      \"syn_b\": \"CAP20|CDKN1|CIP1|MDA-6|P21|SDI1|WAF1|p21CIP1\",\n",
      "                      \"exp_system\": \"Two-hybrid\",\n",
      "                      \"exp_system_type\": \"physical\",\n",
      "                      \"author\": \"Yu P (2001)\",\n",
      "                      \"pmid\": \"11313979\",\n",
      "                      \"organism_a\": \"9606\",\n",
      "                      \"organism_b\": \"9606\",\n",
      "                      \"throughput\": \"Low Throughput\",\n",
      "                      \"score\": null,\n",
      "                      \"modification\": null,\n",
      "                      \"phenotypes\": null,\n",
      "                      \"qualifications\": null,\n",
      "                      \"tags\": null,\n",
      "                      \"source_db\": \"BIOGRID\",\n",
      "                      \"agents\": {\n",
      "                       \"raw_text\": [\n",
      "                        null,\n",
      "                        null\n",
      "                       ]\n",
      "                      },\n",
      "                      \"prior_uuids\": [\n",
      "                       \"6593f025-fcb7-44a4-946f-bc57eb31bab6\"\n",
      "                      ]\n",
      "                     },\n",
      "         text_refs={\n",
      "                    \"PMID\": \"11313979\"\n",
      "                   }\n",
      "         )\n",
      "\n",
      "\n",
      "Generating prompts...:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4/5 [00:41<00:09,  9.31s/it]INFO: [2025-07-01 16:11:05] indra_gpt.chat_curate.chat_curate - Skipping agent glycoprotein() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "INFO: [2025-07-01 16:11:06] indra_gpt.chat_curate.chat_curate - Skipping agent glycoprotein() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "INFO: [2025-07-01 16:11:07] indra_gpt.chat_curate.chat_curate - Skipping agent glycoprotein() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "INFO: [2025-07-01 16:11:08] indra_gpt.chat_curate.chat_curate - Skipping agent glycoprotein() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "INFO: [2025-07-01 16:11:09] indra_gpt.chat_curate.chat_curate - Skipping agent glycoprotein() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "INFO: [2025-07-01 16:11:10] indra_gpt.chat_curate.chat_curate - Skipping agent glycoprotein() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "INFO: [2025-07-01 16:11:11] indra_gpt.chat_curate.chat_curate - Skipping agent glycoprotein() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "INFO: [2025-07-01 16:11:12] indra_gpt.chat_curate.chat_curate - Skipping agent glycoprotein() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "Generating prompts...: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:49<00:00,  9.94s/it]\n",
      "Sending prompts to LLM:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[92m16:11:13 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:11:13] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:11:14] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:11:14 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:11:14] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:11:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:11:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:11:14 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:11:14] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:11:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:15] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:11:15 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:11:15] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:11:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:15] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:11:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:15] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:11:15 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:11:15] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:11:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:15] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:16] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:11:16 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:11:16] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:11:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:16] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:11:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:16] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:11:16 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:11:16] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:11:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:16] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:16] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:11:16 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:11:16] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:11:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:16] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:11:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:16] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:11:16 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:11:16] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:11:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:16] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:17] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:11:17 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:11:17] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:11:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:11:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:11:17 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:11:17] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:11:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:18] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:11:18 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:11:18] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:11:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:11:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:11:18 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:11:18] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:11:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:20] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:11:20 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:11:20] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:11:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:20] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:11:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:20] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:11:20 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:11:20] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:11:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:20] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:20] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:11:20 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:11:20] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:11:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:20] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:11:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Sending prompts to LLM:  20%|‚ñà‚ñà        | 1/5 [00:06<00:27,  6.93s/it]INFO: [2025-07-01 16:11:20] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:11:20 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:11:20] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:11:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:20] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:21] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:11:21 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:11:21] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:11:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:11:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:11:21 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:11:21] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:11:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:22] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:11:22 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:11:22] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:11:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:11:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:11:22 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:11:22] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:11:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:22] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:11:22 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:11:22] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:11:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:11:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:11:22 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:11:22] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:11:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:23] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:11:23 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:11:23] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:11:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:11:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:11:23 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:11:23] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:11:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:24] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:11:24 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:11:24] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:11:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:11:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:11:24 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:11:24] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:11:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:24] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:11:24 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:11:24] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:11:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:11:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:11:24 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:11:24] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:11:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:25] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:11:25 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:11:25] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:11:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:11:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Sending prompts to LLM:  40%|‚ñà‚ñà‚ñà‚ñà      | 2/5 [00:11<00:16,  5.60s/it]INFO: [2025-07-01 16:11:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:11:25 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:11:25] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:11:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:26] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:11:26 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:11:26] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:11:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:11:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:11:26 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:11:26] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:11:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:26] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:11:26 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:11:26] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:11:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:11:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:11:26 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:11:26] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:11:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:27] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:11:27 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:11:27] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:11:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:27] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:11:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:27] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:11:27 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:11:27] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:11:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:27] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:28] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:11:28 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:11:28] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:11:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:11:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:11:28 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:11:28] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:11:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:28] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:11:28 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:11:28] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:11:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:11:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:11:28 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:11:28] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:11:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:29] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:11:29 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:11:29] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:11:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:11:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:11:29 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:11:29] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:11:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:30] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:11:30 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:11:30] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:11:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:11:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:11:30 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:11:30] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:11:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:30] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:11:30 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:11:30] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:11:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:11:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Sending prompts to LLM:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3/5 [00:17<00:11,  5.56s/it]INFO: [2025-07-01 16:11:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:11:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:11:30 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:11:30] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:11:31] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:11:31 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:11:31] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:11:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:11:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:11:31 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:11:31] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:11:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:32] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:11:32 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:11:32] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:11:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:32] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:11:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:32] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:11:32 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:11:32] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:11:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:32] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:32] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:11:32 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:11:32] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:11:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:32] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:11:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:32] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:11:32 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:11:32] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:11:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:32] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:33] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:11:33 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:11:33] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:11:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:11:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:11:33 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:11:33] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:11:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:34] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:11:34 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:11:34] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:11:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:11:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:11:34 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:11:34] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:11:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:35] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:11:35 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:11:35] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:11:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:35] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:11:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:35] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:11:35 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:11:35] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:11:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:35] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:35] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:11:35 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:11:35] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:11:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:35] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:11:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:35] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:11:35 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:11:35] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:11:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:35] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:36] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:11:36 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:11:36] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:11:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:11:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Sending prompts to LLM:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4/5 [00:22<00:05,  5.61s/it]INFO: [2025-07-01 16:11:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:11:36 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:11:36] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:11:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:37] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:11:37 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:11:37] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:11:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:11:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:11:37 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:11:37] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:11:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:37] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:11:37 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:11:37] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:11:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:11:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:11:37 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:11:37] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:11:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:38] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:11:38 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:11:38] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:11:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:38] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:11:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:38] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:11:38 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:11:38] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:11:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:38] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:39] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:11:39 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:11:39] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:11:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:11:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:11:39 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:11:39] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:11:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:39] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:11:39 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:11:39] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:11:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:11:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:11:39 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:11:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:39] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:11:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:40] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:11:40 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:11:40] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:11:40 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:40] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:11:40 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:40] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:11:40 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:11:40] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:11:40 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:40] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:41] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:11:41 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:11:41] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:11:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:11:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:11:41 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:11:41] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:11:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:42] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:11:42 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:11:42] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:11:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:11:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:11:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Sending prompts to LLM: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:28<00:00,  5.64s/it]INFO: [2025-07-01 16:11:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Sending prompts to LLM: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:28<00:00,  5.70s/it]\u001b[92m16:11:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\n",
      "INFO: [2025-07-01 16:11:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Aggregating results: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 51527.08it/s]\n",
      "Generating prompts...:  20%|‚ñà‚ñà        | 1/5 [00:19<01:19, 19.83s/it]INFO: [2025-07-01 16:13:01] indra_gpt.chat_curate.chat_curate - Skipping evidence with no text for statement -2182577807754994: Evidence(source_api='biogrid',\n",
      "         pmid='11313979',\n",
      "         source_id='327840',\n",
      "         annotations={\n",
      "                      \"biogrid_int_id\": \"327840\",\n",
      "                      \"entrez_a\": \"5111\",\n",
      "                      \"entrez_b\": \"1026\",\n",
      "                      \"biogrid_a\": \"111142\",\n",
      "                      \"biogrid_b\": \"107460\",\n",
      "                      \"syst_name_a\": null,\n",
      "                      \"syst_name_b\": null,\n",
      "                      \"hgnc_a\": \"PCNA\",\n",
      "                      \"hgnc_b\": \"CDKN1A\",\n",
      "                      \"syn_a\": \"ATLD2\",\n",
      "                      \"syn_b\": \"CAP20|CDKN1|CIP1|MDA-6|P21|SDI1|WAF1|p21CIP1\",\n",
      "                      \"exp_system\": \"Two-hybrid\",\n",
      "                      \"exp_system_type\": \"physical\",\n",
      "                      \"author\": \"Yu P (2001)\",\n",
      "                      \"pmid\": \"11313979\",\n",
      "                      \"organism_a\": \"9606\",\n",
      "                      \"organism_b\": \"9606\",\n",
      "                      \"throughput\": \"Low Throughput\",\n",
      "                      \"score\": null,\n",
      "                      \"modification\": null,\n",
      "                      \"phenotypes\": null,\n",
      "                      \"qualifications\": null,\n",
      "                      \"tags\": null,\n",
      "                      \"source_db\": \"BIOGRID\",\n",
      "                      \"agents\": {\n",
      "                       \"raw_text\": [\n",
      "                        null,\n",
      "                        null\n",
      "                       ]\n",
      "                      },\n",
      "                      \"prior_uuids\": [\n",
      "                       \"6593f025-fcb7-44a4-946f-bc57eb31bab6\"\n",
      "                      ]\n",
      "                     },\n",
      "         text_refs={\n",
      "                    \"PMID\": \"11313979\"\n",
      "                   }\n",
      "         )\n",
      "\n",
      "\n",
      "Generating prompts...:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4/5 [00:53<00:11, 11.81s/it]INFO: [2025-07-01 16:13:16] indra_gpt.chat_curate.chat_curate - Skipping agent glycoprotein() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "INFO: [2025-07-01 16:13:17] indra_gpt.chat_curate.chat_curate - Skipping agent glycoprotein() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "INFO: [2025-07-01 16:13:18] indra_gpt.chat_curate.chat_curate - Skipping agent glycoprotein() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "INFO: [2025-07-01 16:13:19] indra_gpt.chat_curate.chat_curate - Skipping agent glycoprotein() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "INFO: [2025-07-01 16:13:20] indra_gpt.chat_curate.chat_curate - Skipping agent glycoprotein() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "INFO: [2025-07-01 16:13:21] indra_gpt.chat_curate.chat_curate - Skipping agent glycoprotein() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "INFO: [2025-07-01 16:13:22] indra_gpt.chat_curate.chat_curate - Skipping agent glycoprotein() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "INFO: [2025-07-01 16:13:23] indra_gpt.chat_curate.chat_curate - Skipping agent glycoprotein() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "INFO: [2025-07-01 16:13:24] indra_gpt.chat_curate.chat_curate - Skipping agent glycoprotein() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "INFO: [2025-07-01 16:13:25] indra_gpt.chat_curate.chat_curate - Skipping agent glycoprotein() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "Generating prompts...: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [01:02<00:00, 12.59s/it]\n",
      "Sending prompts to LLM:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[92m16:13:26 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:13:26] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:13:27] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:13:27 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:13:27] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:13:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:27] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:13:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:27] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:13:27 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:13:27] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:13:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:27] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:28] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:13:28 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:13:28] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:13:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:13:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:13:28 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:13:28] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:13:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:28] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:13:28 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:13:28] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:13:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:13:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:13:28 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:13:28] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:13:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:29] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:13:29 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:13:29] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:13:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:13:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:13:29 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:13:29] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:13:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:30] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:13:30 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:13:30] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:13:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:13:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:13:30 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:13:30] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:13:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:31] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:13:31 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:13:31] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:13:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:13:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:13:31 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:13:31] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:13:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:31] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:13:31 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:13:31] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:13:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:13:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:13:31 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:13:31] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:13:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:32] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:13:32 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:13:32] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:13:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:32] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:13:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:32] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:13:32 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:13:32] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:13:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:32] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:34] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:13:34 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:13:34] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:13:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:13:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:13:34 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:13:34] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:13:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:35] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:13:35 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:13:35] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:13:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:35] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:13:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Sending prompts to LLM:  20%|‚ñà‚ñà        | 1/5 [00:08<00:33,  8.40s/it]INFO: [2025-07-01 16:13:35] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:13:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:35] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:13:35 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:13:35] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:13:36] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:13:36 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:13:36] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:13:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:13:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:13:36 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:13:36] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:13:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:36] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:13:36 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:13:36] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:13:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:13:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:13:36 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:13:36] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:13:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:37] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:13:37 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:13:37] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:13:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:13:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:13:37 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:13:37] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:13:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:38] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:13:38 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:13:38] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:13:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:38] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:13:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:38] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:13:38 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:13:38] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:13:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:38] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:38] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:13:38 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:13:38] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:13:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:38] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:13:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:38] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:13:39 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:13:39] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:13:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:39] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:13:39 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:13:39] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:13:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:13:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:13:39 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:13:39] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:13:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:40] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:13:40 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:13:40] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:13:40 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:40] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:13:40 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:40] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:13:40 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:13:40] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:13:40 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:40] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:42] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:13:42 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:13:42] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:13:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:13:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:13:42 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:13:42] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:13:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:42] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:13:42 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:13:42] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:13:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:13:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Sending prompts to LLM:  40%|‚ñà‚ñà‚ñà‚ñà      | 2/5 [00:16<00:24,  8.05s/it]INFO: [2025-07-01 16:13:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:13:42 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:13:42] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:13:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:43] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:13:43 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:13:43] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:13:43 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:43] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:13:43 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:43] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:13:43 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:13:43] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:13:43 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:43] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:44] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:13:44 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:13:44] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:13:44 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:44] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:13:44 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:44] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:13:44 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:13:44] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:13:44 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:44] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:45] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:13:45 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:13:45] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:13:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:13:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:13:45 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:13:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:13:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:45] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:13:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:45] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:13:45 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:13:45] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:13:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:13:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:13:45 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:13:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:45] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:13:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:46] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:13:46 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:13:46] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:13:46 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:46] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:13:46 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:46] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:13:46 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:13:46] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:13:46 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:46] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:46] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:13:46 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:13:46] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:13:46 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:46] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:13:46 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:46] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:13:46 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:13:46] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:13:46 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:46] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:47] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:13:47 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:13:47] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:13:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:13:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:13:47 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:13:47] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:13:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:48] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:13:48 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:13:48] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:13:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:13:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:13:48 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:13:48] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:13:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:49] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:13:49 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:13:49] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:13:49 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:49] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:13:49 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:49] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:13:49 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:13:49] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:13:49 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:49] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:49] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:13:49 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:13:49] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:13:49 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:49] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:13:49 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Sending prompts to LLM:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3/5 [00:23<00:15,  7.55s/it]INFO: [2025-07-01 16:13:49] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:13:49 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:49] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:13:49 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:13:49] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:13:50] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:13:50 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:13:50] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:13:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:50] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:13:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:50] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:13:50 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:13:50] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:13:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:50] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:51] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:13:51 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:13:51] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:13:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:13:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:13:51 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:13:51] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:13:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:51] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:13:51 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:13:51] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:13:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:13:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:13:51 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:13:51] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:13:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:52] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:13:52 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:13:52] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:13:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:13:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:13:52 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:13:52] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:13:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:53] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:13:53 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:13:53] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:13:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:53] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:13:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:53] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:13:53 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:13:53] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:13:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:53] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:53] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:13:53 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:13:53] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:13:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:53] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:13:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:53] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:13:53 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:13:53] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:13:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:53] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:54] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:13:54 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:13:54] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:13:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:54] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:13:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:54] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:13:54 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:13:54] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:13:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:54] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:55] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:13:55 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:13:55] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:13:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:13:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:13:55 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:13:55] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:13:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:55] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:13:55 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:13:55] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:13:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:13:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:13:55 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:13:55] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:13:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:56] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:13:56 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:13:56] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:13:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:56] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:13:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Sending prompts to LLM:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4/5 [00:29<00:07,  7.23s/it]INFO: [2025-07-01 16:13:56] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:13:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:56] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:13:56 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:13:56] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:13:57] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:13:57 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:13:57] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:13:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:57] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:13:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:57] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:13:57 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:13:57] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:13:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:57] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:58] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:13:58 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:13:58] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:13:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:13:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:13:58 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:13:58] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:13:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:58] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:13:58 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:13:58] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:13:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:13:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:13:58 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:13:58] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:13:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:59] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:13:59 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:13:59] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:13:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:59] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:13:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:59] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:13:59 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:13:59] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:13:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:13:59] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:14:00] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:14:00 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:14:00] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:14:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:14:00] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:14:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:14:00] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:14:00 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:14:00] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:14:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:14:00] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:14:01] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:14:01 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:14:01] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:14:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:14:01] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:14:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:14:01] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:14:01 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:14:01] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:14:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:14:01] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:14:01] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:14:01 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:14:01] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:14:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:14:01] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:14:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:14:01] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:14:01 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:14:01] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:14:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:14:01] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:14:02] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:14:02 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:14:02] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:14:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:14:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:14:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:14:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:14:02 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:14:02] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:14:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:14:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:14:02] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:14:03 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:14:03] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:14:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:14:03] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:14:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:14:03] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:14:03 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:14:03] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:14:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:14:03] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:14:03] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:14:03 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:14:03] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:14:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:14:03] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:14:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Sending prompts to LLM: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:37<00:00,  7.21s/it]INFO: [2025-07-01 16:14:03] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:14:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Sending prompts to LLM: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:37<00:00,  7.42s/it]INFO: [2025-07-01 16:14:03] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\n",
      "Aggregating results: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 47233.15it/s]\n",
      "Generating prompts...:  20%|‚ñà‚ñà        | 1/5 [00:19<01:17, 19.43s/it]INFO: [2025-07-01 16:15:27] indra_gpt.chat_curate.chat_curate - Skipping evidence with no text for statement -2182577807754994: Evidence(source_api='biogrid',\n",
      "         pmid='11313979',\n",
      "         source_id='327840',\n",
      "         annotations={\n",
      "                      \"biogrid_int_id\": \"327840\",\n",
      "                      \"entrez_a\": \"5111\",\n",
      "                      \"entrez_b\": \"1026\",\n",
      "                      \"biogrid_a\": \"111142\",\n",
      "                      \"biogrid_b\": \"107460\",\n",
      "                      \"syst_name_a\": null,\n",
      "                      \"syst_name_b\": null,\n",
      "                      \"hgnc_a\": \"PCNA\",\n",
      "                      \"hgnc_b\": \"CDKN1A\",\n",
      "                      \"syn_a\": \"ATLD2\",\n",
      "                      \"syn_b\": \"CAP20|CDKN1|CIP1|MDA-6|P21|SDI1|WAF1|p21CIP1\",\n",
      "                      \"exp_system\": \"Two-hybrid\",\n",
      "                      \"exp_system_type\": \"physical\",\n",
      "                      \"author\": \"Yu P (2001)\",\n",
      "                      \"pmid\": \"11313979\",\n",
      "                      \"organism_a\": \"9606\",\n",
      "                      \"organism_b\": \"9606\",\n",
      "                      \"throughput\": \"Low Throughput\",\n",
      "                      \"score\": null,\n",
      "                      \"modification\": null,\n",
      "                      \"phenotypes\": null,\n",
      "                      \"qualifications\": null,\n",
      "                      \"tags\": null,\n",
      "                      \"source_db\": \"BIOGRID\",\n",
      "                      \"agents\": {\n",
      "                       \"raw_text\": [\n",
      "                        null,\n",
      "                        null\n",
      "                       ]\n",
      "                      },\n",
      "                      \"prior_uuids\": [\n",
      "                       \"6593f025-fcb7-44a4-946f-bc57eb31bab6\"\n",
      "                      ]\n",
      "                     },\n",
      "         text_refs={\n",
      "                    \"PMID\": \"11313979\"\n",
      "                   }\n",
      "         )\n",
      "\n",
      "\n",
      "Generating prompts...:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4/5 [00:52<00:11, 11.77s/it]INFO: [2025-07-01 16:15:43] indra_gpt.chat_curate.chat_curate - Skipping agent glycoprotein() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "INFO: [2025-07-01 16:15:44] indra_gpt.chat_curate.chat_curate - Skipping agent glycoprotein() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "INFO: [2025-07-01 16:15:45] indra_gpt.chat_curate.chat_curate - Skipping agent glycoprotein() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "INFO: [2025-07-01 16:15:46] indra_gpt.chat_curate.chat_curate - Skipping agent glycoprotein() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "INFO: [2025-07-01 16:15:47] indra_gpt.chat_curate.chat_curate - Skipping agent glycoprotein() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "INFO: [2025-07-01 16:15:48] indra_gpt.chat_curate.chat_curate - Skipping agent glycoprotein() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "INFO: [2025-07-01 16:15:49] indra_gpt.chat_curate.chat_curate - Skipping agent glycoprotein() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "INFO: [2025-07-01 16:15:50] indra_gpt.chat_curate.chat_curate - Skipping agent glycoprotein() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "INFO: [2025-07-01 16:15:51] indra_gpt.chat_curate.chat_curate - Skipping agent glycoprotein() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "INFO: [2025-07-01 16:15:52] indra_gpt.chat_curate.chat_curate - Skipping agent glycoprotein() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "Generating prompts...: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [01:02<00:00, 12.53s/it]\n",
      "Sending prompts to LLM:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[92m16:15:53 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:15:53] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:15:53] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:15:53 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:15:53] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:15:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:15:53] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:15:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:15:53] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:15:53 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:15:53] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:15:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:15:53] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:15:54] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:15:54 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:15:54] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:15:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:15:54] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:15:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:15:54] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:15:54 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:15:54] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:15:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:15:54] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:15:55] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:15:55 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:15:55] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:15:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:15:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:15:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:15:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:15:55 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:15:55] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:15:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:15:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:15:56] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:15:56 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:15:56] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:15:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:15:56] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:15:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:15:56] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:15:56 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:15:56] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:15:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:15:56] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:15:57] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:15:57 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:15:57] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:15:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:15:57] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:15:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:15:57] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:15:57 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:15:57] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:15:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:15:57] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:15:57] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:15:57 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:15:57] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:15:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:15:57] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:15:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:15:57] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:15:57 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:15:57] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:15:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:15:57] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:15:58] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:15:58 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:15:58] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:15:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:15:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:15:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:15:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:15:58 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:15:58] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:15:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:15:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:15:58] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:15:58 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:15:58] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:15:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:15:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:15:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:15:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:15:58 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:15:58] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:15:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:15:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:15:59] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:15:59 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:15:59] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:15:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:15:59] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:15:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:15:59] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:15:59 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:15:59] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:15:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:15:59] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:00] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:16:00 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:16:00] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:16:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:00] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:16:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Sending prompts to LLM:  20%|‚ñà‚ñà        | 1/5 [00:07<00:28,  7.07s/it]INFO: [2025-07-01 16:16:00] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:16:00 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:16:00] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:16:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:00] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:01] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:16:02 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:16:02] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:16:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:16:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:16:02 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:16:02] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:16:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:02] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:16:02 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:16:02] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:16:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:16:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:16:02 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:16:02] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:16:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:03] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:16:03 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:16:03] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:16:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:03] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:16:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:03] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:16:03 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:16:03] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:16:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:03] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:03] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:16:03 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:16:03] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:16:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:03] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:16:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:03] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:16:03 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:16:03] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:16:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:03] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:04] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:16:04 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:16:04] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:16:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:16:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:16:04 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:16:04] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:16:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:05] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:16:05 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:16:05] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:16:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:05] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:16:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:05] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:16:05 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:16:05] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:16:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:05] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:05] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:16:05 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:16:05] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:16:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:05] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:16:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:05] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:16:05 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:16:05] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:16:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:05] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:06] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:16:06 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:16:06] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:16:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:06] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:16:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:06] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:16:06 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:16:06] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:16:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:06] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:07] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:16:07 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:16:07] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:16:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:16:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Sending prompts to LLM:  40%|‚ñà‚ñà‚ñà‚ñà      | 2/5 [00:14<00:22,  7.44s/it]INFO: [2025-07-01 16:16:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:16:07 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:16:07] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:16:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:08] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:16:08 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:16:08] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:16:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:08] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:16:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:08] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:16:08 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:16:08] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:16:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:08] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:09] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:16:09 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:16:09] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:16:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:09] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:16:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:09] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:16:09 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:16:09] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:16:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:09] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:10] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:16:10 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:16:10] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:16:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:16:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:16:10 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:16:10] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:16:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:13] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:16:13 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:16:13] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:16:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:16:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:16:13 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:16:13] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:16:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:14] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:16:14 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:16:14] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:16:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:16:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:16:14 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:16:14] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:16:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:15] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:16:15 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:16:15] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:16:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:15] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:16:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:15] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:16:15 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:16:15] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:16:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:15] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:15] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:16:15 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:16:15] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:16:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:15] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:16:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:15] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:16:15 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:16:15] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:16:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:15] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:16] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:16:16 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:16:16] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:16:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:16] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:16:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:16] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:16:16 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:16:16] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:16:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:16] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:17] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:16:17 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:16:17] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:16:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:16:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:16:17 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:16:17] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:16:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:17] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:16:17 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:16:17] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:16:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:16:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Sending prompts to LLM:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3/5 [00:24<00:17,  8.52s/it]INFO: [2025-07-01 16:16:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:16:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:16:17 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:16:17] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:16:18] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:16:18 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:16:18] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:16:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:16:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:16:18 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:16:18] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:16:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:19] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:16:19 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:16:19] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:16:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:16:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:16:19 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:16:19] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:16:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:19] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:16:19 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:16:19] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:16:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:16:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:16:19 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:16:19] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:16:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:20] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:16:20 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:16:20] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:16:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:20] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:16:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:20] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:16:20 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:16:20] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:16:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:20] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:21] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:16:21 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:16:21] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:16:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:16:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:16:21 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:16:21] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:16:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:21] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:16:21 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:16:21] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:16:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:16:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:16:21 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:16:21] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:16:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:22] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:16:22 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:16:22] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:16:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:16:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:16:22 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:16:22] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:16:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:23] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:16:23 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:16:23] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:16:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:16:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:16:23 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:16:23] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:16:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:24] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:16:24 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:16:24] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:16:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:16:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:16:24 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:16:24] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:16:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:25] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:16:25 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:16:25] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:16:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:16:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Sending prompts to LLM:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4/5 [00:31<00:08,  8.02s/it]INFO: [2025-07-01 16:16:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:16:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:16:25 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:16:25] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:16:25] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:16:25 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:16:25] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:16:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:16:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:16:25 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:16:25] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:16:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:26] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:16:26 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:16:26] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:16:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:16:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:16:26 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:16:26] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:16:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:27] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:16:27 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:16:27] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:16:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:27] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:16:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:27] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:16:27 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:16:27] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:16:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:27] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:27] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:16:27 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:16:27] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:16:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:27] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:16:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:27] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:16:27 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:16:27] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:16:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:27] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:28] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:16:28 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:16:28] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:16:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:16:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:16:28 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:16:28] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:16:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:29] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:16:29 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:16:29] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:16:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:16:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:16:29 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:16:29] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:16:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:30] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:16:30 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:16:30] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:16:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:16:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:16:30 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:16:30] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:16:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:30] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:16:30 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:16:30] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:16:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:16:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:16:30 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:16:30] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:16:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:31] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:16:31 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:16:31] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:16:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:16:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:16:31 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-07-01 16:16:31] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "\u001b[92m16:16:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:32] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:16:32 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-07-01 16:16:32] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:16:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-07-01 16:16:32] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:16:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Sending prompts to LLM: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:38<00:00,  7.70s/it]INFO: [2025-07-01 16:16:32] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m16:16:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Sending prompts to LLM: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:38<00:00,  7.79s/it]INFO: [2025-07-01 16:16:32] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\n",
      "Aggregating results: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 37854.73it/s]\n"
     ]
    }
   ],
   "source": [
    "statements = pickle.load(\n",
    "    open(RESULTS_DIR.joinpath(\"statements.pkl\"), \"rb\")\n",
    ")\n",
    "statements = statements[:5]\n",
    "models = ['gpt-4o-mini']\n",
    "for model in models:\n",
    "    for n_evidence_to_curate in [2, 4, 6, 8, 10]:\n",
    "        llm_curations_binary = chat_curate_stmts(statements,\n",
    "                                        n_evidence_to_curate=n_evidence_to_curate,\n",
    "                                        decision_threshold=0.5,\n",
    "                                        binary_classification=True,\n",
    "                                        #ignore_tags=['incorrect'],\n",
    "                                        n_fewshot_examples=3,\n",
    "                                        get_ex_per_tag=True,\n",
    "                                        schema_output_mode=True,\n",
    "                                        model=model)\n",
    "        llm_curations_multiclass = chat_curate_stmts(statements,\n",
    "                                        n_evidence_to_curate=n_evidence_to_curate,\n",
    "                                        decision_threshold=0.5,\n",
    "                                        binary_classification=False,\n",
    "                                        ignore_tags=['incorrect'],\n",
    "                                        n_fewshot_examples=3,\n",
    "                                        get_ex_per_tag=True,\n",
    "                                        schema_output_mode=True,\n",
    "                                        model=model)\n",
    "\n",
    "        if not RESULTS_DIR.joinpath(model).joinpath(f\"num_evidence_{n_evidence_to_curate}\").exists():\n",
    "            RESULTS_DIR.joinpath(model).joinpath(f\"num_evidence_{n_evidence_to_curate}\").mkdir(parents=True)\n",
    "        with open(RESULTS_DIR / model / f\"num_evidence_{n_evidence_to_curate}\" / \"chat_curation_binary_classification.json\", \"w\") as f:\n",
    "            json.dump(llm_curations_binary, f, indent=2)\n",
    "        with open(RESULTS_DIR / model / f\"num_evidence_{n_evidence_to_curate}\" / \"chat_curation_multiclass_classification.json\", \"w\") as f:\n",
    "            json.dump(llm_curations_multiclass, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23533fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing LLM curations:   0%|          | 0/5 [00:00<?, ?it/s]INFO: [2025-07-01 16:18:12] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-2925848004089621\n",
      "INFO: [2025-07-01 16:18:12] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-07-01 16:18:12] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  20%|‚ñà‚ñà        | 1/5 [00:00<00:00,  4.90it/s]INFO: [2025-07-01 16:18:13] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-2182577807754994\n",
      "INFO: [2025-07-01 16:18:13] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-07-01 16:18:13] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  40%|‚ñà‚ñà‚ñà‚ñà      | 2/5 [00:00<00:00,  3.46it/s]INFO: [2025-07-01 16:18:13] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/28913319916172234\n",
      "INFO: [2025-07-01 16:18:13] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-07-01 16:18:13] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3/5 [00:00<00:00,  3.94it/s]INFO: [2025-07-01 16:18:13] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/24621944116777285\n",
      "INFO: [2025-07-01 16:18:13] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-07-01 16:18:13] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4/5 [00:00<00:00,  4.24it/s]INFO: [2025-07-01 16:18:13] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-17373651143639655\n",
      "INFO: [2025-07-01 16:18:13] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-07-01 16:18:13] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:01<00:00,  4.26it/s]\n",
      "Processing LLM curations:   0%|          | 0/5 [00:00<?, ?it/s]INFO: [2025-07-01 16:18:13] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-2925848004089621\n",
      "INFO: [2025-07-01 16:18:13] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-07-01 16:18:13] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  20%|‚ñà‚ñà        | 1/5 [00:00<00:00,  5.13it/s]INFO: [2025-07-01 16:18:14] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-2182577807754994\n",
      "INFO: [2025-07-01 16:18:14] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-07-01 16:18:14] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  40%|‚ñà‚ñà‚ñà‚ñà      | 2/5 [00:00<00:00,  3.24it/s]INFO: [2025-07-01 16:18:14] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/28913319916172234\n",
      "INFO: [2025-07-01 16:18:14] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-07-01 16:18:14] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3/5 [00:00<00:00,  3.81it/s]INFO: [2025-07-01 16:18:14] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/24621944116777285\n",
      "INFO: [2025-07-01 16:18:14] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-07-01 16:18:14] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4/5 [00:01<00:00,  4.12it/s]INFO: [2025-07-01 16:18:14] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-17373651143639655\n",
      "INFO: [2025-07-01 16:18:14] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-07-01 16:18:14] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:01<00:00,  4.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: gpt-4o-mini, Num Evidence: 2\n",
      "binary_classification - Accuracy: 0.8000\n",
      "multiclass_classification - Accuracy: 0.8000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing LLM curations:   0%|          | 0/5 [00:00<?, ?it/s]INFO: [2025-07-01 16:18:15] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-2925848004089621\n",
      "INFO: [2025-07-01 16:18:15] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-07-01 16:18:15] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  20%|‚ñà‚ñà        | 1/5 [00:00<00:00,  5.01it/s]INFO: [2025-07-01 16:18:15] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-2182577807754994\n",
      "INFO: [2025-07-01 16:18:15] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-07-01 16:18:15] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  40%|‚ñà‚ñà‚ñà‚ñà      | 2/5 [00:00<00:00,  3.55it/s]INFO: [2025-07-01 16:18:15] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/28913319916172234\n",
      "INFO: [2025-07-01 16:18:15] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-07-01 16:18:15] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3/5 [00:00<00:00,  4.10it/s]INFO: [2025-07-01 16:18:15] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/24621944116777285\n",
      "INFO: [2025-07-01 16:18:15] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-07-01 16:18:15] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4/5 [00:00<00:00,  4.40it/s]INFO: [2025-07-01 16:18:16] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-17373651143639655\n",
      "INFO: [2025-07-01 16:18:16] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-07-01 16:18:16] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:01<00:00,  4.38it/s]\n",
      "Processing LLM curations:   0%|          | 0/5 [00:00<?, ?it/s]INFO: [2025-07-01 16:18:16] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-2925848004089621\n",
      "INFO: [2025-07-01 16:18:16] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-07-01 16:18:16] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  20%|‚ñà‚ñà        | 1/5 [00:00<00:00,  4.89it/s]INFO: [2025-07-01 16:18:16] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-2182577807754994\n",
      "INFO: [2025-07-01 16:18:16] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-07-01 16:18:16] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  40%|‚ñà‚ñà‚ñà‚ñà      | 2/5 [00:00<00:00,  3.28it/s]INFO: [2025-07-01 16:18:16] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/28913319916172234\n",
      "INFO: [2025-07-01 16:18:16] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-07-01 16:18:16] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3/5 [00:00<00:00,  3.87it/s]INFO: [2025-07-01 16:18:17] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/24621944116777285\n",
      "INFO: [2025-07-01 16:18:17] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-07-01 16:18:17] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4/5 [00:00<00:00,  4.24it/s]INFO: [2025-07-01 16:18:17] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-17373651143639655\n",
      "INFO: [2025-07-01 16:18:17] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-07-01 16:18:17] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:01<00:00,  4.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: gpt-4o-mini, Num Evidence: 4\n",
      "binary_classification - Accuracy: 0.8000\n",
      "multiclass_classification - Accuracy: 0.8000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing LLM curations:   0%|          | 0/5 [00:00<?, ?it/s]INFO: [2025-07-01 16:18:17] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-2925848004089621\n",
      "INFO: [2025-07-01 16:18:17] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-07-01 16:18:17] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  20%|‚ñà‚ñà        | 1/5 [00:00<00:00,  4.82it/s]INFO: [2025-07-01 16:18:17] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-2182577807754994\n",
      "INFO: [2025-07-01 16:18:17] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-07-01 16:18:17] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  40%|‚ñà‚ñà‚ñà‚ñà      | 2/5 [00:00<00:00,  4.81it/s]INFO: [2025-07-01 16:18:17] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/28913319916172234\n",
      "INFO: [2025-07-01 16:18:17] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-07-01 16:18:17] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3/5 [00:00<00:00,  3.51it/s]INFO: [2025-07-01 16:18:18] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/24621944116777285\n",
      "INFO: [2025-07-01 16:18:18] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-07-01 16:18:18] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4/5 [00:01<00:00,  3.88it/s]INFO: [2025-07-01 16:18:18] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-17373651143639655\n",
      "INFO: [2025-07-01 16:18:18] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-07-01 16:18:18] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:01<00:00,  4.11it/s]\n",
      "Processing LLM curations:   0%|          | 0/5 [00:00<?, ?it/s]INFO: [2025-07-01 16:18:18] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-2925848004089621\n",
      "INFO: [2025-07-01 16:18:18] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-07-01 16:18:18] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  20%|‚ñà‚ñà        | 1/5 [00:00<00:00,  4.79it/s]INFO: [2025-07-01 16:18:18] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-2182577807754994\n",
      "INFO: [2025-07-01 16:18:18] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-07-01 16:18:18] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  40%|‚ñà‚ñà‚ñà‚ñà      | 2/5 [00:00<00:00,  4.71it/s]INFO: [2025-07-01 16:18:19] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/28913319916172234\n",
      "INFO: [2025-07-01 16:18:19] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-07-01 16:18:19] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3/5 [00:00<00:00,  3.52it/s]INFO: [2025-07-01 16:18:19] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/24621944116777285\n",
      "INFO: [2025-07-01 16:18:19] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-07-01 16:18:19] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4/5 [00:01<00:00,  3.17it/s]INFO: [2025-07-01 16:18:19] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-17373651143639655\n",
      "INFO: [2025-07-01 16:18:19] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-07-01 16:18:19] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:01<00:00,  3.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: gpt-4o-mini, Num Evidence: 6\n",
      "binary_classification - Accuracy: 0.8000\n",
      "multiclass_classification - Accuracy: 0.8000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing LLM curations:   0%|          | 0/5 [00:00<?, ?it/s]INFO: [2025-07-01 16:18:20] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-2925848004089621\n",
      "INFO: [2025-07-01 16:18:20] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-07-01 16:18:20] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  20%|‚ñà‚ñà        | 1/5 [00:00<00:00,  5.17it/s]INFO: [2025-07-01 16:18:20] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-2182577807754994\n",
      "INFO: [2025-07-01 16:18:20] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-07-01 16:18:20] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  40%|‚ñà‚ñà‚ñà‚ñà      | 2/5 [00:00<00:00,  5.16it/s]INFO: [2025-07-01 16:18:20] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/28913319916172234\n",
      "INFO: [2025-07-01 16:18:20] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-07-01 16:18:20] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3/5 [00:00<00:00,  4.93it/s]INFO: [2025-07-01 16:18:20] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/24621944116777285\n",
      "INFO: [2025-07-01 16:18:20] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-07-01 16:18:20] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4/5 [00:00<00:00,  3.78it/s]INFO: [2025-07-01 16:18:21] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-17373651143639655\n",
      "INFO: [2025-07-01 16:18:21] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-07-01 16:18:21] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:01<00:00,  4.27it/s]\n",
      "Processing LLM curations:   0%|          | 0/5 [00:00<?, ?it/s]INFO: [2025-07-01 16:18:21] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-2925848004089621\n",
      "INFO: [2025-07-01 16:18:21] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-07-01 16:18:21] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  20%|‚ñà‚ñà        | 1/5 [00:00<00:00,  4.60it/s]INFO: [2025-07-01 16:18:21] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-2182577807754994\n",
      "INFO: [2025-07-01 16:18:21] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-07-01 16:18:21] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  40%|‚ñà‚ñà‚ñà‚ñà      | 2/5 [00:00<00:00,  4.33it/s]INFO: [2025-07-01 16:18:21] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/28913319916172234\n",
      "INFO: [2025-07-01 16:18:21] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-07-01 16:18:21] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3/5 [00:00<00:00,  4.53it/s]INFO: [2025-07-01 16:18:21] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/24621944116777285\n",
      "INFO: [2025-07-01 16:18:21] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-07-01 16:18:21] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4/5 [00:01<00:00,  3.64it/s]INFO: [2025-07-01 16:18:22] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-17373651143639655\n",
      "INFO: [2025-07-01 16:18:22] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-07-01 16:18:22] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:01<00:00,  4.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: gpt-4o-mini, Num Evidence: 8\n",
      "binary_classification - Accuracy: 0.8000\n",
      "multiclass_classification - Accuracy: 0.8000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing LLM curations:   0%|          | 0/5 [00:00<?, ?it/s]INFO: [2025-07-01 16:18:22] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-2925848004089621\n",
      "INFO: [2025-07-01 16:18:22] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-07-01 16:18:22] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  20%|‚ñà‚ñà        | 1/5 [00:00<00:00,  4.94it/s]INFO: [2025-07-01 16:18:22] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-2182577807754994\n",
      "INFO: [2025-07-01 16:18:22] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-07-01 16:18:22] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  40%|‚ñà‚ñà‚ñà‚ñà      | 2/5 [00:00<00:00,  4.74it/s]INFO: [2025-07-01 16:18:22] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/28913319916172234\n",
      "INFO: [2025-07-01 16:18:22] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-07-01 16:18:22] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3/5 [00:00<00:00,  4.86it/s]INFO: [2025-07-01 16:18:23] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/24621944116777285\n",
      "INFO: [2025-07-01 16:18:23] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-07-01 16:18:23] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4/5 [00:00<00:00,  4.85it/s]INFO: [2025-07-01 16:18:23] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-17373651143639655\n",
      "INFO: [2025-07-01 16:18:23] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-07-01 16:18:23] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:01<00:00,  4.21it/s]\n",
      "Processing LLM curations:   0%|          | 0/5 [00:00<?, ?it/s]INFO: [2025-07-01 16:18:23] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-2925848004089621\n",
      "INFO: [2025-07-01 16:18:23] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-07-01 16:18:23] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  20%|‚ñà‚ñà        | 1/5 [00:00<00:00,  4.78it/s]INFO: [2025-07-01 16:18:23] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-2182577807754994\n",
      "INFO: [2025-07-01 16:18:23] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-07-01 16:18:23] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  40%|‚ñà‚ñà‚ñà‚ñà      | 2/5 [00:00<00:00,  4.92it/s]INFO: [2025-07-01 16:18:24] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/28913319916172234\n",
      "INFO: [2025-07-01 16:18:24] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-07-01 16:18:24] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3/5 [00:00<00:00,  5.00it/s]INFO: [2025-07-01 16:18:24] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/24621944116777285\n",
      "INFO: [2025-07-01 16:18:24] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-07-01 16:18:24] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4/5 [00:00<00:00,  5.00it/s]INFO: [2025-07-01 16:18:24] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-17373651143639655\n",
      "INFO: [2025-07-01 16:18:24] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-07-01 16:18:24] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:01<00:00,  4.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: gpt-4o-mini, Num Evidence: 10\n",
      "binary_classification - Accuracy: 0.8000\n",
      "multiclass_classification - Accuracy: 0.8000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    for n_evidence_to_curate in [2, 4, 6, 8, 10]:\n",
    "        with open(RESULTS_DIR / model / f\"num_evidence_{n_evidence_to_curate}\" / \"chat_curation_binary_classification.json\", \"r\") as f:\n",
    "            chat_curation_binary_classification = json.load(f)\n",
    "        with open(RESULTS_DIR / model / f\"num_evidence_{n_evidence_to_curate}\" / \"chat_curation_multiclass_classification.json\", \"r\") as f:\n",
    "            chat_curation_multiclass_classification = json.load(f)\n",
    "\n",
    "        eval_stmt_binary = curation_statement_comparison_json(chat_curation_binary_classification)\n",
    "        with open(RESULTS_DIR / model / f\"num_evidence_{n_evidence_to_curate}\" / \"eval_stmt_chat_curation_binary_classification.json\", \"w\") as f:\n",
    "            json.dump(eval_stmt_binary, f, indent=2)\n",
    "\n",
    "        eval_stmt_multi = curation_statement_comparison_json(chat_curation_multiclass_classification)\n",
    "        with open(RESULTS_DIR / model / f\"num_evidence_{n_evidence_to_curate}\" / \"eval_stmt_chat_curation_multiclass_classification.json\", \"w\") as f:\n",
    "            json.dump(eval_stmt_multi, f, indent=2)\n",
    "        \n",
    "        print(f\"Model: {model}, Num Evidence: {n_evidence_to_curate}\")\n",
    "        for eval_strat in ['binary_classification', 'multiclass_classification']:\n",
    "            with open(RESULTS_DIR / model / f\"num_evidence_{n_evidence_to_curate}\" / f\"eval_stmt_chat_curation_{eval_strat}.json\", \"r\") as f:\n",
    "                res = json.load(f)\n",
    "            preds = [res_item['llm_overall_prediction'] for res_item in res]\n",
    "            labels = [res_item['indra_curation'] for res_item in res]\n",
    "            acc = accuracy_score(labels, preds)\n",
    "            print(f\"{eval_strat} - Accuracy: {acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "655ad393",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: [2025-07-01 16:25:31] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-17373651143639655\n",
      "INFO: [2025-07-01 16:25:31] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-07-01 16:25:31] indra.sources.indra_db_rest.util - data: None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'curator': 'ben.gyori@gmail.com',\n",
       "  'date': 'Tue, 15 Dec 2020 15:25:32 GMT',\n",
       "  'ev_json': None,\n",
       "  'id': 10446,\n",
       "  'pa_hash': -17373651143639655,\n",
       "  'pa_json': None,\n",
       "  'source': 'DB REST API',\n",
       "  'source_hash': 3720882788640565537,\n",
       "  'tag': 'entity_boundaries',\n",
       "  'text': ''},\n",
       " {'curator': 'ben.gyori@gmail.com',\n",
       "  'date': 'Tue, 15 Dec 2020 15:25:35 GMT',\n",
       "  'ev_json': None,\n",
       "  'id': 10447,\n",
       "  'pa_hash': -17373651143639655,\n",
       "  'pa_json': None,\n",
       "  'source': 'DB REST API',\n",
       "  'source_hash': -1341935765166920808,\n",
       "  'tag': 'entity_boundaries',\n",
       "  'text': ''}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from indra.sources.indra_db_rest import get_curations\n",
    "\n",
    "get_curations(-17373651143639655)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba7065e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import confusion_matrix\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "\n",
    "# # Extract tags\n",
    "# tags = [c['tag'] for c in curation_comp_json]\n",
    "# predicted_tags = [c['predicted_tag'] for c in curation_comp_json]\n",
    "\n",
    "# # Compute accuracy\n",
    "# accuracy = np.mean([t == p for t, p in zip(tags, predicted_tags)])\n",
    "# accuracy_bin = np.mean([t == p or (t != 'correct' and p == 'incorrect') for t, p in zip(tags, predicted_tags)])\n",
    "# print(f\"Accuracy: {accuracy:.2%}\")\n",
    "# print(f\"Binary Accuracy: {accuracy_bin:.2%}\")\n",
    "\n",
    "# # Define tag label set\n",
    "# tag_set = list(set(tags).union(set(predicted_tags)))\n",
    "\n",
    "# # Compute confusion matrix\n",
    "# cm = confusion_matrix(tags, predicted_tags, labels=tag_set)\n",
    "# cm_df = pd.DataFrame(cm, index=tag_set, columns=tag_set)\n",
    "\n",
    "# # Plot\n",
    "# plt.figure(figsize=(12, 10))\n",
    "# sns.heatmap(cm_df, annot=True, fmt='d', cmap='Blues', cbar=True, linewidths=0.5)\n",
    "# plt.title(\"Confusion Matrix (Binary Classification - Model only predicts 'correct' or 'incorrect')\")\n",
    "# plt.xlabel(\"Predicted Label\")\n",
    "# plt.ylabel(\"True Label\")\n",
    "# plt.xticks(rotation=45, ha='right')\n",
    "# plt.yticks(rotation=0)\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd5fcb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "indra_gpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
