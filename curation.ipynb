{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bca64466",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thomaslim/miniconda3/envs/indra_gpt/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "INFO: [2025-06-27 15:16:27] httpx - HTTP Request: GET https://raw.githubusercontent.com/BerriAI/litellm/main/model_prices_and_context_window.json \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "\n",
    "import indra_gpt.chat_curate.chat_curate\n",
    "importlib.reload(indra_gpt.chat_curate.chat_curate)\n",
    "from indra_gpt.chat_curate.chat_curate import *\n",
    "\n",
    "import indra_gpt.chat_curate.eval\n",
    "importlib.reload(indra_gpt.chat_curate.eval)\n",
    "from indra_gpt.chat_curate.eval import (curation_statement_evidence_pair_comparison_json, \n",
    "                                        curation_statement_comparison_json)\n",
    "\n",
    "import pickle\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59caf037",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_DIR = Path.cwd().joinpath(\"output/curated_statements_sample_100\")\n",
    "if not RESULTS_DIR.exists():\n",
    "    RESULTS_DIR.mkdir(parents=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a574e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: [2025-06-27 15:16:28] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list\n",
      "INFO: [2025-06-27 15:16:28] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 15:16:28] indra.sources.indra_db_rest.util - data: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• Fetching all curations from INDRA DB...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: [2025-06-27 15:16:30] indra_db_rest.query_processor - Retrieving statements that have hash -10033945991593843, -10444363735373102, -1083216214855434, -11019131917628364, -12463996681673250, -12988782223228843, -13505886640472175, -14117628316152430, -14556452501867428, -15297044990735102, -15352348890731234, -17222594879744452, -17407910080587992, -18031556530033893, -18152182327560480, -18387380848780476, -184811282650788, -18949191324265795, -19952367157294119, -20155356540515066, -20439687097155111, -2046863695546735, -2069452773758641, -2139820121868237, -22061102960387551, -22499263970759753, -22627892168184181, -22849205778179846, -23507181552861323, -24316712102315887, -25141892168903907, -25655970173329808, -25725881202629826, -26780953604978411, -28031656773092240, -29122158203077245, -29415098045592940, -32399727139857751, -33852347582520392, -3409159551394617, -34105277816332298, -34803309266443718, -35102576635162472, -35882458128194165, -35884737692158253, -4938783110044412, -5438696396298380, -6690591167508650, -6735076600090236, -7126418877828068, -7666152121409895, -8639253709990781, 10262358575052520, 10757094666506670, 11111675784752136, 12631778325074772, 12642450547914707, 13290267870654994, 1410763986151621, 14377716460635733, 15114781201446083, 15133418971654738, 15568847793479266, 17131318242278983, 1739983631954371, 17470512188912087, 17609986374660936, 17681796354219824, 18334778860223615, 18933828397346607, 19367730649708653, 19706388665464256, 20606471688970148, 20978307744432241, 21321689889868872, 2135209076854093, 21634894993301822, 21893218624143108, 24584688051044679, 25830891211600204, 28030974524863734, 30634204597194783, 30759839524016550, 30902335548899281, 31160008118740626, 31202820582613161, 31420388280123621, 31846767235310716, 3246604237187558, 3297979118605018, 33041281229298748, 33874939274212480, 34364657708684419, 35971629147007369, 4780733614296462, 5566930627431303, 5609203557180661, 5895544448831150, 9130628937861941, or 9371935612488149.\n",
      "INFO: [2025-06-27 15:16:30] indra_db_rest.request_logs - Running 0th request for statements\n",
      "INFO: [2025-06-27 15:16:30] indra_db_rest.request_logs -   LIMIT: None\n",
      "INFO: [2025-06-27 15:16:30] indra_db_rest.request_logs -   OFFSET: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßπ Extracting unique statement hashes...\n",
      "üîç Fetching 100 curated statements from INDRA DB...\n",
      "‚úÖ Saved 92 curated statements to: /Users/thomaslim/gyorilab/indra_gpt/output/curated_statements_sample_100/statements.pkl\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from indra.sources import indra_db_rest\n",
    "\n",
    "# Step 1: Get all curations from the INDRA DB\n",
    "print(\"üì• Fetching all curations from INDRA DB...\")\n",
    "curations = indra_db_rest.get_curations()\n",
    "\n",
    "# Step 2: Extract unique statement hashes from curations\n",
    "print(\"üßπ Extracting unique statement hashes...\")\n",
    "unique_hashes = list({c['pa_hash'] for c in curations if 'pa_hash' in c})\n",
    "\n",
    "# Step 3: Randomly sample up to 100 curated statement hashes\n",
    "sample_size = min(100, len(unique_hashes))\n",
    "sampled_hashes = random.sample(unique_hashes, sample_size)\n",
    "\n",
    "# Step 4: Fetch full statements by hash (including all evidences)\n",
    "print(f\"üîç Fetching {sample_size} curated statements from INDRA DB...\")\n",
    "stmt_proc = indra_db_rest.get_statements_by_hash(sampled_hashes, ev_limit=100)\n",
    "curated_statements = stmt_proc.statements\n",
    "\n",
    "# Step 5: Save to pickle\n",
    "output_path = RESULTS_DIR / \"statements.pkl\"\n",
    "\n",
    "with open(output_path, \"wb\") as f:\n",
    "    pickle.dump(curated_statements, f)\n",
    "\n",
    "print(f\"‚úÖ Saved {len(curated_statements)} curated statements to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e8b436a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Curating statements with chat curation:   0%|          | 0/92 [00:00<?, ?it/s]\u001b[92m15:16:46 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:16:46] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:16:47] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:16:47 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:16:47] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:16:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:16:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:16:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:16:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:16:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:16:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:16:49 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:16:49] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:16:52] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:16:52 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:16:52] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:16:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:16:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:16:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:16:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:16:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:16:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:16:54 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:16:54] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:16:55] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:16:55 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:16:55] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:16:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:16:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:16:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:16:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:16:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:16:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:16:57 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:16:57] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:16:59] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:16:59 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:16:59] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:16:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:16:59] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:16:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:16:59] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:16:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:16:59] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:17:01 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:17:01] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:17:02] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:17:02 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:17:02] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:17:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:17:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:17:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:   1%|          | 1/92 [00:29<45:07, 29.75s/it]INFO: [2025-06-27 15:17:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:17:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:17:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:17:04 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:17:04] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:17:08] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:17:08 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:17:08] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:17:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:17:08] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:17:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:17:08] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:17:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:17:08] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:17:10 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:17:10] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:17:11] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:17:11 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:17:11] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:17:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:17:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:17:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:17:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:17:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:17:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:17:13 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:17:13] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:17:14] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:17:14 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:17:14] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:17:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:17:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:17:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:17:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:17:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:17:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:17:16 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:17:16] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:17:18] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:17:18 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:17:18] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:17:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:17:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:17:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:17:20 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:17:20] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:17:21] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:17:21 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:17:21] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:17:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:17:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:17:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:   2%|‚ñè         | 2/92 [00:48<34:45, 23.17s/it]INFO: [2025-06-27 15:17:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:17:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:17:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:17:23 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:17:23] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:17:24] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:17:24 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:17:24] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:17:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:17:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:17:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:17:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:17:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:17:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:17:26 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:17:26] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:17:27] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:17:27 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:17:27] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:17:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:17:27] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:17:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:17:27] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:17:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:17:27] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:17:29 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:17:29] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:17:30] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:17:30 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:17:30] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:17:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:17:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:17:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:17:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:17:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:17:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:17:32 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:17:32] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:17:33] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:17:33 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:17:33] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:17:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:17:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:17:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:17:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:17:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:17:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:17:35 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:17:35] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:17:36] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:17:36 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:17:36] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:17:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:17:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:17:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:   3%|‚ñé         | 3/92 [01:03<29:04, 19.60s/it]INFO: [2025-06-27 15:17:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:17:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:17:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:17:38 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:17:38] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:17:39] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:17:39 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:17:39] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:17:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:17:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:17:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:17:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:17:40 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:17:40] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:17:42 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:17:42] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:17:43] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:17:43 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:17:43] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:17:43 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:17:43] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:17:43 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:17:43] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:17:43 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:17:43] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:17:45 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:17:45] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:17:48] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:17:48 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:17:48] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:17:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:17:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:17:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:17:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:17:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:17:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:17:50 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:17:50] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:17:52] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:17:52 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:17:52] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:17:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:17:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:17:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:17:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:17:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:17:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:17:54 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:17:54] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:17:56] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:17:56 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:17:56] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:17:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:17:56] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:17:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:   4%|‚ñç         | 4/92 [01:23<28:36, 19.50s/it]INFO: [2025-06-27 15:17:56] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:17:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:17:56] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:17:57 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:17:57] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:17:58] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:17:58 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:17:58] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:17:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:17:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:17:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:17:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:17:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:17:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:17:59 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:17:59] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:18:03] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:18:03 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:18:03] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:18:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:18:03] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:18:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:18:03] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:18:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:18:03] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:18:04 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:18:04] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:18:05] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:18:05 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:18:05] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:18:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:18:05] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:18:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:18:05] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:18:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:18:05] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:18:06 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:18:06] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:18:07] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:18:07 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:18:07] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:18:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:18:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:18:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:18:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:18:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:18:08] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:18:09 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:18:09] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:18:11] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:18:11 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:18:11] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:18:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:18:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:18:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:   5%|‚ñå         | 5/92 [01:38<26:18, 18.14s/it]INFO: [2025-06-27 15:18:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:18:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:18:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:18:14 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:18:14] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:18:15] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:18:15 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:18:15] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:18:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:18:15] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:18:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:18:15] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:18:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:18:15] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:18:17 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:18:17] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:18:20] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:18:20 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:18:20] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:18:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:18:20] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:18:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:18:20] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:18:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:18:20] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:18:22 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:18:22] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:18:24] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:18:24 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:18:24] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:18:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:18:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:18:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:18:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:18:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:18:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:18:26 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:18:26] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:18:29] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:18:29 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:18:29] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:18:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:18:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:18:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:18:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:18:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:18:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:18:31 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:18:31] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:18:33] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:18:33 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:18:33] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:18:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:18:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:18:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:   7%|‚ñã         | 6/92 [02:00<27:36, 19.27s/it]INFO: [2025-06-27 15:18:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:18:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:18:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:18:34 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:18:34] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:18:35] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:18:35 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:18:35] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:18:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:18:35] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:18:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:18:35] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:18:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:18:35] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:18:36 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:18:36] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:18:38] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:18:38 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:18:38] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:18:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:18:38] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:18:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:18:38] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:18:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:18:38] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:18:39 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:18:39] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:18:40] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:18:40 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:18:40] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:18:40 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:18:40] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:18:40 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:18:40] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:18:40 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:18:40] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:18:42 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:18:42] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:18:43] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:18:43 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:18:43] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:18:43 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:18:43] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:18:43 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:18:43] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:18:43 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:18:43] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:18:44 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:18:44] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:18:45] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:18:45 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:18:45] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:18:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:18:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:18:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:   8%|‚ñä         | 7/92 [02:12<24:00, 16.95s/it]INFO: [2025-06-27 15:18:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:18:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:18:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:18:46 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:18:46] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:18:48] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:18:48 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:18:48] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:18:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:18:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:18:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:18:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:18:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:18:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:18:49 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:18:49] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:18:50] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:18:50 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:18:50] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:18:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:18:50] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:18:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:18:50] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:18:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:18:50] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:18:51 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:18:51] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:18:53] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:18:53 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:18:53] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:18:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:18:53] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:18:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:18:53] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:18:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:18:53] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:18:54 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:18:54] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:18:56] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:18:56 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:18:56] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:18:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:18:56] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:18:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:18:56] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:18:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:18:56] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:18:57 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:18:57] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:18:58] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:18:58 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:18:58] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:18:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:18:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:18:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:   9%|‚ñä         | 8/92 [02:25<22:03, 15.76s/it]INFO: [2025-06-27 15:18:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:18:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:18:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:19:00 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:19:00] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:19:02] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:19:02 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:19:02] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:19:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:19:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:19:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:19:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:19:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:19:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:19:04 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:19:04] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:19:05] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:19:05 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:19:05] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:19:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:19:05] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:19:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:19:05] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:19:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:19:05] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:19:07 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:19:07] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:19:08] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:19:08 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:19:08] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:19:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:19:08] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:19:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:19:08] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:19:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:19:09] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:19:11 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:19:11] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:19:12] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:19:12 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:19:12] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:19:12 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:19:12] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:19:12 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:19:12] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:19:12 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:19:12] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:19:14 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:19:14] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:19:15] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:19:15 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:19:15] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:19:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:19:15] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:19:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  10%|‚ñâ         | 9/92 [02:42<22:25, 16.21s/it]INFO: [2025-06-27 15:19:15] indra_gpt.chat_curate.chat_curate - Skipping agent EMT() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "INFO: [2025-06-27 15:19:15] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:19:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:19:16] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:19:16 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:19:16] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:19:17] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:19:17 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:19:17] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:19:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:19:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:19:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:19:17] indra_gpt.chat_curate.chat_curate - Skipping agent EMT() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "INFO: [2025-06-27 15:19:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:19:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:19:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:19:18 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:19:18] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:19:20] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:19:20 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:19:20] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:19:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:19:20] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:19:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:19:20] indra_gpt.chat_curate.chat_curate - Skipping agent EMT() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "INFO: [2025-06-27 15:19:20] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:19:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:19:20] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:19:21 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:19:21] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:19:23] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:19:23 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:19:23] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:19:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:19:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:19:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:19:23] indra_gpt.chat_curate.chat_curate - Skipping agent EMT() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "INFO: [2025-06-27 15:19:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:19:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:19:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:19:24 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:19:24] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:19:25] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:19:25 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:19:25] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:19:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:19:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:19:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:19:25] indra_gpt.chat_curate.chat_curate - Skipping agent EMT() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "INFO: [2025-06-27 15:19:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:19:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:19:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:19:26 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:19:26] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:19:27] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:19:27 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:19:27] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:19:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:19:27] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:19:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  11%|‚ñà         | 10/92 [02:54<20:14, 14.81s/it]INFO: [2025-06-27 15:19:27] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:19:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:19:27] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:19:29 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:19:29] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:19:30] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:19:30 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:19:30] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:19:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:19:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:19:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:19:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:19:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:19:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:19:32 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:19:32] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:19:33] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:19:33 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:19:33] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:19:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:19:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:19:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:19:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:19:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:19:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:19:35 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:19:35] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:19:36] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:19:36 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:19:36] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:19:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:19:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:19:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:19:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:19:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:19:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:19:38 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:19:38] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:19:40] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:19:40 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:19:40] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:19:40 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:19:40] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:19:40 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:19:40] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:19:40 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:19:40] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:19:42 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:19:42] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:19:45] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:19:45 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:19:45] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:19:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:19:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:19:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  12%|‚ñà‚ñè        | 11/92 [03:12<21:27, 15.89s/it]INFO: [2025-06-27 15:19:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:19:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:19:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:19:48 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:19:48] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:19:49] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:19:49 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:19:49] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:19:49 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:19:49] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:19:49 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:19:49] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:19:49 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:19:49] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:19:51 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:19:51] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:19:52] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:19:52 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:19:52] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:19:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:19:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:19:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:19:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:19:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:19:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:19:54 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:19:54] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:19:55] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:19:55 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:19:55] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:19:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:19:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:19:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:19:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:19:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:19:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:19:57 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:19:57] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:19:59] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:19:59 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:19:59] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:19:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:19:59] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:19:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:19:59] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:19:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:19:59] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:20:01 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:20:01] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:20:02] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:20:02 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:20:02] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:20:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:20:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:20:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  13%|‚ñà‚ñé        | 12/92 [03:29<21:33, 16.16s/it]INFO: [2025-06-27 15:20:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:20:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:20:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:20:03 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:20:03] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:20:04] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:20:04 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:20:04] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:20:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:20:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:20:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:20:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:20:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:20:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:20:04 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:20:04] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:20:06] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:20:06 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:20:06] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:20:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:20:06] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:20:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:20:06] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:20:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:20:06] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:20:06 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:20:06] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:20:07] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:20:07 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:20:07] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:20:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:20:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:20:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:20:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:20:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:20:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:20:07 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:20:07] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:20:09] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:20:09 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:20:09] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:20:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:20:09] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:20:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:20:09] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:20:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:20:09] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:20:09 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:20:09] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:20:10] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:20:10 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:20:10] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:20:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:20:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:20:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  14%|‚ñà‚ñç        | 13/92 [03:37<17:53, 13.59s/it]INFO: [2025-06-27 15:20:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:20:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:20:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:20:11 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:20:11] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:20:13] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:20:13 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:20:13] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:20:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:20:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:20:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:20:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:20:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:20:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:20:15 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:20:15] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:20:16] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:20:16 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:20:16] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:20:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:20:16] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:20:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:20:16] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:20:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:20:16] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:20:18 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:20:18] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:20:19] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:20:19 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:20:19] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:20:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:20:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:20:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:20:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:20:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:20:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:20:20 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:20:20] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:20:21] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:20:21 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:20:21] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:20:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:20:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:20:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:20:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:20:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:20:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:20:22 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:20:22] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:20:23] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:20:23 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:20:23] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:20:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:20:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:20:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  15%|‚ñà‚ñå        | 14/92 [03:50<17:39, 13.58s/it]INFO: [2025-06-27 15:20:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:20:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:20:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:20:24 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:20:24] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:20:25] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:20:25 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:20:25] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:20:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:20:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:20:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:20:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:20:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:20:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:20:26 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:20:26] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:20:27] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:20:27 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:20:27] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:20:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:20:27] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:20:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:20:27] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:20:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:20:27] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:20:28 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:20:28] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:20:29] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:20:29 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:20:29] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:20:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:20:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:20:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:20:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:20:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:20:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:20:30 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:20:30] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:20:31] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:20:31 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:20:31] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:20:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:20:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:20:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:20:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:20:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:20:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:20:31 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:20:31] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:20:33] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:20:33 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:20:33] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:20:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:20:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:20:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  16%|‚ñà‚ñã        | 15/92 [04:00<15:45, 12.28s/it]INFO: [2025-06-27 15:20:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:20:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:20:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:20:33 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:20:33] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:20:34] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:20:34 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:20:34] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:20:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:20:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:20:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:20:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:20:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:20:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:20:35 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:20:35] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:20:36] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:20:36 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:20:36] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:20:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:20:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:20:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:20:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:20:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:20:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:20:36 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:20:36] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:20:37] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:20:37 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:20:37] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:20:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:20:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:20:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:20:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:20:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:20:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:20:38 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:20:38] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:20:39] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:20:39 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:20:39] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:20:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:20:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:20:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:20:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:20:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:20:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:20:40 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:20:40] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:20:42] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:20:42 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:20:42] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:20:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:20:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:20:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  17%|‚ñà‚ñã        | 16/92 [04:09<14:21, 11.33s/it]INFO: [2025-06-27 15:20:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:20:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:20:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:20:44 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:20:44] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:20:45] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:20:45 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:20:45] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:20:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:20:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:20:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:20:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:20:46 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:20:46] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:20:48 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:20:48] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:20:49] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:20:49 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:20:49] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:20:49 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:20:49] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:20:49 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:20:49] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:20:49 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:20:49] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:20:51 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:20:51] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:20:52] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:20:52 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:20:52] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:20:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:20:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:20:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:20:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:20:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:20:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:20:54 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:20:54] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:20:55] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:20:55 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:20:55] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:20:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:20:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:20:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:20:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:20:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:20:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:20:57 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:20:57] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:20:58] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:20:58 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:20:58] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:20:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:20:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:20:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  18%|‚ñà‚ñä        | 17/92 [04:25<16:02, 12.84s/it]INFO: [2025-06-27 15:20:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:20:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:20:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:21:01 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:21:01] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:21:02] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:21:02 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:21:02] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:21:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:21:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:21:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:21:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:21:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:21:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:21:04 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:21:04] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:21:05] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:21:05 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:21:05] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:21:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:21:05] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:21:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:21:05] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:21:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:21:06] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:21:07 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:21:07] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:21:09] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:21:09 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:21:09] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:21:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:21:09] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:21:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:21:09] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:21:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:21:09] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:21:11 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:21:11] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:21:12] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:21:12 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:21:12] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:21:12 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:21:12] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:21:12 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:21:12] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:21:12 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:21:12] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:21:14 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:21:14] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:21:15] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:21:15 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:21:15] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:21:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:21:15] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:21:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  20%|‚ñà‚ñâ        | 18/92 [04:42<17:21, 14.07s/it]INFO: [2025-06-27 15:21:15] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:21:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:21:15] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:21:17 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:21:17] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:21:18] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:21:18 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:21:18] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:21:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:21:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:21:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:21:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:21:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:21:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:21:20 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:21:20] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:21:23] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:21:23 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:21:23] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:21:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:21:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:21:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:21:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:21:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:21:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:21:25 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:21:25] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:21:26] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:21:26 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:21:26] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:21:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:21:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:21:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:21:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:21:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:21:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:21:28 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:21:28] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:21:30] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:21:30 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:21:30] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:21:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:21:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:21:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:21:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:21:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:21:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:21:32 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:21:32] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:21:33] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:21:33 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:21:33] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:21:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:21:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:21:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  21%|‚ñà‚ñà        | 19/92 [05:00<18:25, 15.14s/it]INFO: [2025-06-27 15:21:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:21:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:21:33] indra_gpt.chat_curate.chat_curate - Skipping evidence with no text for statement -34105277816332298: Evidence(source_api='biogrid',\n",
      "         pmid='16332543',\n",
      "         source_id='2381443',\n",
      "         annotations={\n",
      "                      \"biogrid_int_id\": \"2381443\",\n",
      "                      \"entrez_a\": \"375\",\n",
      "                      \"entrez_b\": \"55738\",\n",
      "                      \"biogrid_a\": \"106870\",\n",
      "                      \"biogrid_b\": \"120856\",\n",
      "                      \"syst_name_a\": null,\n",
      "                      \"syst_name_b\": \"RP11-261N11.1\",\n",
      "                      \"hgnc_a\": \"ARF1\",\n",
      "                      \"hgnc_b\": \"ARFGAP1\",\n",
      "                      \"syn_a\": null,\n",
      "                      \"syn_b\": \"ARF1GAP|HRIHFB2281\",\n",
      "                      \"exp_system\": \"Reconstituted Complex\",\n",
      "                      \"exp_system_type\": \"physical\",\n",
      "                      \"author\": \"Luo R (2005)\",\n",
      "                      \"pmid\": \"16332543\",\n",
      "                      \"organism_a\": \"9606\",\n",
      "                      \"organism_b\": \"9606\",\n",
      "                      \"throughput\": \"Low Throughput\",\n",
      "                      \"score\": null,\n",
      "                      \"modification\": null,\n",
      "                      \"phenotypes\": null,\n",
      "                      \"qualifications\": \"species of origin for bait and hit is unclear\",\n",
      "                      \"tags\": null,\n",
      "                      \"source_db\": \"BIOGRID\",\n",
      "                      \"agents\": {\n",
      "                       \"raw_text\": [\n",
      "                        null,\n",
      "                        \"RP11-261N11.1\"\n",
      "                       ]\n",
      "                      },\n",
      "                      \"prior_uuids\": [\n",
      "                       \"18c4bfdd-702d-49bf-b005-d2e4f0fc02bd\"\n",
      "                      ]\n",
      "                     },\n",
      "         text_refs={\n",
      "                    \"PMID\": \"16332543\"\n",
      "                   }\n",
      "         )\n",
      "\n",
      "\n",
      "INFO: [2025-06-27 15:21:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:21:35 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:21:35] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:21:36] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:21:36 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:21:36] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:21:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:21:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:21:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:21:36] indra_gpt.chat_curate.chat_curate - Skipping evidence with no text for statement -34105277816332298: Evidence(source_api='biogrid',\n",
      "         pmid='16332543',\n",
      "         source_id='2381444',\n",
      "         annotations={\n",
      "                      \"biogrid_int_id\": \"2381444\",\n",
      "                      \"entrez_a\": \"55738\",\n",
      "                      \"entrez_b\": \"375\",\n",
      "                      \"biogrid_a\": \"120856\",\n",
      "                      \"biogrid_b\": \"106870\",\n",
      "                      \"syst_name_a\": \"RP11-261N11.1\",\n",
      "                      \"syst_name_b\": null,\n",
      "                      \"hgnc_a\": \"ARFGAP1\",\n",
      "                      \"hgnc_b\": \"ARF1\",\n",
      "                      \"syn_a\": \"ARF1GAP|HRIHFB2281\",\n",
      "                      \"syn_b\": null,\n",
      "                      \"exp_system\": \"Biochemical Activity\",\n",
      "                      \"exp_system_type\": \"physical\",\n",
      "                      \"author\": \"Luo R (2005)\",\n",
      "                      \"pmid\": \"16332543\",\n",
      "                      \"organism_a\": \"9606\",\n",
      "                      \"organism_b\": \"9606\",\n",
      "                      \"throughput\": \"Low Throughput\",\n",
      "                      \"score\": null,\n",
      "                      \"modification\": \"No Modification\",\n",
      "                      \"phenotypes\": null,\n",
      "                      \"qualifications\": \"species of origin for bait and hit is unclear\",\n",
      "                      \"tags\": null,\n",
      "                      \"source_db\": \"BIOGRID\",\n",
      "                      \"agents\": {\n",
      "                       \"raw_text\": [\n",
      "                        \"RP11-261N11.1\",\n",
      "                        null\n",
      "                       ]\n",
      "                      },\n",
      "                      \"prior_uuids\": [\n",
      "                       \"1643e188-2b84-4749-87e5-28707e3db1fd\"\n",
      "                      ]\n",
      "                     },\n",
      "         text_refs={\n",
      "                    \"PMID\": \"16332543\"\n",
      "                   }\n",
      "         )\n",
      "\n",
      "\n",
      "INFO: [2025-06-27 15:21:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:21:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:21:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:21:38 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:21:38] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:21:39] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:21:39 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:21:39] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:21:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:21:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:21:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:21:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:21:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:21:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:21:41 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:21:41] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:21:42] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:21:42 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:21:42] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:21:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:21:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:21:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  22%|‚ñà‚ñà‚ñè       | 20/92 [05:09<16:06, 13.42s/it]INFO: [2025-06-27 15:21:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:21:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:21:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:21:45 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:21:45] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:21:46] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:21:46 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:21:46] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:21:46 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:21:46] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:21:46 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:21:46] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:21:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:21:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:21:50 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:21:50] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:21:51] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:21:51 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:21:51] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:21:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:21:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:21:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:21:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:21:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:21:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:21:54 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:21:54] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:21:56] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:21:56 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:21:56] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:21:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:21:56] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:21:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:21:56] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:21:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:21:56] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:21:59 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:21:59] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:22:00] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:22:00 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:22:00] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:22:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:22:00] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:22:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:22:00] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:22:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:22:00] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:22:03 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:22:03] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:22:06] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:22:06 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:22:06] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:22:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:22:06] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:22:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  23%|‚ñà‚ñà‚ñé       | 21/92 [05:33<19:28, 16.46s/it]INFO: [2025-06-27 15:22:06] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:22:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:22:06] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:22:08 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:22:08] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:22:09] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:22:09 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:22:09] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:22:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:22:09] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:22:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:22:09] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:22:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:22:09] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:22:11 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:22:11] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:22:13] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:22:13 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:22:13] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:22:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:22:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:22:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:22:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:22:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:22:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:22:15 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:22:15] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:22:17] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:22:17 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:22:17] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:22:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:22:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:22:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:22:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:22:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:22:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:22:19 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:22:19] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:22:20] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:22:20 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:22:20] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:22:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:22:20] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:22:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:22:20] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:22:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:22:20] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:22:22 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:22:22] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:22:23] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:22:23 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:22:23] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:22:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:22:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:22:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  24%|‚ñà‚ñà‚ñç       | 22/92 [05:50<19:36, 16.81s/it]INFO: [2025-06-27 15:22:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:22:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:22:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:22:25 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:22:25] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:22:27] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:22:27 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:22:27] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:22:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:22:27] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:22:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:22:27] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:22:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:22:27] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:22:29 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:22:29] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:22:30] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:22:30 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:22:30] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:22:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:22:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:22:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:22:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:22:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:22:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:22:32 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:22:32] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:22:33] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:22:33 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:22:33] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:22:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:22:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:22:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:22:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:22:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:22:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:22:35 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:22:35] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:22:36] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:22:36 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:22:36] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:22:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:22:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:22:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:22:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:22:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:22:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:22:38 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:22:38] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:22:40] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:22:40 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:22:40] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:22:40 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:22:40] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:22:40 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  25%|‚ñà‚ñà‚ñå       | 23/92 [06:07<19:15, 16.74s/it]INFO: [2025-06-27 15:22:40] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:22:40 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:22:40] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:22:42 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:22:42] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:22:44] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:22:44 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:22:44] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:22:44 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:22:44] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:22:44 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:22:44] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:22:44 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:22:44] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:22:46 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:22:46] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:22:47] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:22:47 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:22:47] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:22:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:22:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:22:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:22:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:22:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:22:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:22:49 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:22:49] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:22:51] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:22:51 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:22:51] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:22:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:22:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:22:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:22:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:22:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:22:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:22:53 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:22:53] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:22:54] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:22:54 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:22:54] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:22:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:22:54] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:22:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:22:54] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:22:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:22:54] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:22:56 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:22:56] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:22:58] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:22:58 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:22:58] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:22:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:22:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:22:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  26%|‚ñà‚ñà‚ñå       | 24/92 [06:24<19:15, 17.00s/it]INFO: [2025-06-27 15:22:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:22:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:22:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:23:00 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:23:00] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:23:00] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:23:00 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:23:00] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:23:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:23:00] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:23:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:23:00] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:23:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:23:00] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:23:02 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:23:02] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:23:03] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:23:03 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:23:03] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:23:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:23:03] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:23:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:23:03] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:23:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:23:03] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:23:05 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:23:05] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:23:07] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:23:07 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:23:07] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:23:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:23:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:23:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:23:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:23:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:23:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:23:09 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:23:09] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:23:10] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:23:10 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:23:10] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:23:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:23:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:23:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:23:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:23:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:23:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:23:12 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:23:12] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:23:17] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:23:17 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:23:17] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:23:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:23:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:23:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  27%|‚ñà‚ñà‚ñã       | 25/92 [06:44<19:56, 17.86s/it]INFO: [2025-06-27 15:23:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:23:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:23:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:23:20 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:23:20] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:23:21] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:23:21 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:23:21] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:23:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:23:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:23:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:23:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:23:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:23:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:23:24 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:23:24] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:23:25] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:23:25 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:23:25] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:23:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:23:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:23:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:23:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:23:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:23:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:23:27 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:23:27] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:23:28] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:23:28 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:23:28] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:23:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:23:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:23:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:23:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:23:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:23:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:23:30 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:23:30] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:23:32] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:23:32 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:23:32] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:23:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:23:32] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:23:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:23:32] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:23:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:23:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:23:34 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:23:34] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:23:36] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:23:36 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:23:36] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:23:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:23:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:23:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  28%|‚ñà‚ñà‚ñä       | 26/92 [07:03<20:00, 18.19s/it]INFO: [2025-06-27 15:23:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:23:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:23:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:23:38 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:23:38] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:23:40] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:23:40 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:23:40] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:23:40 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:23:40] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:23:40 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:23:40] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:23:40 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:23:40] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:23:42 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:23:42] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:23:43] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:23:43 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:23:43] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:23:43 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:23:43] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:23:43 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:23:43] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:23:43 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:23:43] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:23:45 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:23:45] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:23:46] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:23:46 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:23:46] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:23:46 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:23:46] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:23:46 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:23:46] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:23:46 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:23:46] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:23:49 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:23:49] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:23:50] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:23:50 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:23:50] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:23:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:23:50] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:23:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:23:50] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:23:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:23:50] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:23:52 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:23:52] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:23:53] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:23:53 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:23:53] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:23:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:23:53] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:23:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  29%|‚ñà‚ñà‚ñâ       | 27/92 [07:20<19:11, 17.71s/it]INFO: [2025-06-27 15:23:53] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:23:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:23:53] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:23:54 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:23:54] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:23:55] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:23:55 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:23:55] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:23:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:23:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:23:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:23:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:23:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:23:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:23:56 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:23:56] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:23:57] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:23:57 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:23:57] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:23:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:23:57] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:23:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:23:57] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:23:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:23:57] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:23:58 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:23:58] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:23:59] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:23:59 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:23:59] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:23:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:23:59] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:23:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:23:59] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:23:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:23:59] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:24:00 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:24:00] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:24:02] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:24:02 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:24:02] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:24:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:24:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:24:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:24:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:24:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:24:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:24:03 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:24:03] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:24:04] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:24:04 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:24:04] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:24:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:24:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:24:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  30%|‚ñà‚ñà‚ñà       | 28/92 [07:31<16:43, 15.68s/it]INFO: [2025-06-27 15:24:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:24:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:24:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:24:06 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:24:06] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:24:07] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:24:07 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:24:07] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:24:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:24:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:24:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:24:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:24:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:24:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:24:09 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:24:09] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:24:10] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:24:10 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:24:10] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:24:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:24:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:24:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:24:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:24:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:24:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:24:12 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:24:12] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:24:14] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:24:14 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:24:14] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:24:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:24:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:24:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:24:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:24:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:24:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:24:16 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:24:16] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:24:17] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:24:17 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:24:17] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:24:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:24:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:24:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:24:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:24:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:24:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:24:19 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:24:19] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:24:22] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:24:22 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:24:22] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:24:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:24:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:24:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  32%|‚ñà‚ñà‚ñà‚ñè      | 29/92 [07:49<17:09, 16.35s/it]INFO: [2025-06-27 15:24:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:24:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:24:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:24:24 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:24:24] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:24:25] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:24:25 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:24:25] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:24:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:24:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:24:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:24:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:24:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:24:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:24:27 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:24:27] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:24:28] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:24:28 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:24:28] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:24:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:24:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:24:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:24:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:24:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:24:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:24:30 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:24:30] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:24:31] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:24:31 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:24:31] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:24:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:24:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:24:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:24:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:24:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:24:32] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:24:33 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:24:33] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:24:35] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:24:35 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:24:35] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:24:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:24:35] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:24:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:24:35] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:24:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:24:35] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:24:37 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:24:37] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:24:39] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:24:39 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:24:39] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:24:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:24:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:24:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  33%|‚ñà‚ñà‚ñà‚ñé      | 30/92 [08:05<17:00, 16.46s/it]INFO: [2025-06-27 15:24:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:24:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:24:39] indra_gpt.chat_curate.chat_curate - Skipping agent NP() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "INFO: [2025-06-27 15:24:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:24:40 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:24:40] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:24:41] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:24:41 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:24:41] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:24:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:24:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:24:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:24:41] indra_gpt.chat_curate.chat_curate - Skipping agent NP() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "INFO: [2025-06-27 15:24:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:24:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:24:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:24:42 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:24:42] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:24:43] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:24:43 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:24:43] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:24:43 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:24:43] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:24:43 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:24:43] indra_gpt.chat_curate.chat_curate - Skipping agent NP() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "INFO: [2025-06-27 15:24:43] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:24:43 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:24:43] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:24:44 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:24:44] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:24:45] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:24:45 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:24:45] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:24:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:24:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:24:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:24:45] indra_gpt.chat_curate.chat_curate - Skipping agent NP() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "INFO: [2025-06-27 15:24:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:24:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:24:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:24:46 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:24:46] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:24:47] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:24:47 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:24:47] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:24:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:24:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:24:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:24:47] indra_gpt.chat_curate.chat_curate - Skipping agent NP() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "INFO: [2025-06-27 15:24:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:24:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:24:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:24:48 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:24:48] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:24:49] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:24:49 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:24:49] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:24:49 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:24:49] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:24:49 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  34%|‚ñà‚ñà‚ñà‚ñé      | 31/92 [08:16<14:55, 14.68s/it]INFO: [2025-06-27 15:24:49] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:24:49 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:24:49] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:24:51 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:24:51] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:24:52] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:24:52 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:24:52] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:24:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:24:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:24:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:24:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:24:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:24:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:24:54 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:24:54] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:24:55] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:24:55 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:24:55] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:24:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:24:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:24:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:24:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:24:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:24:56] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:24:57 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:24:57] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:24:58] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:24:58 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:24:58] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:24:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:24:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:24:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:24:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:24:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:24:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:25:00 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:25:00] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:25:01] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:25:01 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:25:01] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:25:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:25:01] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:25:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:25:01] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:25:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:25:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:25:04 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:25:04] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:25:05] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:25:05 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:25:05] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:25:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:25:05] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:25:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  35%|‚ñà‚ñà‚ñà‚ñç      | 32/92 [08:32<14:57, 14.97s/it]INFO: [2025-06-27 15:25:05] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:25:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:25:05] indra_gpt.chat_curate.chat_curate - Skipping evidence with no text for statement 5895544448831150: Evidence(source_api='biogrid',\n",
      "         pmid='11792840',\n",
      "         source_id='280520',\n",
      "         annotations={\n",
      "                      \"biogrid_int_id\": \"280520\",\n",
      "                      \"entrez_a\": \"6840\",\n",
      "                      \"entrez_b\": \"367\",\n",
      "                      \"biogrid_a\": \"112707\",\n",
      "                      \"biogrid_b\": \"106862\",\n",
      "                      \"syst_name_a\": \"RP11-534G20.1\",\n",
      "                      \"syst_name_b\": \"RP11-383C12.1\",\n",
      "                      \"hgnc_a\": \"SVIL\",\n",
      "                      \"hgnc_b\": \"AR\",\n",
      "                      \"syn_a\": null,\n",
      "                      \"syn_b\": \"AIS|DHTR|HUMARA|HYSP1|KD|NR3C4|SBMA|SMAX1|TFM\",\n",
      "                      \"exp_system\": \"Two-hybrid\",\n",
      "                      \"exp_system_type\": \"physical\",\n",
      "                      \"author\": \"Ting HJ (2002)\",\n",
      "                      \"pmid\": \"11792840\",\n",
      "                      \"organism_a\": \"9606\",\n",
      "                      \"organism_b\": \"9606\",\n",
      "                      \"throughput\": \"Low Throughput\",\n",
      "                      \"score\": null,\n",
      "                      \"modification\": null,\n",
      "                      \"phenotypes\": null,\n",
      "                      \"qualifications\": null,\n",
      "                      \"tags\": null,\n",
      "                      \"source_db\": \"BIOGRID\",\n",
      "                      \"agents\": {\n",
      "                       \"raw_text\": [\n",
      "                        \"RP11-534G20.1\",\n",
      "                        \"RP11-383C12.1\"\n",
      "                       ]\n",
      "                      },\n",
      "                      \"prior_uuids\": [\n",
      "                       \"6488b526-899f-42ed-a310-982899f86d16\"\n",
      "                      ]\n",
      "                     },\n",
      "         text_refs={\n",
      "                    \"PMID\": \"11792840\"\n",
      "                   }\n",
      "         )\n",
      "\n",
      "\n",
      "INFO: [2025-06-27 15:25:05] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:25:05] indra_gpt.chat_curate.chat_curate - Skipping evidence with no text for statement 5895544448831150: Evidence(source_api='hprd',\n",
      "         pmid='11792840',\n",
      "         source_id='http://hprd.org/interactions?hprd_id=04992&isoform_id=04992_1&isoform_name=Isoform_1',\n",
      "         annotations={\n",
      "                      \"evidence\": [\n",
      "                       \"in vitro\",\n",
      "                       \"yeast 2-hybrid\"\n",
      "                      ],\n",
      "                      \"agents\": {\n",
      "                       \"raw_text\": [\n",
      "                        null,\n",
      "                        null\n",
      "                       ]\n",
      "                      },\n",
      "                      \"prior_uuids\": [\n",
      "                       \"fd7172f1-a5b9-41c6-831a-53e68d6db1c0\"\n",
      "                      ]\n",
      "                     },\n",
      "         text_refs={\n",
      "                    \"PMID\": \"11792840\"\n",
      "                   }\n",
      "         )\n",
      "\n",
      "\n",
      "\u001b[92m15:25:07 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:25:07] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:25:08] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:25:08 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:25:08] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:25:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:25:08] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:25:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:25:08] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:25:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:25:08] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:25:10 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:25:10] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:25:11] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:25:11 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:25:11] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:25:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:25:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:25:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:25:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:25:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:25:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:25:13 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:25:13] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:25:14] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:25:14 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:25:14] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:25:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:25:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:25:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  36%|‚ñà‚ñà‚ñà‚ñå      | 33/92 [08:41<13:10, 13.41s/it]INFO: [2025-06-27 15:25:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:25:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:25:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:25:16 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:25:16] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:25:17] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:25:17 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:25:17] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:25:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:25:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:25:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:25:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:25:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:25:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:25:18 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:25:18] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:25:21] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:25:21 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:25:21] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:25:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:25:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:25:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:25:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:25:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:25:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:25:22 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:25:22] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:25:23] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:25:23 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:25:23] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:25:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:25:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:25:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:25:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:25:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:25:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:25:24 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:25:24] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:25:25] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:25:26 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:25:26] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:25:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:25:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:25:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:25:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:25:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:25:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:25:27 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:25:27] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:25:28] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:25:28 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:25:28] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:25:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:25:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:25:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  37%|‚ñà‚ñà‚ñà‚ñã      | 34/92 [08:55<12:57, 13.41s/it]INFO: [2025-06-27 15:25:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:25:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:25:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:25:30 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:25:30] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:25:31] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:25:31 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:25:31] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:25:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:25:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:25:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:25:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:25:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:25:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:25:33 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:25:33] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:25:34] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:25:34 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:25:34] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:25:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:25:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:25:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:25:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:25:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:25:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:25:36 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:25:36] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:25:37] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:25:37 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:25:37] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:25:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:25:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:25:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:25:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:25:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:25:38] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:25:40 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:25:40] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:25:41] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:25:41 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:25:41] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:25:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:25:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:25:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:25:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:25:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:25:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:25:43 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:25:43] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:25:44] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:25:44 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:25:44] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:25:44 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:25:44] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:25:44 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  38%|‚ñà‚ñà‚ñà‚ñä      | 35/92 [09:11<13:33, 14.27s/it]INFO: [2025-06-27 15:25:44] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:25:44 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:25:44] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:25:46 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:25:46] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:25:48] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:25:48 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:25:48] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:25:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:25:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:25:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:25:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:25:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:25:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:25:50 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:25:50] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:25:51] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:25:51 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:25:51] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:25:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:25:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:25:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:25:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:25:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:25:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:25:53 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:25:53] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:25:55] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:25:55 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:25:55] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:25:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:25:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:25:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:25:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:25:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:25:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:25:57 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:25:57] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:25:58] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:25:58 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:25:58] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:25:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:25:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:25:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:25:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:25:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:25:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:26:00 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:26:00] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:26:02] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:26:02 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:26:02] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:26:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:26:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:26:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  39%|‚ñà‚ñà‚ñà‚ñâ      | 36/92 [09:28<14:11, 15.21s/it]INFO: [2025-06-27 15:26:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:26:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:26:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:26:03 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:26:03] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:26:04] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:26:04 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:26:04] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:26:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:26:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:26:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:26:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:26:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:26:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:26:05 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:26:05] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:26:06] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:26:06 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:26:06] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:26:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:26:06] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:26:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:26:06] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:26:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:26:06] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:26:07 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:26:07] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:26:08] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:26:08 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:26:08] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:26:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:26:08] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:26:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:26:08] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:26:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:26:08] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:26:10 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:26:10] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:26:11] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:26:11 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:26:11] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:26:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:26:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:26:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:26:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:26:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:26:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:26:12 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:26:12] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:26:13] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:26:13 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:26:13] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:26:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:26:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:26:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  40%|‚ñà‚ñà‚ñà‚ñà      | 37/92 [09:40<12:56, 14.11s/it]INFO: [2025-06-27 15:26:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:26:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:26:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:26:15 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:26:15] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:26:17] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:26:17 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:26:17] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:26:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:26:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:26:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:26:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:26:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:26:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:26:19 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:26:19] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:26:20] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:26:20 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:26:20] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:26:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:26:20] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:26:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:26:20] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:26:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:26:20] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:26:22 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:26:22] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:26:24] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:26:24 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:26:24] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:26:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:26:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:26:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:26:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:26:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:26:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:26:27 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:26:27] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:26:28] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:26:28 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:26:28] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:26:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:26:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:26:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:26:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:26:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:26:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:26:30 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:26:30] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:26:32] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:26:32 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:26:32] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:26:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:26:32] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:26:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 38/92 [09:58<13:52, 15.41s/it]INFO: [2025-06-27 15:26:32] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:26:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:26:32] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:26:34 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:26:34] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:26:35] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:26:35 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:26:35] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:26:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:26:35] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:26:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:26:35] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:26:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:26:35] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:26:37 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:26:37] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:26:38] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:26:38 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:26:38] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:26:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:26:38] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:26:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:26:38] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:26:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:26:38] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:26:40 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:26:40] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:26:41] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:26:41 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:26:41] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:26:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:26:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:26:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:26:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:26:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:26:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:26:43 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:26:43] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:26:44] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:26:44 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:26:44] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:26:44 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:26:44] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:26:44 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:26:44] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:26:44 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:26:44] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:26:46 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:26:46] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:26:47] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:26:47 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:26:47] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:26:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:26:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:26:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 39/92 [10:14<13:44, 15.55s/it]INFO: [2025-06-27 15:26:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:26:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:26:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:26:49 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:26:49] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:26:51] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:26:51 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:26:51] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:26:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:26:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:26:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:26:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:26:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:26:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:26:53 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:26:53] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:26:54] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:26:54 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:26:54] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:26:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:26:54] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:26:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:26:54] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:26:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:26:54] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:26:56 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:26:56] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:26:58] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:26:58 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:26:58] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:26:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:26:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:26:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:26:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:26:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:26:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:27:00 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:27:00] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:27:01] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:27:01 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:27:01] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:27:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:27:01] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:27:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:27:01] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:27:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:27:01] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:27:03 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:27:03] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:27:04] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:27:04 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:27:04] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:27:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:27:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:27:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 40/92 [10:31<13:48, 15.94s/it]INFO: [2025-06-27 15:27:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:27:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:27:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:27:06 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:27:06] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:27:07] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:27:07 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:27:07] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:27:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:27:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:27:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:27:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:27:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:27:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:27:10 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:27:10] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:27:11] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:27:11 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:27:11] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:27:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:27:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:27:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:27:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:27:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:27:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:27:13 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:27:13] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:27:16] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:27:16 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:27:16] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:27:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:27:16] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:27:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:27:16] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:27:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:27:16] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:27:18 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:27:18] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:27:19] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:27:19 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:27:19] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:27:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:27:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:27:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:27:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:27:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:27:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:27:21 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:27:21] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:27:23] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:27:23 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:27:23] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:27:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:27:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:27:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 41/92 [10:50<14:10, 16.67s/it]INFO: [2025-06-27 15:27:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:27:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:27:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:27:25 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:27:25] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:27:26] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:27:26 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:27:26] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:27:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:27:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:27:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:27:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:27:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:27:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:27:28 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:27:28] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:27:29] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:27:29 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:27:29] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:27:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:27:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:27:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:27:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:27:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:27:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:27:31 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:27:31] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:27:32] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:27:32 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:27:32] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:27:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:27:32] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:27:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:27:32] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:27:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:27:32] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:27:34 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:27:34] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:27:35] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:27:35 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:27:35] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:27:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:27:35] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:27:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:27:35] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:27:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:27:35] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:27:37 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:27:37] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:27:39] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:27:39 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:27:39] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:27:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:27:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:27:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 42/92 [11:05<13:41, 16.43s/it]INFO: [2025-06-27 15:27:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:27:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:27:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:27:41 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:27:41] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:27:41] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:27:41 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:27:41] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:27:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:27:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:27:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:27:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:27:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:27:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:27:44 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:27:44] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:27:45] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:27:45 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:27:45] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:27:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:27:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:27:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:27:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:27:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:27:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:27:47 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:27:47] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:27:48] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:27:48 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:27:48] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:27:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:27:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:27:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:27:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:27:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:27:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:27:50 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:27:50] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:27:51] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:27:51 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:27:51] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:27:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:27:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:27:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:27:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:27:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:27:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:27:53 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:27:53] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:27:54] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:27:54 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:27:54] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:27:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:27:54] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:27:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 43/92 [11:21<13:10, 16.14s/it]INFO: [2025-06-27 15:27:54] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:27:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:27:54] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:27:56 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:27:56] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:27:57] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:27:57 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:27:57] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:27:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:27:57] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:27:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:27:57] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:27:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:27:57] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:28:00 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:28:00] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:28:01] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:28:01 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:28:01] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:28:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:28:01] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:28:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:28:01] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:28:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:28:01] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:28:03 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:28:03] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:28:04] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:28:04 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:28:04] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:28:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:28:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:28:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:28:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:28:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:28:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:28:06 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:28:06] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:28:07] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:28:07 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:28:07] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:28:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:28:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:28:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:28:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:28:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:28:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:28:09 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:28:09] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:28:10] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:28:10 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:28:10] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:28:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:28:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:28:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 44/92 [11:37<12:53, 16.12s/it]INFO: [2025-06-27 15:28:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:28:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:28:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:28:12 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:28:12] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:28:13] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:28:13 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:28:13] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:28:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:28:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:28:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:28:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:28:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:28:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:28:15 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:28:15] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:28:16] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:28:16 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:28:16] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:28:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:28:16] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:28:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:28:16] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:28:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:28:16] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:28:18 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:28:18] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:28:20] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:28:20 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:28:20] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:28:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:28:20] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:28:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:28:20] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:28:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:28:20] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:28:22 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:28:22] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:28:23] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:28:23 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:28:23] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:28:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:28:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:28:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:28:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:28:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:28:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:28:25 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:28:25] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:28:26] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:28:26 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:28:26] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:28:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:28:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:28:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 45/92 [11:53<12:32, 16.02s/it]INFO: [2025-06-27 15:28:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:28:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:28:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:28:27 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:28:27] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:28:28] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:28:28 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:28:28] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:28:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:28:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:28:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:28:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:28:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:28:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:28:29 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:28:29] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:28:33] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:28:33 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:28:33] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:28:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:28:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:28:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:28:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:28:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:28:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:28:34 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:28:34] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:28:35] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:28:35 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:28:35] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:28:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:28:35] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:28:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:28:35] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:28:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:28:35] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:28:37 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:28:37] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:28:38] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:28:38 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:28:38] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:28:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:28:38] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:28:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:28:38] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:28:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:28:38] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:28:39 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:28:39] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:28:40] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:28:40 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:28:40] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:28:40 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:28:40] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:28:40 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 46/92 [12:07<11:56, 15.57s/it]INFO: [2025-06-27 15:28:40] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:28:40 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:28:40] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:28:42 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:28:42] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:28:43] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:28:43 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:28:43] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:28:43 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:28:43] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:28:43 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:28:43] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:28:43 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:28:43] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:28:44 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:28:44] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:28:45] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:28:45 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:28:45] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:28:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:28:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:28:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:28:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:28:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:28:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:28:47 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:28:47] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:28:48] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:28:48 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:28:48] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:28:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:28:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:28:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:28:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:28:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:28:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:28:49 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:28:49] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:28:50] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:28:50 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:28:50] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:28:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:28:50] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:28:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:28:50] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:28:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:28:50] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:28:51 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:28:51] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:28:52] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:28:52 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:28:52] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:28:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:28:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:28:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 47/92 [12:19<10:51, 14.48s/it]INFO: [2025-06-27 15:28:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:28:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:28:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:28:54 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:28:54] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:28:56] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:28:56 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:28:56] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:28:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:28:56] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:28:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:28:56] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:28:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:28:56] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:28:58 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:28:58] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:28:59] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:28:59 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:28:59] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:28:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:28:59] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:28:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:28:59] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:28:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:28:59] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:29:01 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:29:01] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:29:03] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:29:03 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:29:03] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:29:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:29:03] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:29:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:29:03] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:29:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:29:03] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:29:05 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:29:05] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:29:06] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:29:06 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:29:06] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:29:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:29:06] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:29:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:29:06] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:29:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:29:06] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:29:08 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:29:08] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:29:11] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:29:11 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:29:11] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:29:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:29:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:29:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 48/92 [12:38<11:28, 15.65s/it]INFO: [2025-06-27 15:29:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:29:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:29:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:29:13 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:29:13] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:29:14] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:29:14 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:29:14] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:29:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:29:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:29:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:29:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:29:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:29:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:29:16 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:29:16] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:29:18] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:29:18 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:29:18] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:29:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:29:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:29:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:29:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:29:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:29:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:29:20 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:29:20] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:29:21] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:29:21 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:29:21] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:29:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:29:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:29:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:29:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:29:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:29:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:29:23 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:29:23] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:29:24] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:29:24 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:29:24] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:29:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:29:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:29:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:29:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:29:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:29:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:29:27 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:29:27] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:29:28] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:29:28 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:29:28] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:29:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:29:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:29:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 49/92 [12:55<11:40, 16.30s/it]INFO: [2025-06-27 15:29:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:29:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:29:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:29:31 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:29:31] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:29:33] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:29:33 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:29:33] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:29:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:29:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:29:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:29:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:29:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:29:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:29:35 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:29:35] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:29:36] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:29:36 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:29:36] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:29:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:29:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:29:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:29:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:29:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:29:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:29:39 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:29:39] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:29:41] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:29:41 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:29:41] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:29:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:29:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:29:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:29:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:29:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:29:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:29:43 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:29:43] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:29:44] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:29:44 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:29:44] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:29:44 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:29:44] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:29:44 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 50/92 [13:11<11:14, 16.05s/it]INFO: [2025-06-27 15:29:44] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:29:44 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:29:44] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:29:46 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:29:46] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:29:47] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:29:47 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:29:47] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:29:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:29:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:29:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:29:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:29:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:29:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:29:49 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:29:49] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:29:51] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:29:51 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:29:51] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:29:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:29:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:29:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:29:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:29:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:29:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:29:53 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:29:53] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:29:54] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:29:54 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:29:54] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:29:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:29:54] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:29:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:29:54] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:29:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:29:54] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:29:56 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:29:56] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:29:57] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:29:57 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:29:57] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:29:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:29:57] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:29:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 51/92 [13:24<10:24, 15.23s/it]INFO: [2025-06-27 15:29:57] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:29:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:29:57] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:29:59 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:29:59] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:30:02] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:30:02 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:30:02] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:30:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:30:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:30:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:30:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:30:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:30:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:30:04 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:30:04] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:30:06] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:30:06 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:30:06] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:30:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:30:06] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:30:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:30:06] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:30:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:30:06] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:30:08 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:30:08] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:30:09] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:30:09 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:30:09] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:30:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:30:09] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:30:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:30:09] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:30:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:30:09] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:30:11 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:30:11] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:30:12] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:30:12 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:30:12] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:30:12 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:30:12] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:30:12 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 52/92 [13:39<10:04, 15.11s/it]INFO: [2025-06-27 15:30:12] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:30:12 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:30:12] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:30:14 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:30:14] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:30:16] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:30:16 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:30:16] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:30:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:30:16] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:30:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:30:16] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:30:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:30:16] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:30:18 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:30:18] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:30:19] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:30:19 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:30:19] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:30:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:30:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:30:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:30:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:30:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:30:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:30:21 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:30:21] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:30:25] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:30:25 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:30:25] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:30:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:30:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:30:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:30:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:30:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:30:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:30:27 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:30:27] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:30:28] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:30:28 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:30:28] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:30:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:30:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:30:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 53/92 [13:55<09:58, 15.34s/it]INFO: [2025-06-27 15:30:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:30:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:30:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:30:28 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:30:28] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:30:29] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:30:29 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:30:29] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:30:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:30:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:30:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:30:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:30:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:30:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:30:30 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:30:30] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:30:31] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:30:31 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:30:31] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:30:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:30:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:30:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:30:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:30:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:30:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:30:31 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:30:31] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:30:32] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:30:32 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:30:32] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:30:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:30:32] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:30:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:30:32] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:30:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:30:32] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:30:33 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:30:33] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:30:36] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:30:36 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:30:36] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:30:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:30:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:30:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 54/92 [14:02<08:14, 13.01s/it]INFO: [2025-06-27 15:30:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:30:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:30:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:30:38 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:30:38] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:30:39] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:30:39 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:30:39] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:30:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:30:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:30:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:30:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:30:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:30:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:30:41 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:30:41] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:30:42] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:30:42 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:30:42] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:30:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:30:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:30:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:30:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:30:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:30:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:30:44 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:30:44] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:30:45] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:30:45 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:30:45] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:30:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:30:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:30:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:30:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:30:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:30:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:30:47 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:30:47] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:30:48] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:30:48 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:30:48] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:30:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:30:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:30:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 55/92 [14:15<07:59, 12.95s/it]INFO: [2025-06-27 15:30:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:30:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:30:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:30:50 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:30:50] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:30:51] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:30:51 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:30:51] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:30:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:30:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:30:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:30:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:30:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:30:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:30:53 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:30:53] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:30:55] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:30:55 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:30:55] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:30:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:30:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:30:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:30:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:30:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:30:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:30:57 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:30:57] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:30:58] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:30:58 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:30:58] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:30:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:30:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:30:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 56/92 [14:25<07:06, 11.86s/it]INFO: [2025-06-27 15:30:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:30:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:30:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:31:00 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:31:00] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:31:01] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:31:01 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:31:01] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:31:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:31:01] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:31:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:31:01] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:31:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:31:01] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:31:03 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:31:03] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:31:04] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:31:04 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:31:04] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:31:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:31:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:31:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:31:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:31:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:31:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:31:06 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:31:06] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:31:08] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:31:08 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:31:08] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:31:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:31:08] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:31:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 57/92 [14:35<06:38, 11.37s/it]INFO: [2025-06-27 15:31:08] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:31:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:31:08] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:31:10 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:31:10] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:31:11] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:31:11 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:31:11] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:31:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:31:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:31:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:31:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:31:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:31:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:31:13 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:31:13] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:31:14] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:31:14 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:31:14] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:31:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:31:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:31:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:31:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:31:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:31:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:31:16 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:31:16] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:31:18] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:31:18 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:31:18] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:31:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:31:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:31:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 58/92 [14:44<06:08, 10.85s/it]INFO: [2025-06-27 15:31:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:31:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:31:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:31:20 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:31:20] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:31:24] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:31:24 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:31:24] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:31:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:31:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:31:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:31:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:31:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:31:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:31:26 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:31:26] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:31:27] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:31:27 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:31:27] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:31:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:31:27] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:31:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:31:27] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:31:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:31:27] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:31:29 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:31:29] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:31:30] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:31:30 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:31:30] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:31:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:31:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:31:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 59/92 [14:57<06:13, 11.31s/it]INFO: [2025-06-27 15:31:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:31:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:31:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:31:32 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:31:32] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:31:33] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:31:33 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:31:33] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:31:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:31:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:31:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:31:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:31:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:31:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:31:36 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:31:36] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:31:37] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:31:37 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:31:37] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:31:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:31:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:31:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:31:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:31:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:31:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:31:39 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:31:39] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:31:40] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:31:40 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:31:40] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:31:40 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:31:40] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:31:40 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 60/92 [15:07<05:53, 11.05s/it]INFO: [2025-06-27 15:31:40] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:31:40 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:31:40] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:31:42 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:31:42] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:31:44] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:31:44 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:31:44] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:31:44 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:31:44] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:31:44 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:31:44] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:31:44 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:31:44] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:31:46 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:31:46] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:31:48] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:31:48 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:31:48] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:31:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:31:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:31:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:31:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:31:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:31:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:31:50 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:31:50] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:31:51] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:31:51 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:31:51] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:31:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:31:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:31:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 61/92 [15:18<05:36, 10.85s/it]INFO: [2025-06-27 15:31:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:31:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:31:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:31:53 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:31:53] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:31:54] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:31:54 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:31:54] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:31:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:31:54] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:31:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:31:54] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:31:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:31:54] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:31:56 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:31:56] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:31:57] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:31:57 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:31:57] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:31:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:31:57] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:31:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:31:57] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:31:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:31:57] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:31:59 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:31:59] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:32:00] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:32:00 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:32:00] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:32:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:32:00] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:32:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 62/92 [15:27<05:13, 10.44s/it]INFO: [2025-06-27 15:32:00] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:32:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:32:00] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:32:02 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:32:02] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:32:03] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:32:03 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:32:03] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:32:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:32:03] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:32:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:32:03] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:32:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:32:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:32:06 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:32:06] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:32:07] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:32:07 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:32:07] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:32:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:32:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:32:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 63/92 [15:34<04:29,  9.31s/it]INFO: [2025-06-27 15:32:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:32:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:32:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:32:09 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:32:09] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:32:11] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:32:11 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:32:11] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:32:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:32:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:32:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:32:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:32:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:32:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:32:13 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:32:13] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:32:14] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:32:14 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:32:14] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:32:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:32:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:32:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 64/92 [15:41<04:03,  8.69s/it]INFO: [2025-06-27 15:32:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:32:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:32:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:32:16 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:32:16] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:32:18] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:32:18 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:32:18] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:32:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:32:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:32:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:32:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:32:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:32:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:32:20 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:32:20] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:32:21] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:32:21 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:32:21] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:32:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:32:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:32:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 65/92 [15:48<03:39,  8.13s/it]INFO: [2025-06-27 15:32:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:32:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:32:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:32:23 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:32:23] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:32:25] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:32:25 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:32:25] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:32:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:32:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:32:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:32:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:32:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:32:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:32:27 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:32:27] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:32:28] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:32:28 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:32:28] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:32:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:32:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:32:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 66/92 [15:55<03:21,  7.76s/it]INFO: [2025-06-27 15:32:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:32:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:32:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:32:28] indra_gpt.chat_curate.chat_curate - Skipping agent function() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "\u001b[92m15:32:29 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:32:29] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:32:31] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:32:31 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:32:31] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:32:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:32:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:32:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:32:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:32:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:32:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:32:31] indra_gpt.chat_curate.chat_curate - Skipping agent function() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "\u001b[92m15:32:32 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:32:32] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:32:37] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:32:37 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:32:37] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:32:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:32:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:32:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 67/92 [16:04<03:21,  8.08s/it]INFO: [2025-06-27 15:32:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:32:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:32:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:32:39 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:32:39] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:32:40] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:32:40 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:32:40] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:32:40 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:32:40] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:32:40 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:32:40] indra_gpt.chat_curate.chat_curate - Skipping evidence with no text for statement -6735076600090236: Evidence(source_api='biopax',\n",
      "         source_id='http://www.phosphosite.org/phosphosite.owl#Catalysis_25233804_604',\n",
      "         annotations={\n",
      "                      \"source_sub_id\": \"phosphositeplus\",\n",
      "                      \"agents\": {\n",
      "                       \"raw_text\": [\n",
      "                        null,\n",
      "                        null\n",
      "                       ]\n",
      "                      },\n",
      "                      \"prior_uuids\": [\n",
      "                       \"bc120eec-d5a9-4509-b2d7-7596d200281e\"\n",
      "                      ]\n",
      "                     },\n",
      "         epistemics={\n",
      "                     \"direct\": true\n",
      "                    }\n",
      "         )\n",
      "\n",
      "\n",
      "Curating statements with chat curation:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 68/92 [16:07<02:39,  6.63s/it]INFO: [2025-06-27 15:32:40] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:32:40 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:32:40] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:32:42 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:32:42] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:32:43] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:32:43 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:32:43] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:32:43 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:32:43] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:32:43 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:32:43] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:32:43 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:32:43] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:32:45 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:32:45] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:32:47] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:32:47 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:32:47] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:32:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:32:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:32:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 69/92 [16:13<02:32,  6.63s/it]INFO: [2025-06-27 15:32:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:32:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:32:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:32:49 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:32:49] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:32:50] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:32:50 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:32:50] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:32:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:32:50] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:32:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:32:50] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:32:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:32:50] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:32:52 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:32:52] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:32:53] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:32:53 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:32:53] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:32:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:32:53] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:32:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 70/92 [16:20<02:23,  6.53s/it]INFO: [2025-06-27 15:32:53] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:32:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:32:53] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:32:54 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:32:54] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:32:55] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:32:55 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:32:55] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:32:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:32:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:32:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:32:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:32:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:32:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:32:57 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:32:57] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:32:58] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:32:58 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:32:58] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:32:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:32:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:32:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 71/92 [16:25<02:11,  6.24s/it]INFO: [2025-06-27 15:32:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:32:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:32:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:33:01 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:33:01] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:33:02] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:33:02 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:33:02] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:33:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:33:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:33:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:33:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:33:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:33:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:33:04 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:33:04] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:33:05] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:33:05 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:33:05] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:33:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:33:05] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:33:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 72/92 [16:32<02:05,  6.27s/it]INFO: [2025-06-27 15:33:05] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:33:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:33:05] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:33:08 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:33:08] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:33:09] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:33:09 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:33:09] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:33:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:33:09] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:33:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:33:09] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:33:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:33:09] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:33:12 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:33:12] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:33:13] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:33:13 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:33:13] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:33:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:33:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:33:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 73/92 [16:40<02:10,  6.88s/it]INFO: [2025-06-27 15:33:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:33:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:33:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:33:15 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:33:15] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:33:17] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:33:17 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:33:17] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:33:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:33:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:33:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 74/92 [16:44<01:46,  5.92s/it]INFO: [2025-06-27 15:33:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:33:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:33:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:33:19 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:33:19] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:33:20] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:33:20 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:33:20] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:33:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:33:20] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:33:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 75/92 [16:47<01:27,  5.12s/it]INFO: [2025-06-27 15:33:20] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:33:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:33:20] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:33:22 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:33:22] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:33:23] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:33:23 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:33:23] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:33:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:33:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:33:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 76/92 [16:50<01:13,  4.60s/it]INFO: [2025-06-27 15:33:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:33:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:33:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:33:26 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:33:26] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:33:27] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:33:27 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:33:27] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:33:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:33:27] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:33:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 77/92 [16:54<01:06,  4.45s/it]INFO: [2025-06-27 15:33:27] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:33:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:33:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:33:29 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:33:29] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:33:30] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:33:30 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:33:30] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:33:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:33:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:33:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 78/92 [16:57<00:55,  3.97s/it]INFO: [2025-06-27 15:33:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:33:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:33:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:33:32 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:33:32] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:33:34] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:33:34 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:33:34] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:33:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:33:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:33:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 79/92 [17:01<00:49,  3.79s/it]INFO: [2025-06-27 15:33:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:33:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:33:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:33:34] indra_gpt.chat_curate.chat_curate - Skipping agent cytokine() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "\u001b[92m15:33:37 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:33:37] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:33:38] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:33:38 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:33:38] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:33:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:33:38] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:33:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 80/92 [17:05<00:46,  3.89s/it]INFO: [2025-06-27 15:33:38] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:33:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:33:38] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:33:40 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:33:40] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:33:41] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:33:41 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:33:41] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:33:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:33:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:33:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 81/92 [17:08<00:41,  3.77s/it]INFO: [2025-06-27 15:33:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:33:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:33:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:33:43 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:33:43] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:33:45] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:33:45 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:33:45] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:33:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:33:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:33:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 82/92 [17:12<00:37,  3.71s/it]INFO: [2025-06-27 15:33:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:33:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:33:45] indra_gpt.chat_curate.chat_curate - Skipping agent cotransporter-2 inhibitor() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "INFO: [2025-06-27 15:33:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:33:46 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:33:46] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:33:47] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:33:47 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:33:47] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:33:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:33:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:33:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 83/92 [17:14<00:29,  3.27s/it]INFO: [2025-06-27 15:33:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:33:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:33:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:33:49 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:33:49] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:33:51] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:33:51 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:33:51] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:33:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:33:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:33:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 84/92 [17:17<00:26,  3.32s/it]INFO: [2025-06-27 15:33:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:33:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:33:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:33:52 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:33:52] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:33:53] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:33:53 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:33:53] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:33:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:33:53] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:33:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 85/92 [17:20<00:21,  3.05s/it]INFO: [2025-06-27 15:33:53] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:33:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:33:53] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:33:55 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:33:55] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:33:57] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:33:57 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:33:57] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:33:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:33:57] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:33:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 86/92 [17:24<00:19,  3.24s/it]INFO: [2025-06-27 15:33:57] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:33:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:33:57] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:34:00 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:34:00] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:34:01] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:34:01 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:34:01] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:34:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:34:01] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:34:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 87/92 [17:28<00:18,  3.65s/it]INFO: [2025-06-27 15:34:01] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:34:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:34:01] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:34:03 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:34:03] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:34:05] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:34:05 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:34:05] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:34:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:34:05] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:34:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 88/92 [17:31<00:14,  3.54s/it]INFO: [2025-06-27 15:34:05] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:34:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:34:05] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:34:07 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:34:07] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:34:08] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:34:08 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:34:08] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:34:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:34:08] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:34:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 89/92 [17:35<00:10,  3.40s/it]INFO: [2025-06-27 15:34:08] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:34:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:34:08] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:34:10 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:34:10] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:34:11] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:34:11 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:34:11] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:34:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:34:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:34:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 90/92 [17:38<00:06,  3.42s/it]INFO: [2025-06-27 15:34:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:34:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:34:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:34:13 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:34:13] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:34:15] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:34:15 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:34:15] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:34:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:34:15] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:34:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 91/92 [17:41<00:03,  3.44s/it]INFO: [2025-06-27 15:34:15] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:34:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:34:15] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:34:17 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:34:17] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:34:18] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:34:18 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:34:18] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:34:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:34:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:34:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 92/92 [17:45<00:00,  3.56s/it]INFO: [2025-06-27 15:34:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 92/92 [17:45<00:00, 11.58s/it]\u001b[92m15:34:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\n",
      "INFO: [2025-06-27 15:34:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:   0%|          | 0/92 [00:00<?, ?it/s]\u001b[92m15:34:20 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:34:20] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:34:22] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:34:22 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:34:22] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:34:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:34:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:34:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:34:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:34:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:34:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:34:24 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:34:24] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:34:25] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:34:25 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:34:25] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:34:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:34:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:34:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:34:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:34:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:34:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:34:27 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:34:27] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:34:28] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:34:28 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:34:28] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:34:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:34:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:34:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:34:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:34:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:34:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:34:30 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:34:30] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:34:31] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:34:31 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:34:31] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:34:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:34:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:34:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:34:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:34:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:34:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:34:34 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:34:34] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:34:35] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:34:35 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:34:35] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:34:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:34:35] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:34:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:   1%|          | 1/92 [00:16<25:13, 16.63s/it]INFO: [2025-06-27 15:34:35] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:34:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:34:35] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:34:37 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:34:37] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:34:38] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:34:38 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:34:38] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:34:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:34:38] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:34:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:34:38] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:34:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:34:38] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:34:40 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:34:40] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:34:41] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:34:41 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:34:41] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:34:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:34:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:34:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:34:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:34:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:34:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:34:43 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:34:43] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:34:44] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:34:44 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:34:44] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:34:44 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:34:44] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:34:44 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:34:44] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:34:44 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:34:44] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:34:46 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:34:46] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:34:47] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:34:47 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:34:47] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:34:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:34:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:34:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:34:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:34:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:34:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:34:49 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:34:49] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:34:51] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:34:51 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:34:51] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:34:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:34:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:34:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:   2%|‚ñè         | 2/92 [00:32<24:01, 16.02s/it]INFO: [2025-06-27 15:34:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:34:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:34:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:34:53 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:34:53] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:34:54] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:34:54 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:34:54] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:34:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:34:54] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:34:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:34:54] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:34:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:34:54] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:34:56 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:34:56] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:34:57] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:34:57 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:34:57] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:34:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:34:57] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:34:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:34:57] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:34:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:34:57] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:34:59 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:34:59] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:35:00] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:35:00 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:35:00] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:35:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:35:00] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:35:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:35:00] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:35:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:35:00] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:35:02 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:35:02] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:35:04] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:35:04 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:35:04] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:35:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:35:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:35:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:35:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:35:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:35:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:35:06 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:35:06] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:35:07] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:35:07 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:35:07] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:35:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:35:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:35:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:   3%|‚ñé         | 3/92 [00:48<23:38, 15.94s/it]INFO: [2025-06-27 15:35:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:35:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:35:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:35:09 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:35:09] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:35:10] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:35:10 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:35:10] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:35:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:35:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:35:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:35:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:35:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:35:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:35:12 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:35:12] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:35:13] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:35:13 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:35:13] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:35:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:35:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:35:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:35:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:35:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:35:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:35:15 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:35:15] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:35:18] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:35:18 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:35:18] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:35:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:35:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:35:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:35:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:35:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:35:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:35:20 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:35:20] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:35:21] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:35:21 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:35:21] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:35:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:35:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:35:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:35:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:35:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:35:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:35:23 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:35:23] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:35:24] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:35:24 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:35:24] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:35:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:35:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:35:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:   4%|‚ñç         | 4/92 [01:05<24:13, 16.52s/it]INFO: [2025-06-27 15:35:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:35:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:35:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:35:25 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:35:25] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:35:26] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:35:26 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:35:26] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:35:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:35:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:35:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:35:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:35:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:35:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:35:27 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:35:27] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:35:28] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:35:28 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:35:28] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:35:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:35:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:35:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:35:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:35:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:35:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:35:30 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:35:30] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:35:31] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:35:31 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:35:31] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:35:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:35:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:35:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:35:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:35:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:35:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:35:32 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:35:32] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:35:33] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:35:33 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:35:33] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:35:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:35:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:35:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:35:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:35:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:35:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:35:34 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:35:34] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:35:35] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:35:35 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:35:35] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:35:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:35:35] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:35:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:   5%|‚ñå         | 5/92 [01:16<21:18, 14.70s/it]INFO: [2025-06-27 15:35:35] indra_gpt.chat_curate.chat_curate - Skipping evidence with no text for statement 3246604237187558: Evidence(source_api='biogrid',\n",
      "         pmid='21949651',\n",
      "         source_id='685047',\n",
      "         annotations={\n",
      "                      \"biogrid_int_id\": \"685047\",\n",
      "                      \"entrez_a\": \"7341\",\n",
      "                      \"entrez_b\": \"7329\",\n",
      "                      \"biogrid_a\": \"113188\",\n",
      "                      \"biogrid_b\": \"113177\",\n",
      "                      \"syst_name_a\": \"OK/SW-cl.43\",\n",
      "                      \"syst_name_b\": \"LA16c-358B7.1\",\n",
      "                      \"hgnc_a\": \"SUMO1\",\n",
      "                      \"hgnc_b\": \"UBE2I\",\n",
      "                      \"syn_a\": \"DAP1|GMP1|OFC10|PIC1|SENP2|SMT3|SMT3C|SMT3H3|UBL1\",\n",
      "                      \"syn_b\": \"C358B7.1|P18|UBC9\",\n",
      "                      \"exp_system\": \"Two-hybrid\",\n",
      "                      \"exp_system_type\": \"physical\",\n",
      "                      \"author\": \"Boutell C (2011)\",\n",
      "                      \"pmid\": \"21949651\",\n",
      "                      \"organism_a\": \"9606\",\n",
      "                      \"organism_b\": \"9606\",\n",
      "                      \"throughput\": \"Low Throughput\",\n",
      "                      \"score\": null,\n",
      "                      \"modification\": null,\n",
      "                      \"phenotypes\": null,\n",
      "                      \"qualifications\": \"#LPPI|Likely protein-protein interaction|figure 3c.\",\n",
      "                      \"tags\": null,\n",
      "                      \"source_db\": \"BIOGRID\",\n",
      "                      \"agents\": {\n",
      "                       \"raw_text\": [\n",
      "                        \"OK/SW-cl.43\",\n",
      "                        \"LA16c-358B7.1\"\n",
      "                       ]\n",
      "                      },\n",
      "                      \"prior_uuids\": [\n",
      "                       \"586757a4-c038-43c4-85a1-dd598f513a47\"\n",
      "                      ]\n",
      "                     },\n",
      "         text_refs={\n",
      "                    \"PMID\": \"21949651\"\n",
      "                   }\n",
      "         )\n",
      "\n",
      "\n",
      "INFO: [2025-06-27 15:35:35] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:35:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:35:35] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:35:37 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:35:37] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:35:39] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:35:39 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:35:39] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:35:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:35:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:35:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:35:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:35:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:35:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:35:41 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:35:41] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:35:42] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:35:42 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:35:42] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:35:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:35:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:35:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:35:42] indra_gpt.chat_curate.chat_curate - Skipping evidence with no text for statement 3246604237187558: Evidence(source_api='hprd',\n",
      "         pmid='12924945',\n",
      "         source_id='http://hprd.org/interactions?hprd_id=09045&isoform_id=09045_1&isoform_name=Isoform_1',\n",
      "         annotations={\n",
      "                      \"evidence\": [\n",
      "                       \"in vitro\",\n",
      "                       \"in vivo\"\n",
      "                      ],\n",
      "                      \"agents\": {\n",
      "                       \"raw_text\": [\n",
      "                        null,\n",
      "                        null\n",
      "                       ]\n",
      "                      },\n",
      "                      \"prior_uuids\": [\n",
      "                       \"c528b5b8-8e6c-463b-a344-a9e49baaefce\"\n",
      "                      ]\n",
      "                     },\n",
      "         text_refs={\n",
      "                    \"PMID\": \"12924945\"\n",
      "                   }\n",
      "         )\n",
      "\n",
      "\n",
      "INFO: [2025-06-27 15:35:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:35:43 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:35:43] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:35:45 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:35:45] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:35:46] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:35:46 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:35:46] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:35:46 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:35:46] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:35:46 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:   7%|‚ñã         | 6/92 [01:27<19:05, 13.32s/it]INFO: [2025-06-27 15:35:46] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:35:46 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:35:46] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:35:47 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:35:47] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:35:48] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:35:48 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:35:48] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:35:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:35:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:35:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:35:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:35:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:35:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:35:49 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:35:49] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:35:50] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:35:50 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:35:50] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:35:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:35:50] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:35:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:35:50] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:35:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:35:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:35:52 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:35:52] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:35:53] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:35:53 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:35:53] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:35:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:35:53] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:35:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:35:53] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:35:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:35:53] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:35:54 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:35:54] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:35:55] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:35:55 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:35:55] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:35:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:35:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:35:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:35:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:35:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:35:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:35:56 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:35:56] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:35:57] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:35:57 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:35:57] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:35:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:35:57] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:35:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:   8%|‚ñä         | 7/92 [01:38<17:58, 12.68s/it]INFO: [2025-06-27 15:35:57] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:35:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:35:57] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:35:59 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:35:59] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:36:00] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:36:00 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:36:00] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:36:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:36:00] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:36:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:36:00] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:36:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:36:00] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:36:01 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:36:01] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:36:02] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:36:02 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:36:02] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:36:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:36:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:36:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:36:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:36:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:36:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:36:03 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:36:03] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:36:04] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:36:04 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:36:04] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:36:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:36:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:36:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:36:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:36:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:36:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:36:06 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:36:06] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:36:07] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:36:07 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:36:07] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:36:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:36:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:36:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:36:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:36:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:36:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:36:08 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:36:08] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:36:09] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:36:09 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:36:09] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:36:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:36:09] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:   9%|‚ñä         | 8/92 [01:50<17:19, 12.37s/it]\u001b[92m15:36:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:36:09] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:36:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:36:09] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:36:11 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:36:11] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:36:12] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:36:12 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:36:12] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:36:12 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:36:12] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:36:12 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:36:12] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:36:12 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:36:12] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:36:14 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:36:14] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:36:16] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:36:16 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:36:16] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:36:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:36:16] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:36:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:36:16] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:36:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:36:16] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:36:18 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:36:18] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:36:19] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:36:19 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:36:19] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:36:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:36:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:36:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:36:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:36:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:36:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:36:21 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:36:21] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:36:23] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:36:23 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:36:23] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:36:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:36:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:36:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:36:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:36:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:36:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:36:25 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:36:25] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:36:30] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:36:30 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:36:30] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:36:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:36:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:36:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  10%|‚ñâ         | 9/92 [02:11<20:39, 14.93s/it]INFO: [2025-06-27 15:36:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:36:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:36:30] indra_gpt.chat_curate.chat_curate - Skipping agent EMT() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "INFO: [2025-06-27 15:36:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:36:31 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:36:31] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:36:32] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:36:32 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:36:32] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:36:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:36:32] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:36:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:36:32] indra_gpt.chat_curate.chat_curate - Skipping agent EMT() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "INFO: [2025-06-27 15:36:32] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:36:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:36:32] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:36:33 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:36:33] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:36:34] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:36:34 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:36:34] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:36:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:36:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:36:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:36:34] indra_gpt.chat_curate.chat_curate - Skipping agent EMT() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "INFO: [2025-06-27 15:36:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:36:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:36:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:36:35 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:36:35] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:36:36] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:36:36 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:36:36] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:36:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:36:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:36:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:36:36] indra_gpt.chat_curate.chat_curate - Skipping agent EMT() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "INFO: [2025-06-27 15:36:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:36:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:36:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:36:38 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:36:38] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:36:39] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:36:39 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:36:39] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:36:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:36:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:36:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:36:39] indra_gpt.chat_curate.chat_curate - Skipping agent EMT() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "INFO: [2025-06-27 15:36:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:36:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:36:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:36:40 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:36:40] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:36:41] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:36:41 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:36:41] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:36:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:36:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:36:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  11%|‚ñà         | 10/92 [02:22<18:51, 13.80s/it]INFO: [2025-06-27 15:36:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:36:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:36:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:36:43 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:36:43] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:36:44] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:36:44 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:36:44] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:36:44 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:36:44] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:36:44 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:36:44] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:36:44 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:36:44] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:36:46 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:36:46] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:36:47] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:36:47 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:36:47] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:36:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:36:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:36:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:36:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:36:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:36:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:36:50 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:36:50] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:36:51] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:36:51 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:36:51] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:36:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:36:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:36:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:36:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:36:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:36:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:36:53 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:36:53] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:36:54] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:36:54 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:36:54] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:36:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:36:54] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:36:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:36:54] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:36:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:36:54] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:36:56 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:36:56] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:36:57] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:36:57 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:36:57] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:36:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:36:57] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:36:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  12%|‚ñà‚ñè        | 11/92 [02:38<19:36, 14.53s/it]INFO: [2025-06-27 15:36:57] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:36:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:36:57] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:36:59 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:36:59] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:37:00] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:37:00 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:37:00] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:37:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:37:00] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:37:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:37:00] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:37:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:37:01] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:37:03 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:37:03] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:37:04] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:37:04 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:37:04] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:37:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:37:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:37:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:37:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:37:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:37:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:37:06 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:37:06] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:37:07] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:37:07 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:37:07] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:37:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:37:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:37:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:37:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:37:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:37:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:37:09 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:37:09] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:37:11] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:37:11 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:37:11] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:37:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:37:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:37:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:37:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:37:12 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:37:12] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:37:14 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:37:14] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:37:15] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:37:15 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:37:15] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:37:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:37:15] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:37:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  13%|‚ñà‚ñé        | 12/92 [02:56<20:42, 15.53s/it]INFO: [2025-06-27 15:37:15] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:37:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:37:15] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:37:15 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:37:15] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:37:16] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:37:16 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:37:16] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:37:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:37:16] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:37:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:37:16] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:37:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:37:16] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:37:17 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:37:17] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:37:18] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:37:18 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:37:18] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:37:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:37:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:37:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:37:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:37:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:37:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:37:19 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:37:19] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:37:20] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:37:20 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:37:20] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:37:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:37:20] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:37:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:37:20] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:37:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:37:20] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:37:20 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:37:20] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:37:21] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:37:21 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:37:21] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:37:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:37:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:37:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:37:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:37:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:37:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:37:22 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:37:22] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:37:23] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:37:23 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:37:23] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:37:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:37:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:37:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  14%|‚ñà‚ñç        | 13/92 [03:04<17:33, 13.34s/it]INFO: [2025-06-27 15:37:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:37:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:37:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:37:25 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:37:25] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:37:26] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:37:26 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:37:26] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:37:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:37:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:37:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:37:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:37:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:37:27] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:37:28 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:37:28] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:37:29] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:37:29 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:37:29] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:37:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:37:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:37:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:37:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:37:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:37:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:37:30 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:37:30] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:37:32] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:37:32 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:37:32] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:37:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:37:32] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:37:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:37:32] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:37:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:37:32] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:37:33 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:37:33] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:37:34] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:37:34 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:37:34] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:37:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:37:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:37:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:37:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:37:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:37:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:37:36 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:37:36] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:37:37] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:37:37 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:37:37] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:37:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:37:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:37:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  15%|‚ñà‚ñå        | 14/92 [03:18<17:24, 13.39s/it]INFO: [2025-06-27 15:37:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:37:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:37:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:37:37 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:37:37] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:37:38] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:37:38 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:37:38] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:37:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:37:38] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:37:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:37:38] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:37:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:37:38] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:37:39 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:37:39] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:37:40] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:37:40 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:37:40] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:37:40 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:37:40] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:37:40 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:37:40] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:37:40 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:37:40] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:37:40 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:37:40] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:37:41] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:37:41 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:37:41] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:37:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:37:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:37:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:37:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:37:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:37:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:37:42 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:37:42] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:37:43] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:37:43 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:37:43] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:37:43 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:37:43] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:37:43 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:37:43] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:37:43 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:37:43] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:37:44 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:37:44] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:37:45] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:37:45 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:37:45] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:37:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:37:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:37:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  16%|‚ñà‚ñã        | 15/92 [03:26<15:05, 11.76s/it]INFO: [2025-06-27 15:37:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:37:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:37:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:37:45 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:37:45] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:37:47] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:37:47 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:37:47] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:37:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:37:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:37:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:37:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:37:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:37:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:37:47 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:37:47] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:37:49] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:37:49 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:37:49] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:37:49 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:37:49] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:37:49 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:37:49] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:37:49 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:37:49] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:37:49 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:37:49] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:37:51] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:37:51 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:37:51] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:37:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:37:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:37:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:37:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:37:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:37:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:37:51 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:37:51] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:37:52] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:37:52 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:37:52] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:37:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:37:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:37:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:37:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:37:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:37:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:37:53 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:37:53] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:37:54] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:37:54 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:37:54] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:37:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:37:54] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:37:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  17%|‚ñà‚ñã        | 16/92 [03:35<13:53, 10.96s/it]INFO: [2025-06-27 15:37:54] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:37:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:37:54] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:37:56 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:37:56] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:37:57] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:37:57 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:37:57] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:37:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:37:57] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:37:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:37:57] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:37:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:37:57] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:37:59 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:37:59] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:38:00] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:38:00 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:38:00] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:38:00] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:38:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:38:00] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:38:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:38:01] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:38:03 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:38:03] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:38:05] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:38:05 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:38:05] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:38:05] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:38:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:38:05] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:38:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:38:05] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:38:07 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:38:07] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:38:08] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:38:08 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:38:08] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:38:08] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:38:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:38:08] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:38:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:38:08] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:38:10 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:38:10] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:38:11] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:38:11 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:38:11] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:38:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:38:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  18%|‚ñà‚ñä        | 17/92 [03:52<16:07, 12.90s/it]INFO: [2025-06-27 15:38:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:38:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:38:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:38:13 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:38:13] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:38:15] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:38:15 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:38:15] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:38:15] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:38:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:38:15] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:38:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:38:15] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:38:18 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:38:18] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:38:19] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:38:19 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:38:19] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:38:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:38:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:38:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:38:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:38:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:38:21 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:38:21] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:38:22] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:38:22 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:38:22] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:38:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:38:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:38:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:38:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:38:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:38:24 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:38:24] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:38:26] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:38:26 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:38:26] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:38:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:38:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:38:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:38:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:38:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:38:28 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:38:28] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:38:29] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:38:29 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:38:29] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:38:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:38:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  20%|‚ñà‚ñâ        | 18/92 [04:10<17:41, 14.35s/it]INFO: [2025-06-27 15:38:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:38:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:38:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:38:31 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:38:31] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:38:32] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:38:32 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:38:32] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:38:32] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:38:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:38:32] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:38:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:38:32] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:38:34 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:38:34] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:38:35] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:38:35 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:38:35] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:38:35] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:38:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:38:35] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:38:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:38:35] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:38:37 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:38:37] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:38:38] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:38:38 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:38:38] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:38:38] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:38:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:38:38] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:38:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:38:38] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:38:40 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:38:40] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:38:42] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:38:42 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:38:42] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:38:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:38:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:38:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:38:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:38:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:38:44 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:38:44] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:38:45] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:38:45 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:38:45] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:38:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:38:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  21%|‚ñà‚ñà        | 19/92 [04:26<17:58, 14.78s/it]INFO: [2025-06-27 15:38:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:38:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:38:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:38:47 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:38:47] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:38:48] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:38:48 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:38:48] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:38:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:38:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:38:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:38:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:38:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:38:50 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:38:50] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:38:51] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:38:51 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:38:51] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:38:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:38:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:38:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:38:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:38:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:38:53 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:38:53] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:38:54] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:38:54 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:38:54] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:38:54] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:38:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:38:54] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:38:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:38:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:38:56 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:38:56] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:38:58] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:38:58 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:38:58] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:38:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:38:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:38:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:38:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:38:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:38:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:39:00 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:39:00] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:39:01] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:39:01 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:39:01] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:39:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:39:01] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:39:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  22%|‚ñà‚ñà‚ñè       | 20/92 [04:42<18:20, 15.29s/it]INFO: [2025-06-27 15:39:01] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:39:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:39:01] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:39:04 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:39:04] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:39:06] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:39:06 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:39:06] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:39:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:39:06] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:39:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:39:06] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:39:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:39:06] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:39:09 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:39:09] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:39:10] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:39:10 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:39:10] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:39:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:39:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:39:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:39:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:39:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:39:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:39:14 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:39:14] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:39:14] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:39:14 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:39:14] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:39:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:39:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:39:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:39:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:39:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:39:15] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:39:18 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:39:18] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:39:19] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:39:19 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:39:19] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:39:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:39:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:39:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:39:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:39:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:39:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:39:22 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:39:22] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:39:23] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:39:23 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:39:23] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:39:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:39:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:39:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  23%|‚ñà‚ñà‚ñé       | 21/92 [05:04<20:18, 17.16s/it]INFO: [2025-06-27 15:39:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:39:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:39:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:39:25 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:39:25] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:39:27] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:39:27 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:39:27] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:39:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:39:27] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:39:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:39:27] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:39:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:39:27] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:39:29 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:39:29] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:39:31] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:39:31 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:39:31] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:39:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:39:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:39:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:39:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:39:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:39:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:39:33 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:39:33] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:39:34] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:39:34 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:39:34] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:39:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:39:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:39:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:39:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:39:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:39:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:39:36 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:39:36] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:39:37] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:39:37 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:39:37] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:39:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:39:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:39:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:39:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:39:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:39:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:39:39 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:39:39] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:39:42] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:39:42 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:39:42] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:39:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:39:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:39:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  24%|‚ñà‚ñà‚ñç       | 22/92 [05:23<20:36, 17.66s/it]INFO: [2025-06-27 15:39:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:39:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:39:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:39:44 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:39:44] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:39:45] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:39:45 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:39:45] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:39:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:39:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:39:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:39:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:39:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:39:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:39:47 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:39:47] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:39:48] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:39:48 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:39:48] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:39:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:39:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:39:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:39:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:39:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:39:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:39:50 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:39:50] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:39:51] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:39:51 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:39:51] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:39:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:39:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:39:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:39:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:39:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:39:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:39:53 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:39:53] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:39:54] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:39:54 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:39:54] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:39:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:39:54] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:39:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:39:54] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:39:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:39:54] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:39:56 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:39:56] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:39:58] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:39:58 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:39:58] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:39:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:39:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:39:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  25%|‚ñà‚ñà‚ñå       | 23/92 [05:39<19:56, 17.34s/it]INFO: [2025-06-27 15:39:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:39:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:39:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:40:00 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:40:00] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:40:01] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:40:01 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:40:01] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:40:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:40:01] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:40:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:40:01] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:40:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:40:01] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:40:03 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:40:03] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:40:04] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:40:04 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:40:04] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:40:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:40:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:40:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:40:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:40:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:40:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:40:06 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:40:06] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:40:08] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:40:08 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:40:08] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:40:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:40:08] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:40:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:40:08] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:40:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:40:08] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:40:10 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:40:10] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:40:11] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:40:11 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:40:11] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:40:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:40:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:40:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:40:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:40:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:40:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:40:13 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:40:13] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:40:14] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:40:14 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:40:14] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:40:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:40:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:40:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  26%|‚ñà‚ñà‚ñå       | 24/92 [05:55<19:11, 16.93s/it]INFO: [2025-06-27 15:40:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:40:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:40:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:40:16 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:40:16] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:40:17] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:40:17 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:40:17] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:40:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:40:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:40:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:40:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:40:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:40:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:40:19 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:40:19] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:40:21] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:40:21 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:40:21] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:40:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:40:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:40:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:40:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:40:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:40:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:40:23 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:40:23] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:40:24] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:40:24 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:40:24] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:40:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:40:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:40:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:40:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:40:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:40:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:40:26 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:40:26] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:40:28] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:40:28 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:40:28] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:40:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:40:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:40:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:40:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:40:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:40:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:40:30 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:40:30] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:40:32] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:40:32 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:40:32] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:40:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:40:32] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:40:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  27%|‚ñà‚ñà‚ñã       | 25/92 [06:14<19:22, 17.35s/it]INFO: [2025-06-27 15:40:32] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:40:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:40:32] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:40:35 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:40:35] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:40:36] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:40:36 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:40:36] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:40:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:40:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:40:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:40:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:40:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:40:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:40:38 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:40:38] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:40:40] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:40:40 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:40:40] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:40:40 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:40:40] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:40:40 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:40:40] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:40:40 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:40:40] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:40:42 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:40:42] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:40:43] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:40:43 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:40:43] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:40:43 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:40:43] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:40:43 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:40:43] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:40:43 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:40:43] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:40:45 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:40:45] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:40:46] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:40:46 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:40:46] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:40:46 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:40:46] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:40:46 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:40:46] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:40:46 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:40:46] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:40:48 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:40:48] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:40:51] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:40:51 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:40:51] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:40:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:40:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:40:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  28%|‚ñà‚ñà‚ñä       | 26/92 [06:32<19:30, 17.74s/it]INFO: [2025-06-27 15:40:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:40:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:40:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:40:53 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:40:53] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:40:55] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:40:55 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:40:55] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:40:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:40:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:40:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:40:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:40:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:40:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:40:57 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:40:57] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:40:58] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:40:58 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:40:58] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:40:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:40:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:40:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:40:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:40:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:40:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:41:00 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:41:00] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:41:01] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:41:01 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:41:01] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:41:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:41:01] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:41:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:41:01] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:41:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:41:01] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:41:03 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:41:03] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:41:04] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:41:04 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:41:04] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:41:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:41:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:41:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:41:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:41:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:41:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:41:06 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:41:06] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:41:09] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:41:09 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:41:09] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:41:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:41:09] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:41:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  29%|‚ñà‚ñà‚ñâ       | 27/92 [06:50<19:12, 17.73s/it]INFO: [2025-06-27 15:41:09] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:41:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:41:09] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:41:10 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:41:10] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:41:11] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:41:11 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:41:11] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:41:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:41:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:41:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:41:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:41:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:41:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:41:12 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:41:12] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:41:13] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:41:13 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:41:13] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:41:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:41:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:41:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:41:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:41:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:41:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:41:14 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:41:14] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:41:16] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:41:16 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:41:16] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:41:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:41:16] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:41:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:41:16] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:41:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:41:16] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:41:17 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:41:17] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:41:19] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:41:19 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:41:19] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:41:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:41:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:41:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:41:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:41:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:41:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:41:20 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:41:20] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:41:22] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:41:22 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:41:22] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:41:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:41:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:41:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  30%|‚ñà‚ñà‚ñà       | 28/92 [07:03<17:27, 16.37s/it]INFO: [2025-06-27 15:41:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:41:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:41:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:41:24 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:41:24] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:41:26] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:41:26 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:41:26] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:41:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:41:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:41:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:41:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:41:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:41:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:41:28 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:41:28] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:41:29] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:41:29 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:41:29] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:41:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:41:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:41:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:41:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:41:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:41:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:41:31 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:41:31] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:41:33] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:41:33 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:41:33] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:41:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:41:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:41:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:41:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:41:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:41:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:41:35 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:41:35] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:41:36] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:41:36 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:41:36] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:41:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:41:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:41:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:41:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:41:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:41:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:41:38 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:41:38] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:41:39] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:41:39 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:41:39] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:41:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:41:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:41:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  32%|‚ñà‚ñà‚ñà‚ñè      | 29/92 [07:20<17:29, 16.65s/it]INFO: [2025-06-27 15:41:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:41:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:41:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:41:41 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:41:41] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:41:42] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:41:42 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:41:42] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:41:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:41:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:41:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:41:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:41:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:41:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:41:44 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:41:44] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:41:46] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:41:46 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:41:46] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:41:46 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:41:46] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:41:46 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:41:46] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:41:46 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:41:46] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:41:48 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:41:48] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:41:49] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:41:49 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:41:49] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:41:49 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:41:49] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:41:49 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:41:49] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:41:49 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:41:49] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:41:51 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:41:51] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:41:52] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:41:52 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:41:52] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:41:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:41:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:41:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:41:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:41:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:41:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:41:54 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:41:54] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:41:55] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:41:55 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:41:55] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:41:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:41:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:41:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  33%|‚ñà‚ñà‚ñà‚ñé      | 30/92 [07:36<16:51, 16.32s/it]INFO: [2025-06-27 15:41:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:41:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:41:55] indra_gpt.chat_curate.chat_curate - Skipping agent NP() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "INFO: [2025-06-27 15:41:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:41:56 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:41:56] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:41:57] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:41:57 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:41:57] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:41:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:41:57] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:41:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:41:57] indra_gpt.chat_curate.chat_curate - Skipping agent NP() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "INFO: [2025-06-27 15:41:57] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:41:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:41:57] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:41:58 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:41:58] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:42:00] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:42:00 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:42:00] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:42:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:42:00] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:42:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:42:00] indra_gpt.chat_curate.chat_curate - Skipping agent NP() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "INFO: [2025-06-27 15:42:00] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:42:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:42:00] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:42:01 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:42:01] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:42:02] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:42:02 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:42:02] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:42:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:42:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:42:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:42:02] indra_gpt.chat_curate.chat_curate - Skipping agent NP() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "INFO: [2025-06-27 15:42:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:42:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:42:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:42:03 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:42:03] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:42:04] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:42:04 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:42:04] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:42:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:42:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:42:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:42:04] indra_gpt.chat_curate.chat_curate - Skipping agent NP() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "INFO: [2025-06-27 15:42:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:42:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:42:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:42:05 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:42:05] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:42:06] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:42:06 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:42:06] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:42:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:42:06] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:42:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  34%|‚ñà‚ñà‚ñà‚ñé      | 31/92 [07:47<14:58, 14.72s/it]INFO: [2025-06-27 15:42:06] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:42:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:42:06] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:42:08 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:42:08] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:42:09] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:42:09 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:42:09] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:42:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:42:09] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:42:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:42:09] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:42:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:42:09] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:42:11 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:42:11] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:42:12] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:42:12 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:42:12] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:42:12 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:42:12] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:42:12 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:42:12] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:42:12 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:42:12] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:42:14 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:42:14] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:42:15] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:42:15 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:42:15] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:42:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:42:15] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:42:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:42:15] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:42:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:42:16] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:42:18 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:42:18] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:42:19] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:42:19 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:42:19] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:42:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:42:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:42:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:42:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:42:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:42:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:42:21 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:42:21] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:42:22] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:42:22 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:42:22] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:42:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:42:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:42:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  35%|‚ñà‚ñà‚ñà‚ñç      | 32/92 [08:03<15:14, 15.25s/it]INFO: [2025-06-27 15:42:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:42:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:42:22] indra_gpt.chat_curate.chat_curate - Skipping evidence with no text for statement 5895544448831150: Evidence(source_api='biogrid',\n",
      "         pmid='11792840',\n",
      "         source_id='280516',\n",
      "         annotations={\n",
      "                      \"biogrid_int_id\": \"280516\",\n",
      "                      \"entrez_a\": \"367\",\n",
      "                      \"entrez_b\": \"6840\",\n",
      "                      \"biogrid_a\": \"106862\",\n",
      "                      \"biogrid_b\": \"112707\",\n",
      "                      \"syst_name_a\": \"RP11-383C12.1\",\n",
      "                      \"syst_name_b\": \"RP11-534G20.1\",\n",
      "                      \"hgnc_a\": \"AR\",\n",
      "                      \"hgnc_b\": \"SVIL\",\n",
      "                      \"syn_a\": \"AIS|DHTR|HUMARA|HYSP1|KD|NR3C4|SBMA|SMAX1|TFM\",\n",
      "                      \"syn_b\": null,\n",
      "                      \"exp_system\": \"Reconstituted Complex\",\n",
      "                      \"exp_system_type\": \"physical\",\n",
      "                      \"author\": \"Ting HJ (2002)\",\n",
      "                      \"pmid\": \"11792840\",\n",
      "                      \"organism_a\": \"9606\",\n",
      "                      \"organism_b\": \"9606\",\n",
      "                      \"throughput\": \"Low Throughput\",\n",
      "                      \"score\": null,\n",
      "                      \"modification\": null,\n",
      "                      \"phenotypes\": null,\n",
      "                      \"qualifications\": null,\n",
      "                      \"tags\": null,\n",
      "                      \"source_db\": \"BIOGRID\",\n",
      "                      \"agents\": {\n",
      "                       \"raw_text\": [\n",
      "                        \"RP11-383C12.1\",\n",
      "                        \"RP11-534G20.1\"\n",
      "                       ]\n",
      "                      },\n",
      "                      \"prior_uuids\": [\n",
      "                       \"903ad8ca-da7c-4afc-9f2c-702d7a1c95fc\"\n",
      "                      ]\n",
      "                     },\n",
      "         text_refs={\n",
      "                    \"PMID\": \"11792840\"\n",
      "                   }\n",
      "         )\n",
      "\n",
      "\n",
      "INFO: [2025-06-27 15:42:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:42:22] indra_gpt.chat_curate.chat_curate - Skipping evidence with no text for statement 5895544448831150: Evidence(source_api='biogrid',\n",
      "         pmid='11792840',\n",
      "         source_id='280520',\n",
      "         annotations={\n",
      "                      \"biogrid_int_id\": \"280520\",\n",
      "                      \"entrez_a\": \"6840\",\n",
      "                      \"entrez_b\": \"367\",\n",
      "                      \"biogrid_a\": \"112707\",\n",
      "                      \"biogrid_b\": \"106862\",\n",
      "                      \"syst_name_a\": \"RP11-534G20.1\",\n",
      "                      \"syst_name_b\": \"RP11-383C12.1\",\n",
      "                      \"hgnc_a\": \"SVIL\",\n",
      "                      \"hgnc_b\": \"AR\",\n",
      "                      \"syn_a\": null,\n",
      "                      \"syn_b\": \"AIS|DHTR|HUMARA|HYSP1|KD|NR3C4|SBMA|SMAX1|TFM\",\n",
      "                      \"exp_system\": \"Two-hybrid\",\n",
      "                      \"exp_system_type\": \"physical\",\n",
      "                      \"author\": \"Ting HJ (2002)\",\n",
      "                      \"pmid\": \"11792840\",\n",
      "                      \"organism_a\": \"9606\",\n",
      "                      \"organism_b\": \"9606\",\n",
      "                      \"throughput\": \"Low Throughput\",\n",
      "                      \"score\": null,\n",
      "                      \"modification\": null,\n",
      "                      \"phenotypes\": null,\n",
      "                      \"qualifications\": null,\n",
      "                      \"tags\": null,\n",
      "                      \"source_db\": \"BIOGRID\",\n",
      "                      \"agents\": {\n",
      "                       \"raw_text\": [\n",
      "                        \"RP11-534G20.1\",\n",
      "                        \"RP11-383C12.1\"\n",
      "                       ]\n",
      "                      },\n",
      "                      \"prior_uuids\": [\n",
      "                       \"6488b526-899f-42ed-a310-982899f86d16\"\n",
      "                      ]\n",
      "                     },\n",
      "         text_refs={\n",
      "                    \"PMID\": \"11792840\"\n",
      "                   }\n",
      "         )\n",
      "\n",
      "\n",
      "\u001b[92m15:42:24 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:42:24] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:42:25] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:42:25 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:42:25] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:42:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:42:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:42:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:42:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:42:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:42:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:42:28 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:42:28] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:42:29] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:42:29 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:42:29] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:42:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:42:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:42:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:42:29] indra_gpt.chat_curate.chat_curate - Skipping evidence with no text for statement 5895544448831150: Evidence(source_api='biogrid',\n",
      "         pmid='11792840',\n",
      "         source_id='280515',\n",
      "         annotations={\n",
      "                      \"biogrid_int_id\": \"280515\",\n",
      "                      \"entrez_a\": \"367\",\n",
      "                      \"entrez_b\": \"6840\",\n",
      "                      \"biogrid_a\": \"106862\",\n",
      "                      \"biogrid_b\": \"112707\",\n",
      "                      \"syst_name_a\": \"RP11-383C12.1\",\n",
      "                      \"syst_name_b\": \"RP11-534G20.1\",\n",
      "                      \"hgnc_a\": \"AR\",\n",
      "                      \"hgnc_b\": \"SVIL\",\n",
      "                      \"syn_a\": \"AIS|DHTR|HUMARA|HYSP1|KD|NR3C4|SBMA|SMAX1|TFM\",\n",
      "                      \"syn_b\": null,\n",
      "                      \"exp_system\": \"Two-hybrid\",\n",
      "                      \"exp_system_type\": \"physical\",\n",
      "                      \"author\": \"Ting HJ (2002)\",\n",
      "                      \"pmid\": \"11792840\",\n",
      "                      \"organism_a\": \"9606\",\n",
      "                      \"organism_b\": \"9606\",\n",
      "                      \"throughput\": \"Low Throughput\",\n",
      "                      \"score\": null,\n",
      "                      \"modification\": null,\n",
      "                      \"phenotypes\": null,\n",
      "                      \"qualifications\": null,\n",
      "                      \"tags\": null,\n",
      "                      \"source_db\": \"BIOGRID\",\n",
      "                      \"agents\": {\n",
      "                       \"raw_text\": [\n",
      "                        \"RP11-383C12.1\",\n",
      "                        \"RP11-534G20.1\"\n",
      "                       ]\n",
      "                      },\n",
      "                      \"prior_uuids\": [\n",
      "                       \"acaad1cf-653a-49f8-8faf-d1087e17cca5\"\n",
      "                      ]\n",
      "                     },\n",
      "         text_refs={\n",
      "                    \"PMID\": \"11792840\"\n",
      "                   }\n",
      "         )\n",
      "\n",
      "\n",
      "Curating statements with chat curation:  36%|‚ñà‚ñà‚ñà‚ñå      | 33/92 [08:10<12:22, 12.58s/it]INFO: [2025-06-27 15:42:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:42:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:42:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:42:30 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:42:30] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:42:31] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:42:31 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:42:31] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:42:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:42:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:42:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:42:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:42:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:42:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:42:33 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:42:33] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:42:34] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:42:34 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:42:34] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:42:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:42:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:42:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:42:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:42:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:42:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:42:35 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:42:35] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:42:37] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:42:37 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:42:37] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:42:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:42:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:42:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:42:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:42:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:42:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:42:38 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:42:38] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:42:40] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:42:40 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:42:40] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:42:40 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:42:40] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:42:40 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:42:40] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:42:40 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:42:40] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:42:41 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:42:41] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:42:43] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:42:43 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:42:43] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:42:43 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:42:43] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:42:43 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  37%|‚ñà‚ñà‚ñà‚ñã      | 34/92 [08:24<12:39, 13.10s/it]INFO: [2025-06-27 15:42:43] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:42:43 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:42:43] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:42:45 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:42:45] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:42:46] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:42:46 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:42:46] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:42:46 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:42:46] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:42:46 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:42:46] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:42:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:42:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:42:49 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:42:49] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:42:49] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:42:49 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:42:49] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:42:49 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:42:49] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:42:49 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:42:49] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:42:49 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:42:49] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:42:51 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:42:51] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:42:52] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:42:52 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:42:52] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:42:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:42:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:42:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:42:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:42:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:42:53] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:42:54 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:42:54] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:42:56] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:42:56 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:42:56] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:42:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:42:56] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:42:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:42:56] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:42:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:42:56] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:42:58 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:42:58] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:42:59] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:42:59 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:42:59] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:42:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:42:59] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:42:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  38%|‚ñà‚ñà‚ñà‚ñä      | 35/92 [08:40<13:10, 13.87s/it]INFO: [2025-06-27 15:42:59] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:42:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:42:59] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:43:01 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:43:01] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:43:02] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:43:02 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:43:02] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:43:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:43:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:43:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:43:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:43:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:43:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:43:04 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:43:04] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:43:06] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:43:06 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:43:06] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:43:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:43:06] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:43:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:43:06] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:43:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:43:06] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:43:09 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:43:09] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:43:11] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:43:11 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:43:11] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:43:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:43:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:43:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:43:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:43:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:43:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:43:13 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:43:13] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:43:14] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:43:14 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:43:14] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:43:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:43:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:43:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:43:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:43:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:43:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:43:16 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:43:16] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:43:18] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:43:18 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:43:18] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:43:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:43:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:43:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  39%|‚ñà‚ñà‚ñà‚ñâ      | 36/92 [08:59<14:25, 15.46s/it]INFO: [2025-06-27 15:43:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:43:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:43:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:43:19 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:43:19] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:43:20] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:43:20 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:43:20] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:43:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:43:20] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:43:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:43:20] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:43:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:43:20] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:43:22 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:43:22] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:43:23] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:43:23 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:43:23] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:43:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:43:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:43:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:43:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:43:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:43:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:43:24 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:43:24] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:43:25] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:43:25 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:43:25] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:43:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:43:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:43:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:43:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:43:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:43:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:43:26 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:43:26] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:43:28] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:43:28 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:43:28] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:43:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:43:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:43:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:43:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:43:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:43:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:43:29 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:43:29] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:43:30] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:43:30 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:43:30] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:43:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:43:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:43:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  40%|‚ñà‚ñà‚ñà‚ñà      | 37/92 [09:11<13:21, 14.57s/it]INFO: [2025-06-27 15:43:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:43:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:43:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:43:32 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:43:32] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:43:34] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:43:34 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:43:34] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:43:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:43:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:43:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:43:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:43:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:43:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:43:36 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:43:36] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:43:37] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:43:37 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:43:37] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:43:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:43:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:43:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:43:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:43:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:43:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:43:39 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:43:39] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:43:40] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:43:40 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:43:40] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:43:40 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:43:40] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:43:40 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:43:40] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:43:40 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:43:40] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:43:42 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:43:42] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:43:44] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:43:44 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:43:44] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:43:44 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:43:44] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:43:44 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:43:44] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:43:44 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:43:44] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:43:46 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:43:46] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:43:47] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:43:47 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:43:47] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:43:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:43:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:43:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 38/92 [09:28<13:47, 15.33s/it]INFO: [2025-06-27 15:43:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:43:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:43:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:43:49 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:43:49] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:43:50] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:43:50 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:43:50] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:43:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:43:50] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:43:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:43:50] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:43:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:43:50] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:43:53 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:43:53] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:43:55] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:43:55 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:43:55] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:43:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:43:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:43:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:43:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:43:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:43:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:43:57 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:43:57] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:43:58] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:43:58 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:43:58] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:43:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:43:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:43:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:43:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:43:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:43:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:44:00 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:44:00] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:44:01] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:44:01 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:44:01] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:44:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:44:01] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:44:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:44:01] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:44:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:44:01] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:44:03 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:44:03] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:44:04] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:44:04 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:44:04] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:44:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:44:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:44:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 39/92 [09:45<13:52, 15.71s/it]INFO: [2025-06-27 15:44:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:44:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:44:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:44:06 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:44:06] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:44:07] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:44:07 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:44:07] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:44:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:44:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:44:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:44:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:44:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:44:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:44:09 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:44:09] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:44:10] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:44:10 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:44:10] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:44:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:44:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:44:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:44:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:44:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:44:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:44:12 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:44:12] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:44:13] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:44:13 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:44:13] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:44:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:44:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:44:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:44:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:44:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:44:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:44:15 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:44:15] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:44:16] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:44:16 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:44:16] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:44:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:44:16] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:44:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:44:16] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:44:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:44:16] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:44:18 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:44:18] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:44:19] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:44:19 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:44:19] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:44:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:44:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:44:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 40/92 [10:00<13:26, 15.51s/it]INFO: [2025-06-27 15:44:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:44:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:44:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:44:21 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:44:21] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:44:22] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:44:22 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:44:22] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:44:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:44:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:44:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:44:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:44:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:44:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:44:24 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:44:24] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:44:25] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:44:25 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:44:25] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:44:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:44:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:44:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:44:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:44:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:44:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:44:27 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:44:27] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:44:29] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:44:29 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:44:29] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:44:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:44:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:44:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:44:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:44:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:44:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:44:31 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:44:31] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:44:33] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:44:33 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:44:33] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:44:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:44:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:44:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:44:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:44:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:44:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:44:35 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:44:35] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:44:37] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:44:37 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:44:37] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:44:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:44:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:44:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 41/92 [10:19<13:55, 16.38s/it]INFO: [2025-06-27 15:44:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:44:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:44:38] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:44:40 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:44:40] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:44:41] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:44:41 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:44:41] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:44:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:44:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:44:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:44:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:44:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:44:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:44:44 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:44:44] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:44:45] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:44:45 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:44:45] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:44:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:44:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:44:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:44:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:44:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:44:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:44:47 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:44:47] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:44:48] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:44:48 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:44:48] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:44:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:44:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:44:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:44:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:44:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:44:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:44:50 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:44:50] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:44:52] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:44:52 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:44:52] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:44:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:44:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:44:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:44:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:44:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:44:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:44:54 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:44:54] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:44:55] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:44:55 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:44:55] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:44:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:44:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 42/92 [10:36<13:56, 16.73s/it]\u001b[92m15:44:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:44:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:44:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:44:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:44:57 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:44:57] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:44:58] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:44:58 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:44:58] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:44:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:44:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:44:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:44:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:44:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:44:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:45:01 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:45:01] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:45:02] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:45:02 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:45:02] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:45:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:45:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:45:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:45:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:45:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:45:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:45:04 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:45:04] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:45:05] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:45:05 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:45:05] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:45:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:45:05] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:45:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:45:05] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:45:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:45:05] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:45:07 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:45:07] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:45:09] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:45:09 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:45:09] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:45:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:45:09] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:45:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:45:09] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:45:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:45:09] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:45:11 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:45:11] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:45:12] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:45:12 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:45:12] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:45:12 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:45:12] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:45:12 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 43/92 [10:53<13:44, 16.82s/it]INFO: [2025-06-27 15:45:12] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:45:12 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:45:12] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:45:14 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:45:14] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:45:16] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:45:16 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:45:16] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:45:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:45:16] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:45:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:45:16] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:45:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:45:16] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:45:18 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:45:18] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:45:19] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:45:19 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:45:19] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:45:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:45:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:45:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:45:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:45:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:45:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:45:21 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:45:21] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:45:22] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:45:22 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:45:22] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:45:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:45:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:45:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:45:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:45:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:45:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:45:24 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:45:24] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:45:25] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:45:25 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:45:25] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:45:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:45:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:45:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:45:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:45:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:45:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:45:27 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:45:27] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:45:28] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:45:28 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:45:28] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:45:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:45:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:45:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 44/92 [11:09<13:16, 16.58s/it]INFO: [2025-06-27 15:45:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:45:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:45:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:45:30 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:45:30] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:45:31] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:45:31 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:45:31] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:45:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:45:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:45:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:45:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:45:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:45:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:45:33 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:45:33] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:45:34] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:45:34 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:45:34] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:45:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:45:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:45:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:45:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:45:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:45:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:45:36 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:45:36] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:45:38] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:45:38 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:45:38] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:45:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:45:38] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:45:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:45:38] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:45:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:45:38] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:45:40 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:45:40] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:45:41] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:45:41 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:45:41] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:45:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:45:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:45:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:45:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:45:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:45:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:45:44 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:45:44] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:45:45] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:45:45 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:45:45] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:45:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:45:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:45:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 45/92 [11:26<12:58, 16.55s/it]INFO: [2025-06-27 15:45:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:45:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:45:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:45:46 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:45:46] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:45:47] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:45:47 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:45:47] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:45:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:45:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:45:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:45:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:45:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:45:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:45:48 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:45:48] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:45:50] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:45:50 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:45:50] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:45:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:45:50] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:45:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:45:50] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:45:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:45:50] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:45:51 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:45:51] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:45:52] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:45:52 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:45:52] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:45:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:45:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:45:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:45:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:45:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:45:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:45:54 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:45:54] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:45:55] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:45:55 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:45:55] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:45:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:45:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:45:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:45:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:45:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:45:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:45:56 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:45:56] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:45:57] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:45:57 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:45:57] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:45:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:45:57] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:45:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 46/92 [11:38<11:45, 15.34s/it]INFO: [2025-06-27 15:45:57] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:45:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:45:57] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:45:58 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:45:58] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:46:00] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:46:00 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:46:00] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:46:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:46:00] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:46:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:46:00] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:46:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:46:00] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:46:01 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:46:01] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:46:02] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:46:02 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:46:02] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:46:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:46:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:46:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:46:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:46:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:46:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:46:03 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:46:03] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:46:04] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:46:04 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:46:04] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:46:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:46:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:46:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:46:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:46:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:46:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:46:06 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:46:06] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:46:07] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:46:07 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:46:07] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:46:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:46:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:46:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:46:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:46:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:46:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:46:08 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:46:08] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:46:09] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:46:09 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:46:09] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:46:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:46:09] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:46:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 47/92 [11:50<10:49, 14.42s/it]INFO: [2025-06-27 15:46:09] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:46:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:46:09] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:46:12 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:46:12] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:46:13] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:46:13 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:46:13] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:46:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:46:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:46:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:46:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:46:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:46:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:46:15 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:46:15] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:46:16] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:46:16 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:46:16] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:46:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:46:16] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:46:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:46:16] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:46:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:46:16] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:46:18 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:46:18] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:46:19] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:46:20 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:46:20] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:46:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:46:20] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:46:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:46:20] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:46:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:46:20] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:46:22 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:46:22] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:46:23] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:46:23 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:46:23] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:46:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:46:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:46:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:46:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:46:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:46:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:46:25 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:46:25] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:46:27] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:46:27 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:46:27] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:46:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:46:27] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:46:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 48/92 [12:08<11:11, 15.26s/it]INFO: [2025-06-27 15:46:27] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:46:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:46:27] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:46:29 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:46:29] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:46:30] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:46:30 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:46:30] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:46:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:46:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:46:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:46:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:46:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:46:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:46:32 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:46:32] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:46:34] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:46:34 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:46:34] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:46:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:46:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:46:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:46:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:46:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:46:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:46:36 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:46:36] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:46:38] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:46:38 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:46:38] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:46:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:46:38] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:46:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:46:38] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:46:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:46:38] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:46:40 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:46:40] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:46:41] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:46:41 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:46:41] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:46:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:46:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:46:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:46:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:46:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:46:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:46:43 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:46:43] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:46:48] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:46:48 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:46:48] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:46:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:46:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:46:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 49/92 [12:29<12:13, 17.07s/it]INFO: [2025-06-27 15:46:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:46:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:46:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:46:50 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:46:50] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:46:51] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:46:51 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:46:51] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:46:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:46:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:46:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:46:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:46:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:46:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:46:53 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:46:53] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:46:54] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:46:54 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:46:54] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:46:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:46:54] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:46:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:46:54] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:46:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:46:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:46:57 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:46:57] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:46:58] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:46:58 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:46:58] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:46:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:46:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:46:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:46:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:46:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:46:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:47:00 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:47:00] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:47:01] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:47:01 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:47:01] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:47:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:47:01] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:47:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 50/92 [12:42<11:09, 15.94s/it]INFO: [2025-06-27 15:47:01] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:47:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:47:01] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:47:03 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:47:03] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:47:05] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:47:05 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:47:05] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:47:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:47:05] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:47:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:47:05] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:47:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:47:05] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:47:07 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:47:07] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:47:08] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:47:08 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:47:08] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:47:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:47:08] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:47:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:47:08] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:47:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:47:08] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:47:10 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:47:10] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:47:11] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:47:11 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:47:11] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:47:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:47:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:47:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:47:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:47:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:47:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:47:13 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:47:13] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:47:14] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:47:14 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:47:14] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:47:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:47:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 51/92 [12:55<10:20, 15.12s/it]\u001b[92m15:47:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:47:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:47:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:47:15] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:47:17 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:47:17] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:47:18] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:47:18 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:47:18] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:47:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:47:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:47:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:47:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:47:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:47:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:47:20 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:47:20] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:47:21] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:47:21 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:47:21] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:47:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:47:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:47:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:47:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:47:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:47:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:47:23 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:47:23] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:47:24] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:47:24 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:47:24] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:47:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:47:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:47:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:47:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:47:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:47:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:47:26 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:47:26] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:47:28] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:47:28 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:47:28] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:47:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:47:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:47:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 52/92 [13:09<09:43, 14.58s/it]INFO: [2025-06-27 15:47:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:47:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:47:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:47:30 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:47:30] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:47:31] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:47:31 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:47:31] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:47:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:47:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:47:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:47:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:47:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:47:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:47:33 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:47:33] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:47:34] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:47:34 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:47:34] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:47:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:47:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:47:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:47:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:47:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:47:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:47:36 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:47:36] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:47:37] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:47:37 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:47:37] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:47:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:47:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:47:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:47:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:47:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:47:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:47:39 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:47:39] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:47:40] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:47:40 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:47:40] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:47:40 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:47:40] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:47:40 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 53/92 [13:21<09:01, 13.89s/it]INFO: [2025-06-27 15:47:40] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:47:40 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:47:40] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:47:40 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:47:40] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:47:42] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:47:42 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:47:42] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:47:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:47:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:47:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:47:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:47:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:47:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:47:42 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:47:42] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:47:43] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:47:43 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:47:43] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:47:43 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:47:43] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:47:43 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:47:43] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:47:43 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:47:43] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:47:44 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:47:44] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:47:45] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:47:45 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:47:45] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:47:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:47:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:47:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:47:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:47:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:47:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:47:46 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:47:46] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:47:47] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:47:47 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:47:47] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:47:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:47:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:47:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 54/92 [13:28<07:25, 11.72s/it]INFO: [2025-06-27 15:47:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:47:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:47:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:47:49 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:47:49] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:47:50] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:47:50 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:47:50] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:47:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:47:50] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:47:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:47:50] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:47:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:47:50] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:47:52 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:47:52] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:47:54] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:47:54 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:47:54] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:47:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:47:54] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:47:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:47:54] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:47:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:47:54] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:47:56 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:47:56] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:47:57] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:47:57 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:47:57] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:47:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:47:57] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:47:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:47:57] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:47:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:47:57] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:47:59 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:47:59] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:48:00] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:48:00 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:48:00] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:48:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:48:00] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:48:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 55/92 [13:41<07:35, 12.32s/it]INFO: [2025-06-27 15:48:00] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:48:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:48:00] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:48:03 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:48:03] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:48:04] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:48:04 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:48:04] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:48:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:48:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:48:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:48:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:48:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:48:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:48:06 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:48:06] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:48:08] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:48:08 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:48:08] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:48:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:48:08] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:48:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:48:08] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:48:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:48:08] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:48:10 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:48:10] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:48:11] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:48:11 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:48:11] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:48:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:48:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:48:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 56/92 [13:52<07:03, 11.76s/it]INFO: [2025-06-27 15:48:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:48:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:48:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:48:13 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:48:13] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:48:15] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:48:15 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:48:15] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:48:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:48:15] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:48:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:48:15] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:48:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:48:15] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:48:17 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:48:17] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:48:18] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:48:18 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:48:18] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:48:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:48:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:48:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:48:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:48:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:48:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:48:20 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:48:20] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:48:22] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:48:22 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:48:22] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:48:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:48:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:48:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 57/92 [14:03<06:40, 11.46s/it]INFO: [2025-06-27 15:48:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:48:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:48:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:48:24 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:48:24] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:48:25] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:48:25 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:48:25] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:48:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:48:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:48:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:48:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:48:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:48:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:48:27 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:48:27] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:48:29] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:48:29 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:48:29] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:48:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:48:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:48:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:48:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:48:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:48:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:48:31 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:48:31] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:48:32] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:48:32 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:48:32] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:48:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:48:32] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:48:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 58/92 [14:13<06:18, 11.12s/it]INFO: [2025-06-27 15:48:32] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:48:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:48:32] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:48:34 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:48:34] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:48:35] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:48:35 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:48:35] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:48:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:48:35] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:48:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:48:35] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:48:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:48:35] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:48:37 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:48:37] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:48:38] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:48:38 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:48:38] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:48:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:48:38] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:48:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:48:38] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:48:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:48:38] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:48:40 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:48:40] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:48:41] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:48:41 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:48:41] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:48:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:48:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:48:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 59/92 [14:22<05:48, 10.55s/it]INFO: [2025-06-27 15:48:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:48:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:48:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:48:43 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:48:43] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:48:45] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:48:45 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:48:45] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:48:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:48:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:48:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:48:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:48:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:48:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:48:47 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:48:47] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:48:48] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:48:48 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:48:48] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:48:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:48:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:48:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:48:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:48:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:48:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:48:50 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:48:50] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:48:51] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:48:51 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:48:51] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:48:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:48:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:48:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 60/92 [14:32<05:33, 10.43s/it]INFO: [2025-06-27 15:48:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:48:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:48:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:48:53 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:48:53] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:48:54] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:48:54 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:48:54] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:48:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:48:54] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:48:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:48:54] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:48:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:48:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:48:56 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:48:56] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:48:58] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:48:58 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:48:58] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:48:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:48:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:48:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:48:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:48:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:48:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:49:00 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:49:00] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:49:01] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:49:01 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:49:01] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:49:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:49:01] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:49:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 61/92 [14:42<05:19, 10.31s/it]INFO: [2025-06-27 15:49:01] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:49:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:49:01] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:49:03 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:49:03] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:49:05] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:49:05 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:49:05] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:49:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:49:05] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:49:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:49:05] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:49:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:49:05] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:49:07 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:49:07] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:49:08] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:49:08 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:49:08] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:49:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:49:08] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:49:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:49:08] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:49:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:49:08] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:49:10 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:49:10] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:49:11] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:49:11 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:49:11] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:49:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:49:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:49:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 62/92 [14:52<05:06, 10.23s/it]INFO: [2025-06-27 15:49:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:49:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:49:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:49:13 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:49:13] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:49:15] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:49:15 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:49:15] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:49:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:49:15] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:49:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:49:15] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:49:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:49:15] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:49:17 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:49:17] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:49:18] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:49:18 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:49:18] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:49:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:49:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:49:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 63/92 [14:59<04:24,  9.13s/it]INFO: [2025-06-27 15:49:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:49:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:49:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:49:20 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:49:20] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:49:21] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:49:21 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:49:21] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:49:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:49:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:49:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:49:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:49:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:49:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:49:23 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:49:23] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:49:24] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:49:24 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:49:24] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:49:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:49:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:49:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 64/92 [15:05<03:52,  8.29s/it]INFO: [2025-06-27 15:49:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:49:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:49:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:49:26 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:49:26] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:49:28] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:49:28 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:49:28] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:49:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:49:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:49:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:49:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:49:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:49:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:49:30 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:49:30] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:49:32] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:49:32 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:49:32] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:49:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:49:32] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:49:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 65/92 [15:13<03:36,  8.02s/it]INFO: [2025-06-27 15:49:32] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:49:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:49:32] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:49:34 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:49:34] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:49:35] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:49:35 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:49:35] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:49:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:49:35] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:49:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:49:35] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:49:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:49:35] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:49:37 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:49:37] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:49:39] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:49:39 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:49:39] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:49:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:49:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:49:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 66/92 [15:20<03:22,  7.80s/it]INFO: [2025-06-27 15:49:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:49:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:49:39] indra_gpt.chat_curate.chat_curate - Skipping agent function() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "INFO: [2025-06-27 15:49:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:49:40 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:49:40] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:49:41] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:49:41 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:49:41] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:49:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:49:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:49:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:49:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:49:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:49:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:49:41] indra_gpt.chat_curate.chat_curate - Skipping agent function() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "\u001b[92m15:49:42 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:49:42] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:49:43] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:49:43 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:49:43] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:49:43 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:49:43] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:49:43 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 67/92 [15:24<02:50,  6.80s/it]INFO: [2025-06-27 15:49:43] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:49:43 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:49:43] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:49:46 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:49:46] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:49:47] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:49:47 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:49:47] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:49:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:49:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:49:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:49:47] indra_gpt.chat_curate.chat_curate - Skipping evidence with no text for statement -6735076600090236: Evidence(source_api='biopax',\n",
      "         source_id='http://www.phosphosite.org/phosphosite.owl#Catalysis_25233804_604',\n",
      "         annotations={\n",
      "                      \"source_sub_id\": \"phosphositeplus\",\n",
      "                      \"agents\": {\n",
      "                       \"raw_text\": [\n",
      "                        null,\n",
      "                        null\n",
      "                       ]\n",
      "                      },\n",
      "                      \"prior_uuids\": [\n",
      "                       \"bc120eec-d5a9-4509-b2d7-7596d200281e\"\n",
      "                      ]\n",
      "                     },\n",
      "         epistemics={\n",
      "                     \"direct\": true\n",
      "                    }\n",
      "         )\n",
      "\n",
      "\n",
      "Curating statements with chat curation:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 68/92 [15:28<02:20,  5.84s/it]INFO: [2025-06-27 15:49:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:49:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:49:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:49:49 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:49:49] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:49:50] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:49:50 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:49:50] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:49:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:49:50] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:49:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:49:50] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:49:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:49:50] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:49:52 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:49:52] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:49:53] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:49:53 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:49:53] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:49:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:49:53] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:49:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 69/92 [15:34<02:16,  5.95s/it]INFO: [2025-06-27 15:49:53] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:49:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:49:53] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:49:55 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:49:55] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:49:57] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:49:57 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:49:57] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:49:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:49:57] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:49:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:49:57] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:49:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:49:57] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:49:59 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:49:59] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:50:01] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:50:01 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:50:01] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:50:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:50:01] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:50:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 70/92 [15:42<02:21,  6.42s/it]INFO: [2025-06-27 15:50:01] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:50:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:50:01] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:50:02 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:50:02] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:50:10] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:50:10 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:50:10] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:50:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:50:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:50:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:50:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:50:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:50:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:50:11 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:50:11] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:50:13] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:50:13 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:50:13] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:50:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:50:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:50:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 71/92 [15:54<02:50,  8.10s/it]INFO: [2025-06-27 15:50:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:50:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:50:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:50:15 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:50:15] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:50:17] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:50:17 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:50:17] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:50:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:50:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:50:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:50:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:50:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:50:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:50:19 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:50:19] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:50:20] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:50:20 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:50:20] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:50:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:50:20] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:50:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 72/92 [16:01<02:39,  7.99s/it]INFO: [2025-06-27 15:50:20] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:50:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:50:20] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:50:24 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:50:24] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:50:25] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:50:25 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:50:25] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:50:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:50:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:50:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:50:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:50:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:50:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:50:28 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:50:28] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:50:29] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:50:29 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:50:29] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:50:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:50:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:50:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 73/92 [16:11<02:37,  8.30s/it]INFO: [2025-06-27 15:50:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:50:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:50:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:50:32 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:50:32] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:50:32] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:50:32 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:50:32] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:50:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:50:32] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 74/92 [16:14<02:00,  6.71s/it]\u001b[92m15:50:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:50:32] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:50:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:50:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:50:35 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:50:35] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:50:36] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:50:36 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:50:36] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:50:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:50:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:50:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 75/92 [16:17<01:35,  5.61s/it]INFO: [2025-06-27 15:50:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:50:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:50:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:50:37 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:50:37] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:50:38] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:50:38 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:50:38] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:50:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:50:38] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:50:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 76/92 [16:20<01:17,  4.81s/it]INFO: [2025-06-27 15:50:38] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:50:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:50:38] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:50:41 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:50:41] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:50:42] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:50:42 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:50:42] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:50:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:50:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:50:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 77/92 [16:23<01:06,  4.42s/it]INFO: [2025-06-27 15:50:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:50:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:50:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:50:43 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:50:43] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:50:45] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:50:45 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:50:45] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:50:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:50:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:50:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 78/92 [16:26<00:55,  3.95s/it]INFO: [2025-06-27 15:50:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:50:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:50:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:50:46 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:50:46] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:50:47] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:50:47 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:50:47] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:50:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:50:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:50:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 79/92 [16:28<00:45,  3.47s/it]INFO: [2025-06-27 15:50:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:50:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:50:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:50:48] indra_gpt.chat_curate.chat_curate - Skipping agent cytokine() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "\u001b[92m15:50:50 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:50:50] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:50:52] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:50:52 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:50:52] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:50:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:50:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:50:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 80/92 [16:33<00:45,  3.75s/it]INFO: [2025-06-27 15:50:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:50:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:50:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:50:54 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:50:54] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:50:55] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:50:55 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:50:55] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:50:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:50:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:50:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 81/92 [16:36<00:39,  3.61s/it]INFO: [2025-06-27 15:50:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:50:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:50:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:50:57 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:50:57] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:51:00] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:51:00 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:51:00] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:51:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:51:00] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:51:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 82/92 [16:41<00:39,  3.97s/it]INFO: [2025-06-27 15:51:00] indra_gpt.chat_curate.chat_curate - Skipping agent cotransporter-2 inhibitor() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "INFO: [2025-06-27 15:51:00] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:51:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:51:00] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:51:01 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:51:01] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:51:02] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:51:02 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:51:02] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:51:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:51:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:51:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 83/92 [16:43<00:30,  3.39s/it]INFO: [2025-06-27 15:51:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:51:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:51:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:51:04 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:51:04] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:51:05] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:51:05 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:51:05] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:51:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:51:05] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:51:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 84/92 [16:46<00:26,  3.33s/it]INFO: [2025-06-27 15:51:05] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:51:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:51:05] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:51:06 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:51:06] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:51:07] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:51:07 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:51:07] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:51:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:51:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:51:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 85/92 [16:48<00:21,  3.04s/it]INFO: [2025-06-27 15:51:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:51:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:51:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:51:09 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:51:09] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:51:10] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:51:10 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:51:10] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:51:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:51:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:51:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 86/92 [16:51<00:18,  3.06s/it]INFO: [2025-06-27 15:51:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:51:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:51:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:51:13 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:51:13] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:51:15] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:51:15 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:51:15] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:51:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:51:15] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:51:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 87/92 [16:56<00:17,  3.45s/it]INFO: [2025-06-27 15:51:15] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:51:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:51:15] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:51:17 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:51:17] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:51:18] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:51:18 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:51:18] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:51:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:51:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:51:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 88/92 [16:59<00:13,  3.40s/it]INFO: [2025-06-27 15:51:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:51:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:51:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:51:20 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:51:20] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:51:21] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:51:21 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:51:21] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:51:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:51:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:51:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 89/92 [17:02<00:10,  3.36s/it]INFO: [2025-06-27 15:51:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:51:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:51:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:51:23 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:51:23] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:51:25] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:51:25 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:51:25] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:51:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:51:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:51:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 90/92 [17:06<00:06,  3.43s/it]INFO: [2025-06-27 15:51:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:51:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:51:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:51:27 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:51:27] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:51:29] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:51:29 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:51:29] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:51:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:51:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:51:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 91/92 [17:10<00:03,  3.63s/it]INFO: [2025-06-27 15:51:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:51:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:51:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:51:31 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:51:31] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO: [2025-06-27 15:51:33] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:51:33 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:51:33] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:51:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO: [2025-06-27 15:51:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m15:51:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 92/92 [17:14<00:00,  3.62s/it]INFO: [2025-06-27 15:51:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 92/92 [17:14<00:00, 11.24s/it]\u001b[92m15:51:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\n",
      "INFO: [2025-06-27 15:51:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "Curating statements with chat curation:   0%|          | 0/92 [00:00<?, ?it/s]\u001b[92m15:51:35 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:51:35] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:51:37] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:51:37 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:51:37] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:51:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:51:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:51:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:51:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:51:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:51:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:51:39 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:51:39] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:51:41] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:51:41 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:51:41] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:51:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:51:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:51:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:51:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:51:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:51:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:51:43 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:51:43] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:51:45] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:51:45 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:51:45] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:51:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:51:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:51:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:51:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:51:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:51:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:51:47 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:51:47] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:51:49] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:51:49 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:51:49] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:51:49 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:51:49] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:51:49 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:51:49] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:51:49 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:51:49] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:51:51 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:51:51] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:51:53] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:51:53 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:51:53] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:51:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:51:53] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:51:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:   1%|          | 1/92 [00:20<30:33, 20.15s/it]INFO: [2025-06-27 15:51:53] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:51:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:51:53] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:51:55 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:51:55] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:51:58] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:51:58 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:51:58] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:51:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:51:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:51:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:51:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:51:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:51:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:52:00 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:52:00] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:52:02] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:52:02 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:52:02] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:52:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:52:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:52:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:52:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:52:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:52:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:52:04 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:52:04] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:52:06] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:52:06 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:52:06] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:52:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:52:06] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:52:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:52:06] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:52:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:52:06] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:52:08 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:52:08] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:52:10] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:52:10 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:52:10] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:52:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:52:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:52:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:52:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:52:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:52:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:52:12 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:52:12] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:52:14] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:52:14 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:52:14] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:52:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:52:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:   2%|‚ñè         | 2/92 [00:41<31:33, 21.04s/it]\u001b[92m15:52:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:52:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:52:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:52:15] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:52:17 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:52:17] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:52:18] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:52:18 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:52:18] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:52:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:52:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:52:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:52:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:52:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:52:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:52:20 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:52:20] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:52:22] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:52:22 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:52:22] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:52:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:52:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:52:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:52:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:52:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:52:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:52:25 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:52:25] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:52:27] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:52:27 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:52:27] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:52:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:52:27] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:52:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:52:27] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:52:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:52:27] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:52:29 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:52:29] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:52:31] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:52:31 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:52:31] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:52:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:52:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:52:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:52:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:52:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:52:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:52:33 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:52:33] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:52:35] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:52:35 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:52:35] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:52:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:52:35] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:52:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:   3%|‚ñé         | 3/92 [01:02<30:48, 20.76s/it]INFO: [2025-06-27 15:52:35] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:52:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:52:35] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:52:37 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:52:37] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:52:39] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:52:39 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:52:39] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:52:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:52:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:52:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:52:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:52:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:52:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:52:41 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:52:41] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:52:43] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:52:43 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:52:43] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:52:43 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:52:43] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:52:43 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:52:43] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:52:43 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:52:43] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:52:45 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:52:45] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:52:46] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:52:46 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:52:46] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:52:46 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:52:46] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:52:46 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:52:46] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:52:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:52:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:52:49 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:52:49] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:52:51] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:52:51 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:52:51] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:52:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:52:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:52:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:52:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:52:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:52:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:52:53 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:52:53] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:52:55] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:52:55 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:52:55] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:52:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:52:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:52:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:   4%|‚ñç         | 4/92 [01:22<30:01, 20.47s/it]INFO: [2025-06-27 15:52:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:52:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:52:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:52:56 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:52:56] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:52:58] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:52:58 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:52:58] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:52:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:52:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:52:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:52:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:52:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:52:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:52:59 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:52:59] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:53:01] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:53:01 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:53:01] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:53:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:53:01] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:53:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:53:01] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:53:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:53:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:53:03 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:53:03] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:53:04] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:53:04 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:53:04] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:53:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:53:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:53:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:53:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:53:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:53:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:53:06 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:53:06] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:53:07] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:53:07 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:53:07] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:53:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:53:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:53:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:53:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:53:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:53:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:53:08 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:53:08] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:53:11] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:53:11 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:53:11] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:53:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:53:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:53:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:   5%|‚ñå         | 5/92 [01:38<27:38, 19.07s/it]INFO: [2025-06-27 15:53:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:53:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:53:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:53:14 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:53:14] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:53:15] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:53:15 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:53:15] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:53:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:53:15] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:53:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:53:15] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:53:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:53:15] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:53:17 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:53:17] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:53:19] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:53:19 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:53:19] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:53:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:53:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:53:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:53:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:53:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:53:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:53:21 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:53:21] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:53:23] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:53:23 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:53:23] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:53:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:53:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:53:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:53:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:53:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:53:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:53:26 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:53:26] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:53:28] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:53:28 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:53:28] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:53:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:53:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:53:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:53:28] indra_gpt.chat_curate.chat_curate - Skipping evidence with no text for statement 3246604237187558: Evidence(source_api='biogrid',\n",
      "         pmid='9353268',\n",
      "         source_id='695850',\n",
      "         annotations={\n",
      "                      \"biogrid_int_id\": \"695850\",\n",
      "                      \"entrez_a\": \"7329\",\n",
      "                      \"entrez_b\": \"7341\",\n",
      "                      \"biogrid_a\": \"113177\",\n",
      "                      \"biogrid_b\": \"113188\",\n",
      "                      \"syst_name_a\": \"LA16c-358B7.1\",\n",
      "                      \"syst_name_b\": \"OK/SW-cl.43\",\n",
      "                      \"hgnc_a\": \"UBE2I\",\n",
      "                      \"hgnc_b\": \"SUMO1\",\n",
      "                      \"syn_a\": \"C358B7.1|P18|UBC9\",\n",
      "                      \"syn_b\": \"DAP1|GMP1|OFC10|PIC1|SENP2|SMT3|SMT3C|SMT3H3|UBL1\",\n",
      "                      \"exp_system\": \"Reconstituted Complex\",\n",
      "                      \"exp_system_type\": \"physical\",\n",
      "                      \"author\": \"Gong L (1997)\",\n",
      "                      \"pmid\": \"9353268\",\n",
      "                      \"organism_a\": \"9606\",\n",
      "                      \"organism_b\": \"9606\",\n",
      "                      \"throughput\": \"Low Throughput\",\n",
      "                      \"score\": null,\n",
      "                      \"modification\": null,\n",
      "                      \"phenotypes\": null,\n",
      "                      \"qualifications\": \"#LPPI|Likely protein-protein interaction\",\n",
      "                      \"tags\": null,\n",
      "                      \"source_db\": \"BIOGRID\",\n",
      "                      \"agents\": {\n",
      "                       \"raw_text\": [\n",
      "                        \"LA16c-358B7.1\",\n",
      "                        \"OK/SW-cl.43\"\n",
      "                       ]\n",
      "                      },\n",
      "                      \"prior_uuids\": [\n",
      "                       \"dec1314a-7a36-4ea9-926e-88f7cea3aaf7\"\n",
      "                      ]\n",
      "                     },\n",
      "         text_refs={\n",
      "                    \"PMID\": \"9353268\"\n",
      "                   }\n",
      "         )\n",
      "\n",
      "\n",
      "Curating statements with chat curation:   7%|‚ñã         | 6/92 [01:55<26:11, 18.27s/it]INFO: [2025-06-27 15:53:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:53:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:53:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:53:29 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:53:29] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:53:31] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:53:31 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:53:31] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:53:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:53:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:53:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:53:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:53:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:53:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:53:33 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:53:33] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:53:35] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:53:35 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:53:35] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:53:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:53:35] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:53:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:53:35] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:53:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:53:35] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:53:36 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:53:36] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:53:38] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:53:38 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:53:38] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:53:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:53:38] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:53:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:53:38] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:53:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:53:38] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:53:39 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:53:39] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:53:42] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:53:42 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:53:42] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:53:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:53:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:53:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:53:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:53:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:53:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:53:43 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:53:43] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:53:45] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:53:45 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:53:45] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:53:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:53:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:53:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:   8%|‚ñä         | 7/92 [02:12<25:02, 17.68s/it]INFO: [2025-06-27 15:53:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:53:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:53:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:53:46 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:53:46] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:53:48] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:53:48 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:53:48] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:53:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:53:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:53:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:53:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:53:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:53:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:53:49 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:53:49] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:53:51] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:53:51 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:53:51] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:53:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:53:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:53:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:53:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:53:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:53:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:53:52 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:53:52] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:53:55] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:53:55 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:53:55] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:53:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:53:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:53:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:53:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:53:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:53:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:53:56 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:53:56] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:53:58] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:53:58 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:53:58] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:53:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:53:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:53:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:53:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:53:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:53:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:53:59 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:53:59] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:54:02] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:54:02 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:54:02] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:54:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:54:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:54:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:   9%|‚ñä         | 8/92 [02:29<24:29, 17.49s/it]INFO: [2025-06-27 15:54:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:54:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:54:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:54:04 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:54:04] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:54:06] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:54:06 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:54:06] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:54:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:54:06] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:54:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:54:06] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:54:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:54:06] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:54:08 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:54:08] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:54:10] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:54:10 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:54:10] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:54:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:54:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:54:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:54:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:54:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:54:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:54:13 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:54:13] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:54:14] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:54:14 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:54:14] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:54:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:54:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:54:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:54:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:54:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:54:15] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:54:16 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:54:16] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:54:18] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:54:18 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:54:18] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:54:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:54:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:54:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:54:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:54:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:54:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:54:20 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:54:20] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:54:23] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:54:23 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:54:23] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:54:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:54:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:54:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  10%|‚ñâ         | 9/92 [02:50<25:42, 18.59s/it]INFO: [2025-06-27 15:54:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:54:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:54:23] indra_gpt.chat_curate.chat_curate - Skipping agent EMT() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "INFO: [2025-06-27 15:54:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:54:24 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:54:24] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:54:26] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:54:26 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:54:26] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:54:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:54:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:54:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:54:26] indra_gpt.chat_curate.chat_curate - Skipping agent EMT() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "INFO: [2025-06-27 15:54:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:54:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:54:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:54:27 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:54:27] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:54:28] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:54:28 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:54:28] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:54:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:54:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:54:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:54:28] indra_gpt.chat_curate.chat_curate - Skipping agent EMT() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "INFO: [2025-06-27 15:54:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:54:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:54:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:54:29 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:54:29] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:54:31] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:54:31 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:54:31] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:54:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:54:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:54:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:54:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:54:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:54:31] indra_gpt.chat_curate.chat_curate - Skipping agent EMT() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "INFO: [2025-06-27 15:54:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:54:32 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:54:32] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:54:34] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:54:34 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:54:34] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:54:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:54:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:54:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:54:34] indra_gpt.chat_curate.chat_curate - Skipping agent EMT() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "INFO: [2025-06-27 15:54:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:54:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:54:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:54:35 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:54:35] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:54:36] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:54:36 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:54:36] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:54:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:54:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:54:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  11%|‚ñà         | 10/92 [03:03<23:08, 16.93s/it]INFO: [2025-06-27 15:54:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:54:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:54:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:54:38 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:54:38] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:54:40] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:54:40 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:54:40] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:54:40 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:54:40] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:54:40 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:54:40] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:54:40 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:54:40] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:54:42 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:54:42] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:54:44] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:54:44 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:54:44] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:54:44 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:54:44] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:54:44 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:54:44] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:54:44 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:54:44] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:54:46 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:54:46] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:54:48] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:54:48 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:54:48] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:54:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:54:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:54:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:54:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:54:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:54:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:54:50 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:54:50] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:54:53] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:54:53 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:54:53] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:54:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:54:53] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:54:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:54:53] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:54:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:54:53] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:54:55 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:54:55] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:54:57] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:54:57 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:54:57] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:54:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:54:57] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:54:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  12%|‚ñà‚ñè        | 11/92 [03:24<24:34, 18.20s/it]INFO: [2025-06-27 15:54:57] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:54:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:54:57] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:54:59 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:54:59] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:55:01] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:55:01 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:55:01] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:55:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:55:01] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:55:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:55:01] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:55:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:55:01] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:55:03 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:55:03] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:55:05] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:55:05 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:55:05] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:55:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:55:05] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:55:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:55:05] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:55:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:55:05] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:55:07 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:55:07] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:55:09] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:55:09 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:55:09] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:55:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:55:09] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:55:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:55:09] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:55:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:55:09] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:55:11 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:55:11] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:55:13] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:55:13 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:55:13] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:55:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:55:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:55:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:55:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:55:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:55:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:55:15 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:55:15] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:55:17] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:55:17 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:55:17] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:55:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:55:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:55:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  13%|‚ñà‚ñé        | 12/92 [03:44<25:04, 18.80s/it]INFO: [2025-06-27 15:55:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:55:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:55:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:55:18 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:55:18] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:55:20] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:55:20 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:55:20] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:55:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:55:20] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:55:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:55:20] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:55:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:55:20] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:55:20 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:55:20] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:55:23] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:55:23 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:55:23] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:55:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:55:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:55:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:55:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:55:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:55:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:55:23 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:55:23] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:55:26] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:55:26 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:55:26] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:55:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:55:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:55:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:55:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:55:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:55:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:55:26 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:55:26] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:55:28] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:55:28 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:55:28] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:55:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:55:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:55:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:55:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:55:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:55:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:55:29 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:55:29] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:55:30] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:55:30 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:55:30] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:55:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:55:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:55:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  14%|‚ñà‚ñç        | 13/92 [03:57<22:31, 17.11s/it]INFO: [2025-06-27 15:55:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:55:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:55:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:55:32 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:55:32] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:55:34] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:55:34 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:55:34] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:55:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:55:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:55:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:55:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:55:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:55:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:55:35 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:55:35] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:55:37] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:55:37 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:55:37] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:55:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:55:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:55:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:55:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:55:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:55:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:55:38 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:55:38] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:55:41] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:55:41 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:55:41] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:55:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:55:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:55:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:55:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:55:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:55:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:55:42 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:55:42] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:55:45] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:55:45 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:55:45] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:55:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:55:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:55:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:55:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:55:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:55:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:55:46 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:55:46] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:55:48] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:55:48 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:55:48] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:55:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:55:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:55:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  15%|‚ñà‚ñå        | 14/92 [04:15<22:19, 17.17s/it]INFO: [2025-06-27 15:55:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:55:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:55:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:55:48 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:55:48] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:55:50] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:55:50 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:55:50] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:55:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:55:50] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:55:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:55:50] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:55:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:55:50] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:55:50 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:55:50] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:55:52] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:55:52 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:55:52] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:55:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:55:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:55:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:55:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:55:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:55:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:55:53 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:55:53] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:55:55] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:55:55 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:55:55] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:55:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:55:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:55:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:55:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:55:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:55:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:55:55 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:55:55] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:55:57] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:55:57 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:55:57] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:55:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:55:57] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:55:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:55:57] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:55:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:55:57] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:55:58 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:55:58] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:55:59] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:55:59 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:55:59] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:55:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:55:59] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:55:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  16%|‚ñà‚ñã        | 15/92 [04:26<19:50, 15.46s/it]INFO: [2025-06-27 15:55:59] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:55:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:55:59] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:56:00 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:56:00] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:56:02] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:56:02 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:56:02] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:56:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:56:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:56:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:56:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:56:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:56:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:56:02 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:56:02] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:56:03] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:56:03 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:56:03] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:56:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:56:03] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:56:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:56:03] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:56:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:56:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:56:04 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:56:04] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:56:06] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:56:06 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:56:06] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:56:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:56:06] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:56:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:56:06] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:56:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:56:06] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:56:07 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:56:07] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:56:08] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:56:08 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:56:08] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:56:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:56:08] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:56:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:56:08] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:56:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:56:08] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:56:09 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:56:09] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:56:10] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:56:10 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:56:10] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:56:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:56:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:56:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  17%|‚ñà‚ñã        | 16/92 [04:37<17:56, 14.17s/it]INFO: [2025-06-27 15:56:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:56:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:56:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:56:13 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:56:13] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:56:14] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:56:14 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:56:14] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:56:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:56:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:56:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:56:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:56:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:56:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:56:17 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:56:17] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:56:18] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:56:18 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:56:18] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:56:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:56:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:56:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:56:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:56:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:56:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:56:21 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:56:21] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:56:22] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:56:22 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:56:22] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:56:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:56:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:56:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:56:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:56:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:56:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:56:24 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:56:24] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:56:26] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:56:26 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:56:26] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:56:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:56:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:56:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:56:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:56:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:56:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:56:28 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:56:28] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:56:30] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:56:30 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:56:30] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:56:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:56:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:56:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  18%|‚ñà‚ñä        | 17/92 [04:57<19:37, 15.70s/it]INFO: [2025-06-27 15:56:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:56:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:56:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:56:32 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:56:32] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:56:35] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:56:35 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:56:35] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:56:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:56:35] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:56:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:56:35] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:56:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:56:35] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:56:37 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:56:37] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:56:42] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:56:42 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:56:42] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:56:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:56:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:56:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:56:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:56:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:56:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:56:44 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:56:44] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:56:45] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:56:45 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:56:45] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:56:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:56:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:56:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:56:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:56:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:56:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:56:47 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:56:47] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:56:50] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:56:50 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:56:50] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:56:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:56:50] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:56:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:56:50] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:56:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:56:50] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:56:52 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:56:52] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:56:54] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:56:54 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:56:54] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:56:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:56:54] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:56:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  20%|‚ñà‚ñâ        | 18/92 [05:21<22:41, 18.40s/it]INFO: [2025-06-27 15:56:54] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:56:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:56:54] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:56:56 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:56:56] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:56:59] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:56:59 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:56:59] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:56:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:56:59] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:56:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:56:59] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:56:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:56:59] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:57:01 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:57:01] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:57:03] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:57:03 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:57:03] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:57:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:57:03] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:57:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:57:03] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:57:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:57:03] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:57:05 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:57:05] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:57:07] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:57:07 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:57:07] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:57:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:57:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:57:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:57:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:57:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:57:08] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:57:09 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:57:09] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:57:13] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:57:13 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:57:13] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:57:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:57:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:57:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:57:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:57:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:57:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:57:15 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:57:15] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:57:17] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:57:17 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:57:17] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:57:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:57:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:57:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  21%|‚ñà‚ñà        | 19/92 [05:44<23:49, 19.58s/it]INFO: [2025-06-27 15:57:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:57:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:57:17] indra_gpt.chat_curate.chat_curate - Skipping evidence with no text for statement -34105277816332298: Evidence(source_api='biogrid',\n",
      "         pmid='16332543',\n",
      "         source_id='2381443',\n",
      "         annotations={\n",
      "                      \"biogrid_int_id\": \"2381443\",\n",
      "                      \"entrez_a\": \"375\",\n",
      "                      \"entrez_b\": \"55738\",\n",
      "                      \"biogrid_a\": \"106870\",\n",
      "                      \"biogrid_b\": \"120856\",\n",
      "                      \"syst_name_a\": null,\n",
      "                      \"syst_name_b\": \"RP11-261N11.1\",\n",
      "                      \"hgnc_a\": \"ARF1\",\n",
      "                      \"hgnc_b\": \"ARFGAP1\",\n",
      "                      \"syn_a\": null,\n",
      "                      \"syn_b\": \"ARF1GAP|HRIHFB2281\",\n",
      "                      \"exp_system\": \"Reconstituted Complex\",\n",
      "                      \"exp_system_type\": \"physical\",\n",
      "                      \"author\": \"Luo R (2005)\",\n",
      "                      \"pmid\": \"16332543\",\n",
      "                      \"organism_a\": \"9606\",\n",
      "                      \"organism_b\": \"9606\",\n",
      "                      \"throughput\": \"Low Throughput\",\n",
      "                      \"score\": null,\n",
      "                      \"modification\": null,\n",
      "                      \"phenotypes\": null,\n",
      "                      \"qualifications\": \"species of origin for bait and hit is unclear\",\n",
      "                      \"tags\": null,\n",
      "                      \"source_db\": \"BIOGRID\",\n",
      "                      \"agents\": {\n",
      "                       \"raw_text\": [\n",
      "                        null,\n",
      "                        \"RP11-261N11.1\"\n",
      "                       ]\n",
      "                      },\n",
      "                      \"prior_uuids\": [\n",
      "                       \"18c4bfdd-702d-49bf-b005-d2e4f0fc02bd\"\n",
      "                      ]\n",
      "                     },\n",
      "         text_refs={\n",
      "                    \"PMID\": \"16332543\"\n",
      "                   }\n",
      "         )\n",
      "\n",
      "\n",
      "INFO: [2025-06-27 15:57:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:57:19 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:57:19] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:57:21] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:57:21 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:57:21] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:57:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:57:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:57:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:57:21] indra_gpt.chat_curate.chat_curate - Skipping evidence with no text for statement -34105277816332298: Evidence(source_api='hprd',\n",
      "         pmid='9733781',\n",
      "         source_id='http://hprd.org/interactions?hprd_id=06443&isoform_id=06443_1&isoform_name=Isoform_1',\n",
      "         annotations={\n",
      "                      \"evidence\": [\n",
      "                       \"in vitro\",\n",
      "                       \"in vivo\"\n",
      "                      ],\n",
      "                      \"agents\": {\n",
      "                       \"raw_text\": [\n",
      "                        null,\n",
      "                        null\n",
      "                       ]\n",
      "                      },\n",
      "                      \"prior_uuids\": [\n",
      "                       \"679c5e2c-3b79-4852-be54-88d081491f97\"\n",
      "                      ]\n",
      "                     },\n",
      "         text_refs={\n",
      "                    \"PMID\": \"9733781\"\n",
      "                   }\n",
      "         )\n",
      "\n",
      "\n",
      "INFO: [2025-06-27 15:57:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:57:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:57:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:57:23 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:57:23] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:57:25] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:57:25 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:57:25] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:57:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:57:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:57:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:57:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:57:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:57:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:57:27 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:57:27] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:57:28] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:57:28 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:57:28] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:57:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:57:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:57:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  22%|‚ñà‚ñà‚ñè       | 20/92 [05:55<20:38, 17.20s/it]INFO: [2025-06-27 15:57:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:57:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:57:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:57:32 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:57:32] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:57:35] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:57:35 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:57:35] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:57:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:57:35] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:57:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:57:35] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:57:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:57:35] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:57:38 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:57:38] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:57:40] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:57:40 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:57:40] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:57:40 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:57:40] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:57:40 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:57:40] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:57:40 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:57:40] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:57:43 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:57:43] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:57:45] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:57:45 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:57:45] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:57:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:57:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:57:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:57:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:57:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:57:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:57:48 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:57:48] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:57:50] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:57:50 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:57:50] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:57:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:57:50] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:57:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:57:50] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:57:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:57:50] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:57:53 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:57:53] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:57:55] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:57:55 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:57:55] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:57:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:57:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:57:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  23%|‚ñà‚ñà‚ñé       | 21/92 [06:22<23:51, 20.16s/it]INFO: [2025-06-27 15:57:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:57:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:57:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:57:58 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:57:58] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:57:59] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:57:59 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:57:59] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:57:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:57:59] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:57:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:57:59] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:57:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:57:59] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:58:01 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:58:01] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:58:03] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:58:03 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:58:03] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:58:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:58:03] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:58:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:58:03] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:58:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:58:03] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:58:05 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:58:05] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:58:07] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:58:07 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:58:07] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:58:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:58:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:58:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:58:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:58:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:58:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:58:09 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:58:09] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:58:11] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:58:11 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:58:11] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:58:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:58:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:58:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:58:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:58:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:58:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:58:13 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:58:13] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:58:15] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:58:15 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:58:15] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:58:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:58:15] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:58:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  24%|‚ñà‚ñà‚ñç       | 22/92 [06:42<23:18, 19.98s/it]INFO: [2025-06-27 15:58:15] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:58:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:58:15] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:58:17 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:58:17] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:58:19] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:58:19 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:58:19] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:58:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:58:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:58:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:58:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:58:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:58:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:58:21 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:58:21] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:58:22] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:58:22 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:58:22] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:58:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:58:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:58:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:58:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:58:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:58:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:58:25 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:58:25] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:58:26] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:58:26 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:58:26] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:58:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:58:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:58:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:58:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:58:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:58:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:58:28 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:58:28] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:58:30] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:58:30 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:58:30] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:58:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:58:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:58:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:58:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:58:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:58:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:58:32 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:58:32] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:58:34] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:58:34 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:58:34] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:58:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:58:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:58:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  25%|‚ñà‚ñà‚ñå       | 23/92 [07:01<22:36, 19.67s/it]INFO: [2025-06-27 15:58:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:58:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:58:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:58:36 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:58:36] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:58:39] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:58:39 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:58:39] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:58:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:58:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:58:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:58:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:58:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:58:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:58:41 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:58:41] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:58:44] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:58:44 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:58:44] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:58:44 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:58:44] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:58:44 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:58:44] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:58:44 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:58:44] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:58:46 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:58:46] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:58:48] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:58:48 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:58:48] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:58:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:58:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:58:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:58:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:58:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:58:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:58:50 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:58:50] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:58:52] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:58:52 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:58:52] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:58:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:58:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:58:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:58:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:58:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:58:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:58:54 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:58:54] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:58:56] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:58:56 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:58:56] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:58:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:58:56] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:58:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  26%|‚ñà‚ñà‚ñå       | 24/92 [07:23<23:09, 20.43s/it]INFO: [2025-06-27 15:58:56] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:58:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:58:56] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:58:58 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:58:58] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:59:01] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:59:01 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:59:01] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:59:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:59:01] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:59:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:59:01] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:59:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:59:01] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:59:03 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:59:03] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:59:05] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:59:05 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:59:05] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:59:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:59:05] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:59:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:59:05] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:59:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:59:05] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:59:07 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:59:07] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:59:13] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:59:13 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:59:13] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:59:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:59:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:59:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:59:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:59:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:59:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:59:15 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:59:15] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:59:17] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:59:17 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:59:17] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:59:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:59:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:59:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:59:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:59:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:59:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:59:19 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:59:19] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:59:21] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:59:21 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:59:21] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:59:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:59:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:59:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  27%|‚ñà‚ñà‚ñã       | 25/92 [07:48<24:14, 21.71s/it]INFO: [2025-06-27 15:59:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:59:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:59:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:59:23 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:59:23] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:59:25] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:59:25 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:59:25] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:59:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:59:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:59:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:59:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:59:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:59:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:59:27 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:59:27] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:59:29] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:59:29 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:59:29] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:59:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:59:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:59:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:59:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:59:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:59:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:59:31 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:59:31] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:59:33] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:59:33 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:59:33] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:59:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:59:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:59:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:59:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:59:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:59:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:59:35 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:59:35] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:59:37] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:59:37 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:59:37] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:59:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:59:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:59:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:59:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:59:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:59:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:59:39 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:59:39] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:59:41] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:59:41 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:59:41] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:59:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:59:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:59:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  28%|‚ñà‚ñà‚ñä       | 26/92 [08:08<23:28, 21.35s/it]INFO: [2025-06-27 15:59:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:59:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:59:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:59:43 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:59:43] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:59:46] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:59:46 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:59:46] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:59:46 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:59:46] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:59:46 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:59:46] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:59:46 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:59:46] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:59:48 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:59:48] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:59:50] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:59:50 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:59:50] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:59:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:59:50] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:59:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:59:50] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:59:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:59:50] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:59:52 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:59:52] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:59:54] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:59:54 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:59:54] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:59:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:59:54] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:59:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:59:54] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:59:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:59:54] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:59:56 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:59:56] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 15:59:58] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m15:59:58 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 15:59:58] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m15:59:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:59:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:59:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:59:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m15:59:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 15:59:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:00:00 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:00:00] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:00:03] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:00:03 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:00:03] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:00:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:00:03] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:00:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  29%|‚ñà‚ñà‚ñâ       | 27/92 [08:30<23:11, 21.41s/it]INFO: [2025-06-27 16:00:03] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:00:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:00:03] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:00:04 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:00:04] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:00:07] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:00:07 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:00:07] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:00:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:00:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:00:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:00:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:00:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:00:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:00:08 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:00:08] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:00:13] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:00:13 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:00:13] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:00:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:00:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:00:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:00:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:00:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:00:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:00:14 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:00:14] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:00:16] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:00:16 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:00:16] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:00:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:00:16] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:00:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:00:16] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:00:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:00:16] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:00:17 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:00:17] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:00:19] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:00:19 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:00:19] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:00:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:00:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:00:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:00:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:00:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:00:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:00:20 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:00:20] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:00:22] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:00:22 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:00:22] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:00:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:00:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:00:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  30%|‚ñà‚ñà‚ñà       | 28/92 [08:49<22:05, 20.71s/it]INFO: [2025-06-27 16:00:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:00:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:00:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:00:24 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:00:24] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:00:27] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:00:27 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:00:27] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:00:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:00:27] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:00:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:00:27] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:00:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:00:27] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:00:29 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:00:29] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:00:31] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:00:31 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:00:31] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:00:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:00:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:00:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:00:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:00:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:00:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:00:33 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:00:33] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:00:36] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:00:36 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:00:36] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:00:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:00:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:00:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:00:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:00:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:00:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:00:38 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:00:38] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:00:41] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:00:41 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:00:41] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:00:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:00:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:00:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:00:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:00:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:00:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:00:43 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:00:43] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:00:45] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:00:45 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:00:45] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:00:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:00:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:00:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  32%|‚ñà‚ñà‚ñà‚ñè      | 29/92 [09:12<22:28, 21.41s/it]INFO: [2025-06-27 16:00:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:00:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:00:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:00:47 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:00:47] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:00:50] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:00:50 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:00:50] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:00:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:00:50] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:00:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:00:50] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:00:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:00:50] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:00:52 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:00:52] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:00:53] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:00:53 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:00:53] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:00:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:00:53] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:00:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:00:53] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:00:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:00:53] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:00:56 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:00:56] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:00:58] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:00:58 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:00:58] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:00:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:00:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:00:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:00:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:00:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:00:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:01:00 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:01:00] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:01:02] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:01:02 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:01:02] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:01:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:01:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:01:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:01:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:01:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:01:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:01:04 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:01:04] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:01:07] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:01:07 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:01:07] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:01:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:01:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:01:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  33%|‚ñà‚ñà‚ñà‚ñé      | 30/92 [09:34<22:24, 21.68s/it]INFO: [2025-06-27 16:01:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:01:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:01:07] indra_gpt.chat_curate.chat_curate - Skipping agent NP() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "INFO: [2025-06-27 16:01:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:01:08 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:01:08] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:01:11] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:01:11 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:01:11] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:01:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:01:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:01:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:01:11] indra_gpt.chat_curate.chat_curate - Skipping agent NP() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "INFO: [2025-06-27 16:01:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:01:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:01:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:01:12 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:01:12] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:01:15] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:01:15 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:01:15] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:01:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:01:15] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:01:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:01:15] indra_gpt.chat_curate.chat_curate - Skipping agent NP() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "INFO: [2025-06-27 16:01:15] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:01:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:01:15] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:01:16 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:01:16] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:01:18] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:01:18 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:01:18] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:01:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:01:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:01:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:01:18] indra_gpt.chat_curate.chat_curate - Skipping agent NP() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "INFO: [2025-06-27 16:01:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:01:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:01:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:01:19 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:01:19] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:01:21] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:01:21 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:01:21] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:01:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:01:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:01:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:01:21] indra_gpt.chat_curate.chat_curate - Skipping agent NP() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "INFO: [2025-06-27 16:01:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:01:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:01:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:01:22 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:01:22] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:01:24] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:01:24 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:01:24] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:01:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:01:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:01:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  34%|‚ñà‚ñà‚ñà‚ñé      | 31/92 [09:51<20:33, 20.22s/it]INFO: [2025-06-27 16:01:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:01:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:01:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:01:26 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:01:26] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:01:28] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:01:28 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:01:28] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:01:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:01:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:01:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:01:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:01:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:01:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:01:30 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:01:30] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:01:32] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:01:32 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:01:32] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:01:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:01:32] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:01:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:01:32] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:01:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:01:32] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:01:34 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:01:34] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:01:37] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:01:37 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:01:37] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:01:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:01:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:01:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:01:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:01:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:01:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:01:39 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:01:39] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:01:41] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:01:41 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:01:41] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:01:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:01:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:01:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:01:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:01:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:01:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:01:43 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:01:43] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:01:45] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:01:45 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:01:45] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:01:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:01:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:01:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  35%|‚ñà‚ñà‚ñà‚ñç      | 32/92 [10:12<20:21, 20.36s/it]INFO: [2025-06-27 16:01:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:01:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:01:45] indra_gpt.chat_curate.chat_curate - Skipping evidence with no text for statement 5895544448831150: Evidence(source_api='biogrid',\n",
      "         pmid='11792840',\n",
      "         source_id='280520',\n",
      "         annotations={\n",
      "                      \"biogrid_int_id\": \"280520\",\n",
      "                      \"entrez_a\": \"6840\",\n",
      "                      \"entrez_b\": \"367\",\n",
      "                      \"biogrid_a\": \"112707\",\n",
      "                      \"biogrid_b\": \"106862\",\n",
      "                      \"syst_name_a\": \"RP11-534G20.1\",\n",
      "                      \"syst_name_b\": \"RP11-383C12.1\",\n",
      "                      \"hgnc_a\": \"SVIL\",\n",
      "                      \"hgnc_b\": \"AR\",\n",
      "                      \"syn_a\": null,\n",
      "                      \"syn_b\": \"AIS|DHTR|HUMARA|HYSP1|KD|NR3C4|SBMA|SMAX1|TFM\",\n",
      "                      \"exp_system\": \"Two-hybrid\",\n",
      "                      \"exp_system_type\": \"physical\",\n",
      "                      \"author\": \"Ting HJ (2002)\",\n",
      "                      \"pmid\": \"11792840\",\n",
      "                      \"organism_a\": \"9606\",\n",
      "                      \"organism_b\": \"9606\",\n",
      "                      \"throughput\": \"Low Throughput\",\n",
      "                      \"score\": null,\n",
      "                      \"modification\": null,\n",
      "                      \"phenotypes\": null,\n",
      "                      \"qualifications\": null,\n",
      "                      \"tags\": null,\n",
      "                      \"source_db\": \"BIOGRID\",\n",
      "                      \"agents\": {\n",
      "                       \"raw_text\": [\n",
      "                        \"RP11-534G20.1\",\n",
      "                        \"RP11-383C12.1\"\n",
      "                       ]\n",
      "                      },\n",
      "                      \"prior_uuids\": [\n",
      "                       \"6488b526-899f-42ed-a310-982899f86d16\"\n",
      "                      ]\n",
      "                     },\n",
      "         text_refs={\n",
      "                    \"PMID\": \"11792840\"\n",
      "                   }\n",
      "         )\n",
      "\n",
      "\n",
      "INFO: [2025-06-27 16:01:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:01:47 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:01:47] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:01:49] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:01:49 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:01:49] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:01:49 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:01:49] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:01:49 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:01:49] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:01:49 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:01:49] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:01:52 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:01:52] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:01:53] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:01:53 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:01:53] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:01:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:01:53] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:01:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:01:53] indra_gpt.chat_curate.chat_curate - Skipping evidence with no text for statement 5895544448831150: Evidence(source_api='biogrid',\n",
      "         pmid='11792840',\n",
      "         source_id='280515',\n",
      "         annotations={\n",
      "                      \"biogrid_int_id\": \"280515\",\n",
      "                      \"entrez_a\": \"367\",\n",
      "                      \"entrez_b\": \"6840\",\n",
      "                      \"biogrid_a\": \"106862\",\n",
      "                      \"biogrid_b\": \"112707\",\n",
      "                      \"syst_name_a\": \"RP11-383C12.1\",\n",
      "                      \"syst_name_b\": \"RP11-534G20.1\",\n",
      "                      \"hgnc_a\": \"AR\",\n",
      "                      \"hgnc_b\": \"SVIL\",\n",
      "                      \"syn_a\": \"AIS|DHTR|HUMARA|HYSP1|KD|NR3C4|SBMA|SMAX1|TFM\",\n",
      "                      \"syn_b\": null,\n",
      "                      \"exp_system\": \"Two-hybrid\",\n",
      "                      \"exp_system_type\": \"physical\",\n",
      "                      \"author\": \"Ting HJ (2002)\",\n",
      "                      \"pmid\": \"11792840\",\n",
      "                      \"organism_a\": \"9606\",\n",
      "                      \"organism_b\": \"9606\",\n",
      "                      \"throughput\": \"Low Throughput\",\n",
      "                      \"score\": null,\n",
      "                      \"modification\": null,\n",
      "                      \"phenotypes\": null,\n",
      "                      \"qualifications\": null,\n",
      "                      \"tags\": null,\n",
      "                      \"source_db\": \"BIOGRID\",\n",
      "                      \"agents\": {\n",
      "                       \"raw_text\": [\n",
      "                        \"RP11-383C12.1\",\n",
      "                        \"RP11-534G20.1\"\n",
      "                       ]\n",
      "                      },\n",
      "                      \"prior_uuids\": [\n",
      "                       \"acaad1cf-653a-49f8-8faf-d1087e17cca5\"\n",
      "                      ]\n",
      "                     },\n",
      "         text_refs={\n",
      "                    \"PMID\": \"11792840\"\n",
      "                   }\n",
      "         )\n",
      "\n",
      "\n",
      "INFO: [2025-06-27 16:01:53] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:01:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:01:53] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:01:55 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:01:55] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:01:57] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:01:57 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:01:57] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:01:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:01:57] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:01:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  36%|‚ñà‚ñà‚ñà‚ñå      | 33/92 [10:24<17:34, 17.86s/it]INFO: [2025-06-27 16:01:57] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:01:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:01:57] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:01:58 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:01:58] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:02:00] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:02:00 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:02:00] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:02:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:02:00] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:02:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:02:00] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:02:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:02:00] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:02:02 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:02:02] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:02:04] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:02:04 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:02:04] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:02:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:02:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:02:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:02:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:02:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:02:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:02:05 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:02:05] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:02:07] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:02:07 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:02:07] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:02:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:02:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:02:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:02:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:02:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:02:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:02:09 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:02:09] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:02:11] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:02:11 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:02:11] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:02:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:02:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:02:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:02:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:02:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:02:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:02:12 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:02:12] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:02:14] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:02:14 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:02:14] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:02:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:02:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:02:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  37%|‚ñà‚ñà‚ñà‚ñã      | 34/92 [10:41<17:07, 17.71s/it]INFO: [2025-06-27 16:02:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:02:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:02:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:02:16 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:02:16] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:02:18] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:02:18 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:02:18] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:02:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:02:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:02:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:02:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:02:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:02:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:02:20 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:02:20] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:02:21] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:02:21 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:02:21] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:02:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:02:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:02:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:02:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:02:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:02:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:02:23 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:02:23] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:02:25] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:02:25 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:02:25] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:02:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:02:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:02:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:02:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:02:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:02:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:02:27 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:02:27] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:02:29] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:02:29 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:02:29] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:02:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:02:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:02:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:02:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:02:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:02:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:02:31 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:02:31] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:02:33] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:02:33 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:02:33] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:02:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:02:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:02:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  38%|‚ñà‚ñà‚ñà‚ñä      | 35/92 [11:00<17:08, 18.05s/it]INFO: [2025-06-27 16:02:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:02:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:02:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:02:35 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:02:35] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:02:38] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:02:38 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:02:38] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:02:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:02:38] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:02:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:02:38] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:02:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:02:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:02:40 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:02:40] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:02:43] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:02:43 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:02:43] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:02:43 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:02:43] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:02:43 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:02:43] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:02:43 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:02:43] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:02:45 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:02:45] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:02:48] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:02:48 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:02:48] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:02:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:02:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:02:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:02:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:02:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:02:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:02:50 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:02:50] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:02:52] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:02:52 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:02:52] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:02:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:02:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:02:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:02:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:02:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:02:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:02:54 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:02:54] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:02:56] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:02:56 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:02:56] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:02:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:02:56] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:02:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  39%|‚ñà‚ñà‚ñà‚ñâ      | 36/92 [11:23<18:19, 19.64s/it]INFO: [2025-06-27 16:02:56] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:02:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:02:56] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:02:58 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:02:58] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:03:00] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:03:00 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:03:00] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:03:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:03:00] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:03:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:03:00] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:03:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:03:00] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:03:01 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:03:01] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:03:03] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:03:03 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:03:03] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:03:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:03:03] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:03:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:03:03] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:03:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:03:03] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:03:04 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:03:04] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:03:07] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:03:07 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:03:07] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:03:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:03:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:03:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:03:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:03:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:03:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:03:08 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:03:08] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:03:11] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:03:11 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:03:11] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:03:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:03:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:03:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:03:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:03:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:03:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:03:12 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:03:12] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:03:13] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:03:13 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:03:13] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:03:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:03:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:03:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  40%|‚ñà‚ñà‚ñà‚ñà      | 37/92 [11:40<17:17, 18.87s/it]INFO: [2025-06-27 16:03:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:03:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:03:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:03:15 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:03:15] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:03:19] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:03:19 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:03:19] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:03:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:03:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:03:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:03:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:03:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:03:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:03:21 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:03:21] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:03:23] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:03:23 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:03:23] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:03:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:03:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:03:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:03:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:03:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:03:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:03:26 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:03:26] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:03:29] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:03:29 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:03:29] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:03:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:03:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:03:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:03:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:03:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:03:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:03:31 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:03:31] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:03:33] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:03:33 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:03:33] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:03:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:03:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:03:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:03:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:03:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:03:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:03:35 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:03:35] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:03:37] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:03:37 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:03:37] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:03:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:03:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:03:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 38/92 [12:04<18:10, 20.19s/it]INFO: [2025-06-27 16:03:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:03:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:03:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:03:39 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:03:39] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:03:41] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:03:41 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:03:41] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:03:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:03:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:03:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:03:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:03:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:03:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:03:43 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:03:43] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:03:44] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:03:44 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:03:44] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:03:44 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:03:44] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:03:44 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:03:44] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:03:44 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:03:44] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:03:46 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:03:46] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:03:48] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:03:48 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:03:48] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:03:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:03:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:03:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:03:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:03:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:03:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:03:50 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:03:50] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:03:53] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:03:53 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:03:53] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:03:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:03:53] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:03:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:03:53] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:03:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:03:53] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:03:55 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:03:55] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:03:58] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:03:58 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:03:58] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:03:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:03:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:03:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 39/92 [12:25<18:12, 20.62s/it]INFO: [2025-06-27 16:03:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:03:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:03:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:04:00 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:04:00] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:04:03] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:04:03 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:04:03] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:04:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:04:03] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:04:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:04:03] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:04:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:04:03] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:04:05 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:04:05] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:04:07] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:04:07 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:04:07] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:04:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:04:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:04:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:04:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:04:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:04:08] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:04:10 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:04:10] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:04:11] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:04:11 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:04:11] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:04:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:04:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:04:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:04:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:04:12 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:04:12] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:04:14 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:04:14] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:04:16] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:04:16 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:04:16] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:04:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:04:16] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:04:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:04:16] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:04:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:04:16] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:04:18 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:04:18] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:04:20] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:04:20 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:04:20] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:04:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:04:20] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:04:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 40/92 [12:47<18:15, 21.06s/it]INFO: [2025-06-27 16:04:20] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:04:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:04:20] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:04:22 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:04:22] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:04:24] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:04:24 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:04:24] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:04:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:04:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:04:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:04:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:04:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:04:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:04:27 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:04:27] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:04:28] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:04:28 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:04:28] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:04:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:04:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:04:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:04:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:04:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:04:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:04:30 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:04:30] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:04:32] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:04:32 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:04:32] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:04:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:04:32] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:04:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:04:32] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:04:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:04:32] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:04:34 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:04:34] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:04:36] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:04:36 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:04:36] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:04:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:04:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:04:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:04:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:04:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:04:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:04:38 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:04:38] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:04:40] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:04:40 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:04:40] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:04:40 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:04:40] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:04:40 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 41/92 [13:07<17:28, 20.55s/it]INFO: [2025-06-27 16:04:40] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:04:40 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:04:40] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:04:42 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:04:42] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:04:43] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:04:43 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:04:43] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:04:43 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:04:43] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:04:43 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:04:43] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:04:43 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:04:43] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:04:45 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:04:45] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:04:47] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:04:47 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:04:47] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:04:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:04:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:04:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:04:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:04:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:04:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:04:50 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:04:50] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:04:51] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:04:51 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:04:51] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:04:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:04:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:04:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:04:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:04:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:04:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:04:53 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:04:53] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:04:55] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:04:55 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:04:55] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:04:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:04:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:04:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:04:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:04:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:04:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:04:57 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:04:57] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:04:58] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:04:58 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:04:58] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:04:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:04:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:04:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 42/92 [13:25<16:38, 19.98s/it]INFO: [2025-06-27 16:04:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:04:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:04:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:05:01 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:05:01] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:05:02] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:05:02 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:05:02] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:05:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:05:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:05:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:05:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:05:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:05:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:05:04 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:05:04] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:05:07] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:05:07 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:05:07] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:05:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:05:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:05:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:05:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:05:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:05:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:05:09 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:05:09] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:05:10] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:05:10 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:05:10] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:05:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:05:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:05:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:05:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:05:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:05:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:05:12 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:05:12] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:05:14] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:05:14 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:05:14] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:05:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:05:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:05:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:05:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:05:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:05:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:05:16 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:05:16] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:05:18] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:05:18 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:05:18] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:05:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:05:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:05:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 43/92 [13:45<16:17, 19.94s/it]INFO: [2025-06-27 16:05:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:05:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:05:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:05:20 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:05:20] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:05:22] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:05:22 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:05:22] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:05:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:05:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:05:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:05:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:05:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:05:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:05:24 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:05:24] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:05:26] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:05:26 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:05:26] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:05:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:05:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:05:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:05:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:05:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:05:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:05:28 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:05:28] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:05:30] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:05:30 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:05:30] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:05:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:05:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:05:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:05:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:05:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:05:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:05:32 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:05:32] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:05:34] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:05:34 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:05:34] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:05:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:05:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:05:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:05:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:05:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:05:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:05:36 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:05:36] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:05:37] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:05:37 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:05:37] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:05:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:05:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:05:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 44/92 [14:04<15:45, 19.69s/it]INFO: [2025-06-27 16:05:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:05:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:05:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:05:40 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:05:40] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:05:41] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:05:41 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:05:41] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:05:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:05:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:05:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:05:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:05:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:05:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:05:43 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:05:43] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:05:45] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:05:45 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:05:45] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:05:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:05:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:05:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:05:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:05:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:05:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:05:47 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:05:47] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:05:48] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:05:48 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:05:48] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:05:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:05:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:05:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:05:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:05:49 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:05:49] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:05:51 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:05:51] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:05:53] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:05:53 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:05:53] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:05:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:05:53] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:05:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:05:53] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:05:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:05:53] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:05:55 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:05:55] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:05:56] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:05:56 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:05:56] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:05:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:05:56] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:05:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 45/92 [14:23<15:15, 19.49s/it]INFO: [2025-06-27 16:05:56] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:05:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:05:56] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:05:58 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:05:58] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:05:59] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:05:59 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:05:59] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:05:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:05:59] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:05:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:05:59] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:06:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:06:00] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:06:02 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:06:02] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:06:03] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:06:03 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:06:03] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:06:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:06:03] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:06:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:06:03] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:06:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:06:03] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:06:04 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:06:04] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:06:06] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:06:06 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:06:06] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:06:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:06:06] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:06:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:06:06] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:06:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:06:06] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:06:08 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:06:08] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:06:09] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:06:09 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:06:09] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:06:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:06:09] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:06:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:06:09] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:06:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:06:09] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:06:11 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:06:11] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:06:12] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:06:12 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:06:12] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:06:12 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:06:12] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:06:12 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 46/92 [14:39<14:08, 18.44s/it]INFO: [2025-06-27 16:06:12] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:06:12 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:06:12] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:06:14 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:06:14] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:06:15] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:06:15 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:06:15] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:06:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:06:15] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:06:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:06:15] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:06:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:06:15] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:06:17 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:06:17] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:06:18] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:06:18 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:06:18] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:06:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:06:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:06:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:06:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:06:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:06:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:06:20 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:06:20] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:06:22] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:06:22 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:06:22] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:06:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:06:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:06:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:06:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:06:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:06:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:06:23 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:06:23] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:06:25] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:06:25 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:06:25] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:06:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:06:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:06:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:06:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:06:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:06:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:06:26 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:06:26] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:06:28] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:06:28 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:06:28] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:06:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:06:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:06:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 47/92 [14:55<13:15, 17.69s/it]INFO: [2025-06-27 16:06:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:06:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:06:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:06:30 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:06:30] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:06:32] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:06:32 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:06:32] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:06:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:06:32] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:06:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:06:32] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:06:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:06:32] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:06:34 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:06:34] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:06:36] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:06:36 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:06:36] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:06:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:06:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:06:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:06:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:06:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:06:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:06:38 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:06:38] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:06:40] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:06:40 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:06:40] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:06:40 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:06:40] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:06:40 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:06:40] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:06:40 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:06:40] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:06:42 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:06:42] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:06:44] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:06:44 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:06:44] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:06:44 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:06:44] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:06:44 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:06:44] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:06:44 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:06:44] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:06:46 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:06:46] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:06:49] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:06:49 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:06:49] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:06:49 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:06:49] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:06:49 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 48/92 [15:15<13:32, 18.46s/it]INFO: [2025-06-27 16:06:49] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:06:49 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:06:49] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:06:51 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:06:51] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:06:53] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:06:53 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:06:53] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:06:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:06:53] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:06:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:06:53] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:06:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:06:53] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:06:55 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:06:55] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:06:57] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:06:57 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:06:57] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:06:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:06:57] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:06:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:06:57] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:06:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:06:57] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:06:59 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:06:59] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:07:01] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:07:01 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:07:01] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:07:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:07:01] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:07:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:07:01] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:07:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:07:01] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:07:03 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:07:03] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:07:05] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:07:05 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:07:05] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:07:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:07:05] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:07:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:07:05] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:07:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:07:05] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:07:07 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:07:07] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:07:09] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:07:09 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:07:09] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:07:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:07:09] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:07:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 49/92 [15:36<13:44, 19.16s/it]INFO: [2025-06-27 16:07:09] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:07:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:07:09] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:07:11 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:07:11] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:07:14] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:07:14 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:07:14] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:07:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:07:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:07:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:07:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:07:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:07:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:07:16 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:07:16] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:07:17] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:07:17 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:07:17] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:07:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:07:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:07:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:07:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:07:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:07:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:07:20 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:07:20] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:07:21] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:07:21 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:07:21] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:07:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:07:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:07:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:07:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:07:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:07:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:07:23 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:07:23] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:07:25] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:07:25 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:07:25] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:07:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:07:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:07:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 50/92 [15:52<12:36, 18.02s/it]INFO: [2025-06-27 16:07:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:07:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:07:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:07:27 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:07:27] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:07:29] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:07:29 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:07:29] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:07:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:07:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:07:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:07:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:07:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:07:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:07:32 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:07:32] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:07:34] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:07:34 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:07:34] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:07:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:07:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:07:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:07:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:07:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:07:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:07:36 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:07:36] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:07:38] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:07:38 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:07:38] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:07:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:07:38] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:07:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:07:38] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:07:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:07:38] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:07:40 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:07:40] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:07:42] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:07:42 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:07:42] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:07:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:07:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:07:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 51/92 [16:09<12:11, 17.85s/it]INFO: [2025-06-27 16:07:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:07:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:07:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:07:44 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:07:44] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:07:46] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:07:46 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:07:46] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:07:46 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:07:46] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:07:46 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:07:46] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:07:46 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:07:46] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:07:48 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:07:48] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:07:51] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:07:51 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:07:51] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:07:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:07:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:07:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:07:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:07:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:07:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:07:53 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:07:53] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:07:55] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:07:55 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:07:55] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:07:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:07:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:07:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:07:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:07:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:07:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:07:57 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:07:57] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:07:59] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:07:59 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:07:59] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:07:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:07:59] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:07:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 52/92 [16:26<11:46, 17.67s/it]INFO: [2025-06-27 16:07:59] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:07:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:07:59] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:08:02 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:08:02] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:08:04] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:08:04 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:08:04] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:08:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:08:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:08:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:08:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:08:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:08:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:08:06 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:08:06] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:08:08] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:08:08 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:08:08] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:08:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:08:08] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:08:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:08:08] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:08:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:08:08] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:08:11 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:08:11] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:08:13] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:08:13 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:08:13] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:08:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:08:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:08:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:08:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:08:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:08:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:08:15 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:08:15] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:08:17] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:08:17 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:08:17] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:08:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:08:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:08:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 53/92 [16:44<11:29, 17.69s/it]INFO: [2025-06-27 16:08:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:08:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:08:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:08:18 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:08:18] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:08:19] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:08:19 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:08:19] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:08:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:08:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:08:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:08:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:08:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:08:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:08:20 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:08:20] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:08:22] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:08:22 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:08:22] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:08:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:08:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:08:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:08:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:08:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:08:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:08:22 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:08:22] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:08:24] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:08:24 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:08:24] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:08:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:08:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:08:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:08:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:08:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:08:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:08:24 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:08:24] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:08:27] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:08:27 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:08:27] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:08:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:08:27] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:08:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 54/92 [16:54<09:39, 15.24s/it]INFO: [2025-06-27 16:08:27] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:08:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:08:27] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:08:29 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:08:29] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:08:31] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:08:31 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:08:31] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:08:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:08:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:08:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:08:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:08:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:08:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:08:33 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:08:33] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:08:35] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:08:35 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:08:35] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:08:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:08:35] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:08:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:08:35] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:08:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:08:35] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:08:37 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:08:37] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:08:39] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:08:39 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:08:39] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:08:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:08:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:08:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:08:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:08:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:08:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:08:41 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:08:41] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:08:43] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:08:43 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:08:43] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:08:43 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:08:43] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:08:43 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 55/92 [17:10<09:32, 15.46s/it]INFO: [2025-06-27 16:08:43] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:08:43 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:08:43] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:08:45 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:08:45] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:08:47] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:08:47 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:08:47] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:08:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:08:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:08:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:08:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:08:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:08:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:08:49 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:08:49] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:08:51] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:08:51 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:08:51] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:08:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:08:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:08:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:08:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:08:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:08:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:08:53 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:08:53] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:08:55] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:08:55 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:08:55] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:08:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:08:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:08:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 56/92 [17:22<08:43, 14.55s/it]INFO: [2025-06-27 16:08:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:08:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:08:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:08:57 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:08:57] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:08:59] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:08:59 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:08:59] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:08:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:08:59] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:08:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:08:59] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:08:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:08:59] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:09:01 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:09:01] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:09:04] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:09:04 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:09:04] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:09:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:09:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:09:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:09:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:09:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:09:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:09:06 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:09:06] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:09:09] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:09:09 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:09:09] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:09:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:09:09] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:09:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 57/92 [17:36<08:27, 14.49s/it]INFO: [2025-06-27 16:09:09] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:09:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:09:09] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:09:11 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:09:11] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:09:14] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:09:14 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:09:14] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:09:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:09:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:09:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:09:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:09:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:09:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:09:16 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:09:16] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:09:18] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:09:18 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:09:18] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:09:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:09:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:09:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:09:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:09:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:09:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:09:20 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:09:20] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:09:23] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:09:23 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:09:23] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:09:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:09:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:09:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 58/92 [17:50<08:00, 14.12s/it]INFO: [2025-06-27 16:09:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:09:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:09:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:09:25 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:09:25] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:09:27] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:09:27 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:09:27] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:09:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:09:27] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:09:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:09:27] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:09:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:09:27] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:09:29 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:09:29] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:09:31] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:09:31 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:09:31] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:09:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:09:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:09:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:09:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:09:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:09:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:09:33 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:09:33] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:09:35] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:09:35 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:09:35] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:09:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:09:35] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:09:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 59/92 [18:02<07:28, 13.58s/it]INFO: [2025-06-27 16:09:35] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:09:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:09:35] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:09:37 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:09:37] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:09:39] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:09:39 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:09:39] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:09:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:09:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:09:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:09:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:09:40 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:09:40] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:09:42 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:09:42] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:09:43] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:09:43 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:09:43] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:09:43 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:09:43] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:09:43 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:09:43] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:09:43 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:09:43] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:09:45 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:09:45] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:09:48] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:09:48 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:09:48] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:09:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:09:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:09:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 60/92 [18:15<07:07, 13.37s/it]INFO: [2025-06-27 16:09:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:09:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:09:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:09:50 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:09:50] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:09:52] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:09:52 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:09:52] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:09:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:09:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:09:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:09:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:09:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:09:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:09:54 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:09:54] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:09:56] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:09:56 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:09:56] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:09:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:09:56] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:09:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:09:56] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:09:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:09:56] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:09:58 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:09:58] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:09:59] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:09:59 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:09:59] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:09:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:09:59] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:09:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 61/92 [18:26<06:37, 12.83s/it]INFO: [2025-06-27 16:09:59] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:09:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:09:59] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:10:02 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:10:02] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:10:04] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:10:04 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:10:04] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:10:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:10:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:10:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:10:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:10:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:10:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:10:06 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:10:06] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:10:08] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:10:08 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:10:08] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:10:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:10:08] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:10:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:10:08] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:10:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:10:08] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:10:10 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:10:10] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:10:12] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:10:12 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:10:12] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:10:12 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:10:12] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:10:12 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 62/92 [18:38<06:18, 12.61s/it]INFO: [2025-06-27 16:10:12] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:10:12 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:10:12] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:10:14 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:10:14] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:10:16] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:10:16 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:10:16] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:10:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:10:16] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:10:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:10:16] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:10:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:10:16] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:10:18 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:10:18] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:10:20] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:10:20 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:10:20] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:10:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:10:20] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:10:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 63/92 [18:47<05:33, 11.49s/it]INFO: [2025-06-27 16:10:20] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:10:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:10:20] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:10:22 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:10:22] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:10:24] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:10:24 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:10:24] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:10:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:10:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:10:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:10:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:10:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:10:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:10:26 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:10:26] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:10:28] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:10:28 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:10:28] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:10:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:10:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:10:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 64/92 [18:55<04:51, 10.41s/it]INFO: [2025-06-27 16:10:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:10:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:10:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:10:30 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:10:30] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:10:33] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:10:33 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:10:33] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:10:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:10:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:10:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:10:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:10:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:10:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:10:35 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:10:35] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:10:37] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:10:37 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:10:37] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:10:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:10:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:10:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 65/92 [19:04<04:25,  9.84s/it]INFO: [2025-06-27 16:10:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:10:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:10:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:10:39 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:10:39] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:10:41] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:10:41 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:10:41] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:10:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:10:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:10:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:10:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:10:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:10:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:10:43 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:10:43] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:10:46] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:10:46 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:10:46] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:10:46 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:10:46] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:10:46 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 66/92 [19:13<04:11,  9.65s/it]INFO: [2025-06-27 16:10:46] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:10:46 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:10:46] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:10:46] indra_gpt.chat_curate.chat_curate - Skipping agent function() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "\u001b[92m16:10:47 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:10:47] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:10:51] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:10:51 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:10:51] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:10:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:10:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:10:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:10:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:10:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:10:51] indra_gpt.chat_curate.chat_curate - Skipping agent function() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "INFO: [2025-06-27 16:10:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:10:52 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:10:52] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:10:56] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:10:56 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:10:56] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:10:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:10:56] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:10:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 67/92 [19:23<04:05,  9.83s/it]INFO: [2025-06-27 16:10:56] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:10:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:10:56] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:10:58 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:10:58] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:11:01] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:11:01 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:11:01] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:11:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:11:01] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:11:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:11:01] indra_gpt.chat_curate.chat_curate - Skipping evidence with no text for statement -6735076600090236: Evidence(source_api='biopax',\n",
      "         source_id='http://www.phosphosite.org/phosphosite.owl#Catalysis_25233804_604',\n",
      "         annotations={\n",
      "                      \"source_sub_id\": \"phosphositeplus\",\n",
      "                      \"agents\": {\n",
      "                       \"raw_text\": [\n",
      "                        null,\n",
      "                        null\n",
      "                       ]\n",
      "                      },\n",
      "                      \"prior_uuids\": [\n",
      "                       \"bc120eec-d5a9-4509-b2d7-7596d200281e\"\n",
      "                      ]\n",
      "                     },\n",
      "         epistemics={\n",
      "                     \"direct\": true\n",
      "                    }\n",
      "         )\n",
      "\n",
      "\n",
      "Curating statements with chat curation:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 68/92 [19:28<03:20,  8.34s/it]INFO: [2025-06-27 16:11:01] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:11:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:11:01] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:11:03 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:11:03] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:11:06] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:11:06 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:11:06] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:11:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:11:06] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:11:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:11:06] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:11:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:11:06] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:11:08 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:11:08] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:11:10] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:11:10 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:11:10] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:11:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:11:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:11:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 69/92 [19:37<03:14,  8.44s/it]INFO: [2025-06-27 16:11:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:11:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:11:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:11:12 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:11:12] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:11:14] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:11:14 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:11:14] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:11:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:11:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:11:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:11:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:11:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:11:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:11:16 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:11:16] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:11:17] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:11:17 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:11:17] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:11:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:11:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:11:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 70/92 [19:44<02:57,  8.05s/it]INFO: [2025-06-27 16:11:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:11:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:11:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:11:18 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:11:18] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:11:20] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:11:20 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:11:20] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:11:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:11:20] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:11:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:11:20] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:11:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:11:20] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:11:21 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:11:21] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:11:23] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:11:23 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:11:23] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:11:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:11:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:11:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 71/92 [19:50<02:38,  7.54s/it]INFO: [2025-06-27 16:11:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:11:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:11:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:11:25 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:11:25] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:11:28] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:11:28 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:11:28] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:11:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:11:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:11:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:11:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:11:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:11:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:11:30 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:11:30] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:11:32] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:11:32 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:11:32] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:11:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:11:32] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:11:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 72/92 [19:59<02:35,  7.77s/it]INFO: [2025-06-27 16:11:32] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:11:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:11:32] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:11:35 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:11:35] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:11:37] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:11:37 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:11:37] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:11:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:11:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:11:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:11:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:11:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:11:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:11:40 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:11:40] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:11:43] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:11:43 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:11:43] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:11:43 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:11:43] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:11:43 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 73/92 [20:10<02:46,  8.77s/it]INFO: [2025-06-27 16:11:43] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:11:43 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:11:43] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:11:45 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:11:45] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:11:47] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:11:47 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:11:47] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:11:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:11:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:11:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 74/92 [20:14<02:13,  7.42s/it]INFO: [2025-06-27 16:11:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:11:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:11:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:11:49 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:11:49] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:11:51] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:11:51 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:11:51] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:11:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:11:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:11:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 75/92 [20:18<01:49,  6.43s/it]INFO: [2025-06-27 16:11:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:11:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:11:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:11:53 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:11:53] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:11:56] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:11:56 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:11:56] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:11:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:11:56] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:11:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 76/92 [20:23<01:35,  6.00s/it]INFO: [2025-06-27 16:11:56] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:11:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:11:56] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:11:58 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:11:58] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:12:01] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:12:01 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:12:01] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:12:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:12:01] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:12:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 77/92 [20:28<01:23,  5.58s/it]INFO: [2025-06-27 16:12:01] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:12:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:12:01] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:12:02 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:12:02] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:12:04] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:12:04 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:12:04] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:12:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:12:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:12:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 78/92 [20:31<01:10,  5.01s/it]INFO: [2025-06-27 16:12:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:12:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:12:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:12:06 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:12:06] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:12:07] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:12:07 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:12:07] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:12:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:12:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:12:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 79/92 [20:34<00:56,  4.37s/it]INFO: [2025-06-27 16:12:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:12:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:12:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:12:08] indra_gpt.chat_curate.chat_curate - Skipping agent cytokine() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "\u001b[92m16:12:10 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:12:10] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:12:13] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:12:13 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:12:13] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:12:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:12:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:12:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 80/92 [20:40<00:58,  4.88s/it]INFO: [2025-06-27 16:12:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:12:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:12:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:12:15 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:12:15] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:12:18] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:12:18 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:12:18] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:12:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:12:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:12:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 81/92 [20:45<00:52,  4.73s/it]INFO: [2025-06-27 16:12:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:12:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:12:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:12:20 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:12:20] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:12:22] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:12:22 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:12:22] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:12:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:12:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:12:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 82/92 [20:49<00:46,  4.68s/it]INFO: [2025-06-27 16:12:22] indra_gpt.chat_curate.chat_curate - Skipping agent cotransporter-2 inhibitor() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "INFO: [2025-06-27 16:12:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:12:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:12:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:12:23 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:12:23] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:12:25] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:12:25 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:12:25] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:12:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:12:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:12:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 83/92 [20:52<00:37,  4.21s/it]INFO: [2025-06-27 16:12:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:12:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:12:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:12:27 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:12:27] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:12:29] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:12:29 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:12:29] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:12:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:12:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:12:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 84/92 [20:56<00:32,  4.06s/it]INFO: [2025-06-27 16:12:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:12:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:12:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:12:30 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:12:30] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:12:33] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:12:33 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:12:33] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:12:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:12:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:12:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 85/92 [21:00<00:28,  4.03s/it]INFO: [2025-06-27 16:12:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:12:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:12:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:12:35 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:12:35] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:12:37] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:12:37 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:12:37] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:12:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:12:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 86/92 [21:04<00:23,  3.90s/it]\u001b[92m16:12:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:12:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:12:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:12:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:12:40 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:12:40] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:12:42] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:12:42 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:12:42] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:12:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:12:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:12:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 87/92 [21:09<00:21,  4.36s/it]INFO: [2025-06-27 16:12:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:12:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:12:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:12:44 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:12:44] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:12:46] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:12:46 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:12:46] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:12:46 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:12:46] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:12:46 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 88/92 [21:13<00:16,  4.25s/it]INFO: [2025-06-27 16:12:46] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:12:46 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:12:46] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:12:48 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:12:48] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:12:52] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:12:52 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:12:52] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:12:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:12:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:12:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 89/92 [21:19<00:14,  4.78s/it]INFO: [2025-06-27 16:12:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:12:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:12:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:12:54 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:12:54] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:12:57] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:12:57 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:12:57] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:12:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:12:57] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:12:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 90/92 [21:24<00:09,  4.70s/it]INFO: [2025-06-27 16:12:57] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:12:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:12:57] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:12:59 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:12:59] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:13:02] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:13:02 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:13:02] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:13:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:13:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:13:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 91/92 [21:29<00:04,  4.92s/it]INFO: [2025-06-27 16:13:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:13:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:13:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:13:04 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:13:04] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:13:06] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:13:06 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:13:06] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:13:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:13:06] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:13:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 92/92 [21:33<00:00,  4.76s/it]INFO: [2025-06-27 16:13:06] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 92/92 [21:33<00:00, 14.06s/it]\u001b[92m16:13:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\n",
      "INFO: [2025-06-27 16:13:06] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:   0%|          | 0/92 [00:00<?, ?it/s]\u001b[92m16:13:09 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:13:09] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:13:11] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:13:11 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:13:11] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:13:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:13:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:13:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:13:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:13:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:13:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:13:13 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:13:13] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:13:15] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:13:15 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:13:15] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:13:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:13:15] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:13:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:13:15] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:13:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:13:15] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:13:17 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:13:17] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:13:20] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:13:20 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:13:20] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:13:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:13:20] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:13:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:13:20] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:13:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:13:20] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:13:22 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:13:22] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:13:24] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:13:24 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:13:24] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:13:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:13:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:13:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:13:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:13:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:13:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:13:26 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:13:26] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:13:28] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:13:28 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:13:28] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:13:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:13:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:13:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:   1%|          | 1/92 [00:21<33:04, 21.81s/it]INFO: [2025-06-27 16:13:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:13:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:13:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:13:30 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:13:30] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:13:33] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:13:33 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:13:33] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:13:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:13:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:13:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:13:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:13:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:13:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:13:35 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:13:35] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:13:37] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:13:37 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:13:37] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:13:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:13:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:13:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:13:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:13:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:13:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:13:39 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:13:39] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:13:41] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:13:41 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:13:41] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:13:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:13:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:13:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:13:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:13:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:13:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:13:43 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:13:43] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:13:45] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:13:45 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:13:45] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:13:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:13:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:13:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:13:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:13:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:13:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:13:47 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:13:47] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:13:48] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:13:48 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:13:48] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:13:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:13:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:13:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:   2%|‚ñè         | 2/92 [00:41<31:15, 20.83s/it]INFO: [2025-06-27 16:13:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:13:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:13:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:13:51 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:13:51] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:13:53] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:13:53 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:13:53] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:13:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:13:53] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:13:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:13:53] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:13:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:13:53] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:13:55 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:13:55] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:13:57] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:13:57 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:13:57] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:13:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:13:57] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:13:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:13:57] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:13:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:13:57] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:13:59 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:13:59] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:14:01] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:14:01 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:14:01] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:14:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:14:01] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:14:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:14:01] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:14:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:14:01] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:14:04 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:14:04] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:14:06] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:14:06 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:14:06] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:14:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:14:06] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:14:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:14:06] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:14:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:14:06] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:14:09 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:14:09] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:14:11] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:14:11 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:14:11] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:14:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:14:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:14:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:   3%|‚ñé         | 3/92 [01:04<31:54, 21.51s/it]INFO: [2025-06-27 16:14:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:14:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:14:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:14:13 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:14:13] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:14:14] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:14:14 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:14:14] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:14:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:14:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:14:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:14:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:14:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:14:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:14:17 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:14:17] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:14:18] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:14:18 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:14:18] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:14:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:14:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:14:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:14:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:14:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:14:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:14:20 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:14:20] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:14:23] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:14:23 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:14:23] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:14:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:14:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:14:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:14:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:14:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:14:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:14:25 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:14:25] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:14:27] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:14:27 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:14:27] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:14:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:14:27] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:14:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:14:27] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:14:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:14:27] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:14:29 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:14:29] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:14:30] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:14:30 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:14:30] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:14:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:14:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:14:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:   4%|‚ñç         | 4/92 [01:23<30:29, 20.79s/it]INFO: [2025-06-27 16:14:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:14:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:14:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:14:32 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:14:32] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:14:33] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:14:33 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:14:33] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:14:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:14:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:14:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:14:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:14:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:14:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:14:35 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:14:35] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:14:37] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:14:37 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:14:37] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:14:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:14:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:14:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:14:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:14:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:14:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:14:38 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:14:38] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:14:39] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:14:39 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:14:39] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:14:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:14:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:14:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:14:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:14:40 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:14:40] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:14:41 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:14:41] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:14:42] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:14:42 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:14:42] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:14:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:14:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:14:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:14:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:14:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:14:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:14:43 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:14:43] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:14:46] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:14:46 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:14:46] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:14:46 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:14:46] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:14:46 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:   5%|‚ñå         | 5/92 [01:39<27:14, 18.79s/it]INFO: [2025-06-27 16:14:46] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:14:46 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:14:46] indra_gpt.chat_curate.chat_curate - Skipping evidence with no text for statement 3246604237187558: Evidence(source_api='biogrid',\n",
      "         pmid='25416956',\n",
      "         source_id='1043150',\n",
      "         annotations={\n",
      "                      \"biogrid_int_id\": \"1043150\",\n",
      "                      \"entrez_a\": \"7329\",\n",
      "                      \"entrez_b\": \"7341\",\n",
      "                      \"biogrid_a\": \"113177\",\n",
      "                      \"biogrid_b\": \"113188\",\n",
      "                      \"syst_name_a\": \"LA16c-358B7.1\",\n",
      "                      \"syst_name_b\": \"OK/SW-cl.43\",\n",
      "                      \"hgnc_a\": \"UBE2I\",\n",
      "                      \"hgnc_b\": \"SUMO1\",\n",
      "                      \"syn_a\": \"C358B7.1|P18|UBC9\",\n",
      "                      \"syn_b\": \"DAP1|GMP1|OFC10|PIC1|SENP2|SMT3|SMT3C|SMT3H3|UBL1\",\n",
      "                      \"exp_system\": \"Two-hybrid\",\n",
      "                      \"exp_system_type\": \"physical\",\n",
      "                      \"author\": \"Rolland T (2014)\",\n",
      "                      \"pmid\": \"25416956\",\n",
      "                      \"organism_a\": \"9606\",\n",
      "                      \"organism_b\": \"9606\",\n",
      "                      \"throughput\": \"High Throughput\",\n",
      "                      \"score\": null,\n",
      "                      \"modification\": null,\n",
      "                      \"phenotypes\": null,\n",
      "                      \"qualifications\": null,\n",
      "                      \"tags\": null,\n",
      "                      \"source_db\": \"BIOGRID\",\n",
      "                      \"agents\": {\n",
      "                       \"raw_text\": [\n",
      "                        \"LA16c-358B7.1\",\n",
      "                        \"OK/SW-cl.43\"\n",
      "                       ]\n",
      "                      },\n",
      "                      \"prior_uuids\": [\n",
      "                       \"de09ff43-7957-416e-acec-0e6952b8d0af\"\n",
      "                      ]\n",
      "                     },\n",
      "         text_refs={\n",
      "                    \"PMID\": \"25416956\"\n",
      "                   }\n",
      "         )\n",
      "\n",
      "\n",
      "INFO: [2025-06-27 16:14:46] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:14:48 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:14:48] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:14:50] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:14:50 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:14:50] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:14:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:14:50] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:14:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:14:50] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:14:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:14:50] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:14:52 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:14:52] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:14:54] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:14:54 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:14:54] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:14:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:14:54] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:14:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:14:54] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:14:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:14:54] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:14:57 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:14:57] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:14:59] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:14:59 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:14:59] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:14:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:14:59] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:14:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:14:59] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:14:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:14:59] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:15:01 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:15:01] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:15:03] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:15:03 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:15:03] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:15:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:15:03] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:15:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:   7%|‚ñã         | 6/92 [01:56<26:06, 18.21s/it]INFO: [2025-06-27 16:15:03] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:15:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:15:03] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:15:04 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:15:04] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:15:06] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:15:06 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:15:06] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:15:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:15:06] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:15:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:15:06] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:15:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:15:06] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:15:07 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:15:07] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:15:10] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:15:10 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:15:10] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:15:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:15:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:15:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:15:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:15:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:15:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:15:11 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:15:11] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:15:14] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:15:14 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:15:14] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:15:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:15:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:15:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:15:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:15:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:15:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:15:15 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:15:15] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:15:17] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:15:17 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:15:17] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:15:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:15:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:15:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:15:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:15:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:15:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:15:19 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:15:19] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:15:21] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:15:21 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:15:21] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:15:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:15:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:15:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:   8%|‚ñä         | 7/92 [02:14<25:42, 18.15s/it]INFO: [2025-06-27 16:15:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:15:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:15:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:15:22 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:15:22] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:15:24] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:15:24 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:15:24] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:15:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:15:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:15:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:15:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:15:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:15:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:15:25 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:15:25] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:15:27] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:15:27 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:15:27] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:15:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:15:27] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:15:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:15:27] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:15:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:15:27] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:15:28 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:15:28] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:15:30] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:15:30 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:15:30] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:15:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:15:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:15:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:15:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:15:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:15:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:15:31 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:15:31] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:15:33] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:15:33 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:15:33] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:15:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:15:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:15:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:15:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:15:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:15:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:15:35 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:15:35] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:15:37] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:15:37 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:15:37] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:15:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:15:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:15:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:   9%|‚ñä         | 8/92 [02:30<24:24, 17.43s/it]INFO: [2025-06-27 16:15:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:15:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:15:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:15:39 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:15:39] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:15:40] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:15:40 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:15:40] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:15:40 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:15:40] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:15:40 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:15:40] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:15:40 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:15:40] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:15:42 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:15:42] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:15:45] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:15:45 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:15:45] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:15:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:15:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:15:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:15:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:15:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:15:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:15:47 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:15:47] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:15:49] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:15:49 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:15:49] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:15:49 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:15:49] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:15:49 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:15:49] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:15:49 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:15:49] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:15:51 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:15:51] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:15:53] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:15:53 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:15:53] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:15:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:15:53] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:15:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:15:53] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:15:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:15:53] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:15:55 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:15:55] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:15:57] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:15:57 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:15:57] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:15:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:15:57] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:15:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  10%|‚ñâ         | 9/92 [02:50<25:29, 18.43s/it]INFO: [2025-06-27 16:15:57] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:15:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:15:57] indra_gpt.chat_curate.chat_curate - Skipping agent EMT() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "INFO: [2025-06-27 16:15:57] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:15:58 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:15:58] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:16:00] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:16:00 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:16:00] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:16:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:16:00] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:16:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:16:00] indra_gpt.chat_curate.chat_curate - Skipping agent EMT() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "INFO: [2025-06-27 16:16:00] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:16:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:16:00] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:16:01 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:16:01] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:16:03] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:16:03 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:16:03] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:16:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:16:03] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:16:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:16:03] indra_gpt.chat_curate.chat_curate - Skipping agent EMT() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "INFO: [2025-06-27 16:16:03] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:16:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:16:03] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:16:04 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:16:04] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:16:06] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:16:06 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:16:06] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:16:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:16:06] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:16:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:16:06] indra_gpt.chat_curate.chat_curate - Skipping agent EMT() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "INFO: [2025-06-27 16:16:06] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:16:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:16:06] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:16:07 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:16:07] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:16:08] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:16:08 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:16:08] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:16:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:16:08] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:16:08] indra_gpt.chat_curate.chat_curate - Skipping agent EMT() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "\u001b[92m16:16:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:16:08] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:16:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:16:08] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:16:09 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:16:09] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:16:11] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:16:11 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:16:11] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:16:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:16:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:16:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  11%|‚ñà         | 10/92 [03:04<23:19, 17.07s/it]INFO: [2025-06-27 16:16:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:16:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:16:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:16:13 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:16:13] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:16:15] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:16:15 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:16:15] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:16:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:16:15] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:16:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:16:15] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:16:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:16:15] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:16:17 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:16:17] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:16:19] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:16:19 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:16:19] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:16:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:16:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:16:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:16:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:16:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:16:20] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:16:22 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:16:22] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:16:23] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:16:23 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:16:23] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:16:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:16:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:16:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:16:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:16:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:16:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:16:25 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:16:25] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:16:27] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:16:27 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:16:27] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:16:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:16:27] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:16:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:16:27] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:16:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:16:27] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:16:29 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:16:29] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:16:31] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:16:31 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:16:31] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:16:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:16:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:16:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  12%|‚ñà‚ñè        | 11/92 [03:24<24:10, 17.91s/it]INFO: [2025-06-27 16:16:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:16:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:16:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:16:33 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:16:33] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:16:35] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:16:35 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:16:35] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:16:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:16:35] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:16:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:16:35] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:16:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:16:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:16:38 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:16:38] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:16:41] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:16:41 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:16:41] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:16:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:16:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:16:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:16:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:16:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:16:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:16:43 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:16:43] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:16:45] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:16:45 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:16:45] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:16:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:16:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:16:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:16:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:16:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:16:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:16:47 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:16:47] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:16:48] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:16:48 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:16:48] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:16:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:16:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:16:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:16:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:16:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:16:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:16:51 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:16:51] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:16:52] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:16:52 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:16:52] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:16:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:16:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:16:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  13%|‚ñà‚ñé        | 12/92 [03:45<25:08, 18.85s/it]INFO: [2025-06-27 16:16:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:16:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:16:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:16:53 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:16:53] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:16:54] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:16:54 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:16:54] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:16:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:16:54] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:16:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:16:54] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:16:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:16:54] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:16:55 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:16:55] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:16:57] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:16:57 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:16:57] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:16:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:16:57] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:16:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:16:57] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:16:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:16:57] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:16:57 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:16:57] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:16:59] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:16:59 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:16:59] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:16:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:16:59] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:16:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:16:59] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:16:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:16:59] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:17:00 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:17:00] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:17:03] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:17:03 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:17:03] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:17:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:17:03] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:17:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:17:03] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:17:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:17:03] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:17:04 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:17:04] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:17:06] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:17:06 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:17:06] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:17:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:17:06] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:17:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  14%|‚ñà‚ñç        | 13/92 [04:00<23:00, 17.48s/it]INFO: [2025-06-27 16:17:06] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:17:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:17:06] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:17:08 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:17:08] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:17:10] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:17:10 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:17:10] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:17:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:17:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:17:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:17:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:17:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:17:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:17:11 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:17:11] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:17:13] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:17:13 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:17:13] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:17:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:17:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:17:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:17:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:17:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:17:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:17:15 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:17:15] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:17:17] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:17:17 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:17:17] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:17:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:17:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:17:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:17:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:17:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:17:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:17:18 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:17:18] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:17:20] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:17:20 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:17:20] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:17:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:17:20] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:17:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:17:20] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:17:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:17:20] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:17:21 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:17:21] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:17:22] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:17:22 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:17:22] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:17:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:17:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:17:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  15%|‚ñà‚ñå        | 14/92 [04:15<22:07, 17.02s/it]INFO: [2025-06-27 16:17:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:17:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:17:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:17:23 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:17:23] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:17:26] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:17:26 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:17:26] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:17:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:17:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:17:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:17:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:17:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:17:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:17:26 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:17:26] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:17:28] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:17:28 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:17:28] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:17:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:17:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:17:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:17:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:17:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:17:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:17:29 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:17:29] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:17:31] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:17:31 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:17:31] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:17:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:17:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:17:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:17:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:17:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:17:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:17:32 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:17:32] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:17:35] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:17:35 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:17:35] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:17:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:17:35] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:17:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:17:35] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:17:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:17:35] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:17:35 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:17:35] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:17:37] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:17:37 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:17:37] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:17:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:17:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:17:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  16%|‚ñà‚ñã        | 15/92 [04:30<20:59, 16.35s/it]INFO: [2025-06-27 16:17:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:17:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:17:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:17:38 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:17:38] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:17:40] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:17:40 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:17:40] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:17:40 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:17:40] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:17:40 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:17:40] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:17:40 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:17:40] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:17:41 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:17:41] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:17:42] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:17:42 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:17:42] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:17:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:17:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:17:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:17:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:17:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:17:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:17:43 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:17:43] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:17:45] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:17:45 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:17:45] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:17:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:17:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:17:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:17:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:17:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:17:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:17:45 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:17:45] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:17:47] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:17:47 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:17:47] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:17:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:17:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:17:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:17:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:17:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:17:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:17:48 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:17:48] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:17:50] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:17:50 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:17:50] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:17:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:17:50] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:17:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  17%|‚ñà‚ñã        | 16/92 [04:43<19:09, 15.13s/it]INFO: [2025-06-27 16:17:50] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:17:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:17:50] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:17:52 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:17:52] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:17:53] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:17:53 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:17:53] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:17:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:17:53] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:17:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:17:53] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:17:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:17:54] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:17:56 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:17:56] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:17:58] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:17:58 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:17:58] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:17:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:17:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:17:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:17:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:17:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:17:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:18:00 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:18:00] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:18:01] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:18:01 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:18:01] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:18:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:18:01] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:18:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:18:01] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:18:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:18:01] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:18:04 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:18:04] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:18:06] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:18:06 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:18:06] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:18:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:18:06] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:18:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:18:06] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:18:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:18:06] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:18:08 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:18:08] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:18:10] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:18:10 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:18:10] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:18:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:18:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:18:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  18%|‚ñà‚ñä        | 17/92 [05:04<21:06, 16.88s/it]INFO: [2025-06-27 16:18:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:18:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:18:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:18:13 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:18:13] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:18:16] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:18:16 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:18:16] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:18:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:18:16] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:18:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:18:16] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:18:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:18:16] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:18:18 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:18:18] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:18:21] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:18:21 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:18:21] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:18:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:18:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:18:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:18:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:18:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:18:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:18:23 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:18:23] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:18:26] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:18:26 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:18:26] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:18:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:18:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:18:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:18:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:18:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:18:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:18:28 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:18:28] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:18:30] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:18:30 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:18:30] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:18:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:18:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:18:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:18:30] indra_gpt.chat_curate.chat_curate - Skipping evidence with no text for statement -7126418877828068: Evidence(source_api='biopax',\n",
      "         source_id='http://www.phosphosite.org/phosphosite.owl#Catalysis_31064601_796',\n",
      "         annotations={\n",
      "                      \"source_sub_id\": \"phosphositeplus\",\n",
      "                      \"agents\": {\n",
      "                       \"raw_text\": [\n",
      "                        null,\n",
      "                        null\n",
      "                       ]\n",
      "                      },\n",
      "                      \"prior_uuids\": [\n",
      "                       \"012cee21-a73d-479d-bad9-cdd5cf5df0f7\"\n",
      "                      ]\n",
      "                     },\n",
      "         epistemics={\n",
      "                     \"direct\": true\n",
      "                    }\n",
      "         )\n",
      "\n",
      "\n",
      "Curating statements with chat curation:  20%|‚ñà‚ñâ        | 18/92 [05:23<21:46, 17.66s/it]INFO: [2025-06-27 16:18:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:18:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:18:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:18:32 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:18:32] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:18:34] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:18:34 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:18:34] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:18:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:18:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:18:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:18:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:18:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:18:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:18:37 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:18:37] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:18:39] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:18:39 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:18:39] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:18:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:18:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:18:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:18:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:18:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:18:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:18:41 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:18:41] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:18:42] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:18:42 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:18:42] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:18:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:18:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:18:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:18:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:18:43 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:18:43] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:18:45 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:18:45] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:18:47] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:18:47 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:18:47] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:18:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:18:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:18:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:18:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:18:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:18:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:18:49 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:18:49] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:18:51] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:18:51 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:18:51] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:18:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:18:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:18:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  21%|‚ñà‚ñà        | 19/92 [05:44<22:32, 18.53s/it]INFO: [2025-06-27 16:18:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:18:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:18:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:18:53 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:18:53] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:18:54] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:18:54 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:18:54] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:18:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:18:54] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:18:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:18:54] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:18:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:18:54] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:18:57 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:18:57] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:18:58] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:18:58 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:18:58] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:18:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:18:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:18:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:18:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:18:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:18:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:19:00 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:19:00] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:19:02] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:19:02 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:19:02] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:19:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:19:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:19:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:19:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:19:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:19:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:19:04 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:19:04] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:19:07] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:19:07 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:19:07] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:19:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:19:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:19:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:19:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:19:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:19:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:19:09 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:19:09] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:19:11] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:19:11 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:19:11] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:19:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:19:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:19:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  22%|‚ñà‚ñà‚ñè       | 20/92 [06:04<22:47, 19.00s/it]INFO: [2025-06-27 16:19:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:19:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:19:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:19:14 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:19:14] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:19:16] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:19:16 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:19:16] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:19:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:19:16] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:19:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:19:16] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:19:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:19:16] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:19:19 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:19:19] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:19:21] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:19:21 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:19:21] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:19:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:19:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:19:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:19:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:19:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:19:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:19:24 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:19:24] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:19:26] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:19:26 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:19:26] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:19:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:19:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:19:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:19:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:19:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:19:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:19:29 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:19:29] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:19:31] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:19:31 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:19:31] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:19:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:19:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:19:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:19:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:19:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:19:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:19:34 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:19:34] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:19:37] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:19:37 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:19:37] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:19:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:19:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:19:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  23%|‚ñà‚ñà‚ñé       | 21/92 [06:30<25:04, 21.19s/it]INFO: [2025-06-27 16:19:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:19:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:19:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:19:39 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:19:39] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:19:41] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:19:41 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:19:41] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:19:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:19:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:19:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:19:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:19:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:19:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:19:43 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:19:43] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:19:45] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:19:45 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:19:45] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:19:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:19:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:19:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:19:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:19:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:19:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:19:47 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:19:47] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:19:49] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:19:49 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:19:49] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:19:49 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:19:49] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:19:49 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:19:49] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:19:49 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:19:49] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:19:51 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:19:51] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:19:53] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:19:53 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:19:53] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:19:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:19:53] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:19:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:19:53] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:19:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:19:53] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:19:55 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:19:55] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:19:57] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:19:57 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:19:57] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:19:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:19:57] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:19:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  24%|‚ñà‚ñà‚ñç       | 22/92 [06:50<24:13, 20.77s/it]INFO: [2025-06-27 16:19:57] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:19:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:19:57] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:19:59 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:19:59] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:20:00] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:20:00 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:20:00] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:20:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:20:00] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:20:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:20:00] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:20:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:20:00] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:20:02 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:20:02] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:20:04] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:20:04 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:20:04] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:20:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:20:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:20:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:20:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:20:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:20:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:20:06 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:20:06] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:20:08] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:20:08 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:20:08] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:20:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:20:08] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:20:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:20:08] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:20:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:20:08] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:20:10 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:20:10] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:20:11] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:20:11 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:20:11] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:20:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:20:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:20:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:20:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:20:12 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:20:12] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:20:14 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:20:14] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:20:15] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:20:15 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:20:15] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:20:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:20:15] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:20:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  25%|‚ñà‚ñà‚ñå       | 23/92 [07:08<22:55, 19.94s/it]INFO: [2025-06-27 16:20:15] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:20:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:20:15] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:20:17 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:20:17] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:20:19] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:20:19 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:20:19] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:20:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:20:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:20:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:20:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:20:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:20:19] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:20:21 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:20:21] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:20:23] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:20:23 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:20:23] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:20:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:20:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:20:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:20:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:20:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:20:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:20:25 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:20:25] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:20:26] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:20:26 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:20:26] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:20:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:20:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:20:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:20:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:20:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:20:27] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:20:28 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:20:28] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:20:31] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:20:31 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:20:31] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:20:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:20:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:20:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:20:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:20:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:20:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:20:33 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:20:33] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:20:35] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:20:35 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:20:35] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:20:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:20:35] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:20:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  26%|‚ñà‚ñà‚ñå       | 24/92 [07:28<22:38, 19.98s/it]INFO: [2025-06-27 16:20:35] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:20:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:20:35] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:20:37 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:20:37] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:20:39] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:20:39 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:20:39] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:20:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:20:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:20:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:20:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:20:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:20:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:20:41 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:20:41] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:20:44] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:20:44 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:20:44] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:20:44 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:20:44] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:20:44 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:20:44] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:20:44 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:20:44] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:20:46 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:20:46] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:20:48] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:20:48 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:20:48] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:20:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:20:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:20:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:20:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:20:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:20:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:20:50 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:20:50] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:20:53] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:20:53 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:20:53] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:20:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:20:53] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:20:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:20:53] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:20:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:20:53] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:20:55 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:20:55] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:20:57] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:20:57 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:20:57] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:20:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:20:57] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:20:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  27%|‚ñà‚ñà‚ñã       | 25/92 [07:51<23:14, 20.81s/it]INFO: [2025-06-27 16:20:57] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:20:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:20:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:21:00 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:21:00] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:21:01] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:21:01 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:21:01] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:21:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:21:01] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:21:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:21:01] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:21:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:21:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:21:04 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:21:04] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:21:05] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:21:05 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:21:05] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:21:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:21:05] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:21:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:21:05] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:21:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:21:05] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:21:07 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:21:07] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:21:10] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:21:10 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:21:10] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:21:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:21:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:21:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:21:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:21:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:21:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:21:12 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:21:12] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:21:15] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:21:15 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:21:15] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:21:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:21:15] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:21:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:21:15] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:21:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:21:15] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:21:17 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:21:17] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:21:20] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:21:20 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:21:20] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:21:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:21:20] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:21:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  28%|‚ñà‚ñà‚ñä       | 26/92 [08:13<23:23, 21.26s/it]INFO: [2025-06-27 16:21:20] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:21:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:21:20] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:21:22 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:21:22] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:21:24] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:21:24 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:21:24] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:21:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:21:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:21:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:21:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:21:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:21:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:21:26 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:21:26] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:21:28] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:21:28 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:21:28] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:21:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:21:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:21:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:21:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:21:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:21:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:21:30 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:21:30] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:21:33] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:21:33 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:21:33] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:21:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:21:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:21:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:21:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:21:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:21:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:21:35 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:21:35] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:21:37] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:21:37 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:21:37] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:21:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:21:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:21:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:21:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:21:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:21:38] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:21:40 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:21:40] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:21:42] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:21:42 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:21:42] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:21:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:21:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:21:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  29%|‚ñà‚ñà‚ñâ       | 27/92 [08:35<23:15, 21.47s/it]INFO: [2025-06-27 16:21:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:21:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:21:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:21:43 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:21:43] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:21:45] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:21:45 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:21:45] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:21:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:21:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:21:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:21:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:21:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:21:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:21:46 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:21:46] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:21:48] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:21:48 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:21:48] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:21:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:21:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:21:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:21:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:21:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:21:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:21:49 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:21:49] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:21:52] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:21:52 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:21:52] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:21:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:21:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:21:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:21:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:21:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:21:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:21:53 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:21:53] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:21:55] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:21:55 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:21:55] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:21:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:21:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:21:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:21:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:21:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:21:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:21:56 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:21:56] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:21:59] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:21:59 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:21:59] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:21:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:21:59] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:21:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  30%|‚ñà‚ñà‚ñà       | 28/92 [08:52<21:23, 20.06s/it]INFO: [2025-06-27 16:21:59] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:21:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:21:59] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:22:01 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:22:01] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:22:03] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:22:03 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:22:03] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:22:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:22:03] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:22:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:22:03] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:22:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:22:03] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:22:05 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:22:05] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:22:06] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:22:06 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:22:06] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:22:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:22:06] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:22:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:22:06] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:22:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:22:06] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:22:08 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:22:08] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:22:10] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:22:10 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:22:10] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:22:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:22:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:22:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:22:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:22:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:22:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:22:12 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:22:12] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:22:14] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:22:14 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:22:14] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:22:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:22:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:22:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:22:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:22:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:22:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:22:16 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:22:16] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:22:18] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:22:18 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:22:18] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:22:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:22:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:22:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  32%|‚ñà‚ñà‚ñà‚ñè      | 29/92 [09:11<20:51, 19.87s/it]INFO: [2025-06-27 16:22:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:22:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:22:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:22:20 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:22:20] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:22:22] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:22:22 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:22:22] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:22:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:22:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:22:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:22:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:22:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:22:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:22:24 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:22:24] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:22:26] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:22:26 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:22:26] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:22:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:22:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:22:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:22:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:22:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:22:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:22:29 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:22:29] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:22:31] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:22:31 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:22:31] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:22:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:22:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:22:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:22:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:22:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:22:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:22:33 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:22:33] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:22:34] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:22:34 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:22:34] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:22:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:22:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:22:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:22:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:22:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:22:35] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:22:37 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:22:37] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:22:38] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:22:38 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:22:38] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:22:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:22:38] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:22:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  33%|‚ñà‚ñà‚ñà‚ñé      | 30/92 [09:31<20:41, 20.03s/it]INFO: [2025-06-27 16:22:38] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:22:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:22:38] indra_gpt.chat_curate.chat_curate - Skipping agent NP() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "INFO: [2025-06-27 16:22:38] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:22:39 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:22:39] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:22:41] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:22:41 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:22:41] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:22:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:22:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:22:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:22:41] indra_gpt.chat_curate.chat_curate - Skipping agent NP() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "INFO: [2025-06-27 16:22:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:22:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:22:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:22:42 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:22:42] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:22:44] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:22:44 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:22:44] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:22:44 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:22:44] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:22:44 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:22:44] indra_gpt.chat_curate.chat_curate - Skipping agent NP() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "INFO: [2025-06-27 16:22:44] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:22:44 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:22:44] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:22:45 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:22:45] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:22:46] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:22:46 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:22:46] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:22:46 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:22:46] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:22:46 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:22:46] indra_gpt.chat_curate.chat_curate - Skipping agent NP() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "INFO: [2025-06-27 16:22:46] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:22:46 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:22:46] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:22:47 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:22:47] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:22:51] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:22:51 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:22:51] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:22:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:22:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:22:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:22:51] indra_gpt.chat_curate.chat_curate - Skipping agent NP() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "INFO: [2025-06-27 16:22:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:22:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:22:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:22:52 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:22:52] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:22:54] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:22:54 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:22:54] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:22:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:22:54] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:22:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  34%|‚ñà‚ñà‚ñà‚ñé      | 31/92 [09:47<19:00, 18.70s/it]INFO: [2025-06-27 16:22:54] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:22:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:22:54] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:22:56 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:22:56] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:22:58] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:22:58 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:22:58] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:22:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:22:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:22:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:22:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:22:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:22:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:23:00 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:23:00] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:23:02] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:23:02 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:23:02] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:23:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:23:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:23:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:23:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:23:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:23:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:23:04 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:23:04] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:23:06] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:23:06 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:23:06] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:23:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:23:06] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:23:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:23:06] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:23:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:23:06] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:23:08 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:23:08] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:23:09] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:23:09 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:23:09] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:23:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:23:09] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:23:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:23:09] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:23:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:23:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:23:11 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:23:11] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:23:14] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:23:14 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:23:14] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:23:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:23:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:23:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  35%|‚ñà‚ñà‚ñà‚ñç      | 32/92 [10:07<18:58, 18.98s/it]INFO: [2025-06-27 16:23:14] indra_gpt.chat_curate.chat_curate - Skipping evidence with no text for statement 5895544448831150: Evidence(source_api='hprd',\n",
      "         pmid='11792840',\n",
      "         source_id='http://hprd.org/interactions?hprd_id=04992&isoform_id=04992_1&isoform_name=Isoform_1',\n",
      "         annotations={\n",
      "                      \"evidence\": [\n",
      "                       \"in vitro\",\n",
      "                       \"yeast 2-hybrid\"\n",
      "                      ],\n",
      "                      \"agents\": {\n",
      "                       \"raw_text\": [\n",
      "                        null,\n",
      "                        null\n",
      "                       ]\n",
      "                      },\n",
      "                      \"prior_uuids\": [\n",
      "                       \"fd7172f1-a5b9-41c6-831a-53e68d6db1c0\"\n",
      "                      ]\n",
      "                     },\n",
      "         text_refs={\n",
      "                    \"PMID\": \"11792840\"\n",
      "                   }\n",
      "         )\n",
      "\n",
      "\n",
      "INFO: [2025-06-27 16:23:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:23:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:23:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:23:16 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:23:16] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:23:18] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:23:18 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:23:18] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:23:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:23:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:23:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:23:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:23:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:23:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:23:20 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:23:20] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:23:22] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:23:22 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:23:22] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:23:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:23:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:23:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:23:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:23:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:23:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:23:24 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:23:24] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:23:26] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:23:26 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:23:26] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:23:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:23:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:23:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:23:26] indra_gpt.chat_curate.chat_curate - Skipping evidence with no text for statement 5895544448831150: Evidence(source_api='biogrid',\n",
      "         pmid='11792840',\n",
      "         source_id='280515',\n",
      "         annotations={\n",
      "                      \"biogrid_int_id\": \"280515\",\n",
      "                      \"entrez_a\": \"367\",\n",
      "                      \"entrez_b\": \"6840\",\n",
      "                      \"biogrid_a\": \"106862\",\n",
      "                      \"biogrid_b\": \"112707\",\n",
      "                      \"syst_name_a\": \"RP11-383C12.1\",\n",
      "                      \"syst_name_b\": \"RP11-534G20.1\",\n",
      "                      \"hgnc_a\": \"AR\",\n",
      "                      \"hgnc_b\": \"SVIL\",\n",
      "                      \"syn_a\": \"AIS|DHTR|HUMARA|HYSP1|KD|NR3C4|SBMA|SMAX1|TFM\",\n",
      "                      \"syn_b\": null,\n",
      "                      \"exp_system\": \"Two-hybrid\",\n",
      "                      \"exp_system_type\": \"physical\",\n",
      "                      \"author\": \"Ting HJ (2002)\",\n",
      "                      \"pmid\": \"11792840\",\n",
      "                      \"organism_a\": \"9606\",\n",
      "                      \"organism_b\": \"9606\",\n",
      "                      \"throughput\": \"Low Throughput\",\n",
      "                      \"score\": null,\n",
      "                      \"modification\": null,\n",
      "                      \"phenotypes\": null,\n",
      "                      \"qualifications\": null,\n",
      "                      \"tags\": null,\n",
      "                      \"source_db\": \"BIOGRID\",\n",
      "                      \"agents\": {\n",
      "                       \"raw_text\": [\n",
      "                        \"RP11-383C12.1\",\n",
      "                        \"RP11-534G20.1\"\n",
      "                       ]\n",
      "                      },\n",
      "                      \"prior_uuids\": [\n",
      "                       \"acaad1cf-653a-49f8-8faf-d1087e17cca5\"\n",
      "                      ]\n",
      "                     },\n",
      "         text_refs={\n",
      "                    \"PMID\": \"11792840\"\n",
      "                   }\n",
      "         )\n",
      "\n",
      "\n",
      "Curating statements with chat curation:  36%|‚ñà‚ñà‚ñà‚ñå      | 33/92 [10:19<16:41, 16.97s/it]INFO: [2025-06-27 16:23:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:23:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:23:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:23:27 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:23:27] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:23:29] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:23:29 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:23:29] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:23:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:23:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:23:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:23:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:23:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:23:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:23:31 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:23:31] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:23:33] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:23:33 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:23:33] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:23:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:23:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:23:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:23:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:23:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:23:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:23:34 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:23:34] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:23:36] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:23:36 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:23:36] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:23:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:23:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:23:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:23:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:23:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:23:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:23:37 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:23:37] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:23:39] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:23:39 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:23:39] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:23:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:23:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:23:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:23:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:23:40 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:23:40] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:23:41 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:23:41] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:23:42] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:23:42 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:23:42] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:23:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:23:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:23:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  37%|‚ñà‚ñà‚ñà‚ñã      | 34/92 [10:35<16:12, 16.78s/it]INFO: [2025-06-27 16:23:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:23:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:23:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:23:44 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:23:44] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:23:46] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:23:46 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:23:46] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:23:46 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:23:46] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:23:46 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:23:46] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:23:46 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:23:46] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:23:48 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:23:48] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:23:49] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:23:49 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:23:49] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:23:49 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:23:49] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:23:49 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:23:49] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:23:49 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:23:49] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:23:51 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:23:51] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:23:53] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:23:53 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:23:53] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:23:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:23:53] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:23:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:23:53] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:23:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:23:53] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:23:55 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:23:55] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:23:58] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:23:58 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:23:58] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:23:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:23:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:23:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:23:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:23:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:23:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:24:00 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:24:00] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:24:01] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:24:01 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:24:01] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:24:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:24:01] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:24:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  38%|‚ñà‚ñà‚ñà‚ñä      | 35/92 [10:54<16:28, 17.35s/it]INFO: [2025-06-27 16:24:01] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:24:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:24:01] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:24:03 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:24:03] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:24:05] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:24:05 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:24:05] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:24:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:24:05] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:24:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:24:05] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:24:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:24:05] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:24:07 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:24:07] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:24:09] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:24:09 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:24:09] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:24:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:24:09] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:24:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:24:09] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:24:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:24:09] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:24:11 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:24:11] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:24:12] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:24:12 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:24:12] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:24:12 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:24:12] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:24:12 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:24:12] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:24:12 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:24:12] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:24:14 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:24:14] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:24:16] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:24:16 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:24:16] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:24:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:24:16] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:24:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:24:16] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:24:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:24:16] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:24:19 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:24:19] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:24:21] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:24:21 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:24:21] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:24:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:24:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:24:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  39%|‚ñà‚ñà‚ñà‚ñâ      | 36/92 [11:14<16:50, 18.04s/it]INFO: [2025-06-27 16:24:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:24:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:24:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:24:22 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:24:22] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:24:23] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:24:23 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:24:23] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:24:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:24:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:24:23 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:24:23] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:24:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:24:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:24:25 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:24:25] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:24:27] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:24:27 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:24:27] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:24:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:24:27] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:24:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:24:27] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:24:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:24:27] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:24:28 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:24:28] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:24:30] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:24:30 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:24:30] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:24:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:24:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:24:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:24:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:24:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:24:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:24:31 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:24:31] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:24:33] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:24:33 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:24:33] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:24:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:24:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:24:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:24:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:24:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:24:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:24:35 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:24:35] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:24:37] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:24:37 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:24:37] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:24:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:24:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:24:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  40%|‚ñà‚ñà‚ñà‚ñà      | 37/92 [11:30<16:11, 17.67s/it]INFO: [2025-06-27 16:24:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:24:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:24:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:24:39 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:24:39] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:24:42] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:24:42 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:24:42] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:24:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:24:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:24:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:24:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:24:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:24:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:24:44 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:24:44] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:24:46] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:24:46 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:24:46] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:24:46 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:24:46] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:24:46 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:24:46] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:24:46 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:24:46] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:24:48 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:24:48] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:24:51] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:24:51 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:24:51] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:24:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:24:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:24:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:24:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:24:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:24:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:24:53 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:24:53] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:24:55] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:24:55 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:24:55] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:24:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:24:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:24:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:24:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:24:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:24:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:24:57 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:24:57] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:24:58] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:24:58 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:24:58] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:24:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:24:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:24:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 38/92 [11:51<16:47, 18.66s/it]INFO: [2025-06-27 16:24:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:24:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:24:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:25:00 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:25:00] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:25:02] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:25:02 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:25:02] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:25:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:25:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:25:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:25:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:25:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:25:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:25:04 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:25:04] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:25:05] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:25:05 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:25:05] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:25:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:25:05] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:25:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:25:05] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:25:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:25:05] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:25:07 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:25:07] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:25:09] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:25:09 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:25:09] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:25:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:25:09] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:25:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:25:09] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:25:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:25:09] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:25:11 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:25:11] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:25:13] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:25:13 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:25:13] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:25:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:25:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:25:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:25:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:25:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:25:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:25:15 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:25:15] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:25:17] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:25:17 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:25:17] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:25:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:25:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:25:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 39/92 [12:10<16:30, 18.69s/it]INFO: [2025-06-27 16:25:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:25:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:25:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:25:19 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:25:19] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:25:21] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:25:21 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:25:21] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:25:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:25:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:25:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:25:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:25:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:25:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:25:23 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:25:23] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:25:25] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:25:25 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:25:25] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:25:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:25:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:25:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:25:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:25:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:25:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:25:27 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:25:27] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:25:30] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:25:30 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:25:30] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:25:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:25:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:25:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:25:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:25:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:25:31] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:25:32 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:25:32] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:25:34] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:25:34 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:25:34] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:25:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:25:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:25:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:25:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:25:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:25:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:25:36 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:25:36] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:25:38] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:25:38 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:25:38] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:25:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:25:38] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:25:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 40/92 [12:31<16:54, 19.50s/it]INFO: [2025-06-27 16:25:38] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:25:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:25:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:25:41 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:25:41] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:25:42] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:25:42 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:25:42] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:25:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:25:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:25:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:25:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:25:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:25:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:25:44 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:25:44] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:25:46] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:25:46 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:25:46] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:25:46 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:25:46] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:25:46 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:25:46] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:25:46 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:25:46] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:25:48 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:25:48] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:25:50] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:25:50 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:25:50] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:25:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:25:50] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:25:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:25:50] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:25:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:25:50] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:25:52 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:25:52] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:25:54] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:25:54 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:25:54] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:25:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:25:54] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:25:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:25:54] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:25:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:25:54] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:25:56 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:25:56] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:25:59] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:25:59 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:25:59] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:25:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:25:59] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:25:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 41/92 [12:52<16:46, 19.73s/it]INFO: [2025-06-27 16:25:59] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:25:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:25:59] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:26:01 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:26:01] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:26:02] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:26:02 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:26:02] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:26:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:26:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:26:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:26:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:26:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:26:03] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:26:05 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:26:05] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:26:07] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:26:07 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:26:07] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:26:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:26:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:26:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:26:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:26:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:26:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:26:09 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:26:09] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:26:11] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:26:11 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:26:11] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:26:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:26:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:26:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:26:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:26:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:26:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:26:13 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:26:13] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:26:14] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:26:14 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:26:14] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:26:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:26:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:26:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:26:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:26:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:26:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:26:16 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:26:16] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:26:18] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:26:18 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:26:18] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:26:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:26:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:26:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 42/92 [13:11<16:17, 19.56s/it]INFO: [2025-06-27 16:26:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:26:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:26:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:26:20 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:26:20] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:26:22] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:26:22 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:26:22] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:26:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:26:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:26:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:26:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:26:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:26:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:26:24 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:26:24] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:26:26] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:26:26 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:26:26] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:26:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:26:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:26:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:26:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:26:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:26:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:26:28 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:26:28] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:26:30] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:26:30 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:26:30] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:26:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:26:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:26:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:26:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:26:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:26:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:26:32 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:26:32] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:26:34] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:26:34 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:26:34] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:26:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:26:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:26:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:26:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:26:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:26:35] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:26:37 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:26:37] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:26:39] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:26:39 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:26:39] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:26:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:26:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:26:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 43/92 [13:32<16:16, 19.93s/it]INFO: [2025-06-27 16:26:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:26:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:26:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:26:41 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:26:41] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:26:42] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:26:42 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:26:42] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:26:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:26:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:26:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:26:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:26:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:26:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:26:44 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:26:44] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:26:46] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:26:46 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:26:46] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:26:46 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:26:46] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:26:46 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:26:46] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:26:46 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:26:46] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:26:48 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:26:48] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:26:51] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:26:51 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:26:51] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:26:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:26:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:26:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:26:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:26:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:26:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:26:53 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:26:53] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:26:55] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:26:55 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:26:55] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:26:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:26:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:26:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:26:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:26:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:26:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:26:57 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:26:57] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:27:00] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:27:00 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:27:00] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:27:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:27:00] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:27:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 44/92 [13:53<16:13, 20.28s/it]INFO: [2025-06-27 16:27:00] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:27:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:27:00] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:27:02 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:27:02] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:27:03] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:27:03 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:27:03] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:27:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:27:03] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:27:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:27:03] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:27:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:27:04] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:27:06 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:27:06] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:27:07] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:27:07 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:27:07] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:27:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:27:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:27:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:27:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:27:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:27:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:27:09 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:27:09] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:27:11] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:27:11 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:27:11] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:27:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:27:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:27:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:27:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:27:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:27:11] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:27:13 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:27:13] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:27:15] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:27:15 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:27:15] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:27:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:27:15] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:27:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:27:15] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:27:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:27:15] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:27:17 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:27:17] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:27:18] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:27:18 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:27:18] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:27:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:27:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:27:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 45/92 [14:11<15:26, 19.72s/it]INFO: [2025-06-27 16:27:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:27:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:27:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:27:20 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:27:20] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:27:21] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:27:21 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:27:21] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:27:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:27:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:27:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:27:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:27:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:27:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:27:22 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:27:22] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:27:24] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:27:24 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:27:24] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:27:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:27:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:27:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:27:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:27:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:27:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:27:25 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:27:25] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:27:27] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:27:27 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:27:27] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:27:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:27:27] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:27:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:27:27] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:27:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:27:27] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:27:29 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:27:29] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:27:30] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:27:30 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:27:30] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:27:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:27:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:27:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:27:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:27:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:27:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:27:32 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:27:32] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:27:33] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:27:33 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:27:33] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:27:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:27:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:27:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 46/92 [14:26<14:01, 18.29s/it]INFO: [2025-06-27 16:27:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:27:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:27:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:27:34 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:27:34] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:27:36] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:27:36 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:27:36] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:27:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:27:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:27:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:27:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:27:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:27:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:27:37 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:27:37] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:27:40] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:27:40 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:27:40] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:27:40 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:27:40] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:27:40 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:27:40] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:27:40 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:27:40] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:27:41 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:27:41] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:27:42] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:27:42 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:27:42] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:27:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:27:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:27:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:27:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:27:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:27:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:27:44 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:27:44] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:27:45] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:27:45 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:27:45] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:27:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:27:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:27:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:27:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:27:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:27:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:27:47 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:27:47] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:27:48] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:27:48 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:27:48] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:27:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:27:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:27:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 47/92 [14:41<12:56, 17.26s/it]INFO: [2025-06-27 16:27:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:27:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:27:48] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:27:50 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:27:50] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:27:52] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:27:52 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:27:52] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:27:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:27:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:27:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:27:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:27:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:27:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:27:54 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:27:54] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:27:55] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:27:55 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:27:55] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:27:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:27:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:27:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:27:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:27:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:27:56] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:27:58 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:27:58] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:27:59] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:27:59 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:27:59] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:27:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:27:59] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:27:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:27:59] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:27:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:27:59] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:28:01 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:28:01] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:28:02] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:28:02 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:28:02] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:28:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:28:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:28:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:28:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:28:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:28:03] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:28:05 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:28:05] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:28:06] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:28:06 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:28:06] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:28:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:28:06] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:28:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 48/92 [14:59<12:51, 17.54s/it]INFO: [2025-06-27 16:28:06] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:28:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:28:06] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:28:08 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:28:08] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:28:10] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:28:10 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:28:10] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:28:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:28:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:28:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:28:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:28:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:28:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:28:12 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:28:12] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:28:13] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:28:13 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:28:13] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:28:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:28:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:28:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:28:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:28:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:28:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:28:15 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:28:15] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:28:17] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:28:17 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:28:17] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:28:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:28:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:28:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:28:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:28:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:28:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:28:19 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:28:19] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:28:21] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:28:21 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:28:21] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:28:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:28:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:28:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:28:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:28:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:28:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:28:23 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:28:23] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:28:25] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:28:25 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:28:25] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:28:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:28:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:28:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 49/92 [15:18<12:50, 17.91s/it]INFO: [2025-06-27 16:28:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:28:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:28:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:28:27 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:28:27] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:28:29] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:28:29 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:28:29] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:28:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:28:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:28:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:28:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:28:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:28:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:28:31 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:28:31] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:28:33] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:28:33 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:28:33] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:28:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:28:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:28:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:28:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:28:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:28:33] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:28:35 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:28:35] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:28:37] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:28:37 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:28:37] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:28:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:28:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:28:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:28:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:28:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:28:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:28:39 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:28:39] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:28:41] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:28:41 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:28:41] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:28:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:28:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:28:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 50/92 [15:34<12:04, 17.25s/it]INFO: [2025-06-27 16:28:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:28:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:28:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:28:43 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:28:43] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:28:45] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:28:45 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:28:45] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:28:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:28:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:28:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:28:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:28:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:28:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:28:47 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:28:47] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:28:49] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:28:49 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:28:49] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:28:49 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:28:49] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:28:49 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:28:49] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:28:49 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:28:49] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:28:51 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:28:51] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:28:52] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:28:52 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:28:52] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:28:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:28:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:28:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:28:52] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:28:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:28:53] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:28:55 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:28:55] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:28:56] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:28:56 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:28:56] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:28:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:28:56] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:28:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 51/92 [15:49<11:28, 16.79s/it]INFO: [2025-06-27 16:28:56] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:28:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:28:56] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:28:59 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:28:59] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:29:01] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:29:01 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:29:01] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:29:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:29:01] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:29:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:29:01] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:29:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:29:01] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:29:03 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:29:03] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:29:05] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:29:05 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:29:05] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:29:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:29:05] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:29:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:29:05] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:29:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:29:05] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:29:07 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:29:07] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:29:09] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:29:09 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:29:09] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:29:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:29:09] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:29:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:29:09] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:29:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:29:09] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:29:11 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:29:11] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:29:14] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:29:14 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:29:14] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:29:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:29:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:29:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 52/92 [16:07<11:17, 16.95s/it]INFO: [2025-06-27 16:29:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:29:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:29:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:29:16 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:29:16] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:29:17] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:29:17 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:29:17] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:29:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:29:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:29:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:29:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:29:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:29:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:29:19 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:29:19] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:29:21] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:29:21 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:29:21] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:29:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:29:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:29:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:29:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:29:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:29:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:29:23 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:29:23] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:29:25] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:29:25 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:29:25] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:29:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:29:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:29:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:29:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:29:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:29:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:29:27 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:29:27] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:29:30] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:29:30 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:29:30] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:29:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:29:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:29:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 53/92 [16:23<10:47, 16.60s/it]INFO: [2025-06-27 16:29:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:29:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:29:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:29:30 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:29:30] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:29:32] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:29:32 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:29:32] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:29:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:29:32] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:29:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:29:32] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:29:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:29:32] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:29:32 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:29:32] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:29:34] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:29:34 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:29:34] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:29:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:29:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:29:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:29:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:29:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:29:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:29:34 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:29:34] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:29:36] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:29:36 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:29:36] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:29:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:29:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:29:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:29:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:29:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:29:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:29:37 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:29:37] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:29:39] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:29:39 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:29:39] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:29:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:29:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:29:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 54/92 [16:32<09:07, 14.41s/it]INFO: [2025-06-27 16:29:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:29:39 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:29:39] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:29:41 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:29:41] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:29:42] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:29:42 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:29:42] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:29:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:29:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:29:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:29:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:29:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:29:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:29:45 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:29:45] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:29:47] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:29:47 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:29:47] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:29:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:29:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:29:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:29:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:29:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:29:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:29:49 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:29:49] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:29:51] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:29:51 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:29:51] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:29:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:29:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:29:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:29:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:29:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:29:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:29:53 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:29:53] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:29:55] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:29:55 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:29:55] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:29:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:29:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:29:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 55/92 [16:48<09:08, 14.84s/it]INFO: [2025-06-27 16:29:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:29:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:29:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:29:57 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:29:57] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:29:58] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:29:58 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:29:58] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:29:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:29:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:29:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:29:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:29:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:29:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:30:00 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:30:00] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:30:02] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:30:02 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:30:02] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:30:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:30:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:30:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:30:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:30:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:30:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:30:04 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:30:04] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:30:05] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:30:05 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:30:05] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:30:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:30:05] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:30:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 56/92 [16:58<08:05, 13.50s/it]INFO: [2025-06-27 16:30:05] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:30:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:30:05] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:30:07 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:30:07] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:30:09] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:30:09 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:30:09] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:30:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:30:09] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:30:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:30:09] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:30:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:30:09] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:30:11 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:30:11] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:30:13] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:30:13 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:30:13] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:30:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:30:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:30:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:30:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:30:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:30:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:30:15 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:30:15] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:30:18] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:30:18 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:30:18] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:30:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:30:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:30:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 57/92 [17:11<07:44, 13.26s/it]INFO: [2025-06-27 16:30:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:30:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:30:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:30:20 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:30:20] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:30:22] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:30:22 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:30:22] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:30:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:30:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:30:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:30:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:30:22 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:30:22] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:30:24 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:30:24] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:30:26] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:30:26 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:30:26] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:30:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:30:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:30:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:30:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:30:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:30:26] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:30:28 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:30:28] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:30:30] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:30:30 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:30:30] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:30:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:30:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:30:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 58/92 [17:23<07:24, 13.07s/it]INFO: [2025-06-27 16:30:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:30:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:30:30] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:30:32 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:30:32] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:30:34] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:30:34 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:30:34] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:30:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:30:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:30:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:30:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:30:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:30:34] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:30:36 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:30:36] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:30:38] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:30:38 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:30:38] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:30:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:30:38] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:30:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:30:38] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:30:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:30:38] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:30:40 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:30:40] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:30:42] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:30:42 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:30:42] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:30:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:30:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:30:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 59/92 [17:35<06:58, 12.67s/it]INFO: [2025-06-27 16:30:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:30:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:30:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:30:44 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:30:44] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:30:46] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:30:46 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:30:46] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:30:46 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:30:46] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:30:46 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:30:46] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:30:46 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:30:46] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:30:48 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:30:48] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:30:51] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:30:51 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:30:51] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:30:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:30:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:30:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:30:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:30:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:30:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:30:53 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:30:53] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:30:55] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:30:55 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:30:55] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:30:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:30:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:30:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 60/92 [17:48<06:49, 12.79s/it]INFO: [2025-06-27 16:30:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:30:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:30:55] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:30:57 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:30:57] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:30:59] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:30:59 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:30:59] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:30:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:30:59] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:30:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:30:59] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:30:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:30:59] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:31:01 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:31:01] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:31:03] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:31:03 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:31:03] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:31:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:31:03] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:31:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:31:03] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:31:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:31:03] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:31:05 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:31:05] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:31:07] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:31:07 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:31:07] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:31:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:31:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:31:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 61/92 [18:00<06:23, 12.38s/it]INFO: [2025-06-27 16:31:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:31:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:31:07] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:31:09 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:31:09] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:31:10] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:31:10 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:31:10] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:31:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:31:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:31:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:31:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:31:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:31:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:31:12 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:31:12] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:31:13] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:31:13 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:31:13] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:31:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:31:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:31:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:31:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:31:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:31:14] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:31:16 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:31:16] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:31:17] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:31:17 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:31:17] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:31:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:31:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:31:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 62/92 [18:10<05:56, 11.89s/it]INFO: [2025-06-27 16:31:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:31:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:31:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:31:19 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:31:19] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:31:21] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:31:21 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:31:21] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:31:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:31:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:31:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:31:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:31:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:31:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:31:23 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:31:23] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:31:24] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:31:24 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:31:24] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:31:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:31:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:31:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 63/92 [18:17<05:01, 10.41s/it]INFO: [2025-06-27 16:31:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:31:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:31:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:31:26 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:31:26] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:31:28] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:31:28 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:31:28] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:31:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:31:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:31:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:31:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:31:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:31:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:31:30 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:31:30] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:31:32] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:31:32 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:31:32] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:31:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:31:32] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:31:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 64/92 [18:25<04:29,  9.62s/it]INFO: [2025-06-27 16:31:32] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:31:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:31:32] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:31:34 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:31:34] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:31:36] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:31:36 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:31:36] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:31:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:31:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:31:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:31:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:31:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:31:36] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:31:38 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:31:38] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:31:42] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:31:42 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:31:42] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:31:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:31:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:31:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 65/92 [18:35<04:22,  9.72s/it]INFO: [2025-06-27 16:31:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:31:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:31:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:31:44 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:31:44] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:31:46] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:31:46 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:31:46] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:31:46 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:31:46] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:31:46 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:31:46] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:31:46 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:31:46] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:31:48 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:31:48] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:31:51] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:31:51 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:31:51] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:31:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:31:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:31:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 66/92 [18:44<04:05,  9.44s/it]INFO: [2025-06-27 16:31:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:31:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:31:51] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:31:51] indra_gpt.chat_curate.chat_curate - Skipping agent function() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "\u001b[92m16:31:52 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:31:52] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:31:54] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:31:54 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:31:54] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:31:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:31:54] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:31:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:31:54] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:31:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:31:54] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:31:54] indra_gpt.chat_curate.chat_curate - Skipping agent function() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "\u001b[92m16:31:55 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:31:55] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:31:57] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:31:57 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:31:57] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:31:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:31:57] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:31:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 67/92 [18:50<03:30,  8.42s/it]INFO: [2025-06-27 16:31:57] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:31:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:31:57] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:31:59 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:31:59] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:32:01] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:32:01 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:32:01] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:32:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:32:01] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:32:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:32:01] indra_gpt.chat_curate.chat_curate - Skipping evidence with no text for statement -6735076600090236: Evidence(source_api='biopax',\n",
      "         source_id='http://www.phosphosite.org/phosphosite.owl#Catalysis_25233804_604',\n",
      "         annotations={\n",
      "                      \"source_sub_id\": \"phosphositeplus\",\n",
      "                      \"agents\": {\n",
      "                       \"raw_text\": [\n",
      "                        null,\n",
      "                        null\n",
      "                       ]\n",
      "                      },\n",
      "                      \"prior_uuids\": [\n",
      "                       \"bc120eec-d5a9-4509-b2d7-7596d200281e\"\n",
      "                      ]\n",
      "                     },\n",
      "         epistemics={\n",
      "                     \"direct\": true\n",
      "                    }\n",
      "         )\n",
      "\n",
      "\n",
      "Curating statements with chat curation:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 68/92 [18:54<02:49,  7.07s/it]INFO: [2025-06-27 16:32:01] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:32:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:32:01] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:32:03 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:32:03] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:32:05] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:32:05 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:32:05] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:32:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:32:05] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:32:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:32:05] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:32:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:32:05] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:32:07 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:32:07] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:32:09] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:32:09 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:32:09] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:32:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:32:09] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:32:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 69/92 [19:02<02:50,  7.40s/it]INFO: [2025-06-27 16:32:09] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:32:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:32:09] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:32:11 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:32:11] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:32:13] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:32:13 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:32:13] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:32:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:32:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:32:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:32:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:32:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:32:13] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:32:15 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:32:15] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:32:17] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:32:17 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:32:17] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:32:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:32:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:32:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 70/92 [19:10<02:45,  7.51s/it]INFO: [2025-06-27 16:32:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:32:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:32:17] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:32:18 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:32:18] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:32:20] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:32:20 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:32:20] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:32:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:32:20] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:32:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:32:20] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:32:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:32:20] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:32:22 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:32:22] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:32:24] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:32:24 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:32:24] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:32:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:32:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:32:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 71/92 [19:17<02:34,  7.35s/it]INFO: [2025-06-27 16:32:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:32:24 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:32:24] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:32:26 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:32:26] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:32:27] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:32:28 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:32:28] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:32:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:32:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:32:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:32:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:32:28 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:32:28] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:32:30 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:32:30] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:32:32] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:32:32 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:32:32] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:32:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:32:32] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:32:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 72/92 [19:25<02:32,  7.63s/it]INFO: [2025-06-27 16:32:32] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:32:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:32:32] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:32:35 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:32:35] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:32:37] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:32:37 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:32:37] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:32:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:32:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:32:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:32:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:32:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:32:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:32:40 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:32:40] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:32:42] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:32:42 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:32:42] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:32:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:32:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:32:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 73/92 [19:35<02:39,  8.38s/it]INFO: [2025-06-27 16:32:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:32:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:32:42] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:32:44 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:32:44] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:32:47] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:32:47 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:32:47] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:32:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:32:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:32:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 74/92 [19:40<02:09,  7.22s/it]INFO: [2025-06-27 16:32:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:32:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:32:47] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:32:49 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:32:49] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:32:50] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:32:50 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:32:50] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:32:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:32:50] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 75/92 [19:43<01:44,  6.16s/it]\u001b[92m16:32:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:32:50] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:32:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:32:50] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:32:52 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:32:52] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:32:54] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:32:54 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:32:54] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:32:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:32:54] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:32:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 76/92 [19:47<01:26,  5.42s/it]INFO: [2025-06-27 16:32:54] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:32:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:32:54] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:32:56 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:32:56] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:32:58] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:32:58 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:32:58] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:32:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:32:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:32:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 77/92 [19:52<01:17,  5.14s/it]INFO: [2025-06-27 16:32:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:32:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:32:58] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:33:00 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:33:00] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:33:02] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:33:02 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:33:02] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:33:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:33:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:33:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 78/92 [19:55<01:05,  4.65s/it]INFO: [2025-06-27 16:33:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:33:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:33:02] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:33:03 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:33:03] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:33:05] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:33:05 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:33:05] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:33:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:33:05] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:33:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 79/92 [19:58<00:53,  4.13s/it]INFO: [2025-06-27 16:33:05] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:33:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:33:05] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:33:05] indra_gpt.chat_curate.chat_curate - Skipping agent cytokine() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "\u001b[92m16:33:08 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:33:08] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:33:10] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:33:10 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:33:10] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:33:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:33:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:33:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 80/92 [20:03<00:54,  4.53s/it]INFO: [2025-06-27 16:33:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:33:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:33:10] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:33:12 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:33:12] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:33:15] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:33:15 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:33:15] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:33:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:33:15] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:33:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 81/92 [20:08<00:49,  4.46s/it]INFO: [2025-06-27 16:33:15] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:33:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:33:15] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:33:17 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:33:17] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:33:18] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:33:18 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:33:18] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:33:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:33:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:33:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 82/92 [20:11<00:42,  4.26s/it]INFO: [2025-06-27 16:33:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:33:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:33:18] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:33:18] indra_gpt.chat_curate.chat_curate - Skipping agent cotransporter-2 inhibitor() with no grounding: sequence item 0: expected str instance, NoneType found\n",
      "\u001b[92m16:33:20 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:33:20] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:33:21] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:33:21 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:33:21] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:33:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:33:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:33:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 83/92 [20:14<00:33,  3.75s/it]INFO: [2025-06-27 16:33:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:33:21 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:33:21] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:33:23 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:33:23] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:33:25] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:33:25 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:33:25] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:33:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:33:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:33:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 84/92 [20:18<00:31,  3.92s/it]INFO: [2025-06-27 16:33:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:33:25 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:33:25] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:33:27 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:33:27] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:33:29] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:33:29 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:33:29] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:33:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:33:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:33:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 85/92 [20:22<00:26,  3.72s/it]INFO: [2025-06-27 16:33:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:33:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:33:29] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:33:31 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:33:31] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:33:32] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:33:32 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:33:32] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:33:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:33:32] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:33:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 86/92 [20:25<00:22,  3.72s/it]INFO: [2025-06-27 16:33:32] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:33:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:33:32] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:33:35 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:33:35] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:33:37] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:33:37 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:33:37] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:33:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:33:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:33:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 87/92 [20:30<00:20,  4.07s/it]INFO: [2025-06-27 16:33:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:33:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:33:37] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:33:39 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:33:39] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:33:41] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:33:41 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:33:41] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:33:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:33:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:33:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 88/92 [20:34<00:16,  4.06s/it]INFO: [2025-06-27 16:33:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:33:41 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:33:41] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:33:43 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:33:43] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:33:45] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:33:45 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:33:45] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:33:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:33:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:33:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 89/92 [20:38<00:11,  4.00s/it]INFO: [2025-06-27 16:33:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:33:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:33:45] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:33:47 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:33:47] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:33:50] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:33:50 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:33:50] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:33:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:33:50] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:33:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 90/92 [20:43<00:08,  4.16s/it]INFO: [2025-06-27 16:33:50] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:33:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:33:50] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:33:52 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:33:52] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:33:53] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:33:53 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:33:53] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:33:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:33:53] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:33:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 91/92 [20:46<00:04,  4.07s/it]INFO: [2025-06-27 16:33:53] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:33:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:33:53] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:33:56 - LiteLLM:INFO\u001b[0m: utils.py:2931 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:33:56] LiteLLM - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO: [2025-06-27 16:33:57] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m16:33:57 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n",
      "INFO: [2025-06-27 16:33:57] LiteLLM - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m16:33:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:33:57] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m16:33:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "Curating statements with chat curation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 92/92 [20:50<00:00, 13.60s/it]INFO: [2025-06-27 16:33:57] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\n",
      "\u001b[92m16:33:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO: [2025-06-27 16:33:57] LiteLLM - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n"
     ]
    }
   ],
   "source": [
    "statements = pickle.load(\n",
    "    open(RESULTS_DIR.joinpath(\"statements.pkl\"), \"rb\")\n",
    ")\n",
    "statements = statements\n",
    "\n",
    "for model in ['gpt-4o-mini', 'gpt-4o']:\n",
    "    llm_curations_binary = chat_curate_stmts(statements, \n",
    "                                    n_evidence_to_curate=5,\n",
    "                                    decision_threshold=0.5,\n",
    "                                    binary_classification=True,\n",
    "                                    #ignore_tags=['incorrect'],\n",
    "                                    n_fewshot_examples=0,\n",
    "                                    model=model)\n",
    "    llm_curations_multiclass = chat_curate_stmts(statements,\n",
    "                                    n_evidence_to_curate=5,\n",
    "                                    decision_threshold=0.5,\n",
    "                                    binary_classification=False,\n",
    "                                    ignore_tags=['incorrect'],\n",
    "                                    n_fewshot_examples=0,\n",
    "                                    model=model)\n",
    "\n",
    "    if not RESULTS_DIR.joinpath(model).exists():\n",
    "        RESULTS_DIR.joinpath(model).mkdir(parents=True)\n",
    "        \n",
    "    with open(RESULTS_DIR / model / \"chat_curation_binary_classification.json\", \"w\") as f:\n",
    "        json.dump(llm_curations_binary, f, indent=2)\n",
    "    with open(RESULTS_DIR / model / \"chat_curation_multiclass_classification.json\", \"w\") as f:\n",
    "        json.dump(llm_curations_multiclass, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23533fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing LLM curations:   0%|          | 0/92 [00:00<?, ?it/s]INFO: [2025-06-27 16:33:57] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-35882458128194165/5038432318346639636\n",
      "INFO: [2025-06-27 16:33:57] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:33:57] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:33:58] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:33:58] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-35882458128194165/-903689740779289442\n",
      "INFO: [2025-06-27 16:33:58] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:33:58] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:33:59] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:33:59] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-35882458128194165/-5334747772439562360\n",
      "INFO: [2025-06-27 16:33:59] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:33:59] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:33:59] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:33:59] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-35882458128194165/-5856418503447962150\n",
      "INFO: [2025-06-27 16:33:59] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:33:59] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:33:59] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:33:59] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-35882458128194165/-4420053477039985357\n",
      "INFO: [2025-06-27 16:33:59] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:33:59] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:33:59] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:   1%|          | 1/92 [00:01<02:47,  1.84s/it]INFO: [2025-06-27 16:33:59] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/31160008118740626/-4642716826570878808\n",
      "INFO: [2025-06-27 16:33:59] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:33:59] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:00] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:00] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/31160008118740626/-2363223023371857031\n",
      "INFO: [2025-06-27 16:34:00] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:00] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:00] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:00] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/31160008118740626/-2582764264033022463\n",
      "INFO: [2025-06-27 16:34:00] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:00] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:01] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:01] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/31160008118740626/332782111888204987\n",
      "INFO: [2025-06-27 16:34:01] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:01] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:01] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:01] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/31160008118740626/-8464314867161205801\n",
      "INFO: [2025-06-27 16:34:01] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:01] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:01] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:   2%|‚ñè         | 2/92 [00:03<02:40,  1.78s/it]INFO: [2025-06-27 16:34:01] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/33874939274212480/-4669591336875541030\n",
      "INFO: [2025-06-27 16:34:01] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:01] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:01] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:01] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/33874939274212480/3390350975225798121\n",
      "INFO: [2025-06-27 16:34:01] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:01] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:02] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:02] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/33874939274212480/-2628242032045869809\n",
      "INFO: [2025-06-27 16:34:02] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:02] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:02] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:02] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/33874939274212480/-4362455459346710243\n",
      "INFO: [2025-06-27 16:34:02] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:02] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:02] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:02] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/33874939274212480/8506126651570199837\n",
      "INFO: [2025-06-27 16:34:02] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:02] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:02] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:   3%|‚ñé         | 3/92 [00:05<02:24,  1.62s/it]INFO: [2025-06-27 16:34:02] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-32399727139857751/4405364781267347528\n",
      "INFO: [2025-06-27 16:34:02] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:02] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:03] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:03] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-32399727139857751/6999750910535732529\n",
      "INFO: [2025-06-27 16:34:03] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:03] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:03] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:03] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-32399727139857751/-1268379201215071625\n",
      "INFO: [2025-06-27 16:34:03] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:03] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:03] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:03] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-32399727139857751/8039706816210237\n",
      "INFO: [2025-06-27 16:34:03] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:03] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:04] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:04] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-32399727139857751/4454607116702361065\n",
      "INFO: [2025-06-27 16:34:04] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:04] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:04] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:   4%|‚ñç         | 4/92 [00:06<02:17,  1.57s/it]INFO: [2025-06-27 16:34:04] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/9371935612488149/6952546342211378665\n",
      "INFO: [2025-06-27 16:34:04] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:04] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:04] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:04] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/9371935612488149/-4297192954608586246\n",
      "INFO: [2025-06-27 16:34:04] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:04] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:05] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:05] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/9371935612488149/-8282073120475303950\n",
      "INFO: [2025-06-27 16:34:05] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:05] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:05] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:05] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/9371935612488149/2659068389317603914\n",
      "INFO: [2025-06-27 16:34:05] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:05] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:05] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:05] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/9371935612488149/569981281064949395\n",
      "INFO: [2025-06-27 16:34:05] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:05] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:05] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:   5%|‚ñå         | 5/92 [00:07<02:12,  1.53s/it]INFO: [2025-06-27 16:34:05] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/3246604237187558/4221141066125913797\n",
      "INFO: [2025-06-27 16:34:05] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:05] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:06] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:06] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/3246604237187558/-865341716126642342\n",
      "INFO: [2025-06-27 16:34:06] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:06] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:06] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:06] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/3246604237187558/1971485495470762176\n",
      "INFO: [2025-06-27 16:34:06] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:06] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:06] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:06] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/3246604237187558/2191672888074016839\n",
      "INFO: [2025-06-27 16:34:06] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:06] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:07] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:07] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/3246604237187558/-791784938196786423\n",
      "INFO: [2025-06-27 16:34:07] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:07] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:07] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:   7%|‚ñã         | 6/92 [00:09<02:10,  1.52s/it]INFO: [2025-06-27 16:34:07] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/9130628937861941/-8855815949152074163\n",
      "INFO: [2025-06-27 16:34:07] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:07] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:07] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:07] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/9130628937861941/7027863548097050059\n",
      "INFO: [2025-06-27 16:34:07] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:07] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:08] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:08] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/9130628937861941/4243243362383628848\n",
      "INFO: [2025-06-27 16:34:08] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:08] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:08] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:08] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/9130628937861941/-8387186753810529601\n",
      "INFO: [2025-06-27 16:34:08] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:08] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:08] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:08] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/9130628937861941/-5752679708329804378\n",
      "INFO: [2025-06-27 16:34:08] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:08] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:08] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:   8%|‚ñä         | 7/92 [00:10<02:07,  1.50s/it]INFO: [2025-06-27 16:34:08] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/19706388665464256/7965222914329343101\n",
      "INFO: [2025-06-27 16:34:08] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:08] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:09] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:09] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/19706388665464256/-6455125861632211672\n",
      "INFO: [2025-06-27 16:34:09] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:09] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:09] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:09] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/19706388665464256/1432444337877372283\n",
      "INFO: [2025-06-27 16:34:09] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:09] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:09] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:09] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/19706388665464256/-2487572322505632226\n",
      "INFO: [2025-06-27 16:34:09] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:09] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:10] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/19706388665464256/-3281622557570732193\n",
      "INFO: [2025-06-27 16:34:10] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:10] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:10] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:   9%|‚ñä         | 8/92 [00:12<02:06,  1.51s/it]INFO: [2025-06-27 16:34:10] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-14556452501867428/3964906719716414989\n",
      "INFO: [2025-06-27 16:34:10] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:10] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:10] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:10] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-14556452501867428/802059349906666131\n",
      "INFO: [2025-06-27 16:34:10] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:10] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:11] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:11] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-14556452501867428/-2378515769215120271\n",
      "INFO: [2025-06-27 16:34:11] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:11] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:11] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:11] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-14556452501867428/7507544855246747616\n",
      "INFO: [2025-06-27 16:34:11] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:11] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:11] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:11] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-14556452501867428/-1325304298386565695\n",
      "INFO: [2025-06-27 16:34:11] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:11] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:11] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  10%|‚ñâ         | 9/92 [00:13<02:01,  1.47s/it]INFO: [2025-06-27 16:34:11] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/15114781201446083/-892738448594905841\n",
      "INFO: [2025-06-27 16:34:11] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:11] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:12] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:12] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/15114781201446083/-6076373598097194483\n",
      "INFO: [2025-06-27 16:34:12] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:12] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:12] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:12] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/15114781201446083/8889527634687503922\n",
      "INFO: [2025-06-27 16:34:12] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:12] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:12] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:12] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/15114781201446083/1522997278303640165\n",
      "INFO: [2025-06-27 16:34:12] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:12] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:12] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:12] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/15114781201446083/5404053056781201289\n",
      "INFO: [2025-06-27 16:34:12] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:12] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:13] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  11%|‚ñà         | 10/92 [00:15<01:58,  1.44s/it]INFO: [2025-06-27 16:34:13] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/13290267870654994/6453445893977860684\n",
      "INFO: [2025-06-27 16:34:13] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:13] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:13] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:13] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/13290267870654994/5534543637716121548\n",
      "INFO: [2025-06-27 16:34:13] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:13] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:13] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:13] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/13290267870654994/8674720215695517734\n",
      "INFO: [2025-06-27 16:34:13] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:13] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:14] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:14] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/13290267870654994/7407753343587668192\n",
      "INFO: [2025-06-27 16:34:14] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:14] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:14] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:14] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/13290267870654994/3299458053686794477\n",
      "INFO: [2025-06-27 16:34:14] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:14] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:14] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  12%|‚ñà‚ñè        | 11/92 [00:16<01:59,  1.48s/it]INFO: [2025-06-27 16:34:14] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/30902335548899281/-1336191485702648356\n",
      "INFO: [2025-06-27 16:34:14] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:14] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:14] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:14] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/30902335548899281/-5903856386844525491\n",
      "INFO: [2025-06-27 16:34:14] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:14] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:15] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/30902335548899281/-967464592367563265\n",
      "INFO: [2025-06-27 16:34:15] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:15] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:15] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:15] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/30902335548899281/-5138713353197435575\n",
      "INFO: [2025-06-27 16:34:15] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:15] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:15] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:15] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/30902335548899281/-7987978502872519615\n",
      "INFO: [2025-06-27 16:34:15] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:15] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:16] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  13%|‚ñà‚ñé        | 12/92 [00:18<01:59,  1.49s/it]INFO: [2025-06-27 16:34:16] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/2135209076854093/-5030540058313466626\n",
      "INFO: [2025-06-27 16:34:16] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:16] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:16] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:16] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/2135209076854093/-9023937700981934496\n",
      "INFO: [2025-06-27 16:34:16] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:16] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:16] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:16] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/2135209076854093/-3871724993895714605\n",
      "INFO: [2025-06-27 16:34:16] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:16] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:17] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:17] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/2135209076854093/1249281260349670441\n",
      "INFO: [2025-06-27 16:34:17] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:17] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:17] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:17] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/2135209076854093/-1803222232034508950\n",
      "INFO: [2025-06-27 16:34:17] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:17] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:17] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  14%|‚ñà‚ñç        | 13/92 [00:19<01:54,  1.45s/it]INFO: [2025-06-27 16:34:17] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-18387380848780476/4832434126075721445\n",
      "INFO: [2025-06-27 16:34:17] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:17] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:18] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:18] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-18387380848780476/-6576171702229301961\n",
      "INFO: [2025-06-27 16:34:18] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:18] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:18] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:18] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-18387380848780476/-8577545268937287218\n",
      "INFO: [2025-06-27 16:34:18] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:18] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:18] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:18] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-18387380848780476/1380099258313743549\n",
      "INFO: [2025-06-27 16:34:18] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:18] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:18] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:18] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-18387380848780476/-6216581390837487486\n",
      "INFO: [2025-06-27 16:34:18] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:18] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:19] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  15%|‚ñà‚ñå        | 14/92 [00:21<01:57,  1.50s/it]INFO: [2025-06-27 16:34:19] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/18933828397346607/5488745354973087240\n",
      "INFO: [2025-06-27 16:34:19] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:19] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:19] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:19] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/18933828397346607/6373864110073986888\n",
      "INFO: [2025-06-27 16:34:19] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:19] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:19] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:19] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/18933828397346607/1854475919424245751\n",
      "INFO: [2025-06-27 16:34:19] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:19] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:20] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:20] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/18933828397346607/7593111080715180787\n",
      "INFO: [2025-06-27 16:34:20] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:20] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:20] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:20] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/18933828397346607/-3768172040271155403\n",
      "INFO: [2025-06-27 16:34:20] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:20] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:20] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  16%|‚ñà‚ñã        | 15/92 [00:22<01:57,  1.52s/it]INFO: [2025-06-27 16:34:20] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/20978307744432241/-6645341673088969382\n",
      "INFO: [2025-06-27 16:34:20] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:20] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:21] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:21] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/20978307744432241/2153480888699432257\n",
      "INFO: [2025-06-27 16:34:21] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:21] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:21] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:21] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/20978307744432241/-2860523599452780399\n",
      "INFO: [2025-06-27 16:34:21] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:21] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:21] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:21] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/20978307744432241/-460182806254602431\n",
      "INFO: [2025-06-27 16:34:21] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:21] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:22] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:22] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/20978307744432241/252521564114939607\n",
      "INFO: [2025-06-27 16:34:22] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:22] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:22] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  17%|‚ñà‚ñã        | 16/92 [00:24<02:06,  1.67s/it]INFO: [2025-06-27 16:34:22] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-35102576635162472/2343622916004568787\n",
      "INFO: [2025-06-27 16:34:22] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:22] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:23] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:23] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-35102576635162472/1081870067815856664\n",
      "INFO: [2025-06-27 16:34:23] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:23] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:23] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:23] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-35102576635162472/6211416098695478955\n",
      "INFO: [2025-06-27 16:34:23] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:23] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:23] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:23] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-35102576635162472/-2069143464549335780\n",
      "INFO: [2025-06-27 16:34:23] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:23] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:23] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-35102576635162472/-5959531301477927791\n",
      "INFO: [2025-06-27 16:34:23] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:23] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:24] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  18%|‚ñà‚ñä        | 17/92 [00:26<02:02,  1.64s/it]INFO: [2025-06-27 16:34:24] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-7126418877828068/8034691053799493837\n",
      "INFO: [2025-06-27 16:34:24] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:24] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:24] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:24] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-7126418877828068/1141267624756420336\n",
      "INFO: [2025-06-27 16:34:24] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:24] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:24] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:24] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-7126418877828068/1341122440037525611\n",
      "INFO: [2025-06-27 16:34:24] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:24] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:25] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:25] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-7126418877828068/-5219449595635824327\n",
      "INFO: [2025-06-27 16:34:25] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:25] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:25] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:25] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-7126418877828068/2064669777936213310\n",
      "INFO: [2025-06-27 16:34:25] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:25] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:26] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  20%|‚ñà‚ñâ        | 18/92 [00:28<02:01,  1.64s/it]INFO: [2025-06-27 16:34:26] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-19952367157294119/7879982668838300654\n",
      "INFO: [2025-06-27 16:34:26] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:26] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:26] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:26] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-19952367157294119/3301859932289183865\n",
      "INFO: [2025-06-27 16:34:26] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:26] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:26] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:26] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-19952367157294119/8759575376421538679\n",
      "INFO: [2025-06-27 16:34:26] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:26] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:26] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:26] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-19952367157294119/5929597371365410725\n",
      "INFO: [2025-06-27 16:34:26] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:26] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:27] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:27] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-19952367157294119/142925013566407975\n",
      "INFO: [2025-06-27 16:34:27] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:27] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  21%|‚ñà‚ñà        | 19/92 [00:29<01:58,  1.63s/it]INFO: [2025-06-27 16:34:27] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-34105277816332298/-1245744215069625574\n",
      "INFO: [2025-06-27 16:34:27] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:27] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:27] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:27] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-34105277816332298/-1288793689237277613\n",
      "INFO: [2025-06-27 16:34:27] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:27] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:28] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-34105277816332298/-7260329194681942815\n",
      "INFO: [2025-06-27 16:34:28] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:28] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:28] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  22%|‚ñà‚ñà‚ñè       | 20/92 [00:30<01:44,  1.46s/it]INFO: [2025-06-27 16:34:28] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-25725881202629826/-3639705050638090691\n",
      "INFO: [2025-06-27 16:34:28] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:28] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:28] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:28] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-25725881202629826/-8266575435136860556\n",
      "INFO: [2025-06-27 16:34:28] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:28] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:29] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:29] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-25725881202629826/-5803794358846613638\n",
      "INFO: [2025-06-27 16:34:29] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:29] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:29] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:29] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-25725881202629826/6958396776840245518\n",
      "INFO: [2025-06-27 16:34:29] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:29] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:29] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:29] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-25725881202629826/-8962668398697605821\n",
      "INFO: [2025-06-27 16:34:29] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:29] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:30] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  23%|‚ñà‚ñà‚ñé       | 21/92 [00:32<01:41,  1.43s/it]INFO: [2025-06-27 16:34:30] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-2046863695546735/-7576606140166963137\n",
      "INFO: [2025-06-27 16:34:30] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:30] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:30] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:30] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-2046863695546735/2260323545912037928\n",
      "INFO: [2025-06-27 16:34:30] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:30] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:30] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:30] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-2046863695546735/-990127862492828733\n",
      "INFO: [2025-06-27 16:34:30] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:30] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:30] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:30] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-2046863695546735/7697599753519692244\n",
      "INFO: [2025-06-27 16:34:30] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:30] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:31] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:31] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-2046863695546735/-5414120092351136630\n",
      "INFO: [2025-06-27 16:34:31] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:31] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  24%|‚ñà‚ñà‚ñç       | 22/92 [00:33<01:42,  1.46s/it]INFO: [2025-06-27 16:34:31] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/12631778325074772/3622062378040551526\n",
      "INFO: [2025-06-27 16:34:31] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:31] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:31] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:31] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/12631778325074772/-5660088039246376770\n",
      "INFO: [2025-06-27 16:34:31] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:31] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:32] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:32] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/12631778325074772/5846748304855713055\n",
      "INFO: [2025-06-27 16:34:32] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:32] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:32] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:32] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/12631778325074772/4226092333848393175\n",
      "INFO: [2025-06-27 16:34:32] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:32] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:32] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:32] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/12631778325074772/-5156252880374989973\n",
      "INFO: [2025-06-27 16:34:32] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:32] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:33] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  25%|‚ñà‚ñà‚ñå       | 23/92 [00:35<01:42,  1.49s/it]INFO: [2025-06-27 16:34:33] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-29122158203077245/-5686880556651863274\n",
      "INFO: [2025-06-27 16:34:33] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:33] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:33] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:33] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-29122158203077245/-7018996456395300040\n",
      "INFO: [2025-06-27 16:34:33] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:33] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:33] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:33] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-29122158203077245/-6544929051100552273\n",
      "INFO: [2025-06-27 16:34:33] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:33] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:33] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:33] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-29122158203077245/-6396036063237276422\n",
      "INFO: [2025-06-27 16:34:33] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:33] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:34] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:34] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-29122158203077245/8998454228303423333\n",
      "INFO: [2025-06-27 16:34:34] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:34] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:34] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  26%|‚ñà‚ñà‚ñå       | 24/92 [00:36<01:42,  1.51s/it]INFO: [2025-06-27 16:34:34] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-22627892168184181/8028853773421260830\n",
      "INFO: [2025-06-27 16:34:34] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:34] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:34] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:34] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-22627892168184181/-2625701155064160228\n",
      "INFO: [2025-06-27 16:34:34] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:34] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:35] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:35] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-22627892168184181/-6121287522203766477\n",
      "INFO: [2025-06-27 16:34:35] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:35] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:35] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:35] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-22627892168184181/-4556705642132470901\n",
      "INFO: [2025-06-27 16:34:35] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:35] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:35] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:35] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-22627892168184181/-3936994053069289867\n",
      "INFO: [2025-06-27 16:34:35] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:35] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:36] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  27%|‚ñà‚ñà‚ñã       | 25/92 [00:38<01:44,  1.56s/it]INFO: [2025-06-27 16:34:36] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/28030974524863734/-3074741708453388847\n",
      "INFO: [2025-06-27 16:34:36] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:36] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:36] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/28030974524863734/5146472025607600600\n",
      "INFO: [2025-06-27 16:34:36] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:36] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:36] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:36] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/28030974524863734/-3424265269175611909\n",
      "INFO: [2025-06-27 16:34:36] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:36] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:37] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:37] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/28030974524863734/41096803244585387\n",
      "INFO: [2025-06-27 16:34:37] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:37] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:37] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:37] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/28030974524863734/-906639502994899913\n",
      "INFO: [2025-06-27 16:34:37] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:37] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:37] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  28%|‚ñà‚ñà‚ñä       | 26/92 [00:40<01:44,  1.58s/it]INFO: [2025-06-27 16:34:37] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-8639253709990781/716383431881062025\n",
      "INFO: [2025-06-27 16:34:38] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:38] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:38] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:38] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-8639253709990781/8895919881072540994\n",
      "INFO: [2025-06-27 16:34:38] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:38] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:38] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:38] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-8639253709990781/-8845668309236611089\n",
      "INFO: [2025-06-27 16:34:38] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:38] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:38] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-8639253709990781/7042973063834155472\n",
      "INFO: [2025-06-27 16:34:38] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:38] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:39] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:39] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-8639253709990781/2700726683991673132\n",
      "INFO: [2025-06-27 16:34:39] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:39] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:39] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  29%|‚ñà‚ñà‚ñâ       | 27/92 [00:41<01:38,  1.51s/it]INFO: [2025-06-27 16:34:39] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/33041281229298748/6497020101194617171\n",
      "INFO: [2025-06-27 16:34:39] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:39] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:39] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:39] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/33041281229298748/-2736425708469822029\n",
      "INFO: [2025-06-27 16:34:39] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:39] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:40] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:40] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/33041281229298748/-3842792248032066274\n",
      "INFO: [2025-06-27 16:34:40] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:40] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:40] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:40] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/33041281229298748/1967083863833861440\n",
      "INFO: [2025-06-27 16:34:40] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:40] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:40] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:40] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/33041281229298748/6819001063288595490\n",
      "INFO: [2025-06-27 16:34:40] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:40] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:40] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  30%|‚ñà‚ñà‚ñà       | 28/92 [00:42<01:38,  1.53s/it]INFO: [2025-06-27 16:34:40] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-26780953604978411/-5575280606509183888\n",
      "INFO: [2025-06-27 16:34:40] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:40] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:41] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:41] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-26780953604978411/-2100308078671207313\n",
      "INFO: [2025-06-27 16:34:41] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:41] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:41] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:41] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-26780953604978411/-2100308078671207313\n",
      "INFO: [2025-06-27 16:34:41] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:41] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:41] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:41] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-26780953604978411/-5575280606509183888\n",
      "INFO: [2025-06-27 16:34:41] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:41] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:42] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:42] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-26780953604978411/-6591501306161014441\n",
      "INFO: [2025-06-27 16:34:42] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:42] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  32%|‚ñà‚ñà‚ñà‚ñè      | 29/92 [00:44<01:35,  1.52s/it]INFO: [2025-06-27 16:34:42] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-18949191324265795/-49564332575376769\n",
      "INFO: [2025-06-27 16:34:42] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:42] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:42] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:42] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-18949191324265795/3571334604632782089\n",
      "INFO: [2025-06-27 16:34:42] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:42] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:43] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:43] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-18949191324265795/3892932039053876148\n",
      "INFO: [2025-06-27 16:34:43] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:43] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:43] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:43] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-18949191324265795/8464842264717430508\n",
      "INFO: [2025-06-27 16:34:43] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:43] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:43] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:43] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-18949191324265795/5149324403950530182\n",
      "INFO: [2025-06-27 16:34:43] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:43] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:43] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  33%|‚ñà‚ñà‚ñà‚ñé      | 30/92 [00:45<01:31,  1.48s/it]INFO: [2025-06-27 16:34:43] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/1410763986151621/-5303531952248046704\n",
      "INFO: [2025-06-27 16:34:43] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:43] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:44] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:44] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/1410763986151621/-2688532263111441383\n",
      "INFO: [2025-06-27 16:34:44] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:44] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:44] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:44] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/1410763986151621/7698876637308498112\n",
      "INFO: [2025-06-27 16:34:44] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:44] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:44] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:44] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/1410763986151621/8563660454736324069\n",
      "INFO: [2025-06-27 16:34:44] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:44] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:45] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:45] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/1410763986151621/-957945175582104365\n",
      "INFO: [2025-06-27 16:34:45] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:45] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:45] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  34%|‚ñà‚ñà‚ñà‚ñé      | 31/92 [00:47<01:30,  1.49s/it]INFO: [2025-06-27 16:34:45] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/1739983631954371/-8909822612301210139\n",
      "INFO: [2025-06-27 16:34:45] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:45] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:45] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:45] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/1739983631954371/-1437531335538991507\n",
      "INFO: [2025-06-27 16:34:45] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:45] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:46] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:46] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/1739983631954371/-6021349484732747496\n",
      "INFO: [2025-06-27 16:34:46] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:46] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:46] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/1739983631954371/-1248106465604525997\n",
      "INFO: [2025-06-27 16:34:46] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:46] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:46] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/1739983631954371/-1954372949916326066\n",
      "INFO: [2025-06-27 16:34:46] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:46] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  35%|‚ñà‚ñà‚ñà‚ñç      | 32/92 [00:48<01:28,  1.48s/it]INFO: [2025-06-27 16:34:46] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/5895544448831150/-5678493114848982685\n",
      "INFO: [2025-06-27 16:34:46] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:46] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:47] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:47] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/5895544448831150/6840415915550283452\n",
      "INFO: [2025-06-27 16:34:47] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:47] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:47] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:47] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/5895544448831150/-490770981002928139\n",
      "INFO: [2025-06-27 16:34:47] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:47] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:47] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  36%|‚ñà‚ñà‚ñà‚ñå      | 33/92 [00:49<01:18,  1.33s/it]INFO: [2025-06-27 16:34:47] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/31202820582613161/1302862404895722931\n",
      "INFO: [2025-06-27 16:34:47] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:47] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:48] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:48] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/31202820582613161/-4710755148228645402\n",
      "INFO: [2025-06-27 16:34:48] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:48] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:48] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:48] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/31202820582613161/-7187469697580805303\n",
      "INFO: [2025-06-27 16:34:48] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:48] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:48] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:48] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/31202820582613161/7174666733000882265\n",
      "INFO: [2025-06-27 16:34:48] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:48] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:49] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:49] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/31202820582613161/-4438341281978505015\n",
      "INFO: [2025-06-27 16:34:49] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:49] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  37%|‚ñà‚ñà‚ñà‚ñã      | 34/92 [00:51<01:23,  1.43s/it]INFO: [2025-06-27 16:34:49] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-35884737692158253/7359123353474896078\n",
      "INFO: [2025-06-27 16:34:49] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:49] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:49] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:49] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-35884737692158253/-851255063151224319\n",
      "INFO: [2025-06-27 16:34:49] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:49] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:49] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:49] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-35884737692158253/-5183722729337929251\n",
      "INFO: [2025-06-27 16:34:49] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:49] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:50] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-35884737692158253/3301184237479273814\n",
      "INFO: [2025-06-27 16:34:50] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:50] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:50] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:50] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-35884737692158253/-6004749260235273668\n",
      "INFO: [2025-06-27 16:34:50] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:50] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:51] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  38%|‚ñà‚ñà‚ñà‚ñä      | 35/92 [00:53<01:27,  1.54s/it]INFO: [2025-06-27 16:34:51] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-34803309266443718/5580369426739380001\n",
      "INFO: [2025-06-27 16:34:51] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:51] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:51] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:51] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-34803309266443718/-6707805339997665826\n",
      "INFO: [2025-06-27 16:34:51] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:51] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:51] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:51] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-34803309266443718/3380995278001123487\n",
      "INFO: [2025-06-27 16:34:51] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:51] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:52] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:52] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-34803309266443718/1711775163034602511\n",
      "INFO: [2025-06-27 16:34:52] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:52] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:52] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:52] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-34803309266443718/8104683881023840410\n",
      "INFO: [2025-06-27 16:34:52] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:52] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  39%|‚ñà‚ñà‚ñà‚ñâ      | 36/92 [00:54<01:24,  1.52s/it]INFO: [2025-06-27 16:34:52] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-22499263970759753/623588335874424306\n",
      "INFO: [2025-06-27 16:34:52] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:52] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:52] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-22499263970759753/-5811406536058053449\n",
      "INFO: [2025-06-27 16:34:52] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:52] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:53] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-22499263970759753/-8230480911474175565\n",
      "INFO: [2025-06-27 16:34:53] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:53] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:53] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:53] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-22499263970759753/4839793808578026488\n",
      "INFO: [2025-06-27 16:34:53] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:53] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:53] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-22499263970759753/-5945603415926029113\n",
      "INFO: [2025-06-27 16:34:53] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:53] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  40%|‚ñà‚ñà‚ñà‚ñà      | 37/92 [00:56<01:22,  1.50s/it]INFO: [2025-06-27 16:34:54] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-12988782223228843/8148382400078380983\n",
      "INFO: [2025-06-27 16:34:54] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:54] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:54] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-12988782223228843/-3157155389966910232\n",
      "INFO: [2025-06-27 16:34:54] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:54] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:54] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-12988782223228843/-7639492274974046551\n",
      "INFO: [2025-06-27 16:34:54] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:54] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:55] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-12988782223228843/-6281577041156644526\n",
      "INFO: [2025-06-27 16:34:55] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:55] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:55] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-12988782223228843/-6959949916298998412\n",
      "INFO: [2025-06-27 16:34:55] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:55] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 38/92 [00:57<01:22,  1.53s/it]INFO: [2025-06-27 16:34:55] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-7666152121409895/6926593929266073454\n",
      "INFO: [2025-06-27 16:34:55] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:55] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:56] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:56] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-7666152121409895/-4209305014920674025\n",
      "INFO: [2025-06-27 16:34:56] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:56] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:56] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:56] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-7666152121409895/4498186992857338885\n",
      "INFO: [2025-06-27 16:34:56] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:56] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:56] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:56] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-7666152121409895/5957595400114768462\n",
      "INFO: [2025-06-27 16:34:56] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:56] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:57] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:57] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-7666152121409895/-5284872250135265225\n",
      "INFO: [2025-06-27 16:34:57] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:57] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:57] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 39/92 [00:59<01:24,  1.60s/it]INFO: [2025-06-27 16:34:57] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/21634894993301822/1225585874383749432\n",
      "INFO: [2025-06-27 16:34:57] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:57] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:57] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:57] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/21634894993301822/947202408938575961\n",
      "INFO: [2025-06-27 16:34:57] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:57] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:58] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/21634894993301822/7556242793233433568\n",
      "INFO: [2025-06-27 16:34:58] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:58] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:58] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:58] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/21634894993301822/6324067640264457939\n",
      "INFO: [2025-06-27 16:34:58] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:58] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:58] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:58] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/21634894993301822/-8754369783480511438\n",
      "INFO: [2025-06-27 16:34:58] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:58] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:58] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 40/92 [01:00<01:20,  1.54s/it]INFO: [2025-06-27 16:34:58] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/34364657708684419/-2629993364031988682\n",
      "INFO: [2025-06-27 16:34:58] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:58] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:59] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/34364657708684419/-5121180977425523747\n",
      "INFO: [2025-06-27 16:34:59] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:59] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:59] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:59] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/34364657708684419/-4126053122944348706\n",
      "INFO: [2025-06-27 16:34:59] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:59] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:34:59] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:34:59] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/34364657708684419/-3727692884436244935\n",
      "INFO: [2025-06-27 16:34:59] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:34:59] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:35:00] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:35:00] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/34364657708684419/1597240253355941547\n",
      "INFO: [2025-06-27 16:35:00] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:00] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:35:00] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 41/92 [01:02<01:22,  1.61s/it]INFO: [2025-06-27 16:35:00] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/10262358575052520/5193588747273290001\n",
      "INFO: [2025-06-27 16:35:00] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:00] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:35:00] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/10262358575052520/6384894172824164400\n",
      "INFO: [2025-06-27 16:35:00] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:00] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:35:01] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:35:01] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/10262358575052520/-2026690185760046657\n",
      "INFO: [2025-06-27 16:35:01] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:01] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:35:01] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:35:01] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/10262358575052520/5193588747273290001\n",
      "INFO: [2025-06-27 16:35:01] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:01] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:35:02] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/10262358575052520/6384894172824164400\n",
      "INFO: [2025-06-27 16:35:02] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:02] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:35:02] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 42/92 [01:04<01:21,  1.63s/it]INFO: [2025-06-27 16:35:02] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/11111675784752136/-8333305609307516398\n",
      "INFO: [2025-06-27 16:35:02] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:02] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:35:02] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:35:02] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/11111675784752136/5350615363953520606\n",
      "INFO: [2025-06-27 16:35:02] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:02] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:35:02] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/11111675784752136/3350719506494207471\n",
      "INFO: [2025-06-27 16:35:02] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:02] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:35:03] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:35:03] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/11111675784752136/3461055843045518806\n",
      "INFO: [2025-06-27 16:35:03] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:03] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:35:03] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:35:03] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/11111675784752136/8348473771820280935\n",
      "INFO: [2025-06-27 16:35:03] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:03] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:35:03] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 43/92 [01:05<01:18,  1.60s/it]INFO: [2025-06-27 16:35:03] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/12642450547914707/8347204528152324975\n",
      "INFO: [2025-06-27 16:35:03] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:03] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:35:04] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:35:04] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/12642450547914707/3478868391458170278\n",
      "INFO: [2025-06-27 16:35:04] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:04] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:35:04] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:35:04] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/12642450547914707/2937249104658770404\n",
      "INFO: [2025-06-27 16:35:04] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:04] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:35:04] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:35:04] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/12642450547914707/1968191420632676549\n",
      "INFO: [2025-06-27 16:35:04] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:04] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:35:04] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:35:04] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/12642450547914707/7620024638601426502\n",
      "INFO: [2025-06-27 16:35:04] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:04] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 44/92 [01:07<01:12,  1.51s/it]INFO: [2025-06-27 16:35:05] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/21893218624143108/573644746304192245\n",
      "INFO: [2025-06-27 16:35:05] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:05] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:35:05] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:35:05] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/21893218624143108/-4945713875907639718\n",
      "INFO: [2025-06-27 16:35:05] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:05] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:35:06] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:35:06] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/21893218624143108/7400069318801841774\n",
      "INFO: [2025-06-27 16:35:06] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:06] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:35:06] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:35:06] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/21893218624143108/3357630899287999218\n",
      "INFO: [2025-06-27 16:35:06] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:06] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:35:06] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:35:06] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/21893218624143108/-7327646880163051373\n",
      "INFO: [2025-06-27 16:35:06] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:06] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 45/92 [01:08<01:12,  1.53s/it]INFO: [2025-06-27 16:35:06] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-24316712102315887/2834571268812183428\n",
      "INFO: [2025-06-27 16:35:06] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:06] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:35:07] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:35:07] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-24316712102315887/3720793000583221964\n",
      "INFO: [2025-06-27 16:35:07] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:07] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:35:07] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:35:07] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-24316712102315887/5984152516802949451\n",
      "INFO: [2025-06-27 16:35:07] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:07] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:35:07] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:35:07] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-24316712102315887/-5150287373429888631\n",
      "INFO: [2025-06-27 16:35:07] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:07] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:35:08] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-24316712102315887/-8910198268186727635\n",
      "INFO: [2025-06-27 16:35:08] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:08] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:35:08] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 46/92 [01:10<01:10,  1.54s/it]INFO: [2025-06-27 16:35:08] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-23507181552861323/3510879047104264830\n",
      "INFO: [2025-06-27 16:35:08] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:08] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:35:08] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:35:08] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-23507181552861323/4137440517101656685\n",
      "INFO: [2025-06-27 16:35:08] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:08] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:35:09] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:35:09] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-23507181552861323/-8238821923278641850\n",
      "INFO: [2025-06-27 16:35:09] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:09] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:35:09] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-23507181552861323/6072207199438534637\n",
      "INFO: [2025-06-27 16:35:09] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:09] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:35:09] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:35:09] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-23507181552861323/-1262045258718203678\n",
      "INFO: [2025-06-27 16:35:09] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:09] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 47/92 [01:11<01:09,  1.54s/it]INFO: [2025-06-27 16:35:09] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-18152182327560480/-4341089490484079760\n",
      "INFO: [2025-06-27 16:35:09] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:09] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:35:10] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:35:10] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-18152182327560480/-2197564856973422755\n",
      "INFO: [2025-06-27 16:35:10] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:10] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:35:10] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-18152182327560480/1371242355701412014\n",
      "INFO: [2025-06-27 16:35:10] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:10] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:35:10] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:35:10] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-18152182327560480/-9126318783037784645\n",
      "INFO: [2025-06-27 16:35:10] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:10] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:35:11] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:35:11] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-18152182327560480/-2638948329676682937\n",
      "INFO: [2025-06-27 16:35:11] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:11] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:35:11] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 48/92 [01:13<01:09,  1.58s/it]INFO: [2025-06-27 16:35:11] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/21321689889868872/-3631827477176517536\n",
      "INFO: [2025-06-27 16:35:11] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:11] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:35:12] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:35:12] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/21321689889868872/4277189631399119518\n",
      "INFO: [2025-06-27 16:35:12] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:12] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:35:12] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:35:12] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/21321689889868872/-3029230678400443214\n",
      "INFO: [2025-06-27 16:35:12] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:12] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:35:12] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/21321689889868872/2513408173929564530\n",
      "INFO: [2025-06-27 16:35:12] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:12] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:35:12] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:35:12] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/21321689889868872/-2131663956400107588\n",
      "INFO: [2025-06-27 16:35:12] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:12] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:35:13] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 49/92 [01:15<01:08,  1.58s/it]INFO: [2025-06-27 16:35:13] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-12463996681673250/1001484088117419076\n",
      "INFO: [2025-06-27 16:35:13] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:13] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:35:13] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:35:13] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-12463996681673250/1208163505060035575\n",
      "INFO: [2025-06-27 16:35:13] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:13] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:35:13] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:35:13] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-12463996681673250/5809878820364426932\n",
      "INFO: [2025-06-27 16:35:13] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:13] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:35:14] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-12463996681673250/-4018071394199911570\n",
      "INFO: [2025-06-27 16:35:14] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:14] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:35:14] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 50/92 [01:16<01:03,  1.51s/it]INFO: [2025-06-27 16:35:14] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-2139820121868237/7174911214789188615\n",
      "INFO: [2025-06-27 16:35:14] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:14] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:35:14] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:35:14] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-2139820121868237/-3965648376808544436\n",
      "INFO: [2025-06-27 16:35:14] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:14] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:35:15] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-2139820121868237/9166163062695038631\n",
      "INFO: [2025-06-27 16:35:15] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:15] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:35:15] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:35:15] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-2139820121868237/-8809767266699174627\n",
      "INFO: [2025-06-27 16:35:15] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:15] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:35:15] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 51/92 [01:17<00:59,  1.46s/it]INFO: [2025-06-27 16:35:15] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-1083216214855434/1353217280393293418\n",
      "INFO: [2025-06-27 16:35:15] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:15] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:35:16] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-1083216214855434/-1961593601051792778\n",
      "INFO: [2025-06-27 16:35:16] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:16] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:35:16] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-1083216214855434/-8258993645454398472\n",
      "INFO: [2025-06-27 16:35:16] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:16] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:35:16] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:35:16] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-1083216214855434/-1435460781728290990\n",
      "INFO: [2025-06-27 16:35:16] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:16] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 52/92 [01:19<00:58,  1.46s/it]INFO: [2025-06-27 16:35:17] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/17131318242278983/1564341055827454194\n",
      "INFO: [2025-06-27 16:35:17] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:17] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:35:17] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:35:17] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/17131318242278983/6902031343714230598\n",
      "INFO: [2025-06-27 16:35:17] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:17] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:35:18] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/17131318242278983/7714819180289531073\n",
      "INFO: [2025-06-27 16:35:18] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:18] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:35:18] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:35:18] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/17131318242278983/4577407953817486235\n",
      "INFO: [2025-06-27 16:35:18] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:18] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:35:19] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 53/92 [01:21<01:05,  1.67s/it]INFO: [2025-06-27 16:35:19] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/20606471688970148/4584402743475666567\n",
      "INFO: [2025-06-27 16:35:19] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:19] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:35:19] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:35:19] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/20606471688970148/-4477833252834350399\n",
      "INFO: [2025-06-27 16:35:19] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:19] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:35:20] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:35:20] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/20606471688970148/2911353927501129219\n",
      "INFO: [2025-06-27 16:35:20] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:20] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:35:20] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:35:20] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/20606471688970148/6030815948872375181\n",
      "INFO: [2025-06-27 16:35:20] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:20] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 54/92 [01:22<00:59,  1.57s/it]INFO: [2025-06-27 16:35:20] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/24584688051044679/-3369816936700840932\n",
      "INFO: [2025-06-27 16:35:20] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:20] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:35:21] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/24584688051044679/6775015327379007916\n",
      "INFO: [2025-06-27 16:35:21] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:21] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:35:21] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/24584688051044679/-1798206033544741742\n",
      "INFO: [2025-06-27 16:35:21] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:21] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:35:21] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/24584688051044679/-2693608016918028982\n",
      "INFO: [2025-06-27 16:35:21] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:21] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:35:22] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 55/92 [01:24<00:54,  1.48s/it]INFO: [2025-06-27 16:35:22] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-25141892168903907/2842787141749613966\n",
      "INFO: [2025-06-27 16:35:22] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:22] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:35:22] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-25141892168903907/-6439376666594011464\n",
      "INFO: [2025-06-27 16:35:22] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:22] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:35:22] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:35:22] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-25141892168903907/-8903314523412236212\n",
      "INFO: [2025-06-27 16:35:22] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:22] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:35:23] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 56/92 [01:25<00:48,  1.35s/it]INFO: [2025-06-27 16:35:23] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-20439687097155111/1775209866093857310\n",
      "INFO: [2025-06-27 16:35:23] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:23] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:35:23] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:35:23] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-20439687097155111/7144522010287559589\n",
      "INFO: [2025-06-27 16:35:23] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:23] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:35:23] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:35:23] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-20439687097155111/8404126418433661645\n",
      "INFO: [2025-06-27 16:35:23] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:23] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:35:23] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 57/92 [01:25<00:41,  1.19s/it]INFO: [2025-06-27 16:35:23] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-15352348890731234/2611632168285154532\n",
      "INFO: [2025-06-27 16:35:23] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:23] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:35:24] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:35:24] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-15352348890731234/-2634502323142599163\n",
      "INFO: [2025-06-27 16:35:24] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:24] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:35:24] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:35:24] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-15352348890731234/1884060885835443568\n",
      "INFO: [2025-06-27 16:35:24] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:24] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:35:24] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 58/92 [01:26<00:39,  1.15s/it]INFO: [2025-06-27 16:35:24] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-4938783110044412/-9078285195640588986\n",
      "INFO: [2025-06-27 16:35:24] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:24] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:35:25] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:35:25] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-4938783110044412/4904932290730580929\n",
      "INFO: [2025-06-27 16:35:25] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:25] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:35:25] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:35:25] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-4938783110044412/1709325522002828324\n",
      "INFO: [2025-06-27 16:35:25] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:25] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 59/92 [01:28<00:37,  1.13s/it]INFO: [2025-06-27 16:35:26] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/17609986374660936/6955319964368225949\n",
      "INFO: [2025-06-27 16:35:26] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:26] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:35:26] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/17609986374660936/-2271101217331081907\n",
      "INFO: [2025-06-27 16:35:26] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:26] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:35:26] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:35:26] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/17609986374660936/-3284830607060838746\n",
      "INFO: [2025-06-27 16:35:26] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:26] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:35:26] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 60/92 [01:28<00:32,  1.03s/it]INFO: [2025-06-27 16:35:26] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/17681796354219824/1937655903082247767\n",
      "INFO: [2025-06-27 16:35:26] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:26] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:35:27] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/17681796354219824/4805165615096784855\n",
      "INFO: [2025-06-27 16:35:27] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:27] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:35:27] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/17681796354219824/3557359331496990844\n",
      "INFO: [2025-06-27 16:35:27] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:27] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:35:27] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 61/92 [01:29<00:31,  1.03s/it]INFO: [2025-06-27 16:35:27] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/35971629147007369/3934064133303539878\n",
      "INFO: [2025-06-27 16:35:27] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:27] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:35:28] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/35971629147007369/-76836233779723673\n",
      "INFO: [2025-06-27 16:35:28] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:28] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:35:28] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/35971629147007369/-5603215187459537893\n",
      "INFO: [2025-06-27 16:35:28] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:28] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 62/92 [01:30<00:28,  1.04it/s]INFO: [2025-06-27 16:35:28] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-29415098045592940/6411323736572457795\n",
      "INFO: [2025-06-27 16:35:28] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:28] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:35:29] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-29415098045592940/-1964285695976284026\n",
      "INFO: [2025-06-27 16:35:29] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:29] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:35:29] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 63/92 [01:31<00:26,  1.08it/s]INFO: [2025-06-27 16:35:29] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-28031656773092240/-8110188940058236355\n",
      "INFO: [2025-06-27 16:35:29] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:29] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:35:29] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-28031656773092240/7195142021001911519\n",
      "INFO: [2025-06-27 16:35:29] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:29] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 64/92 [01:32<00:22,  1.23it/s]INFO: [2025-06-27 16:35:30] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-22849205778179846/-8283104409014302301\n",
      "INFO: [2025-06-27 16:35:30] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:30] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:35:30] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-22849205778179846/4313876108651469704\n",
      "INFO: [2025-06-27 16:35:30] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:30] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:35:30] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 65/92 [01:32<00:21,  1.23it/s]INFO: [2025-06-27 16:35:30] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-18031556530033893/-8627777469347266434\n",
      "INFO: [2025-06-27 16:35:30] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:30] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:35:31] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-18031556530033893/-5274756934146961381\n",
      "INFO: [2025-06-27 16:35:31] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:31] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:35:31] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 66/92 [01:33<00:19,  1.37it/s]INFO: [2025-06-27 16:35:31] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-13505886640472175/-5016407656743507623\n",
      "INFO: [2025-06-27 16:35:31] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:31] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:35:31] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:35:31] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-13505886640472175/5466843209844404034\n",
      "INFO: [2025-06-27 16:35:31] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:31] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 67/92 [01:33<00:16,  1.49it/s]INFO: [2025-06-27 16:35:31] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-6735076600090236/6255694963833004319\n",
      "INFO: [2025-06-27 16:35:31] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:31] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 68/92 [01:34<00:15,  1.57it/s]INFO: [2025-06-27 16:35:32] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-3409159551394617/-1175751077694116458\n",
      "INFO: [2025-06-27 16:35:32] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:32] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:35:32] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-3409159551394617/-925249975991770452\n",
      "INFO: [2025-06-27 16:35:32] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:32] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:35:32] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 69/92 [01:35<00:13,  1.67it/s]INFO: [2025-06-27 16:35:32] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-2069452773758641/-8073980649127594574\n",
      "INFO: [2025-06-27 16:35:32] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:32] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:35:33] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-2069452773758641/-8385030890674185701\n",
      "INFO: [2025-06-27 16:35:33] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:33] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:35:33] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 70/92 [01:35<00:12,  1.73it/s]INFO: [2025-06-27 16:35:33] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/3297979118605018/2121973381815758809\n",
      "INFO: [2025-06-27 16:35:33] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:33] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:35:34] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/3297979118605018/-7629863625189970605\n",
      "INFO: [2025-06-27 16:35:34] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:34] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:35:34] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 71/92 [01:36<00:13,  1.58it/s]INFO: [2025-06-27 16:35:34] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/10757094666506670/2521158598917791125\n",
      "INFO: [2025-06-27 16:35:34] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:34] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:35:34] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/10757094666506670/2049223786216519273\n",
      "INFO: [2025-06-27 16:35:34] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:34] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:35:34] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 72/92 [01:36<00:11,  1.67it/s]INFO: [2025-06-27 16:35:34] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/14377716460635733/224067156940651406\n",
      "INFO: [2025-06-27 16:35:34] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:34] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:35:35] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/14377716460635733/6494760830414415628\n",
      "INFO: [2025-06-27 16:35:35] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:35] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 73/92 [01:37<00:10,  1.74it/s]INFO: [2025-06-27 16:35:35] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-33852347582520392/-1730356740998679943\n",
      "INFO: [2025-06-27 16:35:35] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:35] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 74/92 [01:37<00:10,  1.77it/s]INFO: [2025-06-27 16:35:35] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-25655970173329808/825366547021190712\n",
      "INFO: [2025-06-27 16:35:35] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:35] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 75/92 [01:38<00:08,  2.11it/s]INFO: [2025-06-27 16:35:36] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-22061102960387551/-8905627793055248873\n",
      "INFO: [2025-06-27 16:35:36] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:36] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 76/92 [01:38<00:06,  2.47it/s]INFO: [2025-06-27 16:35:36] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-20155356540515066/1617558396579091168\n",
      "INFO: [2025-06-27 16:35:36] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:36] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 77/92 [01:38<00:05,  2.79it/s]INFO: [2025-06-27 16:35:36] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-14117628316152430/3708495649437002708\n",
      "INFO: [2025-06-27 16:35:36] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:36] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 78/92 [01:38<00:04,  3.00it/s]INFO: [2025-06-27 16:35:36] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-11019131917628364/-7716517932206651477\n",
      "INFO: [2025-06-27 16:35:36] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:36] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 79/92 [01:39<00:05,  2.59it/s]INFO: [2025-06-27 16:35:37] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-10444363735373102/5157584201604396827\n",
      "INFO: [2025-06-27 16:35:37] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:37] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 80/92 [01:39<00:04,  2.85it/s]INFO: [2025-06-27 16:35:37] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-10033945991593843/-8343780824465910733\n",
      "INFO: [2025-06-27 16:35:37] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:37] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 81/92 [01:39<00:03,  3.11it/s]INFO: [2025-06-27 16:35:37] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-184811282650788/7459276384007237512\n",
      "INFO: [2025-06-27 16:35:37] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:37] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 82/92 [01:40<00:03,  3.33it/s]INFO: [2025-06-27 16:35:38] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/5566930627431303/-5089293816558006420\n",
      "INFO: [2025-06-27 16:35:38] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:38] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:35:38] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 83/92 [01:40<00:02,  3.49it/s]INFO: [2025-06-27 16:35:38] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/5609203557180661/-7281660177572507763\n",
      "INFO: [2025-06-27 16:35:38] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:38] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 84/92 [01:40<00:02,  2.84it/s]INFO: [2025-06-27 16:35:38] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/15133418971654738/7647822926109152780\n",
      "INFO: [2025-06-27 16:35:38] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:38] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 85/92 [01:41<00:02,  3.09it/s]INFO: [2025-06-27 16:35:39] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/15568847793479266/-4907848724437537709\n",
      "INFO: [2025-06-27 16:35:39] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:39] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 86/92 [01:41<00:01,  3.29it/s]INFO: [2025-06-27 16:35:39] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/17470512188912087/430810044304398948\n",
      "INFO: [2025-06-27 16:35:39] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:39] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 87/92 [01:41<00:01,  3.45it/s]INFO: [2025-06-27 16:35:39] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/18334778860223615/-7462221171272857117\n",
      "INFO: [2025-06-27 16:35:39] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:39] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 88/92 [01:42<00:01,  2.94it/s]INFO: [2025-06-27 16:35:40] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/19367730649708653/-4042641636918889097\n",
      "INFO: [2025-06-27 16:35:40] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:40] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 89/92 [01:42<00:00,  3.18it/s]INFO: [2025-06-27 16:35:40] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/30634204597194783/-5259171881687072106\n",
      "INFO: [2025-06-27 16:35:40] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:40] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 90/92 [01:42<00:00,  3.36it/s]INFO: [2025-06-27 16:35:40] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/30759839524016550/-3386398509503978146\n",
      "INFO: [2025-06-27 16:35:40] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:40] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:35:40] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 91/92 [01:42<00:00,  3.36it/s]INFO: [2025-06-27 16:35:40] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/31420388280123621/126985844909369330\n",
      "INFO: [2025-06-27 16:35:40] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:40] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 92/92 [01:43<00:00,  1.12s/it]\n",
      "Processing LLM curations:   0%|          | 0/92 [00:00<?, ?it/s]INFO: [2025-06-27 16:35:41] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-35882458128194165\n",
      "INFO: [2025-06-27 16:35:41] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:41] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:   1%|          | 1/92 [00:00<00:24,  3.72it/s]INFO: [2025-06-27 16:35:41] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/31160008118740626\n",
      "INFO: [2025-06-27 16:35:41] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:41] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:   2%|‚ñè         | 2/92 [00:00<00:35,  2.51it/s]INFO: [2025-06-27 16:35:42] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/33874939274212480\n",
      "INFO: [2025-06-27 16:35:42] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:42] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:   3%|‚ñé         | 3/92 [00:01<00:29,  2.97it/s]INFO: [2025-06-27 16:35:42] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-32399727139857751\n",
      "INFO: [2025-06-27 16:35:42] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:42] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:   4%|‚ñç         | 4/92 [00:01<00:26,  3.29it/s]INFO: [2025-06-27 16:35:42] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/9371935612488149\n",
      "INFO: [2025-06-27 16:35:42] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:42] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:   5%|‚ñå         | 5/92 [00:01<00:25,  3.47it/s]INFO: [2025-06-27 16:35:42] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/3246604237187558\n",
      "INFO: [2025-06-27 16:35:42] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:42] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:   7%|‚ñã         | 6/92 [00:01<00:23,  3.60it/s]INFO: [2025-06-27 16:35:43] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/9130628937861941\n",
      "INFO: [2025-06-27 16:35:43] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:43] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:   8%|‚ñä         | 7/92 [00:02<00:29,  2.88it/s]INFO: [2025-06-27 16:35:43] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/19706388665464256\n",
      "INFO: [2025-06-27 16:35:43] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:43] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:   9%|‚ñä         | 8/92 [00:02<00:26,  3.13it/s]INFO: [2025-06-27 16:35:43] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-14556452501867428\n",
      "INFO: [2025-06-27 16:35:43] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:43] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  10%|‚ñâ         | 9/92 [00:02<00:25,  3.30it/s]INFO: [2025-06-27 16:35:44] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/15114781201446083\n",
      "INFO: [2025-06-27 16:35:44] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:44] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  11%|‚ñà         | 10/92 [00:03<00:23,  3.46it/s]INFO: [2025-06-27 16:35:44] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/13290267870654994\n",
      "INFO: [2025-06-27 16:35:44] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:44] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  12%|‚ñà‚ñè        | 11/92 [00:03<00:22,  3.57it/s]INFO: [2025-06-27 16:35:44] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/30902335548899281\n",
      "INFO: [2025-06-27 16:35:44] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:44] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  13%|‚ñà‚ñé        | 12/92 [00:03<00:27,  2.91it/s]INFO: [2025-06-27 16:35:45] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/2135209076854093\n",
      "INFO: [2025-06-27 16:35:45] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:45] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  14%|‚ñà‚ñç        | 13/92 [00:04<00:25,  3.15it/s]INFO: [2025-06-27 16:35:45] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-18387380848780476\n",
      "INFO: [2025-06-27 16:35:45] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:45] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  15%|‚ñà‚ñå        | 14/92 [00:04<00:23,  3.33it/s]INFO: [2025-06-27 16:35:45] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/18933828397346607\n",
      "INFO: [2025-06-27 16:35:45] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:45] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  16%|‚ñà‚ñã        | 15/92 [00:04<00:22,  3.47it/s]INFO: [2025-06-27 16:35:45] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/20978307744432241\n",
      "INFO: [2025-06-27 16:35:45] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:45] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  17%|‚ñà‚ñã        | 16/92 [00:04<00:21,  3.56it/s]INFO: [2025-06-27 16:35:46] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-35102576635162472\n",
      "INFO: [2025-06-27 16:35:46] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:46] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  18%|‚ñà‚ñä        | 17/92 [00:05<00:25,  2.89it/s]INFO: [2025-06-27 16:35:46] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-7126418877828068\n",
      "INFO: [2025-06-27 16:35:46] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:46] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  20%|‚ñà‚ñâ        | 18/92 [00:05<00:23,  3.10it/s]INFO: [2025-06-27 16:35:46] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-19952367157294119\n",
      "INFO: [2025-06-27 16:35:46] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:46] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  21%|‚ñà‚ñà        | 19/92 [00:05<00:22,  3.19it/s]INFO: [2025-06-27 16:35:47] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-34105277816332298\n",
      "INFO: [2025-06-27 16:35:47] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:47] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  22%|‚ñà‚ñà‚ñè       | 20/92 [00:06<00:21,  3.35it/s]INFO: [2025-06-27 16:35:47] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-25725881202629826\n",
      "INFO: [2025-06-27 16:35:47] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:47] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  23%|‚ñà‚ñà‚ñé       | 21/92 [00:06<00:20,  3.41it/s]INFO: [2025-06-27 16:35:47] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-2046863695546735\n",
      "INFO: [2025-06-27 16:35:47] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:47] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  24%|‚ñà‚ñà‚ñç       | 22/92 [00:06<00:25,  2.74it/s]INFO: [2025-06-27 16:35:48] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/12631778325074772\n",
      "INFO: [2025-06-27 16:35:48] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:48] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  25%|‚ñà‚ñà‚ñå       | 23/92 [00:07<00:23,  2.98it/s]INFO: [2025-06-27 16:35:48] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-29122158203077245\n",
      "INFO: [2025-06-27 16:35:48] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:48] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  26%|‚ñà‚ñà‚ñå       | 24/92 [00:07<00:21,  3.15it/s]INFO: [2025-06-27 16:35:48] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-22627892168184181\n",
      "INFO: [2025-06-27 16:35:48] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:48] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  27%|‚ñà‚ñà‚ñã       | 25/92 [00:07<00:20,  3.31it/s]INFO: [2025-06-27 16:35:49] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/28030974524863734\n",
      "INFO: [2025-06-27 16:35:49] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:49] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  28%|‚ñà‚ñà‚ñä       | 26/92 [00:08<00:19,  3.43it/s]INFO: [2025-06-27 16:35:49] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-8639253709990781\n",
      "INFO: [2025-06-27 16:35:49] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:49] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  29%|‚ñà‚ñà‚ñâ       | 27/92 [00:08<00:18,  3.50it/s]INFO: [2025-06-27 16:35:49] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/33041281229298748\n",
      "INFO: [2025-06-27 16:35:49] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:49] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  30%|‚ñà‚ñà‚ñà       | 28/92 [00:08<00:22,  2.87it/s]INFO: [2025-06-27 16:35:50] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-26780953604978411\n",
      "INFO: [2025-06-27 16:35:50] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:50] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  32%|‚ñà‚ñà‚ñà‚ñè      | 29/92 [00:09<00:20,  3.09it/s]INFO: [2025-06-27 16:35:50] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-18949191324265795\n",
      "INFO: [2025-06-27 16:35:50] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:50] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  33%|‚ñà‚ñà‚ñà‚ñé      | 30/92 [00:09<00:19,  3.20it/s]INFO: [2025-06-27 16:35:50] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/1410763986151621\n",
      "INFO: [2025-06-27 16:35:50] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:50] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  34%|‚ñà‚ñà‚ñà‚ñé      | 31/92 [00:09<00:18,  3.36it/s]INFO: [2025-06-27 16:35:50] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/1739983631954371\n",
      "INFO: [2025-06-27 16:35:50] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:50] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  35%|‚ñà‚ñà‚ñà‚ñç      | 32/92 [00:09<00:16,  3.53it/s]INFO: [2025-06-27 16:35:51] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/5895544448831150\n",
      "INFO: [2025-06-27 16:35:51] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:51] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  36%|‚ñà‚ñà‚ñà‚ñå      | 33/92 [00:10<00:21,  2.70it/s]INFO: [2025-06-27 16:35:51] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/31202820582613161\n",
      "INFO: [2025-06-27 16:35:51] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:51] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  37%|‚ñà‚ñà‚ñà‚ñã      | 34/92 [00:10<00:20,  2.88it/s]INFO: [2025-06-27 16:35:52] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-35884737692158253\n",
      "INFO: [2025-06-27 16:35:52] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:52] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  38%|‚ñà‚ñà‚ñà‚ñä      | 35/92 [00:11<00:18,  3.11it/s]INFO: [2025-06-27 16:35:52] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-34803309266443718\n",
      "INFO: [2025-06-27 16:35:52] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:52] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  39%|‚ñà‚ñà‚ñà‚ñâ      | 36/92 [00:11<00:17,  3.27it/s]INFO: [2025-06-27 16:35:52] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-22499263970759753\n",
      "INFO: [2025-06-27 16:35:52] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:52] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  40%|‚ñà‚ñà‚ñà‚ñà      | 37/92 [00:11<00:16,  3.39it/s]INFO: [2025-06-27 16:35:52] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-12988782223228843\n",
      "INFO: [2025-06-27 16:35:52] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:52] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 38/92 [00:12<00:19,  2.70it/s]INFO: [2025-06-27 16:35:53] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-7666152121409895\n",
      "INFO: [2025-06-27 16:35:53] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:53] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 39/92 [00:12<00:17,  2.95it/s]INFO: [2025-06-27 16:35:53] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/21634894993301822\n",
      "INFO: [2025-06-27 16:35:53] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:53] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 40/92 [00:12<00:16,  3.14it/s]INFO: [2025-06-27 16:35:53] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/34364657708684419\n",
      "INFO: [2025-06-27 16:35:53] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:53] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 41/92 [00:12<00:15,  3.24it/s]INFO: [2025-06-27 16:35:54] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/10262358575052520\n",
      "INFO: [2025-06-27 16:35:54] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:54] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 42/92 [00:13<00:14,  3.34it/s]INFO: [2025-06-27 16:35:54] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/11111675784752136\n",
      "INFO: [2025-06-27 16:35:54] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:54] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 43/92 [00:13<00:18,  2.69it/s]INFO: [2025-06-27 16:35:55] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/12642450547914707\n",
      "INFO: [2025-06-27 16:35:55] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:55] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 44/92 [00:14<00:16,  2.92it/s]INFO: [2025-06-27 16:35:55] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/21893218624143108\n",
      "INFO: [2025-06-27 16:35:55] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:55] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 45/92 [00:14<00:15,  3.09it/s]INFO: [2025-06-27 16:35:55] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-24316712102315887\n",
      "INFO: [2025-06-27 16:35:55] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:55] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 46/92 [00:14<00:14,  3.28it/s]INFO: [2025-06-27 16:35:55] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-23507181552861323\n",
      "INFO: [2025-06-27 16:35:55] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:55] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 47/92 [00:14<00:13,  3.37it/s]INFO: [2025-06-27 16:35:56] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-18152182327560480\n",
      "INFO: [2025-06-27 16:35:56] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:56] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 48/92 [00:15<00:12,  3.50it/s]INFO: [2025-06-27 16:35:56] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/21321689889868872\n",
      "INFO: [2025-06-27 16:35:56] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:56] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 49/92 [00:15<00:15,  2.73it/s]INFO: [2025-06-27 16:35:56] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-12463996681673250\n",
      "INFO: [2025-06-27 16:35:56] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:56] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 50/92 [00:15<00:14,  2.83it/s]INFO: [2025-06-27 16:35:57] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-2139820121868237\n",
      "INFO: [2025-06-27 16:35:57] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:57] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 51/92 [00:16<00:13,  3.08it/s]INFO: [2025-06-27 16:35:57] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-1083216214855434\n",
      "INFO: [2025-06-27 16:35:57] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:57] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 52/92 [00:16<00:12,  3.23it/s]INFO: [2025-06-27 16:35:57] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/17131318242278983\n",
      "INFO: [2025-06-27 16:35:57] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:57] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 53/92 [00:16<00:11,  3.37it/s]INFO: [2025-06-27 16:35:58] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/20606471688970148\n",
      "INFO: [2025-06-27 16:35:58] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:58] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 54/92 [00:17<00:11,  3.43it/s]INFO: [2025-06-27 16:35:58] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/24584688051044679\n",
      "INFO: [2025-06-27 16:35:58] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:58] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 55/92 [00:17<00:10,  3.49it/s]INFO: [2025-06-27 16:35:58] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-25141892168903907\n",
      "INFO: [2025-06-27 16:35:58] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:58] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 56/92 [00:17<00:12,  2.83it/s]INFO: [2025-06-27 16:35:59] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-20439687097155111\n",
      "INFO: [2025-06-27 16:35:59] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:59] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 57/92 [00:18<00:11,  3.05it/s]INFO: [2025-06-27 16:35:59] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-15352348890731234\n",
      "INFO: [2025-06-27 16:35:59] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:59] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 58/92 [00:18<00:10,  3.26it/s]INFO: [2025-06-27 16:35:59] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-4938783110044412\n",
      "INFO: [2025-06-27 16:35:59] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:59] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 59/92 [00:18<00:09,  3.39it/s]INFO: [2025-06-27 16:35:59] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/17609986374660936\n",
      "INFO: [2025-06-27 16:35:59] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:35:59] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 60/92 [00:19<00:11,  2.71it/s]INFO: [2025-06-27 16:36:00] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/17681796354219824\n",
      "INFO: [2025-06-27 16:36:00] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:00] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 61/92 [00:19<00:12,  2.43it/s]INFO: [2025-06-27 16:36:00] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/35971629147007369\n",
      "INFO: [2025-06-27 16:36:00] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:00] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 62/92 [00:19<00:11,  2.71it/s]INFO: [2025-06-27 16:36:01] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-29415098045592940\n",
      "INFO: [2025-06-27 16:36:01] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:01] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 63/92 [00:20<00:09,  2.98it/s]INFO: [2025-06-27 16:36:01] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-28031656773092240\n",
      "INFO: [2025-06-27 16:36:01] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:01] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 64/92 [00:20<00:08,  3.17it/s]INFO: [2025-06-27 16:36:01] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-22849205778179846\n",
      "INFO: [2025-06-27 16:36:01] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:01] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 65/92 [00:20<00:08,  3.35it/s]INFO: [2025-06-27 16:36:01] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-18031556530033893\n",
      "INFO: [2025-06-27 16:36:01] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:02] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 66/92 [00:21<00:09,  2.61it/s]INFO: [2025-06-27 16:36:02] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-13505886640472175\n",
      "INFO: [2025-06-27 16:36:02] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:02] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 67/92 [00:21<00:08,  2.88it/s]INFO: [2025-06-27 16:36:02] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-6735076600090236\n",
      "INFO: [2025-06-27 16:36:02] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:02] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 68/92 [00:21<00:07,  3.13it/s]INFO: [2025-06-27 16:36:03] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-3409159551394617\n",
      "INFO: [2025-06-27 16:36:03] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:03] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 69/92 [00:22<00:06,  3.34it/s]INFO: [2025-06-27 16:36:03] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-2069452773758641\n",
      "INFO: [2025-06-27 16:36:03] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:03] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 70/92 [00:22<00:06,  3.51it/s]INFO: [2025-06-27 16:36:03] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/3297979118605018\n",
      "INFO: [2025-06-27 16:36:03] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:03] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 71/92 [00:22<00:07,  2.83it/s]INFO: [2025-06-27 16:36:04] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/10757094666506670\n",
      "INFO: [2025-06-27 16:36:04] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:04] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 72/92 [00:23<00:06,  3.08it/s]INFO: [2025-06-27 16:36:04] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/14377716460635733\n",
      "INFO: [2025-06-27 16:36:04] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:04] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 73/92 [00:23<00:05,  3.28it/s]INFO: [2025-06-27 16:36:04] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-33852347582520392\n",
      "INFO: [2025-06-27 16:36:04] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:04] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 74/92 [00:23<00:05,  3.54it/s]INFO: [2025-06-27 16:36:04] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-25655970173329808\n",
      "INFO: [2025-06-27 16:36:04] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:04] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 75/92 [00:23<00:04,  3.71it/s]INFO: [2025-06-27 16:36:05] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-22061102960387551\n",
      "INFO: [2025-06-27 16:36:05] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:05] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 76/92 [00:24<00:04,  3.31it/s]INFO: [2025-06-27 16:36:05] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-20155356540515066\n",
      "INFO: [2025-06-27 16:36:05] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:05] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 77/92 [00:24<00:04,  3.48it/s]INFO: [2025-06-27 16:36:05] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-14117628316152430\n",
      "INFO: [2025-06-27 16:36:05] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:05] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 78/92 [00:24<00:03,  3.58it/s]INFO: [2025-06-27 16:36:05] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-11019131917628364\n",
      "INFO: [2025-06-27 16:36:05] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:05] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 79/92 [00:25<00:04,  2.95it/s]INFO: [2025-06-27 16:36:06] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-10444363735373102\n",
      "INFO: [2025-06-27 16:36:06] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:06] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 80/92 [00:25<00:03,  3.15it/s]INFO: [2025-06-27 16:36:06] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-10033945991593843\n",
      "INFO: [2025-06-27 16:36:06] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:06] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 81/92 [00:25<00:03,  3.35it/s]INFO: [2025-06-27 16:36:06] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-184811282650788\n",
      "INFO: [2025-06-27 16:36:06] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:06] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 82/92 [00:26<00:02,  3.48it/s]INFO: [2025-06-27 16:36:07] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/5566930627431303\n",
      "INFO: [2025-06-27 16:36:07] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:07] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 83/92 [00:26<00:02,  3.62it/s]INFO: [2025-06-27 16:36:07] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/5609203557180661\n",
      "INFO: [2025-06-27 16:36:07] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:07] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 84/92 [00:26<00:02,  3.00it/s]INFO: [2025-06-27 16:36:07] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/15133418971654738\n",
      "INFO: [2025-06-27 16:36:07] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:07] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 85/92 [00:26<00:02,  3.23it/s]INFO: [2025-06-27 16:36:08] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/15568847793479266\n",
      "INFO: [2025-06-27 16:36:08] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:08] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 86/92 [00:27<00:01,  3.39it/s]INFO: [2025-06-27 16:36:08] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/17470512188912087\n",
      "INFO: [2025-06-27 16:36:08] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:08] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 87/92 [00:27<00:01,  3.42it/s]INFO: [2025-06-27 16:36:08] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/18334778860223615\n",
      "INFO: [2025-06-27 16:36:08] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:08] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 88/92 [00:27<00:01,  3.47it/s]INFO: [2025-06-27 16:36:09] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/19367730649708653\n",
      "INFO: [2025-06-27 16:36:09] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:09] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 89/92 [00:28<00:01,  2.87it/s]INFO: [2025-06-27 16:36:09] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/30634204597194783\n",
      "INFO: [2025-06-27 16:36:09] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:09] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 90/92 [00:28<00:00,  3.05it/s]INFO: [2025-06-27 16:36:09] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/30759839524016550\n",
      "INFO: [2025-06-27 16:36:09] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:09] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 91/92 [00:28<00:00,  3.23it/s]INFO: [2025-06-27 16:36:10] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/31420388280123621\n",
      "INFO: [2025-06-27 16:36:10] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:10] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 92/92 [00:29<00:00,  3.16it/s]\n",
      "Processing LLM curations:   0%|          | 0/92 [00:00<?, ?it/s]INFO: [2025-06-27 16:36:10] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-35882458128194165/1416996966377381290\n",
      "INFO: [2025-06-27 16:36:10] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:10] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:10] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:10] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-35882458128194165/-6353069723196054921\n",
      "INFO: [2025-06-27 16:36:10] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:10] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:11] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:11] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-35882458128194165/4754713970825238213\n",
      "INFO: [2025-06-27 16:36:11] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:11] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:11] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:11] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-35882458128194165/5903862648251449582\n",
      "INFO: [2025-06-27 16:36:11] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:11] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:11] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:11] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-35882458128194165/5034172504052608728\n",
      "INFO: [2025-06-27 16:36:11] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:11] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:11] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:   1%|          | 1/92 [00:01<02:25,  1.59s/it]INFO: [2025-06-27 16:36:11] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/31160008118740626/2699504678203211304\n",
      "INFO: [2025-06-27 16:36:11] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:11] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:12] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:12] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/31160008118740626/8689729849380308038\n",
      "INFO: [2025-06-27 16:36:12] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:12] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:12] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:12] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/31160008118740626/6765310867218114848\n",
      "INFO: [2025-06-27 16:36:12] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:12] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:12] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:12] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/31160008118740626/8260868867431518761\n",
      "INFO: [2025-06-27 16:36:12] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:12] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:13] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:13] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/31160008118740626/-7521514115245079882\n",
      "INFO: [2025-06-27 16:36:13] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:13] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:13] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:   2%|‚ñè         | 2/92 [00:03<02:22,  1.59s/it]INFO: [2025-06-27 16:36:13] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/33874939274212480/-6002100917090733265\n",
      "INFO: [2025-06-27 16:36:13] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:13] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:13] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:13] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/33874939274212480/-7319071814075555632\n",
      "INFO: [2025-06-27 16:36:13] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:13] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:14] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:14] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/33874939274212480/2428811343678749251\n",
      "INFO: [2025-06-27 16:36:14] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:14] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:14] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:14] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/33874939274212480/-8939504886760873647\n",
      "INFO: [2025-06-27 16:36:14] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:14] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:14] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:14] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/33874939274212480/2258460702695255562\n",
      "INFO: [2025-06-27 16:36:14] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:14] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:15] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:   3%|‚ñé         | 3/92 [00:04<02:23,  1.61s/it]INFO: [2025-06-27 16:36:15] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-32399727139857751/6127463270847829718\n",
      "INFO: [2025-06-27 16:36:15] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:15] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:15] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:15] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-32399727139857751/6999750910535732529\n",
      "INFO: [2025-06-27 16:36:15] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:15] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:15] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:15] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-32399727139857751/2789203237128035699\n",
      "INFO: [2025-06-27 16:36:15] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:15] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:16] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:16] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-32399727139857751/991939334722254947\n",
      "INFO: [2025-06-27 16:36:16] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:16] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:16] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:16] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-32399727139857751/7106275797853920609\n",
      "INFO: [2025-06-27 16:36:16] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:16] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:16] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:   4%|‚ñç         | 4/92 [00:06<02:22,  1.62s/it]INFO: [2025-06-27 16:36:16] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/9371935612488149/6952546342211378665\n",
      "INFO: [2025-06-27 16:36:16] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:16] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:17] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:17] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/9371935612488149/-2620906938186192648\n",
      "INFO: [2025-06-27 16:36:17] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:17] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:17] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:17] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/9371935612488149/4809604684171118448\n",
      "INFO: [2025-06-27 16:36:17] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:17] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:17] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:17] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/9371935612488149/4726632211733119181\n",
      "INFO: [2025-06-27 16:36:17] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:17] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:18] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:18] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/9371935612488149/-3265063049454459232\n",
      "INFO: [2025-06-27 16:36:18] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:18] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:18] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:   5%|‚ñå         | 5/92 [00:08<02:22,  1.64s/it]INFO: [2025-06-27 16:36:18] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/3246604237187558/-9099153705661138156\n",
      "INFO: [2025-06-27 16:36:18] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:18] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:18] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:18] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/3246604237187558/-791784938196786423\n",
      "INFO: [2025-06-27 16:36:18] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:18] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:19] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:19] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/3246604237187558/8566933334316170694\n",
      "INFO: [2025-06-27 16:36:19] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:19] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:19] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:   7%|‚ñã         | 6/92 [00:08<01:56,  1.36s/it]INFO: [2025-06-27 16:36:19] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/9130628937861941/6102501705391300747\n",
      "INFO: [2025-06-27 16:36:19] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:19] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:19] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:19] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/9130628937861941/-3080637902455927628\n",
      "INFO: [2025-06-27 16:36:19] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:19] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:19] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:19] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/9130628937861941/-713310756905583794\n",
      "INFO: [2025-06-27 16:36:19] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:19] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:20] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:20] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/9130628937861941/1673812789977996832\n",
      "INFO: [2025-06-27 16:36:20] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:20] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:20] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:20] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/9130628937861941/5670777190210400019\n",
      "INFO: [2025-06-27 16:36:20] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:20] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:20] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:   8%|‚ñä         | 7/92 [00:10<02:01,  1.43s/it]INFO: [2025-06-27 16:36:20] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/19706388665464256/6670240488292146788\n",
      "INFO: [2025-06-27 16:36:20] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:20] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:21] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:21] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/19706388665464256/4531731915733805019\n",
      "INFO: [2025-06-27 16:36:21] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:21] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:21] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:21] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/19706388665464256/-2315041708459279496\n",
      "INFO: [2025-06-27 16:36:21] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:21] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:21] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:21] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/19706388665464256/-2660553431106459469\n",
      "INFO: [2025-06-27 16:36:21] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:21] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:22] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:22] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/19706388665464256/3312037597929625428\n",
      "INFO: [2025-06-27 16:36:22] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:22] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:22] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:   9%|‚ñä         | 8/92 [00:12<02:04,  1.48s/it]INFO: [2025-06-27 16:36:22] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-14556452501867428/-603801183153556545\n",
      "INFO: [2025-06-27 16:36:22] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:22] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:22] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:22] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-14556452501867428/-1236537068805516528\n",
      "INFO: [2025-06-27 16:36:22] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:22] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:22] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:22] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-14556452501867428/9118275356313733531\n",
      "INFO: [2025-06-27 16:36:22] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:22] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:23] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:23] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-14556452501867428/-5757091038381330345\n",
      "INFO: [2025-06-27 16:36:23] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:23] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:23] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:23] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-14556452501867428/-2861455366859779699\n",
      "INFO: [2025-06-27 16:36:23] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:23] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:24] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  10%|‚ñâ         | 9/92 [00:13<02:05,  1.51s/it]INFO: [2025-06-27 16:36:24] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/15114781201446083/-6818851971177365876\n",
      "INFO: [2025-06-27 16:36:24] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:24] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:24] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:24] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/15114781201446083/8072615833711619468\n",
      "INFO: [2025-06-27 16:36:24] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:24] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:24] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:24] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/15114781201446083/228298746317806038\n",
      "INFO: [2025-06-27 16:36:24] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:24] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:24] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:24] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/15114781201446083/8237567953636275636\n",
      "INFO: [2025-06-27 16:36:24] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:24] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:25] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:25] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/15114781201446083/5394718880099235095\n",
      "INFO: [2025-06-27 16:36:25] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:25] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:25] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  11%|‚ñà         | 10/92 [00:15<02:07,  1.55s/it]INFO: [2025-06-27 16:36:25] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/13290267870654994/-7816016630472316549\n",
      "INFO: [2025-06-27 16:36:25] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:25] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:25] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:25] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/13290267870654994/6147374846986812775\n",
      "INFO: [2025-06-27 16:36:25] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:25] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:26] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:26] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/13290267870654994/5570528903892119013\n",
      "INFO: [2025-06-27 16:36:26] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:26] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:26] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:26] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/13290267870654994/1959993206282636872\n",
      "INFO: [2025-06-27 16:36:26] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:26] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:26] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:26] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/13290267870654994/6753800194953217566\n",
      "INFO: [2025-06-27 16:36:26] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:26] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:27] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  12%|‚ñà‚ñè        | 11/92 [00:16<02:05,  1.54s/it]INFO: [2025-06-27 16:36:27] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/30902335548899281/1808680440018708901\n",
      "INFO: [2025-06-27 16:36:27] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:27] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:27] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:27] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/30902335548899281/-1336191485702648356\n",
      "INFO: [2025-06-27 16:36:27] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:27] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:27] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:27] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/30902335548899281/-6652731411323155510\n",
      "INFO: [2025-06-27 16:36:27] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:27] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:28] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:28] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/30902335548899281/8969438097819927127\n",
      "INFO: [2025-06-27 16:36:28] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:28] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:28] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:28] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/30902335548899281/5205855036769276965\n",
      "INFO: [2025-06-27 16:36:28] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:28] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  13%|‚ñà‚ñé        | 12/92 [00:18<02:03,  1.54s/it]INFO: [2025-06-27 16:36:28] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/2135209076854093/4925360230877813612\n",
      "INFO: [2025-06-27 16:36:28] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:28] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:29] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:29] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/2135209076854093/-4209768342817491963\n",
      "INFO: [2025-06-27 16:36:29] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:29] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:29] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:29] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/2135209076854093/-704936703318863953\n",
      "INFO: [2025-06-27 16:36:29] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:29] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:29] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:29] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/2135209076854093/-953130661669382724\n",
      "INFO: [2025-06-27 16:36:29] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:29] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:30] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:30] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/2135209076854093/4822584435461119374\n",
      "INFO: [2025-06-27 16:36:30] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:30] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:30] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  14%|‚ñà‚ñç        | 13/92 [00:20<02:04,  1.57s/it]INFO: [2025-06-27 16:36:30] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-18387380848780476/4633550929731348385\n",
      "INFO: [2025-06-27 16:36:30] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:30] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:30] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:30] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-18387380848780476/6849826706501229990\n",
      "INFO: [2025-06-27 16:36:30] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:30] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:31] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:31] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-18387380848780476/7206489609635607037\n",
      "INFO: [2025-06-27 16:36:31] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:31] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:31] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:31] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-18387380848780476/-4390742723280575418\n",
      "INFO: [2025-06-27 16:36:31] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:31] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:31] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:31] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-18387380848780476/1380099258313743549\n",
      "INFO: [2025-06-27 16:36:31] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:31] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:32] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  15%|‚ñà‚ñå        | 14/92 [00:21<02:04,  1.60s/it]INFO: [2025-06-27 16:36:32] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/18933828397346607/-1459031336310233984\n",
      "INFO: [2025-06-27 16:36:32] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:32] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:32] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:32] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/18933828397346607/8144908962393550932\n",
      "INFO: [2025-06-27 16:36:32] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:32] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:32] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:32] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/18933828397346607/-7537860977181531859\n",
      "INFO: [2025-06-27 16:36:32] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:32] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:32] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:32] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/18933828397346607/-437721026997757692\n",
      "INFO: [2025-06-27 16:36:32] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:32] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:33] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:33] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/18933828397346607/7704141734720067409\n",
      "INFO: [2025-06-27 16:36:33] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:33] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:33] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  16%|‚ñà‚ñã        | 15/92 [00:23<01:57,  1.52s/it]INFO: [2025-06-27 16:36:33] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/20978307744432241/2471877639653037837\n",
      "INFO: [2025-06-27 16:36:33] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:33] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:33] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:33] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/20978307744432241/-2380844828216300110\n",
      "INFO: [2025-06-27 16:36:33] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:33] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:34] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:34] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/20978307744432241/7208167864352268766\n",
      "INFO: [2025-06-27 16:36:34] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:34] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:34] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:34] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/20978307744432241/-3539338498554117161\n",
      "INFO: [2025-06-27 16:36:34] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:34] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:34] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:34] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/20978307744432241/2153480888699432257\n",
      "INFO: [2025-06-27 16:36:34] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:34] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:35] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  17%|‚ñà‚ñã        | 16/92 [00:24<01:58,  1.56s/it]INFO: [2025-06-27 16:36:35] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-35102576635162472/4507388797805457656\n",
      "INFO: [2025-06-27 16:36:35] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:35] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:35] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:35] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-35102576635162472/1840744920579623191\n",
      "INFO: [2025-06-27 16:36:35] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:35] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:35] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:35] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-35102576635162472/-8370254754651504175\n",
      "INFO: [2025-06-27 16:36:35] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:35] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:36] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:36] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-35102576635162472/261491495482355979\n",
      "INFO: [2025-06-27 16:36:36] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:36] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:36] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:36] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-35102576635162472/7876086009799354153\n",
      "INFO: [2025-06-27 16:36:36] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:36] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:36] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  18%|‚ñà‚ñä        | 17/92 [00:26<01:58,  1.58s/it]INFO: [2025-06-27 16:36:36] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-7126418877828068/3698836681160583277\n",
      "INFO: [2025-06-27 16:36:36] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:36] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:36] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:36] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-7126418877828068/-8498377039219930536\n",
      "INFO: [2025-06-27 16:36:36] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:36] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:37] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-7126418877828068/5548902811071695424\n",
      "INFO: [2025-06-27 16:36:37] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:37] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:37] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:37] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-7126418877828068/2156936580174931839\n",
      "INFO: [2025-06-27 16:36:37] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:37] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:38] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:38] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-7126418877828068/-947879101148943417\n",
      "INFO: [2025-06-27 16:36:38] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:38] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:38] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  20%|‚ñà‚ñâ        | 18/92 [00:27<01:58,  1.60s/it]INFO: [2025-06-27 16:36:38] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-19952367157294119/3301859932289183865\n",
      "INFO: [2025-06-27 16:36:38] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:38] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:38] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:38] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-19952367157294119/8759575376421538679\n",
      "INFO: [2025-06-27 16:36:38] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:38] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:39] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:39] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-19952367157294119/2714524897101736757\n",
      "INFO: [2025-06-27 16:36:39] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:39] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:39] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:39] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-19952367157294119/-7068343234270138822\n",
      "INFO: [2025-06-27 16:36:39] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:39] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:39] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-19952367157294119/-160071166771824000\n",
      "INFO: [2025-06-27 16:36:39] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:39] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:40] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  21%|‚ñà‚ñà        | 19/92 [00:29<01:58,  1.63s/it]INFO: [2025-06-27 16:36:40] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-34105277816332298/7497714690546091678\n",
      "INFO: [2025-06-27 16:36:40] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:40] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:40] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:40] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-34105277816332298/-5559266694144991972\n",
      "INFO: [2025-06-27 16:36:40] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:40] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:40] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:40] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-34105277816332298/-199773222473723799\n",
      "INFO: [2025-06-27 16:36:40] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:40] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:41] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:41] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-34105277816332298/8271289617235224755\n",
      "INFO: [2025-06-27 16:36:41] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:41] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:41] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-34105277816332298/-3296131406307922315\n",
      "INFO: [2025-06-27 16:36:41] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:41] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:41] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  22%|‚ñà‚ñà‚ñè       | 20/92 [00:31<01:58,  1.64s/it]INFO: [2025-06-27 16:36:41] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-25725881202629826/959844913786547811\n",
      "INFO: [2025-06-27 16:36:41] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:41] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:41] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:41] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-25725881202629826/5193683310712633212\n",
      "INFO: [2025-06-27 16:36:41] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:41] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:42] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:42] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-25725881202629826/3827571618038816859\n",
      "INFO: [2025-06-27 16:36:42] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:42] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:42] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:42] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-25725881202629826/3126028315336764185\n",
      "INFO: [2025-06-27 16:36:42] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:42] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:42] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:42] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-25725881202629826/6958396776840245518\n",
      "INFO: [2025-06-27 16:36:42] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:42] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:43] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  23%|‚ñà‚ñà‚ñé       | 21/92 [00:32<01:54,  1.62s/it]INFO: [2025-06-27 16:36:43] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-2046863695546735/-2805098949379304551\n",
      "INFO: [2025-06-27 16:36:43] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:43] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:43] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:43] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-2046863695546735/-2151397681958392832\n",
      "INFO: [2025-06-27 16:36:43] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:43] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:43] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:43] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-2046863695546735/7914887876818812230\n",
      "INFO: [2025-06-27 16:36:43] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:43] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:44] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:44] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-2046863695546735/7697599753519692244\n",
      "INFO: [2025-06-27 16:36:44] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:44] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:44] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:44] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-2046863695546735/3620453558191741055\n",
      "INFO: [2025-06-27 16:36:44] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:44] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:44] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  24%|‚ñà‚ñà‚ñç       | 22/92 [00:34<01:53,  1.62s/it]INFO: [2025-06-27 16:36:44] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/12631778325074772/-1133160081467918843\n",
      "INFO: [2025-06-27 16:36:44] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:44] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:45] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:45] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/12631778325074772/-334635241658427994\n",
      "INFO: [2025-06-27 16:36:45] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:45] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:45] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:45] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/12631778325074772/4226092333848393175\n",
      "INFO: [2025-06-27 16:36:45] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:45] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:45] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:45] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/12631778325074772/-5156252880374989973\n",
      "INFO: [2025-06-27 16:36:45] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:45] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:46] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:46] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/12631778325074772/2814719382815597820\n",
      "INFO: [2025-06-27 16:36:46] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:46] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:46] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  25%|‚ñà‚ñà‚ñå       | 23/92 [00:36<01:51,  1.61s/it]INFO: [2025-06-27 16:36:46] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-29122158203077245/4668168701668402186\n",
      "INFO: [2025-06-27 16:36:46] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:46] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:46] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:46] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-29122158203077245/7928238699329657201\n",
      "INFO: [2025-06-27 16:36:46] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:46] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:47] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:47] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-29122158203077245/-7468533896966433990\n",
      "INFO: [2025-06-27 16:36:47] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:47] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:47] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-29122158203077245/-6544929051100552273\n",
      "INFO: [2025-06-27 16:36:47] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:47] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:47] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:47] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-29122158203077245/5489404389924434337\n",
      "INFO: [2025-06-27 16:36:47] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:47] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:48] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  26%|‚ñà‚ñà‚ñå       | 24/92 [00:37<01:49,  1.61s/it]INFO: [2025-06-27 16:36:48] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-22627892168184181/-3313738103646048618\n",
      "INFO: [2025-06-27 16:36:48] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:48] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:48] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:48] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-22627892168184181/-6121287522203766477\n",
      "INFO: [2025-06-27 16:36:48] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:48] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:48] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:48] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-22627892168184181/-4556705642132470901\n",
      "INFO: [2025-06-27 16:36:48] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:48] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:49] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:49] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-22627892168184181/1111188242320460874\n",
      "INFO: [2025-06-27 16:36:49] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:49] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:49] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:49] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-22627892168184181/5950900051614206853\n",
      "INFO: [2025-06-27 16:36:49] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:49] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:49] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  27%|‚ñà‚ñà‚ñã       | 25/92 [00:39<01:46,  1.59s/it]INFO: [2025-06-27 16:36:49] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/28030974524863734/5146472025607600600\n",
      "INFO: [2025-06-27 16:36:49] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:49] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:49] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:49] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/28030974524863734/2035246656474436993\n",
      "INFO: [2025-06-27 16:36:49] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:49] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:50] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:50] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/28030974524863734/41096803244585387\n",
      "INFO: [2025-06-27 16:36:50] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:50] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:50] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:50] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/28030974524863734/-906639502994899913\n",
      "INFO: [2025-06-27 16:36:50] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:50] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:50] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:50] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/28030974524863734/-1590371137899306177\n",
      "INFO: [2025-06-27 16:36:50] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:50] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:51] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  28%|‚ñà‚ñà‚ñä       | 26/92 [00:40<01:44,  1.59s/it]INFO: [2025-06-27 16:36:51] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-8639253709990781/716383431881062025\n",
      "INFO: [2025-06-27 16:36:51] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:51] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:51] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:51] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-8639253709990781/-3246872346744851883\n",
      "INFO: [2025-06-27 16:36:51] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:51] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:51] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:51] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-8639253709990781/-9081180296623689939\n",
      "INFO: [2025-06-27 16:36:51] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:51] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:52] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:52] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-8639253709990781/8895919881072540994\n",
      "INFO: [2025-06-27 16:36:52] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:52] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:52] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:52] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-8639253709990781/2700726683991673132\n",
      "INFO: [2025-06-27 16:36:52] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:52] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:52] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  29%|‚ñà‚ñà‚ñâ       | 27/92 [00:42<01:43,  1.59s/it]INFO: [2025-06-27 16:36:52] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/33041281229298748/-3758581595036284288\n",
      "INFO: [2025-06-27 16:36:52] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:52] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:53] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:53] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/33041281229298748/6689670555803518009\n",
      "INFO: [2025-06-27 16:36:53] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:53] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:53] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:53] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/33041281229298748/-3842792248032066274\n",
      "INFO: [2025-06-27 16:36:53] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:53] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:53] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:53] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/33041281229298748/3893490209951573235\n",
      "INFO: [2025-06-27 16:36:53] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:53] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:54] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:54] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/33041281229298748/1967083863833861440\n",
      "INFO: [2025-06-27 16:36:54] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:54] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:54] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  30%|‚ñà‚ñà‚ñà       | 28/92 [00:43<01:40,  1.58s/it]INFO: [2025-06-27 16:36:54] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-26780953604978411/-5575280606509183888\n",
      "INFO: [2025-06-27 16:36:54] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:54] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:54] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:54] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-26780953604978411/-4056295328900878257\n",
      "INFO: [2025-06-27 16:36:54] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:54] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:54] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:54] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-26780953604978411/-4250877145294801920\n",
      "INFO: [2025-06-27 16:36:54] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:54] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:55] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:55] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-26780953604978411/-2100308078671207313\n",
      "INFO: [2025-06-27 16:36:55] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:55] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:55] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:55] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-26780953604978411/-5575280606509183888\n",
      "INFO: [2025-06-27 16:36:55] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:55] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:55] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  32%|‚ñà‚ñà‚ñà‚ñè      | 29/92 [00:45<01:40,  1.59s/it]INFO: [2025-06-27 16:36:55] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-18949191324265795/-49564332575376769\n",
      "INFO: [2025-06-27 16:36:55] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:55] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:56] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:56] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-18949191324265795/-7412386992750855525\n",
      "INFO: [2025-06-27 16:36:56] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:56] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:56] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:56] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-18949191324265795/-7996588531648180442\n",
      "INFO: [2025-06-27 16:36:56] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:56] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:56] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:56] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-18949191324265795/-6770950505668158144\n",
      "INFO: [2025-06-27 16:36:56] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:56] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:57] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:57] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-18949191324265795/5149324403950530182\n",
      "INFO: [2025-06-27 16:36:57] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:57] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:57] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  33%|‚ñà‚ñà‚ñà‚ñé      | 30/92 [00:47<01:37,  1.57s/it]INFO: [2025-06-27 16:36:57] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/1410763986151621/-5303531952248046704\n",
      "INFO: [2025-06-27 16:36:57] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:57] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:57] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:57] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/1410763986151621/-957945175582104365\n",
      "INFO: [2025-06-27 16:36:57] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:57] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:58] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:58] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/1410763986151621/7698876637308498112\n",
      "INFO: [2025-06-27 16:36:58] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:58] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:58] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:58] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/1410763986151621/6008240046730494545\n",
      "INFO: [2025-06-27 16:36:58] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:58] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:58] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:58] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/1410763986151621/-4676444358467089678\n",
      "INFO: [2025-06-27 16:36:58] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:58] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:59] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  34%|‚ñà‚ñà‚ñà‚ñé      | 31/92 [00:48<01:36,  1.58s/it]INFO: [2025-06-27 16:36:59] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/1739983631954371/-1437531335538991507\n",
      "INFO: [2025-06-27 16:36:59] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:59] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:59] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:36:59] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/1739983631954371/-2641372761280601706\n",
      "INFO: [2025-06-27 16:36:59] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:59] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:59] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/1739983631954371/-6021349484732747496\n",
      "INFO: [2025-06-27 16:36:59] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:59] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:36:59] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/1739983631954371/-4724646644972343183\n",
      "INFO: [2025-06-27 16:36:59] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:36:59] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:00] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/1739983631954371/-1248106465604525997\n",
      "INFO: [2025-06-27 16:37:00] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:00] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  35%|‚ñà‚ñà‚ñà‚ñç      | 32/92 [00:50<01:40,  1.67s/it]INFO: [2025-06-27 16:37:00] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/5895544448831150/-5678493114848982685\n",
      "INFO: [2025-06-27 16:37:00] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:00] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:01] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:37:01] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/5895544448831150/4677892577581706602\n",
      "INFO: [2025-06-27 16:37:01] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:01] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  36%|‚ñà‚ñà‚ñà‚ñå      | 33/92 [00:51<01:18,  1.33s/it]INFO: [2025-06-27 16:37:01] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/31202820582613161/1302862404895722931\n",
      "INFO: [2025-06-27 16:37:01] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:01] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:01] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:37:01] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/31202820582613161/-4710755148228645402\n",
      "INFO: [2025-06-27 16:37:01] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:01] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:02] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:37:02] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/31202820582613161/-5485648695080232873\n",
      "INFO: [2025-06-27 16:37:02] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:02] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:02] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:37:02] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/31202820582613161/1241460319809503127\n",
      "INFO: [2025-06-27 16:37:02] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:02] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:02] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:37:02] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/31202820582613161/7174666733000882265\n",
      "INFO: [2025-06-27 16:37:02] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:02] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:03] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  37%|‚ñà‚ñà‚ñà‚ñã      | 34/92 [00:52<01:21,  1.41s/it]INFO: [2025-06-27 16:37:03] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-35884737692158253/7359123353474896078\n",
      "INFO: [2025-06-27 16:37:03] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:03] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:03] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:37:03] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-35884737692158253/1059193101662654198\n",
      "INFO: [2025-06-27 16:37:03] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:03] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:03] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:37:03] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-35884737692158253/-851255063151224319\n",
      "INFO: [2025-06-27 16:37:03] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:03] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:03] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:37:03] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-35884737692158253/-4181607857325202442\n",
      "INFO: [2025-06-27 16:37:03] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:03] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:04] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:37:04] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-35884737692158253/-6004749260235273668\n",
      "INFO: [2025-06-27 16:37:04] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:04] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:04] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  38%|‚ñà‚ñà‚ñà‚ñä      | 35/92 [00:54<01:23,  1.46s/it]INFO: [2025-06-27 16:37:04] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-34803309266443718/1711775163034602511\n",
      "INFO: [2025-06-27 16:37:04] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:04] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:04] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:37:04] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-34803309266443718/3380995278001123487\n",
      "INFO: [2025-06-27 16:37:04] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:04] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:05] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:37:05] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-34803309266443718/7981458785385132121\n",
      "INFO: [2025-06-27 16:37:05] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:05] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:05] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:37:05] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-34803309266443718/8704463689891911278\n",
      "INFO: [2025-06-27 16:37:05] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:05] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:05] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:37:05] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-34803309266443718/8104683881023840410\n",
      "INFO: [2025-06-27 16:37:05] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:05] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  39%|‚ñà‚ñà‚ñà‚ñâ      | 36/92 [00:55<01:23,  1.48s/it]INFO: [2025-06-27 16:37:06] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-22499263970759753/623588335874424306\n",
      "INFO: [2025-06-27 16:37:06] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:06] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:06] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-22499263970759753/-5811406536058053449\n",
      "INFO: [2025-06-27 16:37:06] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:06] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:06] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-22499263970759753/-8230480911474175565\n",
      "INFO: [2025-06-27 16:37:06] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:06] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:07] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:37:07] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-22499263970759753/4839793808578026488\n",
      "INFO: [2025-06-27 16:37:07] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:07] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:07] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-22499263970759753/5672304901974974070\n",
      "INFO: [2025-06-27 16:37:07] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:07] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  40%|‚ñà‚ñà‚ñà‚ñà      | 37/92 [00:57<01:24,  1.53s/it]INFO: [2025-06-27 16:37:07] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-12988782223228843/8148382400078380983\n",
      "INFO: [2025-06-27 16:37:07] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:07] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:08] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-12988782223228843/9148695508442837630\n",
      "INFO: [2025-06-27 16:37:08] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:08] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:08] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-12988782223228843/-7639492274974046551\n",
      "INFO: [2025-06-27 16:37:08] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:08] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:08] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-12988782223228843/-6281577041156644526\n",
      "INFO: [2025-06-27 16:37:08] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:08] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:09] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-12988782223228843/935323826139098089\n",
      "INFO: [2025-06-27 16:37:09] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:09] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 38/92 [00:59<01:22,  1.52s/it]INFO: [2025-06-27 16:37:09] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-7666152121409895/-5116808700954080261\n",
      "INFO: [2025-06-27 16:37:09] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:09] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:09] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:37:09] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-7666152121409895/-4085553015115928194\n",
      "INFO: [2025-06-27 16:37:09] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:09] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:09] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-7666152121409895/6926593929266073454\n",
      "INFO: [2025-06-27 16:37:09] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:09] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:10] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:37:10] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-7666152121409895/4498186992857338885\n",
      "INFO: [2025-06-27 16:37:10] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:10] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:10] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:37:10] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-7666152121409895/5957595400114768462\n",
      "INFO: [2025-06-27 16:37:10] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:10] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:10] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 39/92 [01:00<01:17,  1.46s/it]INFO: [2025-06-27 16:37:10] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/21634894993301822/1225585874383749432\n",
      "INFO: [2025-06-27 16:37:10] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:10] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:11] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:37:11] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/21634894993301822/-5655673465455323402\n",
      "INFO: [2025-06-27 16:37:11] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:11] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:11] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:37:11] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/21634894993301822/947202408938575961\n",
      "INFO: [2025-06-27 16:37:11] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:11] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:11] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/21634894993301822/7556242793233433568\n",
      "INFO: [2025-06-27 16:37:11] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:11] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:12] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:37:12] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/21634894993301822/6324067640264457939\n",
      "INFO: [2025-06-27 16:37:12] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:12] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:12] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 40/92 [01:01<01:18,  1.51s/it]INFO: [2025-06-27 16:37:12] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/34364657708684419/-5121180977425523747\n",
      "INFO: [2025-06-27 16:37:12] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:12] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:12] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:37:12] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/34364657708684419/7667054288051095229\n",
      "INFO: [2025-06-27 16:37:12] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:12] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:13] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:37:13] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/34364657708684419/-899911900160667312\n",
      "INFO: [2025-06-27 16:37:13] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:13] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:13] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/34364657708684419/-4126053122944348706\n",
      "INFO: [2025-06-27 16:37:13] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:13] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:13] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:37:13] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/34364657708684419/1597240253355941547\n",
      "INFO: [2025-06-27 16:37:13] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:13] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:13] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 41/92 [01:03<01:17,  1.53s/it]INFO: [2025-06-27 16:37:13] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/10262358575052520/5193588747273290001\n",
      "INFO: [2025-06-27 16:37:13] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:13] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:14] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/10262358575052520/5413288797231960807\n",
      "INFO: [2025-06-27 16:37:14] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:14] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:14] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:37:14] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/10262358575052520/6384894172824164400\n",
      "INFO: [2025-06-27 16:37:14] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:14] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:14] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:37:14] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/10262358575052520/5193588747273290001\n",
      "INFO: [2025-06-27 16:37:14] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:14] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:15] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/10262358575052520/6384894172824164400\n",
      "INFO: [2025-06-27 16:37:15] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:15] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:15] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 42/92 [01:05<01:17,  1.54s/it]INFO: [2025-06-27 16:37:15] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/11111675784752136/-8333305609307516398\n",
      "INFO: [2025-06-27 16:37:15] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:15] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:15] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:37:15] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/11111675784752136/5350615363953520606\n",
      "INFO: [2025-06-27 16:37:15] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:15] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:16] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/11111675784752136/3350719506494207471\n",
      "INFO: [2025-06-27 16:37:16] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:16] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:16] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:37:16] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/11111675784752136/8348473771820280935\n",
      "INFO: [2025-06-27 16:37:16] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:16] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:16] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:37:16] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/11111675784752136/8342775031076687992\n",
      "INFO: [2025-06-27 16:37:16] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:16] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:17] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 43/92 [01:06<01:17,  1.58s/it]INFO: [2025-06-27 16:37:17] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/12642450547914707/8347204528152324975\n",
      "INFO: [2025-06-27 16:37:17] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:17] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:17] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:37:17] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/12642450547914707/2937249104658770404\n",
      "INFO: [2025-06-27 16:37:17] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:17] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:17] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:37:17] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/12642450547914707/-4863334710047129031\n",
      "INFO: [2025-06-27 16:37:17] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:17] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:18] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:37:18] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/12642450547914707/1968191420632676549\n",
      "INFO: [2025-06-27 16:37:18] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:18] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:18] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:37:18] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/12642450547914707/7620024638601426502\n",
      "INFO: [2025-06-27 16:37:18] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:18] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 44/92 [01:08<01:16,  1.60s/it]INFO: [2025-06-27 16:37:18] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/21893218624143108/573644746304192245\n",
      "INFO: [2025-06-27 16:37:18] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:18] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:19] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:37:19] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/21893218624143108/4145945370990674474\n",
      "INFO: [2025-06-27 16:37:19] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:19] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:19] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:37:19] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/21893218624143108/-4945713875907639718\n",
      "INFO: [2025-06-27 16:37:19] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:19] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:19] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:37:19] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/21893218624143108/7400069318801841774\n",
      "INFO: [2025-06-27 16:37:19] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:19] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:20] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:37:20] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/21893218624143108/-7327646880163051373\n",
      "INFO: [2025-06-27 16:37:20] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:20] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 45/92 [01:10<01:15,  1.60s/it]INFO: [2025-06-27 16:37:20] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-24316712102315887/2834571268812183428\n",
      "INFO: [2025-06-27 16:37:20] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:20] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:20] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:37:20] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-24316712102315887/3720793000583221964\n",
      "INFO: [2025-06-27 16:37:20] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:20] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:21] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:37:21] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-24316712102315887/5984152516802949451\n",
      "INFO: [2025-06-27 16:37:21] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:21] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:21] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:37:21] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-24316712102315887/-5150287373429888631\n",
      "INFO: [2025-06-27 16:37:21] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:21] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:21] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-24316712102315887/-8910198268186727635\n",
      "INFO: [2025-06-27 16:37:21] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:21] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:22] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 46/92 [01:11<01:14,  1.62s/it]INFO: [2025-06-27 16:37:22] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-23507181552861323/3510879047104264830\n",
      "INFO: [2025-06-27 16:37:22] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:22] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:22] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:37:22] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-23507181552861323/4137440517101656685\n",
      "INFO: [2025-06-27 16:37:22] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:22] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:22] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:37:22] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-23507181552861323/-8238821923278641850\n",
      "INFO: [2025-06-27 16:37:22] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:22] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:23] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-23507181552861323/6072207199438534637\n",
      "INFO: [2025-06-27 16:37:23] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:23] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:23] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:37:23] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-23507181552861323/-1262045258718203678\n",
      "INFO: [2025-06-27 16:37:23] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:23] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 47/92 [01:13<01:15,  1.69s/it]INFO: [2025-06-27 16:37:23] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-18152182327560480/-4341089490484079760\n",
      "INFO: [2025-06-27 16:37:23] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:23] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:24] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:37:24] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-18152182327560480/-2197564856973422755\n",
      "INFO: [2025-06-27 16:37:24] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:24] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:24] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-18152182327560480/1371242355701412014\n",
      "INFO: [2025-06-27 16:37:24] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:24] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:24] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:37:24] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-18152182327560480/-9126318783037784645\n",
      "INFO: [2025-06-27 16:37:24] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:24] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:25] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:37:25] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-18152182327560480/-2638948329676682937\n",
      "INFO: [2025-06-27 16:37:25] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:25] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:25] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 48/92 [01:14<01:10,  1.61s/it]INFO: [2025-06-27 16:37:25] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/21321689889868872/-3631827477176517536\n",
      "INFO: [2025-06-27 16:37:25] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:25] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:25] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:37:25] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/21321689889868872/4277189631399119518\n",
      "INFO: [2025-06-27 16:37:25] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:25] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:25] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:37:25] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/21321689889868872/-3029230678400443214\n",
      "INFO: [2025-06-27 16:37:25] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:25] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:26] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/21321689889868872/2513408173929564530\n",
      "INFO: [2025-06-27 16:37:26] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:26] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:26] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:37:26] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/21321689889868872/-2131663956400107588\n",
      "INFO: [2025-06-27 16:37:26] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:26] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:26] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 49/92 [01:16<01:06,  1.54s/it]INFO: [2025-06-27 16:37:26] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-12463996681673250/1001484088117419076\n",
      "INFO: [2025-06-27 16:37:26] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:26] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:27] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:37:27] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-12463996681673250/1208163505060035575\n",
      "INFO: [2025-06-27 16:37:27] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:27] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:27] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:37:27] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-12463996681673250/5809878820364426932\n",
      "INFO: [2025-06-27 16:37:27] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:27] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:27] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-12463996681673250/-4018071394199911570\n",
      "INFO: [2025-06-27 16:37:27] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:27] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:28] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 50/92 [01:17<01:02,  1.50s/it]INFO: [2025-06-27 16:37:28] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-2139820121868237/7174911214789188615\n",
      "INFO: [2025-06-27 16:37:28] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:28] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:28] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:37:28] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-2139820121868237/-3965648376808544436\n",
      "INFO: [2025-06-27 16:37:28] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:28] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:28] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-2139820121868237/9166163062695038631\n",
      "INFO: [2025-06-27 16:37:28] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:28] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:29] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:37:29] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-2139820121868237/-8809767266699174627\n",
      "INFO: [2025-06-27 16:37:29] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:29] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:29] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 51/92 [01:19<00:59,  1.45s/it]INFO: [2025-06-27 16:37:29] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-1083216214855434/1353217280393293418\n",
      "INFO: [2025-06-27 16:37:29] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:29] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:29] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-1083216214855434/-1961593601051792778\n",
      "INFO: [2025-06-27 16:37:29] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:29] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:29] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-1083216214855434/-8258993645454398472\n",
      "INFO: [2025-06-27 16:37:29] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:29] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:30] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:37:30] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-1083216214855434/-1435460781728290990\n",
      "INFO: [2025-06-27 16:37:30] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:30] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 52/92 [01:20<00:57,  1.43s/it]INFO: [2025-06-27 16:37:30] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/17131318242278983/1564341055827454194\n",
      "INFO: [2025-06-27 16:37:30] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:30] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:31] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:37:31] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/17131318242278983/6902031343714230598\n",
      "INFO: [2025-06-27 16:37:31] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:31] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:31] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/17131318242278983/7714819180289531073\n",
      "INFO: [2025-06-27 16:37:31] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:31] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:31] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:37:31] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/17131318242278983/4577407953817486235\n",
      "INFO: [2025-06-27 16:37:31] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:31] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:32] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 53/92 [01:21<00:53,  1.38s/it]INFO: [2025-06-27 16:37:32] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/20606471688970148/4584402743475666567\n",
      "INFO: [2025-06-27 16:37:32] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:32] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:32] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:37:32] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/20606471688970148/-4477833252834350399\n",
      "INFO: [2025-06-27 16:37:32] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:32] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:32] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:37:32] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/20606471688970148/2911353927501129219\n",
      "INFO: [2025-06-27 16:37:32] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:32] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:33] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:37:33] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/20606471688970148/6030815948872375181\n",
      "INFO: [2025-06-27 16:37:33] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:33] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 54/92 [01:23<00:52,  1.38s/it]INFO: [2025-06-27 16:37:33] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/24584688051044679/-3369816936700840932\n",
      "INFO: [2025-06-27 16:37:33] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:33] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:33] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/24584688051044679/6775015327379007916\n",
      "INFO: [2025-06-27 16:37:33] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:33] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:34] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/24584688051044679/-1798206033544741742\n",
      "INFO: [2025-06-27 16:37:34] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:34] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:34] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/24584688051044679/-2693608016918028982\n",
      "INFO: [2025-06-27 16:37:34] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:34] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:34] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 55/92 [01:24<00:50,  1.36s/it]INFO: [2025-06-27 16:37:34] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-25141892168903907/2842787141749613966\n",
      "INFO: [2025-06-27 16:37:34] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:34] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:35] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-25141892168903907/-6439376666594011464\n",
      "INFO: [2025-06-27 16:37:35] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:35] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:35] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:37:35] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-25141892168903907/-8903314523412236212\n",
      "INFO: [2025-06-27 16:37:35] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:35] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:35] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 56/92 [01:25<00:42,  1.19s/it]INFO: [2025-06-27 16:37:35] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-20439687097155111/1775209866093857310\n",
      "INFO: [2025-06-27 16:37:35] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:35] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:35] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:37:35] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-20439687097155111/7144522010287559589\n",
      "INFO: [2025-06-27 16:37:35] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:35] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:36] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:37:36] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-20439687097155111/8404126418433661645\n",
      "INFO: [2025-06-27 16:37:36] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:36] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:36] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 57/92 [01:26<00:40,  1.16s/it]INFO: [2025-06-27 16:37:36] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-15352348890731234/2611632168285154532\n",
      "INFO: [2025-06-27 16:37:36] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:36] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:36] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:37:36] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-15352348890731234/-2634502323142599163\n",
      "INFO: [2025-06-27 16:37:36] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:36] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:37] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:37:37] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-15352348890731234/1884060885835443568\n",
      "INFO: [2025-06-27 16:37:37] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:37] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:37] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 58/92 [01:27<00:37,  1.10s/it]INFO: [2025-06-27 16:37:37] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-4938783110044412/-9078285195640588986\n",
      "INFO: [2025-06-27 16:37:37] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:37] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:37] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:37:37] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-4938783110044412/4904932290730580929\n",
      "INFO: [2025-06-27 16:37:37] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:37] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:38] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:37:38] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-4938783110044412/1709325522002828324\n",
      "INFO: [2025-06-27 16:37:38] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:38] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 59/92 [01:27<00:32,  1.01it/s]INFO: [2025-06-27 16:37:38] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/17609986374660936/6955319964368225949\n",
      "INFO: [2025-06-27 16:37:38] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:38] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:38] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/17609986374660936/-2271101217331081907\n",
      "INFO: [2025-06-27 16:37:38] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:38] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:39] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:37:39] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/17609986374660936/-3284830607060838746\n",
      "INFO: [2025-06-27 16:37:39] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:39] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:39] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 60/92 [01:28<00:31,  1.02it/s]INFO: [2025-06-27 16:37:39] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/17681796354219824/1937655903082247767\n",
      "INFO: [2025-06-27 16:37:39] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:39] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:39] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/17681796354219824/4805165615096784855\n",
      "INFO: [2025-06-27 16:37:39] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:39] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:39] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/17681796354219824/3557359331496990844\n",
      "INFO: [2025-06-27 16:37:39] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:39] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:40] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 61/92 [01:29<00:28,  1.08it/s]INFO: [2025-06-27 16:37:40] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/35971629147007369/3934064133303539878\n",
      "INFO: [2025-06-27 16:37:40] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:40] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:40] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/35971629147007369/-76836233779723673\n",
      "INFO: [2025-06-27 16:37:40] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:40] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:40] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/35971629147007369/-5603215187459537893\n",
      "INFO: [2025-06-27 16:37:40] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:40] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 62/92 [01:30<00:28,  1.06it/s]INFO: [2025-06-27 16:37:41] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-29415098045592940/6411323736572457795\n",
      "INFO: [2025-06-27 16:37:41] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:41] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:41] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-29415098045592940/-1964285695976284026\n",
      "INFO: [2025-06-27 16:37:41] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:41] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:41] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 63/92 [01:31<00:23,  1.21it/s]INFO: [2025-06-27 16:37:41] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-28031656773092240/-8110188940058236355\n",
      "INFO: [2025-06-27 16:37:41] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:41] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:41] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-28031656773092240/7195142021001911519\n",
      "INFO: [2025-06-27 16:37:41] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:41] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 64/92 [01:31<00:20,  1.36it/s]INFO: [2025-06-27 16:37:42] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-22849205778179846/-8283104409014302301\n",
      "INFO: [2025-06-27 16:37:42] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:42] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:42] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-22849205778179846/4313876108651469704\n",
      "INFO: [2025-06-27 16:37:42] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:42] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:42] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 65/92 [01:32<00:19,  1.36it/s]INFO: [2025-06-27 16:37:42] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-18031556530033893/-8627777469347266434\n",
      "INFO: [2025-06-27 16:37:42] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:42] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:43] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-18031556530033893/-5274756934146961381\n",
      "INFO: [2025-06-27 16:37:43] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:43] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:43] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 66/92 [01:33<00:17,  1.50it/s]INFO: [2025-06-27 16:37:43] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-13505886640472175/-5016407656743507623\n",
      "INFO: [2025-06-27 16:37:43] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:43] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:43] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:37:43] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-13505886640472175/5466843209844404034\n",
      "INFO: [2025-06-27 16:37:43] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:43] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 67/92 [01:33<00:16,  1.47it/s]INFO: [2025-06-27 16:37:44] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-6735076600090236/6255694963833004319\n",
      "INFO: [2025-06-27 16:37:44] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:44] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 68/92 [01:34<00:13,  1.80it/s]INFO: [2025-06-27 16:37:44] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-3409159551394617/-1175751077694116458\n",
      "INFO: [2025-06-27 16:37:44] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:44] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:44] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-3409159551394617/-925249975991770452\n",
      "INFO: [2025-06-27 16:37:44] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:44] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:44] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 69/92 [01:34<00:12,  1.81it/s]INFO: [2025-06-27 16:37:44] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-2069452773758641/-8073980649127594574\n",
      "INFO: [2025-06-27 16:37:44] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:44] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:45] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-2069452773758641/-8385030890674185701\n",
      "INFO: [2025-06-27 16:37:45] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:45] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:45] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 70/92 [01:35<00:14,  1.54it/s]INFO: [2025-06-27 16:37:45] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/3297979118605018/2121973381815758809\n",
      "INFO: [2025-06-27 16:37:45] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:45] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:46] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/3297979118605018/-7629863625189970605\n",
      "INFO: [2025-06-27 16:37:46] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:46] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:46] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 71/92 [01:35<00:12,  1.62it/s]INFO: [2025-06-27 16:37:46] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/10757094666506670/2521158598917791125\n",
      "INFO: [2025-06-27 16:37:46] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:46] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:46] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/10757094666506670/2049223786216519273\n",
      "INFO: [2025-06-27 16:37:46] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:46] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:46] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 72/92 [01:36<00:11,  1.68it/s]INFO: [2025-06-27 16:37:46] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/14377716460635733/224067156940651406\n",
      "INFO: [2025-06-27 16:37:46] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:46] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:47] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/14377716460635733/6494760830414415628\n",
      "INFO: [2025-06-27 16:37:47] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:47] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 73/92 [01:37<00:12,  1.50it/s]INFO: [2025-06-27 16:37:47] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-33852347582520392/-1730356740998679943\n",
      "INFO: [2025-06-27 16:37:47] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:47] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 74/92 [01:37<00:09,  1.82it/s]INFO: [2025-06-27 16:37:48] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-25655970173329808/825366547021190712\n",
      "INFO: [2025-06-27 16:37:48] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:48] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 75/92 [01:37<00:07,  2.17it/s]INFO: [2025-06-27 16:37:48] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-22061102960387551/-8905627793055248873\n",
      "INFO: [2025-06-27 16:37:48] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:48] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 76/92 [01:38<00:07,  2.13it/s]INFO: [2025-06-27 16:37:48] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-20155356540515066/1617558396579091168\n",
      "INFO: [2025-06-27 16:37:48] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:48] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 77/92 [01:38<00:06,  2.46it/s]INFO: [2025-06-27 16:37:49] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-14117628316152430/3708495649437002708\n",
      "INFO: [2025-06-27 16:37:49] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:49] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 78/92 [01:38<00:05,  2.71it/s]INFO: [2025-06-27 16:37:49] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-11019131917628364/-7716517932206651477\n",
      "INFO: [2025-06-27 16:37:49] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:49] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 79/92 [01:39<00:04,  2.99it/s]INFO: [2025-06-27 16:37:49] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-10444363735373102/5157584201604396827\n",
      "INFO: [2025-06-27 16:37:49] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:49] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 80/92 [01:39<00:03,  3.21it/s]INFO: [2025-06-27 16:37:49] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-10033945991593843/-8343780824465910733\n",
      "INFO: [2025-06-27 16:37:49] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:49] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 81/92 [01:39<00:04,  2.70it/s]INFO: [2025-06-27 16:37:50] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-184811282650788/7459276384007237512\n",
      "INFO: [2025-06-27 16:37:50] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:50] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 82/92 [01:40<00:03,  2.96it/s]INFO: [2025-06-27 16:37:50] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/5566930627431303/-5089293816558006420\n",
      "INFO: [2025-06-27 16:37:50] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:50] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:50] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 83/92 [01:40<00:02,  3.17it/s]INFO: [2025-06-27 16:37:50] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/5609203557180661/-7281660177572507763\n",
      "INFO: [2025-06-27 16:37:50] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:50] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 84/92 [01:40<00:02,  3.32it/s]INFO: [2025-06-27 16:37:51] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/15133418971654738/7647822926109152780\n",
      "INFO: [2025-06-27 16:37:51] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:51] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 85/92 [01:41<00:02,  3.46it/s]INFO: [2025-06-27 16:37:51] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/15568847793479266/-4907848724437537709\n",
      "INFO: [2025-06-27 16:37:51] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:51] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 86/92 [01:41<00:02,  2.87it/s]INFO: [2025-06-27 16:37:51] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/17470512188912087/430810044304398948\n",
      "INFO: [2025-06-27 16:37:51] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:51] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 87/92 [01:41<00:01,  3.08it/s]INFO: [2025-06-27 16:37:52] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/18334778860223615/-7462221171272857117\n",
      "INFO: [2025-06-27 16:37:52] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:52] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 88/92 [01:42<00:01,  3.18it/s]INFO: [2025-06-27 16:37:52] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/19367730649708653/-4042641636918889097\n",
      "INFO: [2025-06-27 16:37:52] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:52] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 89/92 [01:42<00:00,  3.34it/s]INFO: [2025-06-27 16:37:52] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/30634204597194783/-5259171881687072106\n",
      "INFO: [2025-06-27 16:37:52] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:52] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 90/92 [01:42<00:00,  3.43it/s]INFO: [2025-06-27 16:37:52] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/30759839524016550/-3386398509503978146\n",
      "INFO: [2025-06-27 16:37:52] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:52] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:37:53] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 91/92 [01:43<00:00,  2.73it/s]INFO: [2025-06-27 16:37:53] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/31420388280123621/126985844909369330\n",
      "INFO: [2025-06-27 16:37:53] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:53] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 92/92 [01:43<00:00,  1.12s/it]\n",
      "Processing LLM curations:   0%|          | 0/92 [00:00<?, ?it/s]INFO: [2025-06-27 16:37:53] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-35882458128194165\n",
      "INFO: [2025-06-27 16:37:53] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:53] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:   1%|          | 1/92 [00:00<00:24,  3.70it/s]INFO: [2025-06-27 16:37:54] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/31160008118740626\n",
      "INFO: [2025-06-27 16:37:54] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:54] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:   2%|‚ñè         | 2/92 [00:00<00:23,  3.78it/s]INFO: [2025-06-27 16:37:54] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/33874939274212480\n",
      "INFO: [2025-06-27 16:37:54] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:54] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:   3%|‚ñé         | 3/92 [00:00<00:23,  3.73it/s]INFO: [2025-06-27 16:37:54] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-32399727139857751\n",
      "INFO: [2025-06-27 16:37:54] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:54] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:   4%|‚ñç         | 4/92 [00:01<00:33,  2.66it/s]INFO: [2025-06-27 16:37:55] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/9371935612488149\n",
      "INFO: [2025-06-27 16:37:55] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:55] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:   5%|‚ñå         | 5/92 [00:01<00:29,  2.93it/s]INFO: [2025-06-27 16:37:55] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/3246604237187558\n",
      "INFO: [2025-06-27 16:37:55] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:55] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:   7%|‚ñã         | 6/92 [00:01<00:27,  3.10it/s]INFO: [2025-06-27 16:37:55] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/9130628937861941\n",
      "INFO: [2025-06-27 16:37:55] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:55] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:   8%|‚ñä         | 7/92 [00:02<00:25,  3.29it/s]INFO: [2025-06-27 16:37:55] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/19706388665464256\n",
      "INFO: [2025-06-27 16:37:55] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:55] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:   9%|‚ñä         | 8/92 [00:02<00:24,  3.42it/s]INFO: [2025-06-27 16:37:56] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-14556452501867428\n",
      "INFO: [2025-06-27 16:37:56] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:56] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  10%|‚ñâ         | 9/92 [00:02<00:28,  2.88it/s]INFO: [2025-06-27 16:37:56] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/15114781201446083\n",
      "INFO: [2025-06-27 16:37:56] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:56] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  11%|‚ñà         | 10/92 [00:03<00:26,  3.12it/s]INFO: [2025-06-27 16:37:56] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/13290267870654994\n",
      "INFO: [2025-06-27 16:37:56] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:56] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  12%|‚ñà‚ñè        | 11/92 [00:03<00:24,  3.28it/s]INFO: [2025-06-27 16:37:57] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/30902335548899281\n",
      "INFO: [2025-06-27 16:37:57] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:57] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  13%|‚ñà‚ñé        | 12/92 [00:03<00:23,  3.41it/s]INFO: [2025-06-27 16:37:57] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/2135209076854093\n",
      "INFO: [2025-06-27 16:37:57] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:57] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  14%|‚ñà‚ñç        | 13/92 [00:03<00:22,  3.49it/s]INFO: [2025-06-27 16:37:57] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-18387380848780476\n",
      "INFO: [2025-06-27 16:37:57] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:57] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  15%|‚ñà‚ñå        | 14/92 [00:04<00:28,  2.75it/s]INFO: [2025-06-27 16:37:58] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/18933828397346607\n",
      "INFO: [2025-06-27 16:37:58] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:58] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  16%|‚ñà‚ñã        | 15/92 [00:04<00:25,  2.97it/s]INFO: [2025-06-27 16:37:58] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/20978307744432241\n",
      "INFO: [2025-06-27 16:37:58] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:58] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  17%|‚ñà‚ñã        | 16/92 [00:05<00:24,  3.14it/s]INFO: [2025-06-27 16:37:58] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-35102576635162472\n",
      "INFO: [2025-06-27 16:37:58] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:58] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  18%|‚ñà‚ñä        | 17/92 [00:05<00:22,  3.31it/s]INFO: [2025-06-27 16:37:59] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-7126418877828068\n",
      "INFO: [2025-06-27 16:37:59] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:59] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  20%|‚ñà‚ñâ        | 18/92 [00:05<00:21,  3.39it/s]INFO: [2025-06-27 16:37:59] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-19952367157294119\n",
      "INFO: [2025-06-27 16:37:59] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:59] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  21%|‚ñà‚ñà        | 19/92 [00:06<00:25,  2.84it/s]INFO: [2025-06-27 16:37:59] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-34105277816332298\n",
      "INFO: [2025-06-27 16:37:59] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:37:59] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  22%|‚ñà‚ñà‚ñè       | 20/92 [00:06<00:28,  2.53it/s]INFO: [2025-06-27 16:38:00] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-25725881202629826\n",
      "INFO: [2025-06-27 16:38:00] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:00] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  23%|‚ñà‚ñà‚ñé       | 21/92 [00:06<00:25,  2.84it/s]INFO: [2025-06-27 16:38:00] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-2046863695546735\n",
      "INFO: [2025-06-27 16:38:00] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:00] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  24%|‚ñà‚ñà‚ñç       | 22/92 [00:07<00:22,  3.07it/s]INFO: [2025-06-27 16:38:00] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/12631778325074772\n",
      "INFO: [2025-06-27 16:38:00] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:00] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  25%|‚ñà‚ñà‚ñå       | 23/92 [00:07<00:21,  3.25it/s]INFO: [2025-06-27 16:38:01] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-29122158203077245\n",
      "INFO: [2025-06-27 16:38:01] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:01] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  26%|‚ñà‚ñà‚ñå       | 24/92 [00:07<00:25,  2.69it/s]INFO: [2025-06-27 16:38:01] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-22627892168184181\n",
      "INFO: [2025-06-27 16:38:01] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:01] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  27%|‚ñà‚ñà‚ñã       | 25/92 [00:08<00:23,  2.89it/s]INFO: [2025-06-27 16:38:01] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/28030974524863734\n",
      "INFO: [2025-06-27 16:38:01] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:01] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  28%|‚ñà‚ñà‚ñä       | 26/92 [00:08<00:21,  3.06it/s]INFO: [2025-06-27 16:38:02] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-8639253709990781\n",
      "INFO: [2025-06-27 16:38:02] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:02] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  29%|‚ñà‚ñà‚ñâ       | 27/92 [00:08<00:19,  3.25it/s]INFO: [2025-06-27 16:38:02] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/33041281229298748\n",
      "INFO: [2025-06-27 16:38:02] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:02] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  30%|‚ñà‚ñà‚ñà       | 28/92 [00:08<00:18,  3.40it/s]INFO: [2025-06-27 16:38:02] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-26780953604978411\n",
      "INFO: [2025-06-27 16:38:02] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:02] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  32%|‚ñà‚ñà‚ñà‚ñè      | 29/92 [00:09<00:19,  3.30it/s]INFO: [2025-06-27 16:38:03] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-18949191324265795\n",
      "INFO: [2025-06-27 16:38:03] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:03] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  33%|‚ñà‚ñà‚ñà‚ñé      | 30/92 [00:09<00:24,  2.49it/s]INFO: [2025-06-27 16:38:03] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/1410763986151621\n",
      "INFO: [2025-06-27 16:38:03] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:03] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  34%|‚ñà‚ñà‚ñà‚ñé      | 31/92 [00:10<00:22,  2.76it/s]INFO: [2025-06-27 16:38:03] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/1739983631954371\n",
      "INFO: [2025-06-27 16:38:03] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:03] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  35%|‚ñà‚ñà‚ñà‚ñç      | 32/92 [00:10<00:20,  2.96it/s]INFO: [2025-06-27 16:38:04] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/5895544448831150\n",
      "INFO: [2025-06-27 16:38:04] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:04] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  36%|‚ñà‚ñà‚ñà‚ñå      | 33/92 [00:10<00:18,  3.13it/s]INFO: [2025-06-27 16:38:04] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/31202820582613161\n",
      "INFO: [2025-06-27 16:38:04] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:04] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  37%|‚ñà‚ñà‚ñà‚ñã      | 34/92 [00:11<00:17,  3.29it/s]INFO: [2025-06-27 16:38:04] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-35884737692158253\n",
      "INFO: [2025-06-27 16:38:04] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:04] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  38%|‚ñà‚ñà‚ñà‚ñä      | 35/92 [00:11<00:20,  2.83it/s]INFO: [2025-06-27 16:38:05] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-34803309266443718\n",
      "INFO: [2025-06-27 16:38:05] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:05] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  39%|‚ñà‚ñà‚ñà‚ñâ      | 36/92 [00:11<00:18,  3.09it/s]INFO: [2025-06-27 16:38:05] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-22499263970759753\n",
      "INFO: [2025-06-27 16:38:05] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:05] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  40%|‚ñà‚ñà‚ñà‚ñà      | 37/92 [00:12<00:16,  3.27it/s]INFO: [2025-06-27 16:38:05] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-12988782223228843\n",
      "INFO: [2025-06-27 16:38:05] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:05] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 38/92 [00:12<00:15,  3.38it/s]INFO: [2025-06-27 16:38:06] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-7666152121409895\n",
      "INFO: [2025-06-27 16:38:06] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:06] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 39/92 [00:12<00:15,  3.49it/s]INFO: [2025-06-27 16:38:06] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/21634894993301822\n",
      "INFO: [2025-06-27 16:38:06] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:06] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 40/92 [00:12<00:14,  3.59it/s]INFO: [2025-06-27 16:38:06] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/34364657708684419\n",
      "INFO: [2025-06-27 16:38:06] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:06] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 41/92 [00:13<00:13,  3.66it/s]INFO: [2025-06-27 16:38:06] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/10262358575052520\n",
      "INFO: [2025-06-27 16:38:06] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:06] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 42/92 [00:13<00:17,  2.82it/s]INFO: [2025-06-27 16:38:07] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/11111675784752136\n",
      "INFO: [2025-06-27 16:38:07] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:07] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 43/92 [00:13<00:16,  3.05it/s]INFO: [2025-06-27 16:38:07] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/12642450547914707\n",
      "INFO: [2025-06-27 16:38:07] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:07] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 44/92 [00:14<00:15,  3.15it/s]INFO: [2025-06-27 16:38:07] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/21893218624143108\n",
      "INFO: [2025-06-27 16:38:07] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:07] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 45/92 [00:14<00:14,  3.33it/s]INFO: [2025-06-27 16:38:08] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-24316712102315887\n",
      "INFO: [2025-06-27 16:38:08] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:08] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 46/92 [00:14<00:13,  3.42it/s]INFO: [2025-06-27 16:38:08] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-23507181552861323\n",
      "INFO: [2025-06-27 16:38:08] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:08] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 47/92 [00:15<00:16,  2.71it/s]INFO: [2025-06-27 16:38:09] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-18152182327560480\n",
      "INFO: [2025-06-27 16:38:09] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:09] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 48/92 [00:15<00:14,  2.94it/s]INFO: [2025-06-27 16:38:09] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/21321689889868872\n",
      "INFO: [2025-06-27 16:38:09] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:09] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 49/92 [00:15<00:13,  3.13it/s]INFO: [2025-06-27 16:38:09] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-12463996681673250\n",
      "INFO: [2025-06-27 16:38:09] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:09] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 50/92 [00:16<00:12,  3.24it/s]INFO: [2025-06-27 16:38:09] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-2139820121868237\n",
      "INFO: [2025-06-27 16:38:09] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:09] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 51/92 [00:16<00:14,  2.91it/s]INFO: [2025-06-27 16:38:10] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-1083216214855434\n",
      "INFO: [2025-06-27 16:38:10] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:10] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 52/92 [00:17<00:15,  2.59it/s]INFO: [2025-06-27 16:38:10] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/17131318242278983\n",
      "INFO: [2025-06-27 16:38:10] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:10] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 53/92 [00:17<00:13,  2.86it/s]INFO: [2025-06-27 16:38:11] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/20606471688970148\n",
      "INFO: [2025-06-27 16:38:11] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:11] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 54/92 [00:17<00:12,  3.08it/s]INFO: [2025-06-27 16:38:11] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/24584688051044679\n",
      "INFO: [2025-06-27 16:38:11] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:11] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 55/92 [00:17<00:11,  3.22it/s]INFO: [2025-06-27 16:38:11] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-25141892168903907\n",
      "INFO: [2025-06-27 16:38:11] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:11] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 56/92 [00:18<00:10,  3.37it/s]INFO: [2025-06-27 16:38:11] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-20439687097155111\n",
      "INFO: [2025-06-27 16:38:11] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:11] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 57/92 [00:18<00:12,  2.87it/s]INFO: [2025-06-27 16:38:12] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-15352348890731234\n",
      "INFO: [2025-06-27 16:38:12] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:12] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 58/92 [00:18<00:10,  3.11it/s]INFO: [2025-06-27 16:38:12] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-4938783110044412\n",
      "INFO: [2025-06-27 16:38:12] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:12] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 59/92 [00:19<00:10,  3.29it/s]INFO: [2025-06-27 16:38:12] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/17609986374660936\n",
      "INFO: [2025-06-27 16:38:12] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:12] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 60/92 [00:19<00:09,  3.37it/s]INFO: [2025-06-27 16:38:13] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/17681796354219824\n",
      "INFO: [2025-06-27 16:38:13] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:13] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 61/92 [00:19<00:08,  3.49it/s]INFO: [2025-06-27 16:38:13] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/35971629147007369\n",
      "INFO: [2025-06-27 16:38:13] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:13] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 62/92 [00:20<00:11,  2.68it/s]INFO: [2025-06-27 16:38:13] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-29415098045592940\n",
      "INFO: [2025-06-27 16:38:13] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:13] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 63/92 [00:20<00:11,  2.49it/s]INFO: [2025-06-27 16:38:14] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-28031656773092240\n",
      "INFO: [2025-06-27 16:38:14] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:14] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 64/92 [00:20<00:10,  2.78it/s]INFO: [2025-06-27 16:38:14] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-22849205778179846\n",
      "INFO: [2025-06-27 16:38:14] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:14] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 65/92 [00:21<00:09,  2.99it/s]INFO: [2025-06-27 16:38:14] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-18031556530033893\n",
      "INFO: [2025-06-27 16:38:14] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:14] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 66/92 [00:21<00:08,  3.14it/s]INFO: [2025-06-27 16:38:15] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-13505886640472175\n",
      "INFO: [2025-06-27 16:38:15] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:15] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 67/92 [00:21<00:07,  3.21it/s]INFO: [2025-06-27 16:38:15] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-6735076600090236\n",
      "INFO: [2025-06-27 16:38:15] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:15] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 68/92 [00:22<00:08,  2.75it/s]INFO: [2025-06-27 16:38:16] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-3409159551394617\n",
      "INFO: [2025-06-27 16:38:16] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:16] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 69/92 [00:22<00:07,  2.95it/s]INFO: [2025-06-27 16:38:16] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-2069452773758641\n",
      "INFO: [2025-06-27 16:38:16] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:16] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 70/92 [00:22<00:06,  3.16it/s]INFO: [2025-06-27 16:38:16] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/3297979118605018\n",
      "INFO: [2025-06-27 16:38:16] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:16] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 71/92 [00:23<00:06,  3.28it/s]INFO: [2025-06-27 16:38:16] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/10757094666506670\n",
      "INFO: [2025-06-27 16:38:16] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:16] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 72/92 [00:23<00:05,  3.44it/s]INFO: [2025-06-27 16:38:17] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/14377716460635733\n",
      "INFO: [2025-06-27 16:38:17] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:17] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 73/92 [00:23<00:06,  2.75it/s]INFO: [2025-06-27 16:38:17] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-33852347582520392\n",
      "INFO: [2025-06-27 16:38:17] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:17] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 74/92 [00:24<00:06,  2.96it/s]INFO: [2025-06-27 16:38:17] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-25655970173329808\n",
      "INFO: [2025-06-27 16:38:17] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:17] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 75/92 [00:24<00:05,  3.17it/s]INFO: [2025-06-27 16:38:18] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-22061102960387551\n",
      "INFO: [2025-06-27 16:38:18] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:18] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 76/92 [00:24<00:04,  3.34it/s]INFO: [2025-06-27 16:38:18] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-20155356540515066\n",
      "INFO: [2025-06-27 16:38:18] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:18] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 77/92 [00:24<00:04,  3.43it/s]INFO: [2025-06-27 16:38:18] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-14117628316152430\n",
      "INFO: [2025-06-27 16:38:18] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:18] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 78/92 [00:25<00:05,  2.68it/s]INFO: [2025-06-27 16:38:19] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-11019131917628364\n",
      "INFO: [2025-06-27 16:38:19] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:19] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 79/92 [00:25<00:04,  2.92it/s]INFO: [2025-06-27 16:38:19] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-10444363735373102\n",
      "INFO: [2025-06-27 16:38:19] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:19] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 80/92 [00:26<00:03,  3.14it/s]INFO: [2025-06-27 16:38:19] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-10033945991593843\n",
      "INFO: [2025-06-27 16:38:19] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:19] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 81/92 [00:26<00:03,  3.25it/s]INFO: [2025-06-27 16:38:20] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-184811282650788\n",
      "INFO: [2025-06-27 16:38:20] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:20] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 82/92 [00:26<00:02,  3.40it/s]INFO: [2025-06-27 16:38:20] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/5566930627431303\n",
      "INFO: [2025-06-27 16:38:20] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:20] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 83/92 [00:27<00:03,  2.85it/s]INFO: [2025-06-27 16:38:20] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/5609203557180661\n",
      "INFO: [2025-06-27 16:38:20] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:20] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 84/92 [00:27<00:02,  3.03it/s]INFO: [2025-06-27 16:38:21] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/15133418971654738\n",
      "INFO: [2025-06-27 16:38:21] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:21] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 85/92 [00:27<00:02,  2.52it/s]INFO: [2025-06-27 16:38:21] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/15568847793479266\n",
      "INFO: [2025-06-27 16:38:21] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:21] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 86/92 [00:28<00:02,  2.28it/s]INFO: [2025-06-27 16:38:22] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/17470512188912087\n",
      "INFO: [2025-06-27 16:38:22] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:22] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 87/92 [00:28<00:02,  2.16it/s]INFO: [2025-06-27 16:38:22] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/18334778860223615\n",
      "INFO: [2025-06-27 16:38:22] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:22] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 88/92 [00:29<00:02,  1.84it/s]INFO: [2025-06-27 16:38:23] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/19367730649708653\n",
      "INFO: [2025-06-27 16:38:23] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:23] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 89/92 [00:30<00:01,  1.87it/s]INFO: [2025-06-27 16:38:23] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/30634204597194783\n",
      "INFO: [2025-06-27 16:38:23] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:23] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 90/92 [00:30<00:01,  2.00it/s]INFO: [2025-06-27 16:38:24] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/30759839524016550\n",
      "INFO: [2025-06-27 16:38:24] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:24] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 91/92 [00:31<00:00,  2.12it/s]INFO: [2025-06-27 16:38:24] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/31420388280123621\n",
      "INFO: [2025-06-27 16:38:24] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:24] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 92/92 [00:31<00:00,  2.93it/s]\n",
      "Processing LLM curations:   0%|          | 0/92 [00:00<?, ?it/s]INFO: [2025-06-27 16:38:25] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-35882458128194165/5786764702333762182\n",
      "INFO: [2025-06-27 16:38:25] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:25] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:38:25] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:38:25] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-35882458128194165/8355678935622345172\n",
      "INFO: [2025-06-27 16:38:25] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:25] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:38:26] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:38:26] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-35882458128194165/-851512429100447464\n",
      "INFO: [2025-06-27 16:38:26] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:26] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:38:26] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:38:26] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-35882458128194165/7179196441195013825\n",
      "INFO: [2025-06-27 16:38:26] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:26] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:38:26] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:38:26] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-35882458128194165/4841837800197172830\n",
      "INFO: [2025-06-27 16:38:26] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:26] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:38:26] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:   1%|          | 1/92 [00:01<02:30,  1.66s/it]INFO: [2025-06-27 16:38:26] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/31160008118740626/6159932226767496941\n",
      "INFO: [2025-06-27 16:38:26] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:26] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:38:27] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:38:27] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/31160008118740626/3003949102852070921\n",
      "INFO: [2025-06-27 16:38:27] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:27] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:38:27] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:38:27] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/31160008118740626/-2045230806938344941\n",
      "INFO: [2025-06-27 16:38:27] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:27] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:38:27] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:38:27] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/31160008118740626/5695956303061955816\n",
      "INFO: [2025-06-27 16:38:27] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:27] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:38:28] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:38:28] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/31160008118740626/-3887864339415451174\n",
      "INFO: [2025-06-27 16:38:28] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:28] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:38:28] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:   2%|‚ñè         | 2/92 [00:03<02:26,  1.63s/it]INFO: [2025-06-27 16:38:28] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/33874939274212480/-4406591150498265399\n",
      "INFO: [2025-06-27 16:38:28] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:28] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:38:29] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:38:29] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/33874939274212480/4627384812003952825\n",
      "INFO: [2025-06-27 16:38:29] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:29] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:38:29] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:38:29] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/33874939274212480/-5004582495550212402\n",
      "INFO: [2025-06-27 16:38:29] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:29] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:38:29] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:38:29] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/33874939274212480/-3559495535232157783\n",
      "INFO: [2025-06-27 16:38:29] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:29] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:38:29] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:38:29] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/33874939274212480/3517783696879133090\n",
      "INFO: [2025-06-27 16:38:29] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:29] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:38:30] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:   3%|‚ñé         | 3/92 [00:04<02:26,  1.65s/it]INFO: [2025-06-27 16:38:30] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-32399727139857751/7689470029421916432\n",
      "INFO: [2025-06-27 16:38:30] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:30] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:38:30] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-32399727139857751/1409334065256120280\n",
      "INFO: [2025-06-27 16:38:30] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:30] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:38:31] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:38:31] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-32399727139857751/-9147103155553158697\n",
      "INFO: [2025-06-27 16:38:31] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:31] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:38:31] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:38:31] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-32399727139857751/2789203237128035699\n",
      "INFO: [2025-06-27 16:38:31] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:31] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:38:31] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:38:31] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-32399727139857751/1946863589627249918\n",
      "INFO: [2025-06-27 16:38:31] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:31] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:38:31] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:   4%|‚ñç         | 4/92 [00:06<02:30,  1.71s/it]INFO: [2025-06-27 16:38:31] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/9371935612488149/-2557397083932418191\n",
      "INFO: [2025-06-27 16:38:31] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:31] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:38:32] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:38:32] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/9371935612488149/-3751220421119537230\n",
      "INFO: [2025-06-27 16:38:32] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:32] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:38:32] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:38:32] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/9371935612488149/-5251629381712573172\n",
      "INFO: [2025-06-27 16:38:32] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:32] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:38:32] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:38:32] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/9371935612488149/371900031548666870\n",
      "INFO: [2025-06-27 16:38:32] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:32] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:38:33] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:38:33] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/9371935612488149/2659068389317603914\n",
      "INFO: [2025-06-27 16:38:33] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:33] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:38:33] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:   5%|‚ñå         | 5/92 [00:08<02:19,  1.61s/it]INFO: [2025-06-27 16:38:33] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/3246604237187558/-1076305511976019755\n",
      "INFO: [2025-06-27 16:38:33] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:33] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:38:33] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:38:33] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/3246604237187558/6329274706803238746\n",
      "INFO: [2025-06-27 16:38:33] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:33] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:38:33] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:38:33] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/3246604237187558/-8293782568953535602\n",
      "INFO: [2025-06-27 16:38:33] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:33] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:38:34] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:38:34] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/3246604237187558/-4952987943045688040\n",
      "INFO: [2025-06-27 16:38:34] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:34] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:38:34] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:   7%|‚ñã         | 6/92 [00:09<02:10,  1.52s/it]INFO: [2025-06-27 16:38:34] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/9130628937861941/-3283194163382337469\n",
      "INFO: [2025-06-27 16:38:34] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:34] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:38:34] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:38:34] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/9130628937861941/743498562049544529\n",
      "INFO: [2025-06-27 16:38:34] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:34] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:38:35] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:38:35] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/9130628937861941/5973269625090323243\n",
      "INFO: [2025-06-27 16:38:35] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:35] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:38:35] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:38:35] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/9130628937861941/-1692900409242322119\n",
      "INFO: [2025-06-27 16:38:35] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:35] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:38:35] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:38:35] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/9130628937861941/3057153924612093929\n",
      "INFO: [2025-06-27 16:38:35] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:35] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:38:36] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:   8%|‚ñä         | 7/92 [00:10<02:08,  1.51s/it]INFO: [2025-06-27 16:38:36] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/19706388665464256/-7917492718183589806\n",
      "INFO: [2025-06-27 16:38:36] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:36] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:38:36] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:38:36] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/19706388665464256/-8717026125890922783\n",
      "INFO: [2025-06-27 16:38:36] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:36] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:38:36] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:38:36] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/19706388665464256/1836846670502670413\n",
      "INFO: [2025-06-27 16:38:36] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:36] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:38:36] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:38:36] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/19706388665464256/-7398129200642253854\n",
      "INFO: [2025-06-27 16:38:36] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:36] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:38:37] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:38:37] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/19706388665464256/1432444337877372283\n",
      "INFO: [2025-06-27 16:38:37] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:37] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:38:37] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:   9%|‚ñä         | 8/92 [00:12<02:08,  1.53s/it]INFO: [2025-06-27 16:38:37] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-14556452501867428/-6804206536452889127\n",
      "INFO: [2025-06-27 16:38:37] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:37] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:38:38] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:38:38] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-14556452501867428/5164641014754436985\n",
      "INFO: [2025-06-27 16:38:38] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:38] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:38:38] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:38:38] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-14556452501867428/5996087898722862932\n",
      "INFO: [2025-06-27 16:38:38] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:38] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:38:38] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:38:38] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-14556452501867428/2262633760749043004\n",
      "INFO: [2025-06-27 16:38:38] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:38] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:38:39] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:38:39] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-14556452501867428/-6585280312434014708\n",
      "INFO: [2025-06-27 16:38:39] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:39] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:38:39] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  10%|‚ñâ         | 9/92 [00:14<02:07,  1.53s/it]INFO: [2025-06-27 16:38:39] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/15114781201446083/-2804486832599618891\n",
      "INFO: [2025-06-27 16:38:39] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:39] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:38:39] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:38:39] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/15114781201446083/26318288762802825\n",
      "INFO: [2025-06-27 16:38:39] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:39] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:38:39] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:38:39] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/15114781201446083/-9086953831185223707\n",
      "INFO: [2025-06-27 16:38:39] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:39] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:38:40] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:38:40] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/15114781201446083/-1547984374499703471\n",
      "INFO: [2025-06-27 16:38:40] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:40] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:38:40] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:38:40] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/15114781201446083/5404053056781201289\n",
      "INFO: [2025-06-27 16:38:40] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:40] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:38:40] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  11%|‚ñà         | 10/92 [00:15<02:07,  1.55s/it]INFO: [2025-06-27 16:38:40] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/13290267870654994/-9128340997249573733\n",
      "INFO: [2025-06-27 16:38:40] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:40] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:38:41] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:38:41] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/13290267870654994/9190118004478562135\n",
      "INFO: [2025-06-27 16:38:41] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:41] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:38:41] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:38:41] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/13290267870654994/8070647525160963090\n",
      "INFO: [2025-06-27 16:38:41] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:41] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:38:41] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:38:41] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/13290267870654994/2461950003156571909\n",
      "INFO: [2025-06-27 16:38:41] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:41] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:38:41] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:38:41] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/13290267870654994/3299458053686794477\n",
      "INFO: [2025-06-27 16:38:41] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:41] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:38:42] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  12%|‚ñà‚ñè        | 11/92 [00:17<02:07,  1.58s/it]INFO: [2025-06-27 16:38:42] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/30902335548899281/7413267225472944649\n",
      "INFO: [2025-06-27 16:38:42] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:42] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:38:42] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:38:42] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/30902335548899281/-2018347506425391607\n",
      "INFO: [2025-06-27 16:38:42] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:42] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:38:43] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:38:43] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/30902335548899281/5238680422789339725\n",
      "INFO: [2025-06-27 16:38:43] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:43] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:38:43] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:38:43] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/30902335548899281/5205855036769276965\n",
      "INFO: [2025-06-27 16:38:43] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:43] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:38:43] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/30902335548899281/6609061953088271943\n",
      "INFO: [2025-06-27 16:38:43] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:43] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  13%|‚ñà‚ñé        | 12/92 [00:18<02:05,  1.57s/it]INFO: [2025-06-27 16:38:44] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/2135209076854093/9165069320254869333\n",
      "INFO: [2025-06-27 16:38:44] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:44] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:38:44] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:38:44] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/2135209076854093/2918182937795155731\n",
      "INFO: [2025-06-27 16:38:44] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:44] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:38:44] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:38:44] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/2135209076854093/1390508654814789913\n",
      "INFO: [2025-06-27 16:38:44] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:44] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:38:44] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:38:44] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/2135209076854093/-1624416844767968113\n",
      "INFO: [2025-06-27 16:38:44] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:44] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:38:45] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:38:45] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/2135209076854093/-3114337614064462746\n",
      "INFO: [2025-06-27 16:38:45] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:45] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:38:45] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  14%|‚ñà‚ñç        | 13/92 [00:20<02:00,  1.53s/it]INFO: [2025-06-27 16:38:45] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-18387380848780476/-2228134318647310754\n",
      "INFO: [2025-06-27 16:38:45] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:45] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:38:46] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:38:46] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-18387380848780476/-5671575296626762908\n",
      "INFO: [2025-06-27 16:38:46] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:46] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:38:46] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:38:46] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-18387380848780476/5268987589786392033\n",
      "INFO: [2025-06-27 16:38:46] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:46] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:38:46] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:38:46] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-18387380848780476/3043511906331179521\n",
      "INFO: [2025-06-27 16:38:46] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:46] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:38:46] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:38:46] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-18387380848780476/3175535594596127363\n",
      "INFO: [2025-06-27 16:38:46] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:46] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:38:47] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  15%|‚ñà‚ñå        | 14/92 [00:21<02:00,  1.54s/it]INFO: [2025-06-27 16:38:47] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/18933828397346607/3094904524259390266\n",
      "INFO: [2025-06-27 16:38:47] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:47] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:38:47] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:38:47] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/18933828397346607/5488745354973087240\n",
      "INFO: [2025-06-27 16:38:47] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:47] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:38:47] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:38:47] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/18933828397346607/-8588548413507570270\n",
      "INFO: [2025-06-27 16:38:47] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:47] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:38:47] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:38:47] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/18933828397346607/-8399108198503837244\n",
      "INFO: [2025-06-27 16:38:47] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:47] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:38:48] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:38:48] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/18933828397346607/2248490328067003110\n",
      "INFO: [2025-06-27 16:38:48] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:48] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:38:48] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  16%|‚ñà‚ñã        | 15/92 [00:23<01:53,  1.48s/it]INFO: [2025-06-27 16:38:48] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/20978307744432241/4562586356517768118\n",
      "INFO: [2025-06-27 16:38:48] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:48] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:38:48] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:38:48] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/20978307744432241/-4029103074837611889\n",
      "INFO: [2025-06-27 16:38:48] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:48] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:38:49] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:38:49] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/20978307744432241/-3539338498554117161\n",
      "INFO: [2025-06-27 16:38:49] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:49] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:38:49] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:38:49] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/20978307744432241/-7288726938550294928\n",
      "INFO: [2025-06-27 16:38:49] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:49] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:38:49] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:38:49] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/20978307744432241/-1577552131954112247\n",
      "INFO: [2025-06-27 16:38:49] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:49] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:38:50] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  17%|‚ñà‚ñã        | 16/92 [00:24<01:57,  1.54s/it]INFO: [2025-06-27 16:38:50] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-35102576635162472/2343622916004568787\n",
      "INFO: [2025-06-27 16:38:50] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:50] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:38:50] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:38:50] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-35102576635162472/4862965305945228335\n",
      "INFO: [2025-06-27 16:38:50] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:50] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:38:50] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:38:50] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-35102576635162472/981652804965920531\n",
      "INFO: [2025-06-27 16:38:50] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:50] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:38:50] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:38:50] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-35102576635162472/-8370254754651504175\n",
      "INFO: [2025-06-27 16:38:50] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:50] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:38:51] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:38:51] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-35102576635162472/7876086009799354153\n",
      "INFO: [2025-06-27 16:38:51] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:51] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:38:51] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  18%|‚ñà‚ñä        | 17/92 [00:26<01:53,  1.52s/it]INFO: [2025-06-27 16:38:51] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-7126418877828068/-1259986438941955146\n",
      "INFO: [2025-06-27 16:38:51] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:51] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:38:51] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:38:51] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-7126418877828068/-7663726527793105769\n",
      "INFO: [2025-06-27 16:38:51] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:51] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:38:52] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:38:52] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-7126418877828068/7177956674382236705\n",
      "INFO: [2025-06-27 16:38:52] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:52] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:38:52] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:38:52] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-7126418877828068/1141267624756420336\n",
      "INFO: [2025-06-27 16:38:52] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:52] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:38:52] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:38:52] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-7126418877828068/5548902811071695424\n",
      "INFO: [2025-06-27 16:38:52] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:52] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:38:52] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  20%|‚ñà‚ñâ        | 18/92 [00:27<01:49,  1.48s/it]INFO: [2025-06-27 16:38:52] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-19952367157294119/2185735117996718161\n",
      "INFO: [2025-06-27 16:38:52] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:52] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:38:53] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:38:53] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-19952367157294119/-3416044498495900465\n",
      "INFO: [2025-06-27 16:38:53] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:53] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:38:53] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:38:53] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-19952367157294119/3390836050203658972\n",
      "INFO: [2025-06-27 16:38:53] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:53] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:38:53] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:38:53] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-19952367157294119/-160071166771824000\n",
      "INFO: [2025-06-27 16:38:53] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:53] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:38:53] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:38:53] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-19952367157294119/-1778770983960530625\n",
      "INFO: [2025-06-27 16:38:53] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:53] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  21%|‚ñà‚ñà        | 19/92 [00:29<01:46,  1.46s/it]INFO: [2025-06-27 16:38:54] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-34105277816332298/-8892540475182985534\n",
      "INFO: [2025-06-27 16:38:54] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:54] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:38:54] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:38:54] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-34105277816332298/-782020178267754741\n",
      "INFO: [2025-06-27 16:38:54] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:54] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:38:54] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:38:54] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-34105277816332298/-7260329194681942815\n",
      "INFO: [2025-06-27 16:38:54] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:54] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:38:55] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  22%|‚ñà‚ñà‚ñè       | 20/92 [00:29<01:29,  1.24s/it]INFO: [2025-06-27 16:38:55] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-25725881202629826/2800114118065263059\n",
      "INFO: [2025-06-27 16:38:55] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:55] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:38:55] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:38:55] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-25725881202629826/-3639705050638090691\n",
      "INFO: [2025-06-27 16:38:55] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:55] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:38:55] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:38:55] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-25725881202629826/3126028315336764185\n",
      "INFO: [2025-06-27 16:38:55] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:55] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:38:55] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:38:55] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-25725881202629826/-3388978621357165195\n",
      "INFO: [2025-06-27 16:38:55] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:55] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:38:56] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:38:56] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-25725881202629826/-8962668398697605821\n",
      "INFO: [2025-06-27 16:38:56] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:56] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:38:56] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  23%|‚ñà‚ñà‚ñé       | 21/92 [00:31<01:34,  1.33s/it]INFO: [2025-06-27 16:38:56] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-2046863695546735/-2478064006328255455\n",
      "INFO: [2025-06-27 16:38:56] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:56] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:38:56] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:38:56] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-2046863695546735/-2805098949379304551\n",
      "INFO: [2025-06-27 16:38:56] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:56] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:38:57] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:38:57] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-2046863695546735/6720834043830302236\n",
      "INFO: [2025-06-27 16:38:57] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:57] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:38:57] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:38:57] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-2046863695546735/901826316009339016\n",
      "INFO: [2025-06-27 16:38:57] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:57] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:38:57] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:38:57] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-2046863695546735/4765117616567612294\n",
      "INFO: [2025-06-27 16:38:57] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:57] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:38:58] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  24%|‚ñà‚ñà‚ñç       | 22/92 [00:32<01:37,  1.39s/it]INFO: [2025-06-27 16:38:58] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/12631778325074772/433066566401342778\n",
      "INFO: [2025-06-27 16:38:58] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:58] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:38:58] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:38:58] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/12631778325074772/6301599981403109691\n",
      "INFO: [2025-06-27 16:38:58] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:58] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:38:58] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/12631778325074772/-5660088039246376770\n",
      "INFO: [2025-06-27 16:38:58] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:58] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:38:58] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:38:58] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/12631778325074772/-6797821670496085910\n",
      "INFO: [2025-06-27 16:38:58] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:58] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:38:59] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:38:59] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/12631778325074772/-5156252880374989973\n",
      "INFO: [2025-06-27 16:38:59] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:59] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:38:59] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  25%|‚ñà‚ñà‚ñå       | 23/92 [00:34<01:38,  1.43s/it]INFO: [2025-06-27 16:38:59] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-29122158203077245/-2005769166081712460\n",
      "INFO: [2025-06-27 16:38:59] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:59] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:38:59] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:38:59] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-29122158203077245/-7468533896966433990\n",
      "INFO: [2025-06-27 16:38:59] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:38:59] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:00] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-29122158203077245/-7018996456395300040\n",
      "INFO: [2025-06-27 16:39:00] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:00] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:00] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:39:00] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-29122158203077245/-6544929051100552273\n",
      "INFO: [2025-06-27 16:39:00] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:00] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:01] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:39:01] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-29122158203077245/-6396036063237276422\n",
      "INFO: [2025-06-27 16:39:01] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:01] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:01] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  26%|‚ñà‚ñà‚ñå       | 24/92 [00:36<01:41,  1.50s/it]INFO: [2025-06-27 16:39:01] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-22627892168184181/4032058879330639101\n",
      "INFO: [2025-06-27 16:39:01] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:01] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:01] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:39:01] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-22627892168184181/470173927382475785\n",
      "INFO: [2025-06-27 16:39:01] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:01] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:01] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:39:01] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-22627892168184181/-4556705642132470901\n",
      "INFO: [2025-06-27 16:39:01] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:01] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:02] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:39:02] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-22627892168184181/1111188242320460874\n",
      "INFO: [2025-06-27 16:39:02] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:02] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:02] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:39:02] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-22627892168184181/-879898175572310842\n",
      "INFO: [2025-06-27 16:39:02] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:02] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:02] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  27%|‚ñà‚ñà‚ñã       | 25/92 [00:37<01:40,  1.51s/it]INFO: [2025-06-27 16:39:02] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/28030974524863734/-3074741708453388847\n",
      "INFO: [2025-06-27 16:39:02] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:02] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:03] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/28030974524863734/-2726299984476970082\n",
      "INFO: [2025-06-27 16:39:03] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:03] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:03] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:39:03] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/28030974524863734/2035246656474436993\n",
      "INFO: [2025-06-27 16:39:03] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:03] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:03] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:39:03] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/28030974524863734/-3424265269175611909\n",
      "INFO: [2025-06-27 16:39:03] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:03] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:04] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:39:04] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/28030974524863734/41096803244585387\n",
      "INFO: [2025-06-27 16:39:04] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:04] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:04] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  28%|‚ñà‚ñà‚ñä       | 26/92 [00:39<01:37,  1.48s/it]INFO: [2025-06-27 16:39:04] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-8639253709990781/-3246872346744851883\n",
      "INFO: [2025-06-27 16:39:04] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:04] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:04] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:39:04] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-8639253709990781/716383431881062025\n",
      "INFO: [2025-06-27 16:39:04] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:04] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:05] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:39:05] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-8639253709990781/8895919881072540994\n",
      "INFO: [2025-06-27 16:39:05] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:05] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:05] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:39:05] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-8639253709990781/-6690632259270732649\n",
      "INFO: [2025-06-27 16:39:05] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:05] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:05] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:39:05] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-8639253709990781/2700726683991673132\n",
      "INFO: [2025-06-27 16:39:05] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:05] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:05] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  29%|‚ñà‚ñà‚ñâ       | 27/92 [00:40<01:37,  1.50s/it]INFO: [2025-06-27 16:39:05] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/33041281229298748/-3842792248032066274\n",
      "INFO: [2025-06-27 16:39:05] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:05] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:06] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:39:06] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/33041281229298748/-2736425708469822029\n",
      "INFO: [2025-06-27 16:39:06] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:06] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:06] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:39:06] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/33041281229298748/7784519163434280305\n",
      "INFO: [2025-06-27 16:39:06] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:06] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:06] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:39:06] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/33041281229298748/1967083863833861440\n",
      "INFO: [2025-06-27 16:39:06] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:06] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:07] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:39:07] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/33041281229298748/6819001063288595490\n",
      "INFO: [2025-06-27 16:39:07] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:07] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:07] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  30%|‚ñà‚ñà‚ñà       | 28/92 [00:42<01:42,  1.60s/it]INFO: [2025-06-27 16:39:07] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-26780953604978411/-4250877145294801920\n",
      "INFO: [2025-06-27 16:39:07] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:07] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:07] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:39:07] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-26780953604978411/-8492825480326791538\n",
      "INFO: [2025-06-27 16:39:07] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:07] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:08] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:39:08] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-26780953604978411/-2100308078671207313\n",
      "INFO: [2025-06-27 16:39:08] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:08] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:08] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:39:08] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-26780953604978411/-5575280606509183888\n",
      "INFO: [2025-06-27 16:39:08] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:08] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:08] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:39:08] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-26780953604978411/-6591501306161014441\n",
      "INFO: [2025-06-27 16:39:08] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:08] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  32%|‚ñà‚ñà‚ñà‚ñè      | 29/92 [00:44<01:40,  1.60s/it]INFO: [2025-06-27 16:39:09] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-18949191324265795/-49564332575376769\n",
      "INFO: [2025-06-27 16:39:09] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:09] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:09] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:39:09] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-18949191324265795/3892932039053876148\n",
      "INFO: [2025-06-27 16:39:09] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:09] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:09] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:39:09] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-18949191324265795/-7412386992750855525\n",
      "INFO: [2025-06-27 16:39:09] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:09] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:10] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:39:10] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-18949191324265795/-7996588531648180442\n",
      "INFO: [2025-06-27 16:39:10] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:10] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:10] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:39:10] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-18949191324265795/-6770950505668158144\n",
      "INFO: [2025-06-27 16:39:10] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:10] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:10] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  33%|‚ñà‚ñà‚ñà‚ñé      | 30/92 [00:45<01:33,  1.51s/it]INFO: [2025-06-27 16:39:10] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/1410763986151621/-5303531952248046704\n",
      "INFO: [2025-06-27 16:39:10] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:10] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:11] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:39:11] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/1410763986151621/-2688532263111441383\n",
      "INFO: [2025-06-27 16:39:11] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:11] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:11] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:39:11] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/1410763986151621/8563660454736324069\n",
      "INFO: [2025-06-27 16:39:11] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:11] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:11] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:39:11] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/1410763986151621/-4676444358467089678\n",
      "INFO: [2025-06-27 16:39:11] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:11] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:11] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:39:11] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/1410763986151621/-957945175582104365\n",
      "INFO: [2025-06-27 16:39:11] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:11] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:12] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  34%|‚ñà‚ñà‚ñà‚ñé      | 31/92 [00:46<01:33,  1.53s/it]INFO: [2025-06-27 16:39:12] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/1739983631954371/-8909822612301210139\n",
      "INFO: [2025-06-27 16:39:12] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:12] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:12] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:39:12] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/1739983631954371/-2641372761280601706\n",
      "INFO: [2025-06-27 16:39:12] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:12] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:12] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/1739983631954371/-6021349484732747496\n",
      "INFO: [2025-06-27 16:39:12] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:12] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:13] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/1739983631954371/-4724646644972343183\n",
      "INFO: [2025-06-27 16:39:13] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:13] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:13] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/1739983631954371/-1954372949916326066\n",
      "INFO: [2025-06-27 16:39:13] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:13] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  35%|‚ñà‚ñà‚ñà‚ñç      | 32/92 [00:48<01:31,  1.52s/it]INFO: [2025-06-27 16:39:13] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/5895544448831150/4677892577581706602\n",
      "INFO: [2025-06-27 16:39:13] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:13] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:13] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/5895544448831150/-5678493114848982685\n",
      "INFO: [2025-06-27 16:39:13] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:13] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:14] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:39:14] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/5895544448831150/-490770981002928139\n",
      "INFO: [2025-06-27 16:39:14] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:14] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:14] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  36%|‚ñà‚ñà‚ñà‚ñå      | 33/92 [00:49<01:20,  1.36s/it]INFO: [2025-06-27 16:39:14] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/31202820582613161/1302862404895722931\n",
      "INFO: [2025-06-27 16:39:14] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:14] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:14] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:39:14] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/31202820582613161/5971038755421669400\n",
      "INFO: [2025-06-27 16:39:14] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:14] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:15] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:39:15] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/31202820582613161/-7187469697580805303\n",
      "INFO: [2025-06-27 16:39:15] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:15] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:15] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:39:15] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/31202820582613161/-5485648695080232873\n",
      "INFO: [2025-06-27 16:39:15] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:15] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:16] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:39:16] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/31202820582613161/-4438341281978505015\n",
      "INFO: [2025-06-27 16:39:16] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:16] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  37%|‚ñà‚ñà‚ñà‚ñã      | 34/92 [00:51<01:24,  1.45s/it]INFO: [2025-06-27 16:39:16] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-35884737692158253/1059193101662654198\n",
      "INFO: [2025-06-27 16:39:16] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:16] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:16] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:39:16] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-35884737692158253/-851255063151224319\n",
      "INFO: [2025-06-27 16:39:16] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:16] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:17] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:39:17] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-35884737692158253/-5183722729337929251\n",
      "INFO: [2025-06-27 16:39:17] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:17] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:17] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-35884737692158253/-4181607857325202442\n",
      "INFO: [2025-06-27 16:39:17] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:17] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:17] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:39:17] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-35884737692158253/-6004749260235273668\n",
      "INFO: [2025-06-27 16:39:17] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:17] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:17] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  38%|‚ñà‚ñà‚ñà‚ñä      | 35/92 [00:52<01:25,  1.50s/it]INFO: [2025-06-27 16:39:17] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-34803309266443718/5580369426739380001\n",
      "INFO: [2025-06-27 16:39:17] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:17] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:18] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:39:18] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-34803309266443718/-6707805339997665826\n",
      "INFO: [2025-06-27 16:39:18] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:18] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:18] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:39:18] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-34803309266443718/3380995278001123487\n",
      "INFO: [2025-06-27 16:39:18] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:18] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:19] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:39:19] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-34803309266443718/8704463689891911278\n",
      "INFO: [2025-06-27 16:39:19] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:19] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:19] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:39:19] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-34803309266443718/1711775163034602511\n",
      "INFO: [2025-06-27 16:39:19] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:19] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:19] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  39%|‚ñà‚ñà‚ñà‚ñâ      | 36/92 [00:54<01:26,  1.54s/it]INFO: [2025-06-27 16:39:19] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-22499263970759753/623588335874424306\n",
      "INFO: [2025-06-27 16:39:19] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:19] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:20] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-22499263970759753/-5811406536058053449\n",
      "INFO: [2025-06-27 16:39:20] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:20] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:20] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-22499263970759753/-8230480911474175565\n",
      "INFO: [2025-06-27 16:39:20] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:20] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:20] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:39:20] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-22499263970759753/4839793808578026488\n",
      "INFO: [2025-06-27 16:39:20] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:20] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:20] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-22499263970759753/5672304901974974070\n",
      "INFO: [2025-06-27 16:39:20] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:20] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  40%|‚ñà‚ñà‚ñà‚ñà      | 37/92 [00:55<01:26,  1.57s/it]INFO: [2025-06-27 16:39:21] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-12988782223228843/8148382400078380983\n",
      "INFO: [2025-06-27 16:39:21] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:21] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:21] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-12988782223228843/9148695508442837630\n",
      "INFO: [2025-06-27 16:39:21] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:21] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:22] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-12988782223228843/-6281577041156644526\n",
      "INFO: [2025-06-27 16:39:22] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:22] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:22] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-12988782223228843/-7639492274974046551\n",
      "INFO: [2025-06-27 16:39:22] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:22] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:22] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-12988782223228843/935323826139098089\n",
      "INFO: [2025-06-27 16:39:22] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:22] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 38/92 [00:57<01:25,  1.59s/it]INFO: [2025-06-27 16:39:22] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-7666152121409895/-5116808700954080261\n",
      "INFO: [2025-06-27 16:39:22] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:22] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:23] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:39:23] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-7666152121409895/-4085553015115928194\n",
      "INFO: [2025-06-27 16:39:23] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:23] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:23] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-7666152121409895/-4209305014920674025\n",
      "INFO: [2025-06-27 16:39:23] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:23] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:23] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:39:23] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-7666152121409895/4498186992857338885\n",
      "INFO: [2025-06-27 16:39:23] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:23] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:24] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:39:24] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-7666152121409895/-5284872250135265225\n",
      "INFO: [2025-06-27 16:39:24] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:24] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:24] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 39/92 [00:59<01:27,  1.66s/it]INFO: [2025-06-27 16:39:24] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/21634894993301822/1225585874383749432\n",
      "INFO: [2025-06-27 16:39:24] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:24] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:24] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:39:24] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/21634894993301822/7556242793233433568\n",
      "INFO: [2025-06-27 16:39:24] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:24] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:25] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:39:25] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/21634894993301822/947202408938575961\n",
      "INFO: [2025-06-27 16:39:25] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:25] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:25] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/21634894993301822/6324067640264457939\n",
      "INFO: [2025-06-27 16:39:25] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:25] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:25] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:39:25] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/21634894993301822/951277465173199171\n",
      "INFO: [2025-06-27 16:39:25] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:25] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 40/92 [01:00<01:20,  1.54s/it]INFO: [2025-06-27 16:39:25] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/34364657708684419/-2629993364031988682\n",
      "INFO: [2025-06-27 16:39:25] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:25] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:26] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/34364657708684419/-5121180977425523747\n",
      "INFO: [2025-06-27 16:39:26] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:26] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:26] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:39:26] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/34364657708684419/-4126053122944348706\n",
      "INFO: [2025-06-27 16:39:26] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:26] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:26] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:39:26] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/34364657708684419/-3727692884436244935\n",
      "INFO: [2025-06-27 16:39:26] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:26] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:27] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:39:27] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/34364657708684419/1597240253355941547\n",
      "INFO: [2025-06-27 16:39:27] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:27] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:27] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 41/92 [01:02<01:18,  1.55s/it]INFO: [2025-06-27 16:39:27] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/10262358575052520/5193588747273290001\n",
      "INFO: [2025-06-27 16:39:27] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:27] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:27] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/10262358575052520/5413288797231960807\n",
      "INFO: [2025-06-27 16:39:27] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:27] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:28] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:39:28] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/10262358575052520/6384894172824164400\n",
      "INFO: [2025-06-27 16:39:28] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:28] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:28] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:39:28] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/10262358575052520/5193588747273290001\n",
      "INFO: [2025-06-27 16:39:28] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:28] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:28] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/10262358575052520/6384894172824164400\n",
      "INFO: [2025-06-27 16:39:28] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:28] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:29] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 42/92 [01:03<01:18,  1.58s/it]INFO: [2025-06-27 16:39:29] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/11111675784752136/-8333305609307516398\n",
      "INFO: [2025-06-27 16:39:29] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:29] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:29] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:39:29] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/11111675784752136/5350615363953520606\n",
      "INFO: [2025-06-27 16:39:29] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:29] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:29] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/11111675784752136/3350719506494207471\n",
      "INFO: [2025-06-27 16:39:29] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:29] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:30] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:39:30] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/11111675784752136/3461055843045518806\n",
      "INFO: [2025-06-27 16:39:30] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:30] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:30] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:39:30] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/11111675784752136/8342775031076687992\n",
      "INFO: [2025-06-27 16:39:30] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:30] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:30] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 43/92 [01:05<01:18,  1.59s/it]INFO: [2025-06-27 16:39:30] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/12642450547914707/8347204528152324975\n",
      "INFO: [2025-06-27 16:39:30] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:30] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:30] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:39:30] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/12642450547914707/2937249104658770404\n",
      "INFO: [2025-06-27 16:39:30] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:30] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:31] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:39:31] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/12642450547914707/-4863334710047129031\n",
      "INFO: [2025-06-27 16:39:31] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:31] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:31] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:39:31] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/12642450547914707/1968191420632676549\n",
      "INFO: [2025-06-27 16:39:31] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:31] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:32] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:39:32] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/12642450547914707/7620024638601426502\n",
      "INFO: [2025-06-27 16:39:32] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:32] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 44/92 [01:07<01:15,  1.58s/it]INFO: [2025-06-27 16:39:32] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/21893218624143108/4145945370990674474\n",
      "INFO: [2025-06-27 16:39:32] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:32] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:32] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:39:32] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/21893218624143108/573644746304192245\n",
      "INFO: [2025-06-27 16:39:32] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:32] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:33] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:39:33] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/21893218624143108/-4945713875907639718\n",
      "INFO: [2025-06-27 16:39:33] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:33] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:33] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:39:33] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/21893218624143108/3357630899287999218\n",
      "INFO: [2025-06-27 16:39:33] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:33] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:33] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:39:33] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/21893218624143108/-7327646880163051373\n",
      "INFO: [2025-06-27 16:39:33] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:33] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 45/92 [01:08<01:14,  1.58s/it]INFO: [2025-06-27 16:39:33] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-24316712102315887/2834571268812183428\n",
      "INFO: [2025-06-27 16:39:33] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:33] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:34] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:39:34] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-24316712102315887/3720793000583221964\n",
      "INFO: [2025-06-27 16:39:34] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:34] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:34] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:39:34] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-24316712102315887/5984152516802949451\n",
      "INFO: [2025-06-27 16:39:34] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:34] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:34] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:39:34] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-24316712102315887/-5150287373429888631\n",
      "INFO: [2025-06-27 16:39:34] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:34] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:35] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-24316712102315887/-8910198268186727635\n",
      "INFO: [2025-06-27 16:39:35] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:35] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:35] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 46/92 [01:10<01:12,  1.59s/it]INFO: [2025-06-27 16:39:35] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-23507181552861323/3510879047104264830\n",
      "INFO: [2025-06-27 16:39:35] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:35] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:35] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:39:35] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-23507181552861323/4137440517101656685\n",
      "INFO: [2025-06-27 16:39:35] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:35] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:36] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:39:36] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-23507181552861323/-8238821923278641850\n",
      "INFO: [2025-06-27 16:39:36] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:36] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:36] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-23507181552861323/6072207199438534637\n",
      "INFO: [2025-06-27 16:39:36] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:36] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:36] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:39:36] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-23507181552861323/-1262045258718203678\n",
      "INFO: [2025-06-27 16:39:36] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:36] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 47/92 [01:11<01:10,  1.57s/it]INFO: [2025-06-27 16:39:37] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-18152182327560480/-4341089490484079760\n",
      "INFO: [2025-06-27 16:39:37] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:37] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:37] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:39:37] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-18152182327560480/-2197564856973422755\n",
      "INFO: [2025-06-27 16:39:37] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:37] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:37] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-18152182327560480/1371242355701412014\n",
      "INFO: [2025-06-27 16:39:37] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:37] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:37] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:39:37] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-18152182327560480/-9126318783037784645\n",
      "INFO: [2025-06-27 16:39:37] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:37] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:38] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:39:38] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-18152182327560480/-2638948329676682937\n",
      "INFO: [2025-06-27 16:39:38] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:38] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:38] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 48/92 [01:13<01:08,  1.56s/it]INFO: [2025-06-27 16:39:38] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/21321689889868872/-3631827477176517536\n",
      "INFO: [2025-06-27 16:39:38] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:38] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:38] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:39:38] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/21321689889868872/4277189631399119518\n",
      "INFO: [2025-06-27 16:39:38] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:38] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:39] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:39:39] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/21321689889868872/-3029230678400443214\n",
      "INFO: [2025-06-27 16:39:39] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:39] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:39] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/21321689889868872/2513408173929564530\n",
      "INFO: [2025-06-27 16:39:39] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:39] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:39] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:39:39] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/21321689889868872/-2131663956400107588\n",
      "INFO: [2025-06-27 16:39:39] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:39] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:40] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 49/92 [01:14<01:07,  1.58s/it]INFO: [2025-06-27 16:39:40] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-12463996681673250/1001484088117419076\n",
      "INFO: [2025-06-27 16:39:40] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:40] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:40] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:39:40] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-12463996681673250/1208163505060035575\n",
      "INFO: [2025-06-27 16:39:40] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:40] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:40] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:39:40] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-12463996681673250/5809878820364426932\n",
      "INFO: [2025-06-27 16:39:40] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:40] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:41] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-12463996681673250/-4018071394199911570\n",
      "INFO: [2025-06-27 16:39:41] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:41] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:41] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 50/92 [01:16<01:02,  1.49s/it]INFO: [2025-06-27 16:39:41] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-2139820121868237/7174911214789188615\n",
      "INFO: [2025-06-27 16:39:41] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:41] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:41] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:39:41] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-2139820121868237/-3965648376808544436\n",
      "INFO: [2025-06-27 16:39:41] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:41] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:41] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-2139820121868237/9166163062695038631\n",
      "INFO: [2025-06-27 16:39:41] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:41] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:42] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:39:42] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-2139820121868237/-8809767266699174627\n",
      "INFO: [2025-06-27 16:39:42] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:42] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:42] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 51/92 [01:17<00:58,  1.43s/it]INFO: [2025-06-27 16:39:42] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-1083216214855434/1353217280393293418\n",
      "INFO: [2025-06-27 16:39:42] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:42] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:42] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-1083216214855434/-1961593601051792778\n",
      "INFO: [2025-06-27 16:39:42] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:42] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:43] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-1083216214855434/-8258993645454398472\n",
      "INFO: [2025-06-27 16:39:43] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:43] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:43] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:39:43] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-1083216214855434/-1435460781728290990\n",
      "INFO: [2025-06-27 16:39:43] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:43] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 52/92 [01:18<00:56,  1.41s/it]INFO: [2025-06-27 16:39:44] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/17131318242278983/1564341055827454194\n",
      "INFO: [2025-06-27 16:39:44] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:44] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:44] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:39:44] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/17131318242278983/6902031343714230598\n",
      "INFO: [2025-06-27 16:39:44] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:44] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:44] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/17131318242278983/7714819180289531073\n",
      "INFO: [2025-06-27 16:39:44] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:44] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:44] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:39:44] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/17131318242278983/4577407953817486235\n",
      "INFO: [2025-06-27 16:39:44] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:44] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:45] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 53/92 [01:20<00:51,  1.32s/it]INFO: [2025-06-27 16:39:45] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/20606471688970148/4584402743475666567\n",
      "INFO: [2025-06-27 16:39:45] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:45] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:45] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:39:45] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/20606471688970148/-4477833252834350399\n",
      "INFO: [2025-06-27 16:39:45] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:45] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:45] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:39:45] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/20606471688970148/2911353927501129219\n",
      "INFO: [2025-06-27 16:39:45] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:45] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:46] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:39:46] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/20606471688970148/6030815948872375181\n",
      "INFO: [2025-06-27 16:39:46] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:46] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 54/92 [01:21<00:50,  1.32s/it]INFO: [2025-06-27 16:39:46] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/24584688051044679/-3369816936700840932\n",
      "INFO: [2025-06-27 16:39:46] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:46] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:46] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/24584688051044679/6775015327379007916\n",
      "INFO: [2025-06-27 16:39:46] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:46] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:47] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/24584688051044679/-1798206033544741742\n",
      "INFO: [2025-06-27 16:39:47] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:47] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:47] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/24584688051044679/-2693608016918028982\n",
      "INFO: [2025-06-27 16:39:47] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:47] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:47] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 55/92 [01:22<00:49,  1.34s/it]INFO: [2025-06-27 16:39:47] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-25141892168903907/2842787141749613966\n",
      "INFO: [2025-06-27 16:39:47] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:47] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:48] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-25141892168903907/-6439376666594011464\n",
      "INFO: [2025-06-27 16:39:48] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:48] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:48] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:39:48] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-25141892168903907/-8903314523412236212\n",
      "INFO: [2025-06-27 16:39:48] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:48] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:48] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 56/92 [01:23<00:45,  1.27s/it]INFO: [2025-06-27 16:39:48] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-20439687097155111/1775209866093857310\n",
      "INFO: [2025-06-27 16:39:48] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:48] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:49] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:39:49] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-20439687097155111/7144522010287559589\n",
      "INFO: [2025-06-27 16:39:49] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:49] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:49] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:39:49] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-20439687097155111/8404126418433661645\n",
      "INFO: [2025-06-27 16:39:49] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:49] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:49] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 57/92 [01:24<00:39,  1.14s/it]INFO: [2025-06-27 16:39:49] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-15352348890731234/2611632168285154532\n",
      "INFO: [2025-06-27 16:39:49] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:49] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:50] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:39:50] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-15352348890731234/-2634502323142599163\n",
      "INFO: [2025-06-27 16:39:50] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:50] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:50] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:39:50] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-15352348890731234/1884060885835443568\n",
      "INFO: [2025-06-27 16:39:50] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:50] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:50] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 58/92 [01:25<00:37,  1.11s/it]INFO: [2025-06-27 16:39:50] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-4938783110044412/-9078285195640588986\n",
      "INFO: [2025-06-27 16:39:50] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:50] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:51] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:39:51] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-4938783110044412/4904932290730580929\n",
      "INFO: [2025-06-27 16:39:51] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:51] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:51] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:39:51] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-4938783110044412/1709325522002828324\n",
      "INFO: [2025-06-27 16:39:51] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:51] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 59/92 [01:26<00:33,  1.01s/it]INFO: [2025-06-27 16:39:51] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/17609986374660936/6955319964368225949\n",
      "INFO: [2025-06-27 16:39:51] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:51] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:52] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/17609986374660936/-2271101217331081907\n",
      "INFO: [2025-06-27 16:39:52] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:52] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:52] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:39:52] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/17609986374660936/-3284830607060838746\n",
      "INFO: [2025-06-27 16:39:52] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:52] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:52] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 60/92 [01:27<00:32,  1.02s/it]INFO: [2025-06-27 16:39:52] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/17681796354219824/1937655903082247767\n",
      "INFO: [2025-06-27 16:39:52] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:52] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:52] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/17681796354219824/4805165615096784855\n",
      "INFO: [2025-06-27 16:39:52] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:52] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:53] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/17681796354219824/3557359331496990844\n",
      "INFO: [2025-06-27 16:39:53] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:53] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:53] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 61/92 [01:28<00:32,  1.05s/it]INFO: [2025-06-27 16:39:53] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/35971629147007369/3934064133303539878\n",
      "INFO: [2025-06-27 16:39:53] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:53] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:54] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/35971629147007369/-76836233779723673\n",
      "INFO: [2025-06-27 16:39:54] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:54] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:54] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/35971629147007369/-5603215187459537893\n",
      "INFO: [2025-06-27 16:39:54] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:54] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 62/92 [01:29<00:29,  1.02it/s]INFO: [2025-06-27 16:39:54] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-29415098045592940/6411323736572457795\n",
      "INFO: [2025-06-27 16:39:54] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:54] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:54] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-29415098045592940/-1964285695976284026\n",
      "INFO: [2025-06-27 16:39:54] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:54] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:55] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 63/92 [01:30<00:25,  1.15it/s]INFO: [2025-06-27 16:39:55] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-28031656773092240/-8110188940058236355\n",
      "INFO: [2025-06-27 16:39:55] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:55] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:55] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-28031656773092240/7195142021001911519\n",
      "INFO: [2025-06-27 16:39:55] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:55] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 64/92 [01:30<00:23,  1.19it/s]INFO: [2025-06-27 16:39:56] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-22849205778179846/-8283104409014302301\n",
      "INFO: [2025-06-27 16:39:56] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:56] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:56] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-22849205778179846/4313876108651469704\n",
      "INFO: [2025-06-27 16:39:56] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:56] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:56] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 65/92 [01:31<00:20,  1.32it/s]INFO: [2025-06-27 16:39:56] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-18031556530033893/-8627777469347266434\n",
      "INFO: [2025-06-27 16:39:56] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:56] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:56] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-18031556530033893/-5274756934146961381\n",
      "INFO: [2025-06-27 16:39:56] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:56] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:57] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 66/92 [01:32<00:20,  1.29it/s]INFO: [2025-06-27 16:39:57] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-13505886640472175/-5016407656743507623\n",
      "INFO: [2025-06-27 16:39:57] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:57] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:57] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:39:57] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-13505886640472175/5466843209844404034\n",
      "INFO: [2025-06-27 16:39:57] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:57] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 67/92 [01:32<00:17,  1.42it/s]INFO: [2025-06-27 16:39:57] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-6735076600090236/6255694963833004319\n",
      "INFO: [2025-06-27 16:39:57] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:57] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 68/92 [01:33<00:13,  1.74it/s]INFO: [2025-06-27 16:39:58] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-3409159551394617/-1175751077694116458\n",
      "INFO: [2025-06-27 16:39:58] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:58] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:58] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-3409159551394617/-925249975991770452\n",
      "INFO: [2025-06-27 16:39:58] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:58] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:59] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 69/92 [01:33<00:14,  1.54it/s]INFO: [2025-06-27 16:39:59] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-2069452773758641/-8073980649127594574\n",
      "INFO: [2025-06-27 16:39:59] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:59] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:59] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-2069452773758641/-8385030890674185701\n",
      "INFO: [2025-06-27 16:39:59] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:59] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:39:59] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 70/92 [01:34<00:13,  1.62it/s]INFO: [2025-06-27 16:39:59] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/3297979118605018/2121973381815758809\n",
      "INFO: [2025-06-27 16:39:59] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:39:59] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:40:00] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/3297979118605018/-7629863625189970605\n",
      "INFO: [2025-06-27 16:40:00] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:00] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:40:00] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 71/92 [01:35<00:15,  1.33it/s]INFO: [2025-06-27 16:40:00] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/10757094666506670/2521158598917791125\n",
      "INFO: [2025-06-27 16:40:00] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:00] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:40:00] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/10757094666506670/2049223786216519273\n",
      "INFO: [2025-06-27 16:40:00] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:00] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:40:01] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 72/92 [01:36<00:15,  1.33it/s]INFO: [2025-06-27 16:40:01] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/14377716460635733/224067156940651406\n",
      "INFO: [2025-06-27 16:40:01] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:01] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:40:01] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/14377716460635733/6494760830414415628\n",
      "INFO: [2025-06-27 16:40:01] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:01] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 73/92 [01:36<00:13,  1.38it/s]INFO: [2025-06-27 16:40:02] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-33852347582520392/-1730356740998679943\n",
      "INFO: [2025-06-27 16:40:02] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:02] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 74/92 [01:37<00:10,  1.69it/s]INFO: [2025-06-27 16:40:02] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-25655970173329808/825366547021190712\n",
      "INFO: [2025-06-27 16:40:02] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:02] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 75/92 [01:37<00:08,  2.04it/s]INFO: [2025-06-27 16:40:02] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-22061102960387551/-8905627793055248873\n",
      "INFO: [2025-06-27 16:40:02] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:02] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 76/92 [01:37<00:07,  2.13it/s]INFO: [2025-06-27 16:40:03] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-20155356540515066/1617558396579091168\n",
      "INFO: [2025-06-27 16:40:03] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:03] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 77/92 [01:38<00:06,  2.46it/s]INFO: [2025-06-27 16:40:03] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-14117628316152430/3708495649437002708\n",
      "INFO: [2025-06-27 16:40:03] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:03] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 78/92 [01:38<00:05,  2.78it/s]INFO: [2025-06-27 16:40:03] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-11019131917628364/-7716517932206651477\n",
      "INFO: [2025-06-27 16:40:03] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:03] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 79/92 [01:38<00:04,  3.05it/s]INFO: [2025-06-27 16:40:03] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-10444363735373102/5157584201604396827\n",
      "INFO: [2025-06-27 16:40:03] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:03] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 80/92 [01:38<00:03,  3.25it/s]INFO: [2025-06-27 16:40:04] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-10033945991593843/-8343780824465910733\n",
      "INFO: [2025-06-27 16:40:04] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:04] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 81/92 [01:39<00:03,  2.90it/s]INFO: [2025-06-27 16:40:04] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-184811282650788/7459276384007237512\n",
      "INFO: [2025-06-27 16:40:04] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:04] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 82/92 [01:39<00:03,  3.22it/s]INFO: [2025-06-27 16:40:04] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/5566930627431303/-5089293816558006420\n",
      "INFO: [2025-06-27 16:40:04] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:04] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:40:04] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 83/92 [01:39<00:02,  3.39it/s]INFO: [2025-06-27 16:40:04] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/5609203557180661/-7281660177572507763\n",
      "INFO: [2025-06-27 16:40:04] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:04] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 84/92 [01:40<00:02,  2.87it/s]INFO: [2025-06-27 16:40:05] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/15133418971654738/7647822926109152780\n",
      "INFO: [2025-06-27 16:40:05] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:05] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 85/92 [01:40<00:02,  3.11it/s]INFO: [2025-06-27 16:40:05] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/15568847793479266/-4907848724437537709\n",
      "INFO: [2025-06-27 16:40:05] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:05] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 86/92 [01:40<00:01,  3.26it/s]INFO: [2025-06-27 16:40:05] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/17470512188912087/430810044304398948\n",
      "INFO: [2025-06-27 16:40:05] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:05] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 87/92 [01:41<00:01,  3.46it/s]INFO: [2025-06-27 16:40:06] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/18334778860223615/-7462221171272857117\n",
      "INFO: [2025-06-27 16:40:06] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:06] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 88/92 [01:41<00:01,  3.56it/s]INFO: [2025-06-27 16:40:06] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/19367730649708653/-4042641636918889097\n",
      "INFO: [2025-06-27 16:40:06] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:06] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 89/92 [01:41<00:00,  3.10it/s]INFO: [2025-06-27 16:40:06] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/30634204597194783/-5259171881687072106\n",
      "INFO: [2025-06-27 16:40:06] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:06] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 90/92 [01:41<00:00,  3.31it/s]INFO: [2025-06-27 16:40:07] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/30759839524016550/-3386398509503978146\n",
      "INFO: [2025-06-27 16:40:07] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:07] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:40:07] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 91/92 [01:42<00:00,  3.50it/s]INFO: [2025-06-27 16:40:07] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/31420388280123621/126985844909369330\n",
      "INFO: [2025-06-27 16:40:07] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:07] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 92/92 [01:42<00:00,  1.11s/it]\n",
      "Processing LLM curations:   0%|          | 0/92 [00:00<?, ?it/s]INFO: [2025-06-27 16:40:07] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-35882458128194165\n",
      "INFO: [2025-06-27 16:40:07] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:07] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:   1%|          | 1/92 [00:00<00:22,  4.12it/s]INFO: [2025-06-27 16:40:07] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/31160008118740626\n",
      "INFO: [2025-06-27 16:40:07] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:07] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:   2%|‚ñè         | 2/92 [00:00<00:30,  2.95it/s]INFO: [2025-06-27 16:40:08] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/33874939274212480\n",
      "INFO: [2025-06-27 16:40:08] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:08] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:   3%|‚ñé         | 3/92 [00:00<00:27,  3.24it/s]INFO: [2025-06-27 16:40:08] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-32399727139857751\n",
      "INFO: [2025-06-27 16:40:08] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:08] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:   4%|‚ñç         | 4/92 [00:01<00:25,  3.51it/s]INFO: [2025-06-27 16:40:08] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/9371935612488149\n",
      "INFO: [2025-06-27 16:40:08] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:08] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:   5%|‚ñå         | 5/92 [00:01<00:23,  3.64it/s]INFO: [2025-06-27 16:40:09] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/3246604237187558\n",
      "INFO: [2025-06-27 16:40:09] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:09] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:   7%|‚ñã         | 6/92 [00:01<00:22,  3.74it/s]INFO: [2025-06-27 16:40:09] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/9130628937861941\n",
      "INFO: [2025-06-27 16:40:09] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:09] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:   8%|‚ñä         | 7/92 [00:02<00:28,  3.03it/s]INFO: [2025-06-27 16:40:09] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/19706388665464256\n",
      "INFO: [2025-06-27 16:40:09] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:09] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:   9%|‚ñä         | 8/92 [00:02<00:26,  3.21it/s]INFO: [2025-06-27 16:40:10] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-14556452501867428\n",
      "INFO: [2025-06-27 16:40:10] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:10] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  10%|‚ñâ         | 9/92 [00:02<00:24,  3.40it/s]INFO: [2025-06-27 16:40:10] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/15114781201446083\n",
      "INFO: [2025-06-27 16:40:10] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:10] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  11%|‚ñà         | 10/92 [00:02<00:23,  3.55it/s]INFO: [2025-06-27 16:40:10] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/13290267870654994\n",
      "INFO: [2025-06-27 16:40:10] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:10] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  12%|‚ñà‚ñè        | 11/92 [00:03<00:21,  3.71it/s]INFO: [2025-06-27 16:40:10] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/30902335548899281\n",
      "INFO: [2025-06-27 16:40:10] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:10] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  13%|‚ñà‚ñé        | 12/92 [00:03<00:27,  2.91it/s]INFO: [2025-06-27 16:40:11] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/2135209076854093\n",
      "INFO: [2025-06-27 16:40:11] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:11] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  14%|‚ñà‚ñç        | 13/92 [00:03<00:24,  3.16it/s]INFO: [2025-06-27 16:40:11] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-18387380848780476\n",
      "INFO: [2025-06-27 16:40:11] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:11] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  15%|‚ñà‚ñå        | 14/92 [00:04<00:23,  3.36it/s]INFO: [2025-06-27 16:40:11] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/18933828397346607\n",
      "INFO: [2025-06-27 16:40:11] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:11] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  16%|‚ñà‚ñã        | 15/92 [00:04<00:22,  3.47it/s]INFO: [2025-06-27 16:40:12] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/20978307744432241\n",
      "INFO: [2025-06-27 16:40:12] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:12] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  17%|‚ñà‚ñã        | 16/92 [00:04<00:20,  3.63it/s]INFO: [2025-06-27 16:40:12] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-35102576635162472\n",
      "INFO: [2025-06-27 16:40:12] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:12] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  18%|‚ñà‚ñä        | 17/92 [00:05<00:23,  3.15it/s]INFO: [2025-06-27 16:40:12] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-7126418877828068\n",
      "INFO: [2025-06-27 16:40:12] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:12] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  20%|‚ñà‚ñâ        | 18/92 [00:05<00:22,  3.29it/s]INFO: [2025-06-27 16:40:13] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-19952367157294119\n",
      "INFO: [2025-06-27 16:40:13] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:13] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  21%|‚ñà‚ñà        | 19/92 [00:05<00:20,  3.49it/s]INFO: [2025-06-27 16:40:13] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-34105277816332298\n",
      "INFO: [2025-06-27 16:40:13] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:13] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  22%|‚ñà‚ñà‚ñè       | 20/92 [00:05<00:20,  3.54it/s]INFO: [2025-06-27 16:40:13] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-25725881202629826\n",
      "INFO: [2025-06-27 16:40:13] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:13] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  23%|‚ñà‚ñà‚ñé       | 21/92 [00:06<00:19,  3.58it/s]INFO: [2025-06-27 16:40:13] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-2046863695546735\n",
      "INFO: [2025-06-27 16:40:13] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:13] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  24%|‚ñà‚ñà‚ñç       | 22/92 [00:06<00:19,  3.65it/s]INFO: [2025-06-27 16:40:14] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/12631778325074772\n",
      "INFO: [2025-06-27 16:40:14] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:14] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  25%|‚ñà‚ñà‚ñå       | 23/92 [00:06<00:23,  2.89it/s]INFO: [2025-06-27 16:40:14] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-29122158203077245\n",
      "INFO: [2025-06-27 16:40:14] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:14] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  26%|‚ñà‚ñà‚ñå       | 24/92 [00:07<00:22,  3.09it/s]INFO: [2025-06-27 16:40:14] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-22627892168184181\n",
      "INFO: [2025-06-27 16:40:14] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:14] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  27%|‚ñà‚ñà‚ñã       | 25/92 [00:07<00:20,  3.23it/s]INFO: [2025-06-27 16:40:15] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/28030974524863734\n",
      "INFO: [2025-06-27 16:40:15] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:15] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  28%|‚ñà‚ñà‚ñä       | 26/92 [00:07<00:19,  3.38it/s]INFO: [2025-06-27 16:40:15] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-8639253709990781\n",
      "INFO: [2025-06-27 16:40:15] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:15] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  29%|‚ñà‚ñà‚ñâ       | 27/92 [00:08<00:18,  3.44it/s]INFO: [2025-06-27 16:40:15] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/33041281229298748\n",
      "INFO: [2025-06-27 16:40:15] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:15] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  30%|‚ñà‚ñà‚ñà       | 28/92 [00:08<00:23,  2.71it/s]INFO: [2025-06-27 16:40:16] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-26780953604978411\n",
      "INFO: [2025-06-27 16:40:16] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:16] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  32%|‚ñà‚ñà‚ñà‚ñè      | 29/92 [00:08<00:21,  2.96it/s]INFO: [2025-06-27 16:40:16] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-18949191324265795\n",
      "INFO: [2025-06-27 16:40:16] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:16] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  33%|‚ñà‚ñà‚ñà‚ñé      | 30/92 [00:09<00:19,  3.13it/s]INFO: [2025-06-27 16:40:16] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/1410763986151621\n",
      "INFO: [2025-06-27 16:40:16] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:16] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  34%|‚ñà‚ñà‚ñà‚ñé      | 31/92 [00:09<00:18,  3.25it/s]INFO: [2025-06-27 16:40:17] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/1739983631954371\n",
      "INFO: [2025-06-27 16:40:17] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:17] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  35%|‚ñà‚ñà‚ñà‚ñç      | 32/92 [00:09<00:17,  3.38it/s]INFO: [2025-06-27 16:40:17] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/5895544448831150\n",
      "INFO: [2025-06-27 16:40:17] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:17] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  36%|‚ñà‚ñà‚ñà‚ñå      | 33/92 [00:10<00:21,  2.69it/s]INFO: [2025-06-27 16:40:17] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/31202820582613161\n",
      "INFO: [2025-06-27 16:40:17] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:17] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  37%|‚ñà‚ñà‚ñà‚ñã      | 34/92 [00:10<00:19,  2.94it/s]INFO: [2025-06-27 16:40:18] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-35884737692158253\n",
      "INFO: [2025-06-27 16:40:18] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:18] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  38%|‚ñà‚ñà‚ñà‚ñä      | 35/92 [00:10<00:18,  3.13it/s]INFO: [2025-06-27 16:40:18] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-34803309266443718\n",
      "INFO: [2025-06-27 16:40:18] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:18] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  39%|‚ñà‚ñà‚ñà‚ñâ      | 36/92 [00:11<00:17,  3.26it/s]INFO: [2025-06-27 16:40:18] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-22499263970759753\n",
      "INFO: [2025-06-27 16:40:18] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:18] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  40%|‚ñà‚ñà‚ñà‚ñà      | 37/92 [00:11<00:16,  3.38it/s]INFO: [2025-06-27 16:40:18] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-12988782223228843\n",
      "INFO: [2025-06-27 16:40:18] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:18] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 38/92 [00:11<00:20,  2.69it/s]INFO: [2025-06-27 16:40:19] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-7666152121409895\n",
      "INFO: [2025-06-27 16:40:19] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:19] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 39/92 [00:12<00:17,  2.98it/s]INFO: [2025-06-27 16:40:19] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/21634894993301822\n",
      "INFO: [2025-06-27 16:40:19] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:19] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 40/92 [00:12<00:16,  3.19it/s]INFO: [2025-06-27 16:40:20] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/34364657708684419\n",
      "INFO: [2025-06-27 16:40:20] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:20] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 41/92 [00:12<00:15,  3.30it/s]INFO: [2025-06-27 16:40:20] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/10262358575052520\n",
      "INFO: [2025-06-27 16:40:20] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:20] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 42/92 [00:13<00:17,  2.91it/s]INFO: [2025-06-27 16:40:20] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/11111675784752136\n",
      "INFO: [2025-06-27 16:40:20] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:20] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 43/92 [00:13<00:15,  3.15it/s]INFO: [2025-06-27 16:40:20] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/12642450547914707\n",
      "INFO: [2025-06-27 16:40:20] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:20] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 44/92 [00:13<00:14,  3.38it/s]INFO: [2025-06-27 16:40:21] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/21893218624143108\n",
      "INFO: [2025-06-27 16:40:21] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:21] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 45/92 [00:13<00:13,  3.43it/s]INFO: [2025-06-27 16:40:21] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-24316712102315887\n",
      "INFO: [2025-06-27 16:40:21] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:21] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 46/92 [00:14<00:13,  3.50it/s]INFO: [2025-06-27 16:40:21] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-23507181552861323\n",
      "INFO: [2025-06-27 16:40:21] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:21] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 47/92 [00:14<00:12,  3.53it/s]INFO: [2025-06-27 16:40:22] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-18152182327560480\n",
      "INFO: [2025-06-27 16:40:22] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:22] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 48/92 [00:14<00:12,  3.45it/s]INFO: [2025-06-27 16:40:22] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/21321689889868872\n",
      "INFO: [2025-06-27 16:40:22] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:22] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 49/92 [00:15<00:15,  2.86it/s]INFO: [2025-06-27 16:40:22] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-12463996681673250\n",
      "INFO: [2025-06-27 16:40:22] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:22] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 50/92 [00:15<00:16,  2.59it/s]INFO: [2025-06-27 16:40:23] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-2139820121868237\n",
      "INFO: [2025-06-27 16:40:23] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:23] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 51/92 [00:15<00:14,  2.83it/s]INFO: [2025-06-27 16:40:23] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-1083216214855434\n",
      "INFO: [2025-06-27 16:40:23] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:23] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 52/92 [00:16<00:12,  3.08it/s]INFO: [2025-06-27 16:40:23] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/17131318242278983\n",
      "INFO: [2025-06-27 16:40:23] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:23] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 53/92 [00:16<00:12,  3.21it/s]INFO: [2025-06-27 16:40:24] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/20606471688970148\n",
      "INFO: [2025-06-27 16:40:24] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:24] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 54/92 [00:17<00:14,  2.55it/s]INFO: [2025-06-27 16:40:24] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/24584688051044679\n",
      "INFO: [2025-06-27 16:40:24] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:24] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 55/92 [00:17<00:13,  2.77it/s]INFO: [2025-06-27 16:40:25] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-25141892168903907\n",
      "INFO: [2025-06-27 16:40:25] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:25] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 56/92 [00:17<00:11,  3.00it/s]INFO: [2025-06-27 16:40:25] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-20439687097155111\n",
      "INFO: [2025-06-27 16:40:25] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:25] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 57/92 [00:17<00:11,  3.12it/s]INFO: [2025-06-27 16:40:25] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-15352348890731234\n",
      "INFO: [2025-06-27 16:40:25] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:25] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 58/92 [00:18<00:12,  2.78it/s]INFO: [2025-06-27 16:40:26] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-4938783110044412\n",
      "INFO: [2025-06-27 16:40:26] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:26] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 59/92 [00:18<00:13,  2.40it/s]INFO: [2025-06-27 16:40:26] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/17609986374660936\n",
      "INFO: [2025-06-27 16:40:26] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:26] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 60/92 [00:19<00:12,  2.66it/s]INFO: [2025-06-27 16:40:26] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/17681796354219824\n",
      "INFO: [2025-06-27 16:40:26] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:26] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 61/92 [00:19<00:10,  2.92it/s]INFO: [2025-06-27 16:40:27] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/35971629147007369\n",
      "INFO: [2025-06-27 16:40:27] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:27] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 62/92 [00:19<00:09,  3.16it/s]INFO: [2025-06-27 16:40:27] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-29415098045592940\n",
      "INFO: [2025-06-27 16:40:27] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:27] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 63/92 [00:20<00:08,  3.33it/s]INFO: [2025-06-27 16:40:27] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-28031656773092240\n",
      "INFO: [2025-06-27 16:40:27] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:27] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 64/92 [00:20<00:10,  2.63it/s]INFO: [2025-06-27 16:40:28] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-22849205778179846\n",
      "INFO: [2025-06-27 16:40:28] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:28] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 65/92 [00:20<00:09,  2.88it/s]INFO: [2025-06-27 16:40:28] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-18031556530033893\n",
      "INFO: [2025-06-27 16:40:28] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:28] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 66/92 [00:21<00:08,  3.11it/s]INFO: [2025-06-27 16:40:28] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-13505886640472175\n",
      "INFO: [2025-06-27 16:40:28] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:28] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 67/92 [00:21<00:07,  3.23it/s]INFO: [2025-06-27 16:40:29] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-6735076600090236\n",
      "INFO: [2025-06-27 16:40:29] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:29] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 68/92 [00:21<00:07,  3.32it/s]INFO: [2025-06-27 16:40:29] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-3409159551394617\n",
      "INFO: [2025-06-27 16:40:29] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:29] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 69/92 [00:22<00:08,  2.67it/s]INFO: [2025-06-27 16:40:29] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-2069452773758641\n",
      "INFO: [2025-06-27 16:40:29] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:29] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 70/92 [00:22<00:08,  2.60it/s]INFO: [2025-06-27 16:40:30] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/3297979118605018\n",
      "INFO: [2025-06-27 16:40:30] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:30] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 71/92 [00:22<00:07,  2.91it/s]INFO: [2025-06-27 16:40:30] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/10757094666506670\n",
      "INFO: [2025-06-27 16:40:30] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:30] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 72/92 [00:23<00:06,  3.13it/s]INFO: [2025-06-27 16:40:30] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/14377716460635733\n",
      "INFO: [2025-06-27 16:40:30] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:30] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 73/92 [00:23<00:05,  3.31it/s]INFO: [2025-06-27 16:40:31] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-33852347582520392\n",
      "INFO: [2025-06-27 16:40:31] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:31] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 74/92 [00:23<00:06,  2.64it/s]INFO: [2025-06-27 16:40:31] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-25655970173329808\n",
      "INFO: [2025-06-27 16:40:31] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:31] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 75/92 [00:24<00:05,  2.93it/s]INFO: [2025-06-27 16:40:31] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-22061102960387551\n",
      "INFO: [2025-06-27 16:40:31] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:31] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 76/92 [00:24<00:05,  3.13it/s]INFO: [2025-06-27 16:40:32] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-20155356540515066\n",
      "INFO: [2025-06-27 16:40:32] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:32] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 77/92 [00:24<00:04,  3.30it/s]INFO: [2025-06-27 16:40:32] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-14117628316152430\n",
      "INFO: [2025-06-27 16:40:32] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:32] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 78/92 [00:25<00:04,  3.43it/s]INFO: [2025-06-27 16:40:32] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-11019131917628364\n",
      "INFO: [2025-06-27 16:40:32] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:32] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 79/92 [00:25<00:03,  3.58it/s]INFO: [2025-06-27 16:40:32] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-10444363735373102\n",
      "INFO: [2025-06-27 16:40:32] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:32] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 80/92 [00:25<00:04,  2.79it/s]INFO: [2025-06-27 16:40:33] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-10033945991593843\n",
      "INFO: [2025-06-27 16:40:33] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:33] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 81/92 [00:26<00:03,  3.02it/s]INFO: [2025-06-27 16:40:33] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-184811282650788\n",
      "INFO: [2025-06-27 16:40:33] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:33] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 82/92 [00:26<00:03,  3.23it/s]INFO: [2025-06-27 16:40:33] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/5566930627431303\n",
      "INFO: [2025-06-27 16:40:33] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:33] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 83/92 [00:26<00:02,  3.39it/s]INFO: [2025-06-27 16:40:34] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/5609203557180661\n",
      "INFO: [2025-06-27 16:40:34] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:34] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 84/92 [00:26<00:02,  3.52it/s]INFO: [2025-06-27 16:40:34] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/15133418971654738\n",
      "INFO: [2025-06-27 16:40:34] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:34] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 85/92 [00:27<00:02,  2.97it/s]INFO: [2025-06-27 16:40:34] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/15568847793479266\n",
      "INFO: [2025-06-27 16:40:34] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:34] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 86/92 [00:27<00:01,  3.19it/s]INFO: [2025-06-27 16:40:35] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/17470512188912087\n",
      "INFO: [2025-06-27 16:40:35] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:35] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 87/92 [00:27<00:01,  3.38it/s]INFO: [2025-06-27 16:40:35] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/18334778860223615\n",
      "INFO: [2025-06-27 16:40:35] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:35] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 88/92 [00:28<00:01,  3.49it/s]INFO: [2025-06-27 16:40:35] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/19367730649708653\n",
      "INFO: [2025-06-27 16:40:35] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:35] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 89/92 [00:28<00:00,  3.63it/s]INFO: [2025-06-27 16:40:35] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/30634204597194783\n",
      "INFO: [2025-06-27 16:40:35] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:35] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 90/92 [00:28<00:00,  2.82it/s]INFO: [2025-06-27 16:40:36] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/30759839524016550\n",
      "INFO: [2025-06-27 16:40:36] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:36] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 91/92 [00:29<00:00,  3.08it/s]INFO: [2025-06-27 16:40:36] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/31420388280123621\n",
      "INFO: [2025-06-27 16:40:36] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:36] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 92/92 [00:29<00:00,  3.13it/s]\n",
      "Processing LLM curations:   0%|          | 0/92 [00:00<?, ?it/s]INFO: [2025-06-27 16:40:37] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-35882458128194165/1938690358594167689\n",
      "INFO: [2025-06-27 16:40:37] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:37] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:40:37] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:40:37] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-35882458128194165/-3134915728042432850\n",
      "INFO: [2025-06-27 16:40:37] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:37] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:40:37] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:40:37] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-35882458128194165/-2918325224516975291\n",
      "INFO: [2025-06-27 16:40:37] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:37] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:40:38] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:40:38] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-35882458128194165/1188999731104970142\n",
      "INFO: [2025-06-27 16:40:38] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:38] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:40:38] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:40:38] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-35882458128194165/8396446238500599993\n",
      "INFO: [2025-06-27 16:40:38] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:38] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:40:38] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:   1%|          | 1/92 [00:01<02:17,  1.51s/it]INFO: [2025-06-27 16:40:38] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/31160008118740626/-2027361663396374461\n",
      "INFO: [2025-06-27 16:40:38] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:38] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:40:38] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:40:38] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/31160008118740626/-6979698373652945405\n",
      "INFO: [2025-06-27 16:40:38] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:38] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:40:39] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:40:39] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/31160008118740626/3880795213340901323\n",
      "INFO: [2025-06-27 16:40:39] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:39] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:40:39] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:40:39] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/31160008118740626/-8788851609986855947\n",
      "INFO: [2025-06-27 16:40:39] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:39] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:40:39] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:40:39] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/31160008118740626/412867969793807489\n",
      "INFO: [2025-06-27 16:40:39] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:39] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:40:40] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:   2%|‚ñè         | 2/92 [00:03<02:20,  1.56s/it]INFO: [2025-06-27 16:40:40] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/33874939274212480/-4669591336875541030\n",
      "INFO: [2025-06-27 16:40:40] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:40] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:40:40] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:40:40] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/33874939274212480/7874641916508667945\n",
      "INFO: [2025-06-27 16:40:40] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:40] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:40:40] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:40:40] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/33874939274212480/5009290479354605301\n",
      "INFO: [2025-06-27 16:40:40] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:40] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:40:41] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:40:41] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/33874939274212480/-6002100917090733265\n",
      "INFO: [2025-06-27 16:40:41] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:41] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:40:41] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:40:41] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/33874939274212480/7802730623424876208\n",
      "INFO: [2025-06-27 16:40:41] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:41] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:40:41] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:   3%|‚ñé         | 3/92 [00:04<02:18,  1.55s/it]INFO: [2025-06-27 16:40:41] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-32399727139857751/3603741314522730535\n",
      "INFO: [2025-06-27 16:40:41] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:41] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:40:41] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:40:41] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-32399727139857751/-2043106889490646470\n",
      "INFO: [2025-06-27 16:40:41] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:41] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:40:42] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:40:42] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-32399727139857751/4405364781267347528\n",
      "INFO: [2025-06-27 16:40:42] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:42] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:40:42] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:40:42] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-32399727139857751/7344964365046198878\n",
      "INFO: [2025-06-27 16:40:42] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:42] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:40:42] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:40:42] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-32399727139857751/1672087129709357229\n",
      "INFO: [2025-06-27 16:40:42] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:42] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:40:43] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:   4%|‚ñç         | 4/92 [00:06<02:14,  1.53s/it]INFO: [2025-06-27 16:40:43] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/9371935612488149/-2620906938186192648\n",
      "INFO: [2025-06-27 16:40:43] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:43] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:40:43] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:40:43] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/9371935612488149/4144472102258836646\n",
      "INFO: [2025-06-27 16:40:43] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:43] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:40:43] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:40:43] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/9371935612488149/-7239966494664021582\n",
      "INFO: [2025-06-27 16:40:43] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:43] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:40:44] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:40:44] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/9371935612488149/7530734717755828244\n",
      "INFO: [2025-06-27 16:40:44] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:44] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:40:44] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:40:44] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/9371935612488149/-4370733044840420571\n",
      "INFO: [2025-06-27 16:40:44] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:44] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:40:44] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:   5%|‚ñå         | 5/92 [00:07<02:12,  1.53s/it]INFO: [2025-06-27 16:40:44] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/3246604237187558/-6950590062567455233\n",
      "INFO: [2025-06-27 16:40:44] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:44] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:40:44] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:40:44] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/3246604237187558/-3266570665522357864\n",
      "INFO: [2025-06-27 16:40:44] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:44] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:40:45] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:40:45] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/3246604237187558/2914228909343198949\n",
      "INFO: [2025-06-27 16:40:45] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:45] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:40:45] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:40:45] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/3246604237187558/1165098629901065394\n",
      "INFO: [2025-06-27 16:40:45] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:45] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:40:45] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:   7%|‚ñã         | 6/92 [00:08<02:04,  1.45s/it]INFO: [2025-06-27 16:40:45] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/9130628937861941/2461302388636224732\n",
      "INFO: [2025-06-27 16:40:45] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:45] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:40:46] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:40:46] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/9130628937861941/-4588659392760549759\n",
      "INFO: [2025-06-27 16:40:46] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:46] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:40:46] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:40:46] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/9130628937861941/3958941374801519603\n",
      "INFO: [2025-06-27 16:40:46] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:46] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:40:46] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/9130628937861941/-1692900409242322119\n",
      "INFO: [2025-06-27 16:40:46] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:46] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:40:47] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:40:47] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/9130628937861941/1133957129739150327\n",
      "INFO: [2025-06-27 16:40:47] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:47] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:40:47] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:   8%|‚ñä         | 7/92 [00:10<02:05,  1.48s/it]INFO: [2025-06-27 16:40:47] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/19706388665464256/-7917492718183589806\n",
      "INFO: [2025-06-27 16:40:47] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:47] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:40:47] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:40:47] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/19706388665464256/6671069886073016616\n",
      "INFO: [2025-06-27 16:40:47] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:47] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:40:48] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:40:48] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/19706388665464256/7033479116567972073\n",
      "INFO: [2025-06-27 16:40:48] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:48] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:40:48] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/19706388665464256/1836846670502670413\n",
      "INFO: [2025-06-27 16:40:48] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:48] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:40:48] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:40:48] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/19706388665464256/-2158214213192566763\n",
      "INFO: [2025-06-27 16:40:48] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:48] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:40:49] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:   9%|‚ñä         | 8/92 [00:12<02:05,  1.49s/it]INFO: [2025-06-27 16:40:49] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-14556452501867428/-7409270844860335477\n",
      "INFO: [2025-06-27 16:40:49] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:49] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:40:49] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:40:49] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-14556452501867428/-8560175068554562446\n",
      "INFO: [2025-06-27 16:40:49] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:49] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:40:49] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-14556452501867428/-2378515769215120271\n",
      "INFO: [2025-06-27 16:40:49] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:49] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:40:49] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:40:49] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-14556452501867428/6109172826936989164\n",
      "INFO: [2025-06-27 16:40:49] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:49] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:40:50] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:40:50] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-14556452501867428/7005389174867950469\n",
      "INFO: [2025-06-27 16:40:50] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:50] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:40:50] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  10%|‚ñâ         | 9/92 [00:13<02:05,  1.51s/it]INFO: [2025-06-27 16:40:50] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/15114781201446083/5062401353739605120\n",
      "INFO: [2025-06-27 16:40:50] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:50] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:40:50] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:40:50] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/15114781201446083/-4659160111401289158\n",
      "INFO: [2025-06-27 16:40:50] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:50] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:40:51] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:40:51] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/15114781201446083/227791839109059500\n",
      "INFO: [2025-06-27 16:40:51] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:51] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:40:51] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:40:51] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/15114781201446083/-1547984374499703471\n",
      "INFO: [2025-06-27 16:40:51] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:51] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:40:51] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:40:51] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/15114781201446083/-2215864027968062973\n",
      "INFO: [2025-06-27 16:40:51] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:51] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:40:52] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  11%|‚ñà         | 10/92 [00:15<02:04,  1.52s/it]INFO: [2025-06-27 16:40:52] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/13290267870654994/-7816016630472316549\n",
      "INFO: [2025-06-27 16:40:52] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:52] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:40:52] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:40:52] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/13290267870654994/8674720215695517734\n",
      "INFO: [2025-06-27 16:40:52] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:52] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:40:52] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:40:52] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/13290267870654994/3118304660890167350\n",
      "INFO: [2025-06-27 16:40:52] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:52] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:40:52] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:40:52] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/13290267870654994/-9022055847051917455\n",
      "INFO: [2025-06-27 16:40:52] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:52] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:40:53] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:40:53] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/13290267870654994/-5387049026338604217\n",
      "INFO: [2025-06-27 16:40:53] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:53] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:40:53] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  12%|‚ñà‚ñè        | 11/92 [00:16<02:03,  1.52s/it]INFO: [2025-06-27 16:40:53] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/30902335548899281/-6452656985917027033\n",
      "INFO: [2025-06-27 16:40:53] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:53] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:40:53] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:40:53] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/30902335548899281/7413267225472944649\n",
      "INFO: [2025-06-27 16:40:53] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:53] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:40:54] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:40:54] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/30902335548899281/-5138713353197435575\n",
      "INFO: [2025-06-27 16:40:54] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:54] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:40:54] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:40:54] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/30902335548899281/2446452447396815598\n",
      "INFO: [2025-06-27 16:40:54] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:54] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:40:54] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:40:54] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/30902335548899281/-1045048612220408182\n",
      "INFO: [2025-06-27 16:40:55] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:55] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:40:55] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  13%|‚ñà‚ñé        | 12/92 [00:18<02:03,  1.55s/it]INFO: [2025-06-27 16:40:55] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/2135209076854093/-559129980004163759\n",
      "INFO: [2025-06-27 16:40:55] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:55] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:40:55] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:40:55] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/2135209076854093/2713359617464566430\n",
      "INFO: [2025-06-27 16:40:55] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:55] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:40:55] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:40:55] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/2135209076854093/2466034248509608385\n",
      "INFO: [2025-06-27 16:40:55] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:55] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:40:56] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:40:56] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/2135209076854093/1536312070379657505\n",
      "INFO: [2025-06-27 16:40:56] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:56] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:40:56] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:40:56] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/2135209076854093/1249281260349670441\n",
      "INFO: [2025-06-27 16:40:56] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:56] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:40:56] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  14%|‚ñà‚ñç        | 13/92 [00:19<02:03,  1.56s/it]INFO: [2025-06-27 16:40:56] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-18387380848780476/6849826706501229990\n",
      "INFO: [2025-06-27 16:40:56] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:56] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:40:57] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:40:57] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-18387380848780476/-2228134318647310754\n",
      "INFO: [2025-06-27 16:40:57] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:57] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:40:57] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:40:57] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-18387380848780476/-5495954846659676187\n",
      "INFO: [2025-06-27 16:40:57] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:57] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:40:57] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:40:57] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-18387380848780476/3843572116858059127\n",
      "INFO: [2025-06-27 16:40:57] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:57] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:40:58] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:40:58] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-18387380848780476/1380099258313743549\n",
      "INFO: [2025-06-27 16:40:58] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:58] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:40:58] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  15%|‚ñà‚ñå        | 14/92 [00:21<02:03,  1.58s/it]INFO: [2025-06-27 16:40:58] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/18933828397346607/-1459031336310233984\n",
      "INFO: [2025-06-27 16:40:58] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:58] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:40:58] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:40:58] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/18933828397346607/-2649534700503586110\n",
      "INFO: [2025-06-27 16:40:58] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:58] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:40:59] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:40:59] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/18933828397346607/1018050502530135037\n",
      "INFO: [2025-06-27 16:40:59] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:59] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:40:59] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:40:59] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/18933828397346607/1854475919424245751\n",
      "INFO: [2025-06-27 16:40:59] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:59] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:40:59] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:40:59] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/18933828397346607/1437122857892217651\n",
      "INFO: [2025-06-27 16:40:59] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:40:59] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:00] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  16%|‚ñà‚ñã        | 15/92 [00:23<02:05,  1.63s/it]INFO: [2025-06-27 16:41:00] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/20978307744432241/-404441144855857833\n",
      "INFO: [2025-06-27 16:41:00] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:00] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:00] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:00] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/20978307744432241/-7599247568604731841\n",
      "INFO: [2025-06-27 16:41:00] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:00] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:01] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:01] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/20978307744432241/-4029103074837611889\n",
      "INFO: [2025-06-27 16:41:01] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:01] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:01] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:01] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/20978307744432241/8168334415053205230\n",
      "INFO: [2025-06-27 16:41:01] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:01] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:01] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:01] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/20978307744432241/7784733191871577424\n",
      "INFO: [2025-06-27 16:41:01] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:01] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:02] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  17%|‚ñà‚ñã        | 16/92 [00:25<02:08,  1.69s/it]INFO: [2025-06-27 16:41:02] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-35102576635162472/6308597682360572317\n",
      "INFO: [2025-06-27 16:41:02] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:02] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:02] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:02] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-35102576635162472/-5959531301477927791\n",
      "INFO: [2025-06-27 16:41:02] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:02] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:02] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:02] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-35102576635162472/-2069143464549335780\n",
      "INFO: [2025-06-27 16:41:02] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:02] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:03] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-35102576635162472/981652804965920531\n",
      "INFO: [2025-06-27 16:41:03] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:03] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:03] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:03] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-35102576635162472/7366507816412148205\n",
      "INFO: [2025-06-27 16:41:03] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:03] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:03] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  18%|‚ñà‚ñä        | 17/92 [00:26<02:03,  1.65s/it]INFO: [2025-06-27 16:41:03] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-7126418877828068/-8508424358657670021\n",
      "INFO: [2025-06-27 16:41:03] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:03] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:03] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:03] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-7126418877828068/-8498377039219930536\n",
      "INFO: [2025-06-27 16:41:03] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:03] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:04] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-7126418877828068/5548902811071695424\n",
      "INFO: [2025-06-27 16:41:04] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:04] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:04] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:04] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-7126418877828068/4546162344026363902\n",
      "INFO: [2025-06-27 16:41:04] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:04] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:04] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  20%|‚ñà‚ñâ        | 18/92 [00:27<01:55,  1.55s/it]INFO: [2025-06-27 16:41:04] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-19952367157294119/2562985927380474115\n",
      "INFO: [2025-06-27 16:41:04] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:04] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:05] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:05] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-19952367157294119/4967341891201213094\n",
      "INFO: [2025-06-27 16:41:05] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:05] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:05] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:05] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-19952367157294119/-5378179395054085145\n",
      "INFO: [2025-06-27 16:41:05] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:05] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:05] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:05] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-19952367157294119/3390836050203658972\n",
      "INFO: [2025-06-27 16:41:05] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:05] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:06] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:06] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-19952367157294119/-7068343234270138822\n",
      "INFO: [2025-06-27 16:41:06] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:06] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  21%|‚ñà‚ñà        | 19/92 [00:29<01:55,  1.58s/it]INFO: [2025-06-27 16:41:06] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-34105277816332298/-5559266694144991972\n",
      "INFO: [2025-06-27 16:41:06] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:06] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:06] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:06] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-34105277816332298/3954140072486804566\n",
      "INFO: [2025-06-27 16:41:06] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:06] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:07] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:07] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-34105277816332298/-2177969513087281108\n",
      "INFO: [2025-06-27 16:41:07] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:07] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:07] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:07] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-34105277816332298/6454371830264512612\n",
      "INFO: [2025-06-27 16:41:07] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:07] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:07] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:07] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-34105277816332298/-3296131406307922315\n",
      "INFO: [2025-06-27 16:41:07] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:07] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:08] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  22%|‚ñà‚ñà‚ñè       | 20/92 [00:31<01:54,  1.59s/it]INFO: [2025-06-27 16:41:08] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-25725881202629826/959844913786547811\n",
      "INFO: [2025-06-27 16:41:08] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:08] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:08] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:08] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-25725881202629826/-2484056816489324066\n",
      "INFO: [2025-06-27 16:41:08] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:08] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:08] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:08] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-25725881202629826/7150039753984863212\n",
      "INFO: [2025-06-27 16:41:08] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:08] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:09] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:09] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-25725881202629826/815401891292696997\n",
      "INFO: [2025-06-27 16:41:09] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:09] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:09] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-25725881202629826/-2274493842406966373\n",
      "INFO: [2025-06-27 16:41:09] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:09] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  23%|‚ñà‚ñà‚ñé       | 21/92 [00:32<01:52,  1.58s/it]INFO: [2025-06-27 16:41:09] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-2046863695546735/8874733314673183270\n",
      "INFO: [2025-06-27 16:41:09] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:09] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:10] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:10] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-2046863695546735/-990127862492828733\n",
      "INFO: [2025-06-27 16:41:10] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:10] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:10] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:10] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-2046863695546735/7914887876818812230\n",
      "INFO: [2025-06-27 16:41:10] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:10] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:10] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:10] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-2046863695546735/-1764083285352349992\n",
      "INFO: [2025-06-27 16:41:10] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:10] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:11] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:11] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-2046863695546735/-383589224486802827\n",
      "INFO: [2025-06-27 16:41:11] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:11] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:11] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  24%|‚ñà‚ñà‚ñç       | 22/92 [00:34<01:51,  1.60s/it]INFO: [2025-06-27 16:41:11] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/12631778325074772/3622062378040551526\n",
      "INFO: [2025-06-27 16:41:11] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:11] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:11] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:11] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/12631778325074772/-5660088039246376770\n",
      "INFO: [2025-06-27 16:41:11] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:11] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:11] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:11] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/12631778325074772/-6797821670496085910\n",
      "INFO: [2025-06-27 16:41:11] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:11] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:12] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:12] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/12631778325074772/1889856174591444054\n",
      "INFO: [2025-06-27 16:41:12] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:12] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:12] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:12] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/12631778325074772/2814719382815597820\n",
      "INFO: [2025-06-27 16:41:12] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:12] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:13] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  25%|‚ñà‚ñà‚ñå       | 23/92 [00:35<01:50,  1.61s/it]INFO: [2025-06-27 16:41:13] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-29122158203077245/4668168701668402186\n",
      "INFO: [2025-06-27 16:41:13] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:13] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:13] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:13] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-29122158203077245/-2005769166081712460\n",
      "INFO: [2025-06-27 16:41:13] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:13] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:13] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:13] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-29122158203077245/-7018996456395300040\n",
      "INFO: [2025-06-27 16:41:13] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:13] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:13] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:13] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-29122158203077245/-4554728706389556233\n",
      "INFO: [2025-06-27 16:41:13] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:13] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:14] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:14] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-29122158203077245/7928238699329657201\n",
      "INFO: [2025-06-27 16:41:14] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:14] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:14] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  26%|‚ñà‚ñà‚ñå       | 24/92 [00:37<01:44,  1.53s/it]INFO: [2025-06-27 16:41:14] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-22627892168184181/4032058879330639101\n",
      "INFO: [2025-06-27 16:41:14] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:14] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:14] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:14] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-22627892168184181/470173927382475785\n",
      "INFO: [2025-06-27 16:41:14] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:14] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:15] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:15] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-22627892168184181/-2625701155064160228\n",
      "INFO: [2025-06-27 16:41:15] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:15] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:15] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:15] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-22627892168184181/1111188242320460874\n",
      "INFO: [2025-06-27 16:41:15] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:15] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:15] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:15] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-22627892168184181/5950900051614206853\n",
      "INFO: [2025-06-27 16:41:15] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:15] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:15] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  27%|‚ñà‚ñà‚ñã       | 25/92 [00:38<01:40,  1.50s/it]INFO: [2025-06-27 16:41:15] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/28030974524863734/-3074741708453388847\n",
      "INFO: [2025-06-27 16:41:15] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:15] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:16] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/28030974524863734/-2726299984476970082\n",
      "INFO: [2025-06-27 16:41:16] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:16] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:16] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:16] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/28030974524863734/2035246656474436993\n",
      "INFO: [2025-06-27 16:41:16] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:16] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:16] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:16] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/28030974524863734/41096803244585387\n",
      "INFO: [2025-06-27 16:41:16] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:16] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:17] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:17] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/28030974524863734/-906639502994899913\n",
      "INFO: [2025-06-27 16:41:17] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:17] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:17] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  28%|‚ñà‚ñà‚ñä       | 26/92 [00:40<01:39,  1.51s/it]INFO: [2025-06-27 16:41:17] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-8639253709990781/-3246872346744851883\n",
      "INFO: [2025-06-27 16:41:17] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:17] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:17] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:17] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-8639253709990781/-4135230855856286337\n",
      "INFO: [2025-06-27 16:41:17] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:17] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:18] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:18] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-8639253709990781/-1938381138234820512\n",
      "INFO: [2025-06-27 16:41:18] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:18] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:18] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:18] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-8639253709990781/-6690632259270732649\n",
      "INFO: [2025-06-27 16:41:18] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:18] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:18] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:18] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-8639253709990781/2700726683991673132\n",
      "INFO: [2025-06-27 16:41:18] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:18] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:18] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  29%|‚ñà‚ñà‚ñâ       | 27/92 [00:41<01:37,  1.50s/it]INFO: [2025-06-27 16:41:18] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/33041281229298748/-2736425708469822029\n",
      "INFO: [2025-06-27 16:41:18] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:18] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:19] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:19] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/33041281229298748/6497020101194617171\n",
      "INFO: [2025-06-27 16:41:19] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:19] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:19] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:19] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/33041281229298748/3893490209951573235\n",
      "INFO: [2025-06-27 16:41:19] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:19] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:19] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:19] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/33041281229298748/1967083863833861440\n",
      "INFO: [2025-06-27 16:41:19] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:19] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:20] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:20] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/33041281229298748/6819001063288595490\n",
      "INFO: [2025-06-27 16:41:20] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:20] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:20] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  30%|‚ñà‚ñà‚ñà       | 28/92 [00:43<01:37,  1.53s/it]INFO: [2025-06-27 16:41:20] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-26780953604978411/-4250877145294801920\n",
      "INFO: [2025-06-27 16:41:20] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:20] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:20] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:20] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-26780953604978411/-4056295328900878257\n",
      "INFO: [2025-06-27 16:41:20] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:20] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:21] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:21] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-26780953604978411/-2100308078671207313\n",
      "INFO: [2025-06-27 16:41:21] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:21] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:21] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:21] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-26780953604978411/-2100308078671207313\n",
      "INFO: [2025-06-27 16:41:21] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:21] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:21] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:21] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-26780953604978411/-6591501306161014441\n",
      "INFO: [2025-06-27 16:41:21] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:21] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  32%|‚ñà‚ñà‚ñà‚ñè      | 29/92 [00:45<01:38,  1.56s/it]INFO: [2025-06-27 16:41:22] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-18949191324265795/-49564332575376769\n",
      "INFO: [2025-06-27 16:41:22] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:22] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:22] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:22] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-18949191324265795/3571334604632782089\n",
      "INFO: [2025-06-27 16:41:22] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:22] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:22] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:22] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-18949191324265795/3892932039053876148\n",
      "INFO: [2025-06-27 16:41:22] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:22] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:23] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:23] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-18949191324265795/-7412386992750855525\n",
      "INFO: [2025-06-27 16:41:23] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:23] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:23] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:23] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-18949191324265795/-7996588531648180442\n",
      "INFO: [2025-06-27 16:41:23] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:23] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:23] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  33%|‚ñà‚ñà‚ñà‚ñé      | 30/92 [00:46<01:35,  1.55s/it]INFO: [2025-06-27 16:41:23] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/1410763986151621/-5303531952248046704\n",
      "INFO: [2025-06-27 16:41:23] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:23] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:23] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:23] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/1410763986151621/-4676444358467089678\n",
      "INFO: [2025-06-27 16:41:23] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:23] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:24] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:24] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/1410763986151621/8563660454736324069\n",
      "INFO: [2025-06-27 16:41:24] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:24] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:24] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:24] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/1410763986151621/6008240046730494545\n",
      "INFO: [2025-06-27 16:41:24] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:24] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:24] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:24] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/1410763986151621/-957945175582104365\n",
      "INFO: [2025-06-27 16:41:24] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:24] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:25] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  34%|‚ñà‚ñà‚ñà‚ñé      | 31/92 [00:48<01:35,  1.56s/it]INFO: [2025-06-27 16:41:25] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/1739983631954371/-8909822612301210139\n",
      "INFO: [2025-06-27 16:41:25] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:25] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:25] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:25] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/1739983631954371/-1437531335538991507\n",
      "INFO: [2025-06-27 16:41:25] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:25] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:26] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:26] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/1739983631954371/-4724646644972343183\n",
      "INFO: [2025-06-27 16:41:26] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:26] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:26] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/1739983631954371/-1954372949916326066\n",
      "INFO: [2025-06-27 16:41:26] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:26] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:27] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/1739983631954371/407226705361777075\n",
      "INFO: [2025-06-27 16:41:27] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:27] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  35%|‚ñà‚ñà‚ñà‚ñç      | 32/92 [00:50<01:51,  1.85s/it]INFO: [2025-06-27 16:41:27] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/5895544448831150/6840415915550283452\n",
      "INFO: [2025-06-27 16:41:27] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:27] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:28] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:28] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/5895544448831150/4677892577581706602\n",
      "INFO: [2025-06-27 16:41:28] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:28] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:28] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/5895544448831150/-5678493114848982685\n",
      "INFO: [2025-06-27 16:41:28] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:28] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:29] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  36%|‚ñà‚ñà‚ñà‚ñå      | 33/92 [00:52<01:43,  1.75s/it]INFO: [2025-06-27 16:41:29] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/31202820582613161/1302862404895722931\n",
      "INFO: [2025-06-27 16:41:29] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:29] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:29] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:29] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/31202820582613161/-4710755148228645402\n",
      "INFO: [2025-06-27 16:41:29] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:29] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:29] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:29] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/31202820582613161/-7187469697580805303\n",
      "INFO: [2025-06-27 16:41:29] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:29] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:30] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:30] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/31202820582613161/1241460319809503127\n",
      "INFO: [2025-06-27 16:41:30] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:30] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:30] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:30] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/31202820582613161/7174666733000882265\n",
      "INFO: [2025-06-27 16:41:30] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:30] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:30] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  37%|‚ñà‚ñà‚ñà‚ñã      | 34/92 [00:53<01:39,  1.71s/it]INFO: [2025-06-27 16:41:30] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-35884737692158253/7359123353474896078\n",
      "INFO: [2025-06-27 16:41:30] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:30] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:31] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:31] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-35884737692158253/1059193101662654198\n",
      "INFO: [2025-06-27 16:41:31] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:31] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:31] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:31] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-35884737692158253/-851255063151224319\n",
      "INFO: [2025-06-27 16:41:31] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:31] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:31] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:31] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-35884737692158253/3301184237479273814\n",
      "INFO: [2025-06-27 16:41:31] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:31] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:32] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:32] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-35884737692158253/-6004749260235273668\n",
      "INFO: [2025-06-27 16:41:32] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:32] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:32] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  38%|‚ñà‚ñà‚ñà‚ñä      | 35/92 [00:55<01:33,  1.64s/it]INFO: [2025-06-27 16:41:32] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-34803309266443718/5580369426739380001\n",
      "INFO: [2025-06-27 16:41:32] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:32] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:32] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:32] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-34803309266443718/-6707805339997665826\n",
      "INFO: [2025-06-27 16:41:32] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:32] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:32] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:32] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-34803309266443718/3380995278001123487\n",
      "INFO: [2025-06-27 16:41:32] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:32] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:33] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:33] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-34803309266443718/1711775163034602511\n",
      "INFO: [2025-06-27 16:41:33] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:33] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:33] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:33] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-34803309266443718/8104683881023840410\n",
      "INFO: [2025-06-27 16:41:33] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:33] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  39%|‚ñà‚ñà‚ñà‚ñâ      | 36/92 [00:56<01:29,  1.60s/it]INFO: [2025-06-27 16:41:33] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-22499263970759753/623588335874424306\n",
      "INFO: [2025-06-27 16:41:33] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:33] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:34] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-22499263970759753/-8230480911474175565\n",
      "INFO: [2025-06-27 16:41:34] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:34] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:34] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:34] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-22499263970759753/4839793808578026488\n",
      "INFO: [2025-06-27 16:41:34] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:34] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:34] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-22499263970759753/-115069093920676335\n",
      "INFO: [2025-06-27 16:41:34] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:34] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:35] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-22499263970759753/-5945603415926029113\n",
      "INFO: [2025-06-27 16:41:35] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:35] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  40%|‚ñà‚ñà‚ñà‚ñà      | 37/92 [00:58<01:28,  1.60s/it]INFO: [2025-06-27 16:41:35] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-12988782223228843/8148382400078380983\n",
      "INFO: [2025-06-27 16:41:35] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:35] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:35] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-12988782223228843/-3157155389966910232\n",
      "INFO: [2025-06-27 16:41:35] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:35] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:35] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-12988782223228843/9148695508442837630\n",
      "INFO: [2025-06-27 16:41:35] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:35] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:36] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-12988782223228843/-6281577041156644526\n",
      "INFO: [2025-06-27 16:41:36] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:36] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:36] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-12988782223228843/-7639492274974046551\n",
      "INFO: [2025-06-27 16:41:36] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:36] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 38/92 [00:59<01:21,  1.51s/it]INFO: [2025-06-27 16:41:36] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-7666152121409895/-5116808700954080261\n",
      "INFO: [2025-06-27 16:41:36] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:36] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:37] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:37] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-7666152121409895/6926593929266073454\n",
      "INFO: [2025-06-27 16:41:37] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:37] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:37] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:37] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-7666152121409895/-4209305014920674025\n",
      "INFO: [2025-06-27 16:41:37] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:37] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:37] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:37] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-7666152121409895/4498186992857338885\n",
      "INFO: [2025-06-27 16:41:37] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:37] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:38] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:38] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-7666152121409895/-5284872250135265225\n",
      "INFO: [2025-06-27 16:41:38] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:38] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:38] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 39/92 [01:01<01:20,  1.53s/it]INFO: [2025-06-27 16:41:38] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/21634894993301822/-5655673465455323402\n",
      "INFO: [2025-06-27 16:41:38] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:38] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:38] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:38] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/21634894993301822/1225585874383749432\n",
      "INFO: [2025-06-27 16:41:38] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:38] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:38] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:38] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/21634894993301822/947202408938575961\n",
      "INFO: [2025-06-27 16:41:38] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:38] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:39] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/21634894993301822/-8754369783480511438\n",
      "INFO: [2025-06-27 16:41:39] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:39] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:39] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:39] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/21634894993301822/951277465173199171\n",
      "INFO: [2025-06-27 16:41:39] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:39] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 40/92 [01:02<01:21,  1.56s/it]INFO: [2025-06-27 16:41:39] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/34364657708684419/-2629993364031988682\n",
      "INFO: [2025-06-27 16:41:39] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:39] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:40] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/34364657708684419/-5121180977425523747\n",
      "INFO: [2025-06-27 16:41:40] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:40] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:40] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:40] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/34364657708684419/7667054288051095229\n",
      "INFO: [2025-06-27 16:41:40] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:40] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:40] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:40] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/34364657708684419/-4126053122944348706\n",
      "INFO: [2025-06-27 16:41:40] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:40] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:41] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:41] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/34364657708684419/-3727692884436244935\n",
      "INFO: [2025-06-27 16:41:41] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:41] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:41] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 41/92 [01:04<01:17,  1.52s/it]INFO: [2025-06-27 16:41:41] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/10262358575052520/5413288797231960807\n",
      "INFO: [2025-06-27 16:41:41] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:41] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:41] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:41] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/10262358575052520/6384894172824164400\n",
      "INFO: [2025-06-27 16:41:41] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:41] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:41] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:41] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/10262358575052520/-2026690185760046657\n",
      "INFO: [2025-06-27 16:41:41] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:41] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:42] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:42] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/10262358575052520/5193588747273290001\n",
      "INFO: [2025-06-27 16:41:42] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:42] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:42] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/10262358575052520/6384894172824164400\n",
      "INFO: [2025-06-27 16:41:42] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:42] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:42] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 42/92 [01:05<01:14,  1.49s/it]INFO: [2025-06-27 16:41:42] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/11111675784752136/-8333305609307516398\n",
      "INFO: [2025-06-27 16:41:42] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:42] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:42] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:42] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/11111675784752136/5350615363953520606\n",
      "INFO: [2025-06-27 16:41:42] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:42] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:43] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/11111675784752136/3350719506494207471\n",
      "INFO: [2025-06-27 16:41:43] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:43] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:43] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:43] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/11111675784752136/3461055843045518806\n",
      "INFO: [2025-06-27 16:41:43] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:43] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:43] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:43] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/11111675784752136/8348473771820280935\n",
      "INFO: [2025-06-27 16:41:43] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:43] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:44] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 43/92 [01:07<01:12,  1.47s/it]INFO: [2025-06-27 16:41:44] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/12642450547914707/3478868391458170278\n",
      "INFO: [2025-06-27 16:41:44] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:44] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:44] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:44] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/12642450547914707/2937249104658770404\n",
      "INFO: [2025-06-27 16:41:44] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:44] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:44] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:44] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/12642450547914707/-4863334710047129031\n",
      "INFO: [2025-06-27 16:41:44] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:44] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:45] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:45] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/12642450547914707/1968191420632676549\n",
      "INFO: [2025-06-27 16:41:45] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:45] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:45] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:45] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/12642450547914707/7620024638601426502\n",
      "INFO: [2025-06-27 16:41:45] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:45] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 44/92 [01:08<01:11,  1.50s/it]INFO: [2025-06-27 16:41:45] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/21893218624143108/573644746304192245\n",
      "INFO: [2025-06-27 16:41:45] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:45] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:46] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:46] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/21893218624143108/-4945713875907639718\n",
      "INFO: [2025-06-27 16:41:46] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:46] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:46] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:46] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/21893218624143108/7400069318801841774\n",
      "INFO: [2025-06-27 16:41:46] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:46] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:46] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:46] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/21893218624143108/3357630899287999218\n",
      "INFO: [2025-06-27 16:41:46] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:46] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:46] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:46] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/21893218624143108/-7327646880163051373\n",
      "INFO: [2025-06-27 16:41:46] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:46] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 45/92 [01:10<01:09,  1.48s/it]INFO: [2025-06-27 16:41:47] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-24316712102315887/2834571268812183428\n",
      "INFO: [2025-06-27 16:41:47] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:47] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:47] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:47] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-24316712102315887/3720793000583221964\n",
      "INFO: [2025-06-27 16:41:47] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:47] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:47] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:47] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-24316712102315887/5984152516802949451\n",
      "INFO: [2025-06-27 16:41:47] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:47] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:47] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:47] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-24316712102315887/-5150287373429888631\n",
      "INFO: [2025-06-27 16:41:47] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:47] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:48] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-24316712102315887/-8910198268186727635\n",
      "INFO: [2025-06-27 16:41:48] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:48] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:48] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 46/92 [01:11<01:08,  1.50s/it]INFO: [2025-06-27 16:41:48] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-23507181552861323/3510879047104264830\n",
      "INFO: [2025-06-27 16:41:48] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:48] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:48] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:48] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-23507181552861323/4137440517101656685\n",
      "INFO: [2025-06-27 16:41:48] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:48] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:49] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:49] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-23507181552861323/-8238821923278641850\n",
      "INFO: [2025-06-27 16:41:49] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:49] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:49] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-23507181552861323/6072207199438534637\n",
      "INFO: [2025-06-27 16:41:49] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:49] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:49] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:49] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-23507181552861323/-1262045258718203678\n",
      "INFO: [2025-06-27 16:41:49] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:49] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 47/92 [01:13<01:06,  1.48s/it]INFO: [2025-06-27 16:41:50] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-18152182327560480/-4341089490484079760\n",
      "INFO: [2025-06-27 16:41:50] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:50] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:50] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:50] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-18152182327560480/-2197564856973422755\n",
      "INFO: [2025-06-27 16:41:50] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:50] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:50] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-18152182327560480/1371242355701412014\n",
      "INFO: [2025-06-27 16:41:50] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:50] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:51] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:51] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-18152182327560480/-9126318783037784645\n",
      "INFO: [2025-06-27 16:41:51] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:51] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:51] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:51] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-18152182327560480/-2638948329676682937\n",
      "INFO: [2025-06-27 16:41:51] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:51] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:51] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 48/92 [01:14<01:05,  1.50s/it]INFO: [2025-06-27 16:41:51] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/21321689889868872/-3631827477176517536\n",
      "INFO: [2025-06-27 16:41:51] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:51] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:51] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:51] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/21321689889868872/4277189631399119518\n",
      "INFO: [2025-06-27 16:41:51] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:51] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:52] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:52] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/21321689889868872/-3029230678400443214\n",
      "INFO: [2025-06-27 16:41:52] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:52] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:52] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/21321689889868872/2513408173929564530\n",
      "INFO: [2025-06-27 16:41:52] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:52] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:52] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:52] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/21321689889868872/-2131663956400107588\n",
      "INFO: [2025-06-27 16:41:52] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:52] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:53] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 49/92 [01:16<01:04,  1.51s/it]INFO: [2025-06-27 16:41:53] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-12463996681673250/1001484088117419076\n",
      "INFO: [2025-06-27 16:41:53] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:53] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:53] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:53] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-12463996681673250/1208163505060035575\n",
      "INFO: [2025-06-27 16:41:53] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:53] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:53] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:53] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-12463996681673250/5809878820364426932\n",
      "INFO: [2025-06-27 16:41:53] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:53] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:54] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-12463996681673250/-4018071394199911570\n",
      "INFO: [2025-06-27 16:41:54] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:54] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:54] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 50/92 [01:17<01:00,  1.45s/it]INFO: [2025-06-27 16:41:54] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-2139820121868237/7174911214789188615\n",
      "INFO: [2025-06-27 16:41:54] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:54] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:54] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:54] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-2139820121868237/-3965648376808544436\n",
      "INFO: [2025-06-27 16:41:54] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:54] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:55] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-2139820121868237/9166163062695038631\n",
      "INFO: [2025-06-27 16:41:55] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:55] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:55] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:55] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-2139820121868237/-8809767266699174627\n",
      "INFO: [2025-06-27 16:41:55] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:55] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:55] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 51/92 [01:18<00:54,  1.33s/it]INFO: [2025-06-27 16:41:55] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-1083216214855434/1353217280393293418\n",
      "INFO: [2025-06-27 16:41:55] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:55] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:56] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-1083216214855434/-1961593601051792778\n",
      "INFO: [2025-06-27 16:41:56] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:56] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:56] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-1083216214855434/-8258993645454398472\n",
      "INFO: [2025-06-27 16:41:56] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:56] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:56] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:56] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-1083216214855434/-1435460781728290990\n",
      "INFO: [2025-06-27 16:41:56] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:56] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 52/92 [01:20<00:56,  1.41s/it]INFO: [2025-06-27 16:41:57] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/17131318242278983/1564341055827454194\n",
      "INFO: [2025-06-27 16:41:57] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:57] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:57] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:57] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/17131318242278983/6902031343714230598\n",
      "INFO: [2025-06-27 16:41:57] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:57] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:57] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/17131318242278983/7714819180289531073\n",
      "INFO: [2025-06-27 16:41:57] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:57] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:57] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:57] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/17131318242278983/4577407953817486235\n",
      "INFO: [2025-06-27 16:41:57] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:57] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:58] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 53/92 [01:21<00:54,  1.40s/it]INFO: [2025-06-27 16:41:58] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/20606471688970148/4584402743475666567\n",
      "INFO: [2025-06-27 16:41:58] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:58] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:58] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:58] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/20606471688970148/-4477833252834350399\n",
      "INFO: [2025-06-27 16:41:58] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:58] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:59] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:59] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/20606471688970148/2911353927501129219\n",
      "INFO: [2025-06-27 16:41:59] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:59] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:59] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:41:59] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/20606471688970148/6030815948872375181\n",
      "INFO: [2025-06-27 16:41:59] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:59] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 54/92 [01:22<00:49,  1.30s/it]INFO: [2025-06-27 16:41:59] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/24584688051044679/-3369816936700840932\n",
      "INFO: [2025-06-27 16:41:59] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:59] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:41:59] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/24584688051044679/6775015327379007916\n",
      "INFO: [2025-06-27 16:41:59] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:41:59] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:42:00] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/24584688051044679/-1798206033544741742\n",
      "INFO: [2025-06-27 16:42:00] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:00] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:42:00] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/24584688051044679/-2693608016918028982\n",
      "INFO: [2025-06-27 16:42:00] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:00] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:42:01] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 55/92 [01:24<00:49,  1.34s/it]INFO: [2025-06-27 16:42:01] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-25141892168903907/2842787141749613966\n",
      "INFO: [2025-06-27 16:42:01] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:01] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:42:01] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-25141892168903907/-6439376666594011464\n",
      "INFO: [2025-06-27 16:42:01] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:01] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:42:01] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:42:01] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-25141892168903907/-8903314523412236212\n",
      "INFO: [2025-06-27 16:42:01] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:01] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:42:01] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 56/92 [01:24<00:42,  1.17s/it]INFO: [2025-06-27 16:42:01] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-20439687097155111/1775209866093857310\n",
      "INFO: [2025-06-27 16:42:01] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:01] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:42:02] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:42:02] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-20439687097155111/7144522010287559589\n",
      "INFO: [2025-06-27 16:42:02] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:02] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:42:02] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:42:02] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-20439687097155111/8404126418433661645\n",
      "INFO: [2025-06-27 16:42:02] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:02] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:42:02] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 57/92 [01:25<00:38,  1.10s/it]INFO: [2025-06-27 16:42:02] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-15352348890731234/2611632168285154532\n",
      "INFO: [2025-06-27 16:42:02] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:02] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:42:02] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:42:02] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-15352348890731234/-2634502323142599163\n",
      "INFO: [2025-06-27 16:42:03] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:03] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:42:03] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:42:03] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-15352348890731234/1884060885835443568\n",
      "INFO: [2025-06-27 16:42:03] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:03] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:42:03] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 58/92 [01:26<00:34,  1.01s/it]INFO: [2025-06-27 16:42:03] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-4938783110044412/-9078285195640588986\n",
      "INFO: [2025-06-27 16:42:03] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:03] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:42:03] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:42:03] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-4938783110044412/4904932290730580929\n",
      "INFO: [2025-06-27 16:42:03] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:03] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:42:04] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:42:04] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-4938783110044412/1709325522002828324\n",
      "INFO: [2025-06-27 16:42:04] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:04] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 59/92 [01:27<00:34,  1.03s/it]INFO: [2025-06-27 16:42:04] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/17609986374660936/6955319964368225949\n",
      "INFO: [2025-06-27 16:42:04] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:04] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:42:04] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/17609986374660936/-2271101217331081907\n",
      "INFO: [2025-06-27 16:42:04] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:04] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:42:05] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:42:05] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/17609986374660936/-3284830607060838746\n",
      "INFO: [2025-06-27 16:42:05] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:05] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:42:05] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 60/92 [01:28<00:30,  1.05it/s]INFO: [2025-06-27 16:42:05] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/17681796354219824/1937655903082247767\n",
      "INFO: [2025-06-27 16:42:05] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:05] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:42:05] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/17681796354219824/4805165615096784855\n",
      "INFO: [2025-06-27 16:42:05] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:05] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:42:06] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/17681796354219824/3557359331496990844\n",
      "INFO: [2025-06-27 16:42:06] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:06] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:42:06] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 61/92 [01:29<00:30,  1.02it/s]INFO: [2025-06-27 16:42:06] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/35971629147007369/3934064133303539878\n",
      "INFO: [2025-06-27 16:42:06] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:06] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:42:06] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/35971629147007369/-76836233779723673\n",
      "INFO: [2025-06-27 16:42:06] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:06] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:42:06] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/35971629147007369/-5603215187459537893\n",
      "INFO: [2025-06-27 16:42:06] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:06] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 62/92 [01:30<00:30,  1.02s/it]INFO: [2025-06-27 16:42:07] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-29415098045592940/6411323736572457795\n",
      "INFO: [2025-06-27 16:42:07] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:07] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:42:07] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-29415098045592940/-1964285695976284026\n",
      "INFO: [2025-06-27 16:42:07] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:07] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:42:08] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 63/92 [01:31<00:25,  1.14it/s]INFO: [2025-06-27 16:42:08] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-28031656773092240/-8110188940058236355\n",
      "INFO: [2025-06-27 16:42:08] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:08] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:42:08] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-28031656773092240/7195142021001911519\n",
      "INFO: [2025-06-27 16:42:08] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:08] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 64/92 [01:31<00:21,  1.30it/s]INFO: [2025-06-27 16:42:08] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-22849205778179846/-8283104409014302301\n",
      "INFO: [2025-06-27 16:42:08] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:08] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:42:08] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-22849205778179846/4313876108651469704\n",
      "INFO: [2025-06-27 16:42:08] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:08] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:42:09] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 65/92 [01:32<00:20,  1.29it/s]INFO: [2025-06-27 16:42:09] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-18031556530033893/-8627777469347266434\n",
      "INFO: [2025-06-27 16:42:09] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:09] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:42:09] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-18031556530033893/-5274756934146961381\n",
      "INFO: [2025-06-27 16:42:09] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:09] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:42:09] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 66/92 [01:32<00:18,  1.40it/s]INFO: [2025-06-27 16:42:09] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-13505886640472175/-5016407656743507623\n",
      "INFO: [2025-06-27 16:42:09] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:09] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:42:10] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "INFO: [2025-06-27 16:42:10] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-13505886640472175/5466843209844404034\n",
      "INFO: [2025-06-27 16:42:10] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:10] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 67/92 [01:33<00:16,  1.52it/s]INFO: [2025-06-27 16:42:10] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-6735076600090236/6255694963833004319\n",
      "INFO: [2025-06-27 16:42:10] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:10] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 68/92 [01:33<00:14,  1.67it/s]INFO: [2025-06-27 16:42:10] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-3409159551394617/-1175751077694116458\n",
      "INFO: [2025-06-27 16:42:10] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:10] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:42:11] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-3409159551394617/-925249975991770452\n",
      "INFO: [2025-06-27 16:42:11] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:11] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:42:11] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 69/92 [01:34<00:13,  1.72it/s]INFO: [2025-06-27 16:42:11] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-2069452773758641/-8073980649127594574\n",
      "INFO: [2025-06-27 16:42:11] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:11] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:42:11] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-2069452773758641/-8385030890674185701\n",
      "INFO: [2025-06-27 16:42:11] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:11] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:42:12] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 70/92 [01:35<00:12,  1.76it/s]INFO: [2025-06-27 16:42:12] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/3297979118605018/2121973381815758809\n",
      "INFO: [2025-06-27 16:42:12] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:12] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:42:12] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/3297979118605018/-7629863625189970605\n",
      "INFO: [2025-06-27 16:42:12] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:12] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:42:12] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 71/92 [01:35<00:13,  1.57it/s]INFO: [2025-06-27 16:42:12] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/10757094666506670/2521158598917791125\n",
      "INFO: [2025-06-27 16:42:12] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:12] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:42:13] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/10757094666506670/2049223786216519273\n",
      "INFO: [2025-06-27 16:42:13] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:13] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:42:13] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 72/92 [01:36<00:12,  1.66it/s]INFO: [2025-06-27 16:42:13] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/14377716460635733/224067156940651406\n",
      "INFO: [2025-06-27 16:42:13] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:13] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:42:13] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/14377716460635733/6494760830414415628\n",
      "INFO: [2025-06-27 16:42:13] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:13] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 73/92 [01:37<00:12,  1.55it/s]INFO: [2025-06-27 16:42:14] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-33852347582520392/-1730356740998679943\n",
      "INFO: [2025-06-27 16:42:14] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:14] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 74/92 [01:37<00:09,  1.87it/s]INFO: [2025-06-27 16:42:14] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-25655970173329808/825366547021190712\n",
      "INFO: [2025-06-27 16:42:14] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:14] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 75/92 [01:37<00:07,  2.21it/s]INFO: [2025-06-27 16:42:14] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-22061102960387551/-8905627793055248873\n",
      "INFO: [2025-06-27 16:42:14] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:14] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 76/92 [01:37<00:06,  2.52it/s]INFO: [2025-06-27 16:42:14] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-20155356540515066/1617558396579091168\n",
      "INFO: [2025-06-27 16:42:14] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:14] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 77/92 [01:38<00:05,  2.81it/s]INFO: [2025-06-27 16:42:15] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-14117628316152430/3708495649437002708\n",
      "INFO: [2025-06-27 16:42:15] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:15] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 78/92 [01:38<00:05,  2.37it/s]INFO: [2025-06-27 16:42:15] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-11019131917628364/-7716517932206651477\n",
      "INFO: [2025-06-27 16:42:15] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:15] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 79/92 [01:38<00:04,  2.63it/s]INFO: [2025-06-27 16:42:16] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-10444363735373102/5157584201604396827\n",
      "INFO: [2025-06-27 16:42:16] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:16] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 80/92 [01:39<00:04,  2.91it/s]INFO: [2025-06-27 16:42:16] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-10033945991593843/-8343780824465910733\n",
      "INFO: [2025-06-27 16:42:16] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:16] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 81/92 [01:39<00:03,  3.11it/s]INFO: [2025-06-27 16:42:16] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-184811282650788/7459276384007237512\n",
      "INFO: [2025-06-27 16:42:16] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:16] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 82/92 [01:39<00:03,  3.29it/s]INFO: [2025-06-27 16:42:16] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/5566930627431303/-5089293816558006420\n",
      "INFO: [2025-06-27 16:42:16] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:16] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:42:17] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 83/92 [01:40<00:03,  2.61it/s]INFO: [2025-06-27 16:42:17] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/5609203557180661/-7281660177572507763\n",
      "INFO: [2025-06-27 16:42:17] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:17] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 84/92 [01:40<00:02,  2.87it/s]INFO: [2025-06-27 16:42:17] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/15133418971654738/7647822926109152780\n",
      "INFO: [2025-06-27 16:42:17] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:17] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 85/92 [01:40<00:02,  3.07it/s]INFO: [2025-06-27 16:42:17] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/15568847793479266/-4907848724437537709\n",
      "INFO: [2025-06-27 16:42:17] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:17] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 86/92 [01:41<00:01,  3.16it/s]INFO: [2025-06-27 16:42:18] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/17470512188912087/430810044304398948\n",
      "INFO: [2025-06-27 16:42:18] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:18] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 87/92 [01:41<00:01,  3.30it/s]INFO: [2025-06-27 16:42:18] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/18334778860223615/-7462221171272857117\n",
      "INFO: [2025-06-27 16:42:18] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:18] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 88/92 [01:41<00:01,  2.70it/s]INFO: [2025-06-27 16:42:19] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/19367730649708653/-4042641636918889097\n",
      "INFO: [2025-06-27 16:42:19] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:19] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 89/92 [01:42<00:01,  2.83it/s]INFO: [2025-06-27 16:42:19] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/30634204597194783/-5259171881687072106\n",
      "INFO: [2025-06-27 16:42:19] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:19] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 90/92 [01:42<00:00,  3.04it/s]INFO: [2025-06-27 16:42:19] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/30759839524016550/-3386398509503978146\n",
      "INFO: [2025-06-27 16:42:19] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:19] indra.sources.indra_db_rest.util - data: None\n",
      "INFO: [2025-06-27 16:42:19] indra_gpt.chat_curate.eval - Error processing evidence curation: list index out of rangeskipping this curation\n",
      "Processing LLM curations:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 91/92 [01:42<00:00,  3.24it/s]INFO: [2025-06-27 16:42:19] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/31420388280123621/126985844909369330\n",
      "INFO: [2025-06-27 16:42:19] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:19] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 92/92 [01:43<00:00,  1.12s/it]\n",
      "Processing LLM curations:   0%|          | 0/92 [00:00<?, ?it/s]INFO: [2025-06-27 16:42:20] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-35882458128194165\n",
      "INFO: [2025-06-27 16:42:20] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:20] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:   1%|          | 1/92 [00:00<00:47,  1.93it/s]INFO: [2025-06-27 16:42:20] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/31160008118740626\n",
      "INFO: [2025-06-27 16:42:20] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:20] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:   2%|‚ñè         | 2/92 [00:00<00:33,  2.65it/s]INFO: [2025-06-27 16:42:20] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/33874939274212480\n",
      "INFO: [2025-06-27 16:42:20] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:20] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:   3%|‚ñé         | 3/92 [00:01<00:29,  3.00it/s]INFO: [2025-06-27 16:42:21] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-32399727139857751\n",
      "INFO: [2025-06-27 16:42:21] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:21] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:   4%|‚ñç         | 4/92 [00:01<00:27,  3.20it/s]INFO: [2025-06-27 16:42:21] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/9371935612488149\n",
      "INFO: [2025-06-27 16:42:21] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:21] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:   5%|‚ñå         | 5/92 [00:01<00:25,  3.40it/s]INFO: [2025-06-27 16:42:21] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/3246604237187558\n",
      "INFO: [2025-06-27 16:42:21] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:21] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:   7%|‚ñã         | 6/92 [00:02<00:30,  2.82it/s]INFO: [2025-06-27 16:42:22] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/9130628937861941\n",
      "INFO: [2025-06-27 16:42:22] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:22] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:   8%|‚ñä         | 7/92 [00:02<00:27,  3.14it/s]INFO: [2025-06-27 16:42:22] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/19706388665464256\n",
      "INFO: [2025-06-27 16:42:22] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:22] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:   9%|‚ñä         | 8/92 [00:02<00:25,  3.35it/s]INFO: [2025-06-27 16:42:22] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-14556452501867428\n",
      "INFO: [2025-06-27 16:42:22] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:22] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  10%|‚ñâ         | 9/92 [00:02<00:23,  3.48it/s]INFO: [2025-06-27 16:42:22] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/15114781201446083\n",
      "INFO: [2025-06-27 16:42:22] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:22] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  11%|‚ñà         | 10/92 [00:03<00:22,  3.59it/s]INFO: [2025-06-27 16:42:23] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/13290267870654994\n",
      "INFO: [2025-06-27 16:42:23] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:23] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  12%|‚ñà‚ñè        | 11/92 [00:03<00:27,  2.94it/s]INFO: [2025-06-27 16:42:23] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/30902335548899281\n",
      "INFO: [2025-06-27 16:42:23] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:23] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  13%|‚ñà‚ñé        | 12/92 [00:03<00:25,  3.15it/s]INFO: [2025-06-27 16:42:23] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/2135209076854093\n",
      "INFO: [2025-06-27 16:42:23] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:23] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  14%|‚ñà‚ñç        | 13/92 [00:04<00:23,  3.33it/s]INFO: [2025-06-27 16:42:24] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-18387380848780476\n",
      "INFO: [2025-06-27 16:42:24] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:24] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  15%|‚ñà‚ñå        | 14/92 [00:04<00:22,  3.43it/s]INFO: [2025-06-27 16:42:24] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/18933828397346607\n",
      "INFO: [2025-06-27 16:42:24] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:24] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  16%|‚ñà‚ñã        | 15/92 [00:04<00:21,  3.55it/s]INFO: [2025-06-27 16:42:24] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/20978307744432241\n",
      "INFO: [2025-06-27 16:42:24] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:24] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  17%|‚ñà‚ñã        | 16/92 [00:05<00:25,  2.94it/s]INFO: [2025-06-27 16:42:25] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-35102576635162472\n",
      "INFO: [2025-06-27 16:42:25] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:25] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  18%|‚ñà‚ñä        | 17/92 [00:05<00:23,  3.15it/s]INFO: [2025-06-27 16:42:25] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-7126418877828068\n",
      "INFO: [2025-06-27 16:42:25] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:25] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  20%|‚ñà‚ñâ        | 18/92 [00:05<00:22,  3.32it/s]INFO: [2025-06-27 16:42:25] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-19952367157294119\n",
      "INFO: [2025-06-27 16:42:25] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:25] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  21%|‚ñà‚ñà        | 19/92 [00:05<00:20,  3.49it/s]INFO: [2025-06-27 16:42:26] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-34105277816332298\n",
      "INFO: [2025-06-27 16:42:26] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:26] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  22%|‚ñà‚ñà‚ñè       | 20/92 [00:06<00:20,  3.58it/s]INFO: [2025-06-27 16:42:26] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-25725881202629826\n",
      "INFO: [2025-06-27 16:42:26] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:26] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  23%|‚ñà‚ñà‚ñé       | 21/92 [00:06<00:22,  3.13it/s]INFO: [2025-06-27 16:42:26] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-2046863695546735\n",
      "INFO: [2025-06-27 16:42:26] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:26] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  24%|‚ñà‚ñà‚ñç       | 22/92 [00:06<00:21,  3.32it/s]INFO: [2025-06-27 16:42:26] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/12631778325074772\n",
      "INFO: [2025-06-27 16:42:26] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:26] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  25%|‚ñà‚ñà‚ñå       | 23/92 [00:07<00:19,  3.52it/s]INFO: [2025-06-27 16:42:27] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-29122158203077245\n",
      "INFO: [2025-06-27 16:42:27] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:27] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  26%|‚ñà‚ñà‚ñå       | 24/92 [00:07<00:19,  3.57it/s]INFO: [2025-06-27 16:42:27] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-22627892168184181\n",
      "INFO: [2025-06-27 16:42:27] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:27] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  27%|‚ñà‚ñà‚ñã       | 25/92 [00:07<00:24,  2.79it/s]INFO: [2025-06-27 16:42:28] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/28030974524863734\n",
      "INFO: [2025-06-27 16:42:28] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:28] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  28%|‚ñà‚ñà‚ñä       | 26/92 [00:08<00:21,  3.04it/s]INFO: [2025-06-27 16:42:28] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-8639253709990781\n",
      "INFO: [2025-06-27 16:42:28] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:28] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  29%|‚ñà‚ñà‚ñâ       | 27/92 [00:08<00:26,  2.48it/s]INFO: [2025-06-27 16:42:28] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/33041281229298748\n",
      "INFO: [2025-06-27 16:42:28] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:28] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  30%|‚ñà‚ñà‚ñà       | 28/92 [00:09<00:23,  2.75it/s]INFO: [2025-06-27 16:42:29] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-26780953604978411\n",
      "INFO: [2025-06-27 16:42:29] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:29] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  32%|‚ñà‚ñà‚ñà‚ñè      | 29/92 [00:09<00:21,  2.97it/s]INFO: [2025-06-27 16:42:29] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-18949191324265795\n",
      "INFO: [2025-06-27 16:42:29] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:29] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  33%|‚ñà‚ñà‚ñà‚ñé      | 30/92 [00:09<00:19,  3.14it/s]INFO: [2025-06-27 16:42:29] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/1410763986151621\n",
      "INFO: [2025-06-27 16:42:29] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:29] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  34%|‚ñà‚ñà‚ñà‚ñé      | 31/92 [00:09<00:18,  3.32it/s]INFO: [2025-06-27 16:42:29] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/1739983631954371\n",
      "INFO: [2025-06-27 16:42:29] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:29] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  35%|‚ñà‚ñà‚ñà‚ñç      | 32/92 [00:10<00:21,  2.76it/s]INFO: [2025-06-27 16:42:30] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/5895544448831150\n",
      "INFO: [2025-06-27 16:42:30] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:30] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  36%|‚ñà‚ñà‚ñà‚ñå      | 33/92 [00:10<00:19,  3.01it/s]INFO: [2025-06-27 16:42:30] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/31202820582613161\n",
      "INFO: [2025-06-27 16:42:30] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:30] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  37%|‚ñà‚ñà‚ñà‚ñã      | 34/92 [00:10<00:18,  3.19it/s]INFO: [2025-06-27 16:42:30] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-35884737692158253\n",
      "INFO: [2025-06-27 16:42:30] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:30] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  38%|‚ñà‚ñà‚ñà‚ñä      | 35/92 [00:11<00:17,  3.32it/s]INFO: [2025-06-27 16:42:31] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-34803309266443718\n",
      "INFO: [2025-06-27 16:42:31] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:31] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  39%|‚ñà‚ñà‚ñà‚ñâ      | 36/92 [00:11<00:19,  2.88it/s]INFO: [2025-06-27 16:42:31] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-22499263970759753\n",
      "INFO: [2025-06-27 16:42:31] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:31] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  40%|‚ñà‚ñà‚ñà‚ñà      | 37/92 [00:11<00:17,  3.12it/s]INFO: [2025-06-27 16:42:31] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-12988782223228843\n",
      "INFO: [2025-06-27 16:42:31] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:31] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 38/92 [00:12<00:15,  3.38it/s]INFO: [2025-06-27 16:42:32] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-7666152121409895\n",
      "INFO: [2025-06-27 16:42:32] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:32] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 39/92 [00:12<00:14,  3.55it/s]INFO: [2025-06-27 16:42:32] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/21634894993301822\n",
      "INFO: [2025-06-27 16:42:32] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:32] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 40/92 [00:12<00:14,  3.58it/s]INFO: [2025-06-27 16:42:32] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/34364657708684419\n",
      "INFO: [2025-06-27 16:42:32] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:32] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 41/92 [00:12<00:13,  3.71it/s]INFO: [2025-06-27 16:42:32] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/10262358575052520\n",
      "INFO: [2025-06-27 16:42:32] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:32] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 42/92 [00:13<00:13,  3.81it/s]INFO: [2025-06-27 16:42:33] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/11111675784752136\n",
      "INFO: [2025-06-27 16:42:33] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:33] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 43/92 [00:13<00:15,  3.26it/s]INFO: [2025-06-27 16:42:33] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/12642450547914707\n",
      "INFO: [2025-06-27 16:42:33] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:33] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 44/92 [00:13<00:13,  3.50it/s]INFO: [2025-06-27 16:42:33] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/21893218624143108\n",
      "INFO: [2025-06-27 16:42:33] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:33] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 45/92 [00:14<00:13,  3.52it/s]INFO: [2025-06-27 16:42:34] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-24316712102315887\n",
      "INFO: [2025-06-27 16:42:34] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:34] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 46/92 [00:14<00:16,  2.78it/s]INFO: [2025-06-27 16:42:34] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-23507181552861323\n",
      "INFO: [2025-06-27 16:42:34] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:34] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 47/92 [00:14<00:14,  3.02it/s]INFO: [2025-06-27 16:42:34] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-18152182327560480\n",
      "INFO: [2025-06-27 16:42:34] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:34] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 48/92 [00:15<00:13,  3.18it/s]INFO: [2025-06-27 16:42:35] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/21321689889868872\n",
      "INFO: [2025-06-27 16:42:35] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:35] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 49/92 [00:15<00:13,  3.27it/s]INFO: [2025-06-27 16:42:35] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-12463996681673250\n",
      "INFO: [2025-06-27 16:42:35] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:35] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 50/92 [00:15<00:12,  3.43it/s]INFO: [2025-06-27 16:42:35] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-2139820121868237\n",
      "INFO: [2025-06-27 16:42:35] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:35] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 51/92 [00:16<00:15,  2.71it/s]INFO: [2025-06-27 16:42:36] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-1083216214855434\n",
      "INFO: [2025-06-27 16:42:36] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:36] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 52/92 [00:16<00:13,  2.94it/s]INFO: [2025-06-27 16:42:36] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/17131318242278983\n",
      "INFO: [2025-06-27 16:42:36] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:36] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 53/92 [00:16<00:12,  3.09it/s]INFO: [2025-06-27 16:42:36] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/20606471688970148\n",
      "INFO: [2025-06-27 16:42:36] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:36] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 54/92 [00:17<00:11,  3.26it/s]INFO: [2025-06-27 16:42:37] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/24584688051044679\n",
      "INFO: [2025-06-27 16:42:37] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:37] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 55/92 [00:17<00:10,  3.42it/s]INFO: [2025-06-27 16:42:37] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-25141892168903907\n",
      "INFO: [2025-06-27 16:42:37] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:37] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 56/92 [00:17<00:13,  2.70it/s]INFO: [2025-06-27 16:42:37] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-20439687097155111\n",
      "INFO: [2025-06-27 16:42:37] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:37] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 57/92 [00:18<00:11,  2.98it/s]INFO: [2025-06-27 16:42:38] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-15352348890731234\n",
      "INFO: [2025-06-27 16:42:38] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:38] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 58/92 [00:18<00:10,  3.18it/s]INFO: [2025-06-27 16:42:38] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-4938783110044412\n",
      "INFO: [2025-06-27 16:42:38] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:38] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 59/92 [00:18<00:09,  3.39it/s]INFO: [2025-06-27 16:42:38] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/17609986374660936\n",
      "INFO: [2025-06-27 16:42:38] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:38] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 60/92 [00:18<00:09,  3.52it/s]INFO: [2025-06-27 16:42:38] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/17681796354219824\n",
      "INFO: [2025-06-27 16:42:38] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:38] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 61/92 [00:19<00:10,  2.84it/s]INFO: [2025-06-27 16:42:39] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/35971629147007369\n",
      "INFO: [2025-06-27 16:42:39] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:39] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 62/92 [00:19<00:09,  3.13it/s]INFO: [2025-06-27 16:42:39] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-29415098045592940\n",
      "INFO: [2025-06-27 16:42:39] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:39] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 63/92 [00:19<00:08,  3.30it/s]INFO: [2025-06-27 16:42:40] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-28031656773092240\n",
      "INFO: [2025-06-27 16:42:40] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:40] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 64/92 [00:20<00:08,  3.46it/s]INFO: [2025-06-27 16:42:40] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-22849205778179846\n",
      "INFO: [2025-06-27 16:42:40] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:40] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 65/92 [00:20<00:07,  3.62it/s]INFO: [2025-06-27 16:42:40] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-18031556530033893\n",
      "INFO: [2025-06-27 16:42:40] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:40] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 66/92 [00:20<00:07,  3.69it/s]INFO: [2025-06-27 16:42:40] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-13505886640472175\n",
      "INFO: [2025-06-27 16:42:40] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:40] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 67/92 [00:21<00:08,  3.03it/s]INFO: [2025-06-27 16:42:41] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-6735076600090236\n",
      "INFO: [2025-06-27 16:42:41] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:41] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 68/92 [00:21<00:07,  3.32it/s]INFO: [2025-06-27 16:42:41] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-3409159551394617\n",
      "INFO: [2025-06-27 16:42:41] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:41] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 69/92 [00:21<00:06,  3.45it/s]INFO: [2025-06-27 16:42:41] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-2069452773758641\n",
      "INFO: [2025-06-27 16:42:41] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:41] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 70/92 [00:21<00:06,  3.46it/s]INFO: [2025-06-27 16:42:42] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/3297979118605018\n",
      "INFO: [2025-06-27 16:42:42] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:42] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 71/92 [00:22<00:06,  3.50it/s]INFO: [2025-06-27 16:42:42] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/10757094666506670\n",
      "INFO: [2025-06-27 16:42:42] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:42] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 72/92 [00:22<00:07,  2.82it/s]INFO: [2025-06-27 16:42:42] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/14377716460635733\n",
      "INFO: [2025-06-27 16:42:42] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:42] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 73/92 [00:22<00:06,  3.01it/s]INFO: [2025-06-27 16:42:43] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-33852347582520392\n",
      "INFO: [2025-06-27 16:42:43] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:43] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 74/92 [00:23<00:05,  3.21it/s]INFO: [2025-06-27 16:42:43] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-25655970173329808\n",
      "INFO: [2025-06-27 16:42:43] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:43] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 75/92 [00:23<00:05,  3.32it/s]INFO: [2025-06-27 16:42:43] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-22061102960387551\n",
      "INFO: [2025-06-27 16:42:43] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:43] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 76/92 [00:23<00:04,  3.43it/s]INFO: [2025-06-27 16:42:43] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-20155356540515066\n",
      "INFO: [2025-06-27 16:42:43] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:43] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 77/92 [00:24<00:05,  2.81it/s]INFO: [2025-06-27 16:42:44] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-14117628316152430\n",
      "INFO: [2025-06-27 16:42:44] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:44] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 78/92 [00:24<00:04,  3.01it/s]INFO: [2025-06-27 16:42:44] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-11019131917628364\n",
      "INFO: [2025-06-27 16:42:44] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:44] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 79/92 [00:24<00:04,  3.23it/s]INFO: [2025-06-27 16:42:44] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-10444363735373102\n",
      "INFO: [2025-06-27 16:42:44] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:44] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 80/92 [00:25<00:03,  3.30it/s]INFO: [2025-06-27 16:42:45] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-10033945991593843\n",
      "INFO: [2025-06-27 16:42:45] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:45] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 81/92 [00:25<00:03,  3.49it/s]INFO: [2025-06-27 16:42:45] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/-184811282650788\n",
      "INFO: [2025-06-27 16:42:45] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:45] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 82/92 [00:25<00:03,  2.69it/s]INFO: [2025-06-27 16:42:46] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/5566930627431303\n",
      "INFO: [2025-06-27 16:42:46] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:46] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 83/92 [00:26<00:03,  2.96it/s]INFO: [2025-06-27 16:42:46] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/5609203557180661\n",
      "INFO: [2025-06-27 16:42:46] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:46] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 84/92 [00:26<00:02,  3.19it/s]INFO: [2025-06-27 16:42:46] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/15133418971654738\n",
      "INFO: [2025-06-27 16:42:46] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:46] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 85/92 [00:26<00:02,  3.38it/s]INFO: [2025-06-27 16:42:46] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/15568847793479266\n",
      "INFO: [2025-06-27 16:42:46] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:46] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 86/92 [00:26<00:01,  3.39it/s]INFO: [2025-06-27 16:42:47] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/17470512188912087\n",
      "INFO: [2025-06-27 16:42:47] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:47] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 87/92 [00:27<00:01,  2.64it/s]INFO: [2025-06-27 16:42:47] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/18334778860223615\n",
      "INFO: [2025-06-27 16:42:47] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:47] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 88/92 [00:27<00:01,  2.92it/s]INFO: [2025-06-27 16:42:47] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/19367730649708653\n",
      "INFO: [2025-06-27 16:42:47] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:47] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 89/92 [00:28<00:00,  3.14it/s]INFO: [2025-06-27 16:42:48] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/30634204597194783\n",
      "INFO: [2025-06-27 16:42:48] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:48] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 90/92 [00:28<00:00,  3.31it/s]INFO: [2025-06-27 16:42:48] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/30759839524016550\n",
      "INFO: [2025-06-27 16:42:48] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:48] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 91/92 [00:28<00:00,  3.43it/s]INFO: [2025-06-27 16:42:48] indra.sources.indra_db_rest.util - query: https://db.indra.bio/curation/list/31420388280123621\n",
      "INFO: [2025-06-27 16:42:48] indra.sources.indra_db_rest.util - params: {'api_key': '[api-key]'}\n",
      "INFO: [2025-06-27 16:42:48] indra.sources.indra_db_rest.util - data: None\n",
      "Processing LLM curations: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 92/92 [00:29<00:00,  3.16it/s]\n"
     ]
    }
   ],
   "source": [
    "for model in ['gpt-4o-mini', 'gpt-4o']:\n",
    "    with open(RESULTS_DIR / model / \"chat_curation_binary_classification.json\", \"r\") as f:\n",
    "        chat_curation_binary_classification = json.load(f)\n",
    "    with open(RESULTS_DIR / model / \"chat_curation_multiclass_classification.json\", \"r\") as f:\n",
    "        chat_curation_multiclass_classification = json.load(f)\n",
    "\n",
    "    eval_stmt_ev_pair_binary = curation_statement_evidence_pair_comparison_json(chat_curation_binary_classification)\n",
    "    with open(RESULTS_DIR / model / \"eval_stmt_ev_pair_chat_curation_binary_classification.json\", \"w\") as f:\n",
    "        json.dump(eval_stmt_ev_pair_binary, f, indent=2)\n",
    "\n",
    "    eval_stmt_binary = curation_statement_comparison_json(chat_curation_binary_classification)\n",
    "    with open(RESULTS_DIR / model / \"eval_stmt_chat_curation_binary_classification.json\", \"w\") as f:\n",
    "        json.dump(eval_stmt_binary, f, indent=2)\n",
    "\n",
    "    eval_stmt_ev_pair_multi = curation_statement_evidence_pair_comparison_json(chat_curation_multiclass_classification)\n",
    "    with open(RESULTS_DIR / model / \"eval_stmt_ev_pair_chat_curation_multiclass_classification.json\", \"w\") as f:\n",
    "        json.dump(eval_stmt_ev_pair_multi, f, indent=2)\n",
    "\n",
    "    eval_stmt_multi = curation_statement_comparison_json(chat_curation_multiclass_classification)\n",
    "    with open(RESULTS_DIR / model / \"eval_stmt_chat_curation_multiclass_classification.json\", \"w\") as f:\n",
    "        json.dump(eval_stmt_multi, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef96cc00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: gpt-4o-mini\n",
      "binary_classification - Accuracy: 0.7065\n",
      "multiclass_classification - Accuracy: 0.5870\n",
      "Model: gpt-4o\n",
      "binary_classification - Accuracy: 0.7500\n",
      "multiclass_classification - Accuracy: 0.7174\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "for model in ['gpt-4o-mini', 'gpt-4o']:\n",
    "    print(f\"Model: {model}\")\n",
    "    for eval_strat in ['binary_classification', 'multiclass_classification']:\n",
    "        with open(RESULTS_DIR / model / f\"eval_stmt_chat_curation_{eval_strat}.json\", \"r\") as f:\n",
    "            res = json.load(f)\n",
    "        preds = [res_item['llm_overall_prediction'] for res_item in res]\n",
    "        labels = [res_item['indra_curation'] for res_item in res]\n",
    "        acc = accuracy_score(labels, preds)\n",
    "        print(f\"{eval_strat} - Accuracy: {acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cba7065e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import confusion_matrix\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "\n",
    "# # Extract tags\n",
    "# tags = [c['tag'] for c in curation_comp_json]\n",
    "# predicted_tags = [c['predicted_tag'] for c in curation_comp_json]\n",
    "\n",
    "# # Compute accuracy\n",
    "# accuracy = np.mean([t == p for t, p in zip(tags, predicted_tags)])\n",
    "# accuracy_bin = np.mean([t == p or (t != 'correct' and p == 'incorrect') for t, p in zip(tags, predicted_tags)])\n",
    "# print(f\"Accuracy: {accuracy:.2%}\")\n",
    "# print(f\"Binary Accuracy: {accuracy_bin:.2%}\")\n",
    "\n",
    "# # Define tag label set\n",
    "# tag_set = list(set(tags).union(set(predicted_tags)))\n",
    "\n",
    "# # Compute confusion matrix\n",
    "# cm = confusion_matrix(tags, predicted_tags, labels=tag_set)\n",
    "# cm_df = pd.DataFrame(cm, index=tag_set, columns=tag_set)\n",
    "\n",
    "# # Plot\n",
    "# plt.figure(figsize=(12, 10))\n",
    "# sns.heatmap(cm_df, annot=True, fmt='d', cmap='Blues', cbar=True, linewidths=0.5)\n",
    "# plt.title(\"Confusion Matrix (Binary Classification - Model only predicts 'correct' or 'incorrect')\")\n",
    "# plt.xlabel(\"Predicted Label\")\n",
    "# plt.ylabel(\"True Label\")\n",
    "# plt.xticks(rotation=45, ha='right')\n",
    "# plt.yticks(rotation=0)\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a26fae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "indra_gpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
